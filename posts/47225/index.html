<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>CUDA编程——执行模型 - 亦初</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="亦初"><meta name="msapplication-TileImage" content="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="亦初"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由"><meta property="og:type" content="blog"><meta property="og:title" content="亦初"><meta property="og:url" content="https://deleter-d.github.io/"><meta property="og:site_name" content="亦初"><meta property="og:description" content="很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><meta property="article:published_time" content="2024-02-20T08:02:16.000Z"><meta property="article:modified_time" content="2024-03-23T07:24:06.548Z"><meta property="article:author" content="亦初"><meta property="article:tag" content="异构计算"><meta property="article:tag" content="CUDA"><meta property="article:tag" content="高性能计算"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://deleter-d.github.io/posts/47225/"},"headline":"亦初","image":[],"datePublished":"2024-02-20T08:02:16.000Z","dateModified":"2024-03-23T07:24:06.548Z","author":{"@type":"Person","name":"亦初"},"description":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由"}</script><link rel="canonical" href="https://deleter-d.github.io/posts/47225/"><link rel="icon" href="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.2"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="亦初" type="application/atom+xml">
</head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg" alt="亦初" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/music">音乐</a><a class="navbar-item" href="/message">留言</a><a class="navbar-item" href="/self-talking">碎碎念</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2024-02-20  <a class="commentCountImg" href="/posts/47225/#comment-container"><span class="display-none-class">daa95f3554c2779420c5910516ab94d0</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="daa95f3554c2779420c5910516ab94d0">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>1 小时  <i class="fas fa-pencil-alt"> </i>11.1 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">CUDA编程——执行模型</h1><div class="content"><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p>
<span id="more"></span>
<h2 id="cuda运行时">CUDA运行时</h2>
<p><code>cudart</code>库是CUDA运行时的实现，该库可以通过<code>cudart.lib</code>或<code>libcudart.a</code>静态链接到程序中，也可以通过<code>cudart.dll</code>或<code>libcudart.so</code>动态链接。需要动态链接的该库的程序，通常将<code>cudart.dll</code>或<code>libcudart.so</code>作为程序安装包的一部分。</p>
<p>只有在链接到同一个CUDA运行时实例的组件之间传递CUDA运行时符号地址才是安全的。</p>
<p>该库的所有API均带有<code>cuda</code>前缀。</p>
<h3 id="初始化">初始化</h3>
<p>从CUDA 12.0开始，<code>cudaInitDevice()</code>和<code>cudaSetDevice()</code>调用会初始化与指定设备关联的运行时和主上下文。如不进行这些调用，运行时会隐式地使用设备0，并按需进行自初始化来执行其他运行时API请求。</p>
<p>在CUDA 12.0之前，<code>cudaSetDevice()</code>不会初始化运行时，程序通常使用空操作运行时调用<code>cudaFree(0)</code>，将运行时初始化与其他API活动隔离开。</p>
<p>运行时将会为每个设备创建一个CUDA上下文，称之为主上下文（primary context）。该上下文将在调用第一个需要活动上下文的运行时函数时被初始化。主机端的所有线程共享该上下文。在创建上下文过程中，必要情况下会将设备代码即时编译并加载到设备内存中</p>
<p>当主机线程调用<code>cudaDeviceReset()</code>时，将销毁该线程当前操作设备的主上下文。任何拥有该设备的主机线程进行下一个运行时函数调用时，将为该设备创建一个新的主上下文。</p>
<h2 id="cuda执行模型概述">CUDA执行模型概述</h2>
<h3 id="gpu架构概述">GPU架构概述</h3>
<p>GPU是围绕流式多处理器（SM）的可扩展阵列搭建的，通过复制这种架构的构建块来实现GPU的硬件并行。</p>
<p>SM的核心组件如下：</p>
<ul>
<li>CUDA核心；</li>
<li>共享内存 / 一级缓存；</li>
<li>寄存器文件；</li>
<li>加载 / 存储单元；</li>
<li>特殊功能单元；</li>
<li>线程束调度器。</li>
</ul>
<p>每个SM可以支持数百个线程并发执行，每个GPU通常有多个SM，所以一个GPU上并发执行数千个线程是有可能的。启动一个核函数时，线程块被分配在了可用的SM上，线程块一旦被调度到一个SM上，其中的线程只会在当前的SM上执行。多个线程块可能被分配在同一个SM上，是根据SM资源的可用性进行调度的。同一线程值的指令利用指令级并行性进行流水线化。</p>
<p>CUDA采用单指令多线程（SIMT）架构来管理和执行线程，每32个线程为一组，成为线程束（warp）。</p>
<p>在并行线程中共享数据可能会引起竞争，CUDA提供了一种用来同步线程块内线程的方法，但没有提供块间同步的原语。</p>
<p>虽然线程块内的线程束可以任意顺序调度，但活跃的线程束仍会受到SM资源的限制。当线程束闲置时，SM可以从同一SM上的常驻线程块中调度其他可用的线程束。在并发的线程束之间切换没有开销，因为硬件资源已经被分配到了SM上的所有线程和块中。</p>
<h2 id="线程束的本质">线程束的本质</h2>
<h3 id="线程束和线程块">线程束和线程块</h3>
<p>线程束是SM中基本的执行单元。一旦线程块被调度到一个SM上，线程块中的线程会被进一步划分为线程束。一个线程束由32个连续的线程组成，在一个线程束中，所有的线程按照SIMT方式执行。</p>
<p>虽然线程块可以组织为一维、二维或三维的，但从硬件角度看，所有线程都被组织成了一维的。例如有一个128线程的一维线程块，它将被组织进4个线程束中，如下所示。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Warp</span> <span class="hljs-number">0</span>: thread  <span class="hljs-number">0</span>, thread  <span class="hljs-number">1</span>, thread  <span class="hljs-number">2</span>, ... thread <span class="hljs-number">31</span><br><span class="hljs-attribute">Warp</span> <span class="hljs-number">1</span>: thread <span class="hljs-number">32</span>, thread <span class="hljs-number">33</span>, thread <span class="hljs-number">34</span>, ... thread <span class="hljs-number">63</span><br><span class="hljs-attribute">Warp</span> <span class="hljs-number">2</span>: thread <span class="hljs-number">64</span>, thread <span class="hljs-number">65</span>, thread <span class="hljs-number">66</span>, ... thread <span class="hljs-number">95</span><br><span class="hljs-attribute">Warp</span> <span class="hljs-number">3</span>: thread <span class="hljs-number">96</span>, thread <span class="hljs-number">97</span>, thread <span class="hljs-number">98</span>, ... thread <span class="hljs-number">127</span><br></code></pre></td></tr></table></figure>
<p>二维、三维的线程块是同理的，只需要计算出其唯一线程ID即可。</p>
<p>一个线程块的线程束数量由下式确定。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="46.513ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 20558.6 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(556,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(834,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1334,0)"></path><path data-c="6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z" transform="translate(1778,0)"></path></g><g data-mml-node="mi" transform="translate(2306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(3306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mtext" transform="translate(4306,0)"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(722,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1222,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1614,0)"></path></g><g data-mml-node="mi" transform="translate(6476,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(7476,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g><g data-mml-node="mo" transform="translate(8753.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(9809.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="2308" d="M246 -949V1450H571V1388H308V-949H246Z"></path></g><g data-mml-node="mfrac" transform="translate(583,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mtext"><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(556,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(834,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1334,0)"></path><path data-c="6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z" transform="translate(1778,0)"></path></g><g data-mml-node="mi" transform="translate(2306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(3306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mtext" transform="translate(4306,0)"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1337,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1781,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(2281,0)"></path></g><g data-mml-node="mi" transform="translate(7143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(8143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g><g data-mml-node="mrow" transform="translate(2706.5,-710)"><g data-mml-node="mtext"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(722,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1222,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1614,0)"></path></g><g data-mml-node="mi" transform="translate(2170,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">大</text></g><g data-mml-node="mi" transform="translate(3170,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g></g><rect width="9343" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10166,0) translate(0 -0.5)"><path data-c="2309" d="M11 1388V1450H336V-949H274V1388H11Z"></path></g></g></g></g></svg></mjx-container></span> 线程束不会在不同的线程块之间分离，若线程块的大小不是线程束大小的整数倍，则在最后的线程束中会有些线程处于不活跃状态。例如有一个二维的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="6.159ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 2722.4 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></svg></mjx-container></span>的线程块，他会被分配在3个线程束中，最后一个线程束的后半段是不活跃的，但依然会占用SM的资源。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/25ef389c-18fd-4810-bc4a-bcfe47c374a5"></p>
<h3 id="线程束分化">线程束分化</h3>
<p>首先要注意一点，一个线程束中的所有线程在同一周期内必须执行相同的指令。考虑下列语句：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (cond) {<br>    ...<br>} <span class="hljs-keyword">else</span> {<br>    ...<br>}<br></code></pre></td></tr></table></figure>
<p>假设在一个线程束中，有16个线程的<code>cond</code>为<code>true</code>，另外16个线程为<code>false</code>。此时，一半的线程需要执行<code>if</code>语句块中的指令，另一半需要执行<code>else</code>中的指令。这种在同一线程束中的线程执行不同指令的现象，被称为线程束分化。</p>
<p>当发生线程束分化时，线程束将连续执行每个分支路径，同时禁用不执行这一路径的线程，这会导致性能明显下降。条件分支越多，并行性削弱越严重。</p>
<blockquote>
<p>线程束分化只发生在同一线程束中，不同线程束的不同条件值不会引起线程束分化。</p>
</blockquote>
<p>这里引入一个概念，分支效率，即未分化分支与全部分支之比。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="43.417ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 19190.4 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">效</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g><g data-mml-node="mo" transform="translate(4277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5333.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(7055.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mrow" transform="translate(8056,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(3222.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mtext" transform="translate(4222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">化</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g></g><g data-mml-node="mtext" transform="translate(3331.2,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g><rect width="9422.4" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10398.4,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg></mjx-container></span> 设想以下三种情况：</p>
<ul>
<li>情况一：线程ID为偶数的执行<code>if</code>，线程ID为奇数的执行<code>else</code>；</li>
<li>情况二：线程束ID为偶数的执行<code>if</code>， 线程束ID为奇数的执行<code>else</code>；</li>
<li>情况三：线程ID为偶数的执行<code>if</code>，线程ID为奇数的执行另一个<code>if</code>。</li>
</ul>
<p>具体到代码即为：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 线程ID为偶数的执行if，线程ID为奇数的执行else</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">mathKernel1</span><span class="hljs-params">(<span class="hljs-type">float</span> *c)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> a, b;<br>    a = b = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">if</span> (tid % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>)<br>        a = <span class="hljs-number">100.0f</span>;<br>    <span class="hljs-keyword">else</span><br>        b = <span class="hljs-number">200.0f</span>;<br>    c[tid] = a + b;<br>}<br></code></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 线程束ID为偶数的执行if， 线程束ID为奇数的执行else</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">mathKernel2</span><span class="hljs-params">(<span class="hljs-type">float</span> *c)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> a, b;<br>    a = b = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">if</span> ((tid / warpSize) % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>)<br>        a = <span class="hljs-number">100.0f</span>;<br>    <span class="hljs-keyword">else</span><br>        b = <span class="hljs-number">200.0f</span>;<br>    c[tid] = a + b;<br>}<br></code></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 线程ID为偶数的执行if，线程ID为奇数的执行另一个if</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">mathKernel3</span><span class="hljs-params">(<span class="hljs-type">float</span> *c)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> a, b;<br>    a = b = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-type">bool</span> ipred = (tid % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">if</span> (ipred)<br>        a = <span class="hljs-number">100.0f</span>;<br>    <span class="hljs-keyword">if</span> (!ipred)<br>        b = <span class="hljs-number">200.0f</span>;<br>    c[tid] = a + b;<br>}<br></code></pre></td></tr></table></figure>
<p>调用这三个核函数，使用<code>ncu</code>来统计分支效率，结果如下所示。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>分支效率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>mathKernel1(float *) (1, 1, 1)x(64, 1, 1)</code></td>
<td>80%</td>
</tr>
<tr class="even">
<td><code>mathKernel2(float *) (1, 1, 1)x(64, 1, 1)</code></td>
<td>100%</td>
</tr>
<tr class="odd">
<td><code>mathKernel3(float *) (1, 1, 1)x(64, 1, 1)</code></td>
<td>71.43%</td>
</tr>
</tbody>
</table>
<blockquote>
<p>为了阅读方便，这里简化了<code>ncu</code>的输出信息，实际的输出比上述形式要丰富，后续的<code>ncu</code>分析结果也以同样的方式简化。</p>
</blockquote>
<p>可以观察到，情况一由于发生了分支分化，导致分支效率降低。而情况二由于分支分化的粒度是线程束大小的整倍数，所以分支效率统计为100%。情况三在情况一的前提下改造为了两个<code>if</code>，这样可以使得分化分支的数量翻倍。</p>
<blockquote>
<p>分化分支数量翻倍但效率没有降低至一半是因为，虽然在编译时加上了<code>-G</code>参数来阻止分支预测优化，但还有其他优化手段，以保证分支效率在50%以上。</p>
<p>详细代码示例参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/01_warp_divergence.cu">warp_divergence.cu</a></p>
</blockquote>
<h3 id="资源分配">资源分配</h3>
<p>线程束的本地执行上下文主要由以下资源组成：</p>
<ul>
<li>程序计数器；</li>
<li>寄存器；</li>
<li>共享内存。</li>
</ul>
<p>由SM处理的每个线程束的执行上下文，在整个线程束的生存期中是保存在芯片内的。所以从一个执行上下文切换到另一个执行上下文没有损失。对于一个给定的核函数，同时存在于同一个SM中的线程块和线程束的数量，取决于在SM中可用的与核函数所需的寄存器和共享内存数量。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/49674a9f-2a18-4eae-ae62-0f70dddc6046"></p>
<p>如上图所示，每个线程消耗的寄存器较少，同一SM上就可以多分配一些线程。同理，每个线程块消耗的共享内存较少，同一SM上就可以多分配一些线程块。</p>
<p>如果每个SM没有足够的寄存器或共享内存去处理至少一个块，那么核函数就无法启动。</p>
<p>当计算资源已经分配给线程块时，线程块被称为活跃的块。它所包含的线程束被称为活跃的线程束。活跃的线程束可以分为以下三种类型：</p>
<ul>
<li>选定的线程束：正在执行的活跃线程束；</li>
<li>阻塞的线程束：未准备好执行的线程束；</li>
<li>符合条件的线程束：准备执行但尚未执行的活跃线程束。</li>
</ul>
<p>同时满足以下两个条件则线程束符合执行条件：</p>
<ul>
<li>32个CUDA核心可用于执行；</li>
<li>当前指令中所有的参数都已就绪。</li>
</ul>
<h3 id="延迟隐藏">延迟隐藏</h3>
<p>指令延迟是指在指令发出和完成之间的时钟周期数。指令可以被分为两种基本类型：</p>
<ul>
<li>算术指令：一个算术操作从开始到产生输出之间的时钟周期，一般为10～20个周期；</li>
<li>内存指令：发送出的加载或存储操作和数据到达目的地之间的时钟周期，全局内存访问一般为400～800个周期。</li>
</ul>
<p>当每个时钟周期内所有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。在GPU中往往有着大量的线程，通过在其他常驻线程束中发布其他指令来隐藏指令延迟至关重要。</p>
<p>可以通过利特尔法则来估算隐藏延迟所需的活跃线程束数量。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="51.032ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 22556 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">所</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">需</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">线</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">程</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">束</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text><text data-variant="normal" transform="translate(6000,0) scale(1,-1)" font-size="884px" font-family="serif">量</text></g><g data-mml-node="mo" transform="translate(7277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(8333.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">指</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">令</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">平</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">均</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">延</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">迟</text></g><g data-mml-node="mo" transform="translate(14555.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(15556,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">欲</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">达</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">到</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">的</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">吞</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">吐</text><text data-variant="normal" transform="translate(6000,0) scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g></g></svg></mjx-container></span> 此处是一个粗略化的公式，并不是直接套用即可算出所需线程束数量，后面将具体的介绍如何运用该法则。</p>
<h4 id="算术延迟隐藏">算术延迟隐藏</h4>
<p>对于算术运算，所需的并行数可以表示为隐藏算术延迟所需的操作数量。</p>
<p>假设某个算术指令延迟为20个周期，我们想要令SM保持32个操作的吞吐量，即每个周期进行32次操作。根据上面提到的利特尔法则，我们可以得到所需并行数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="13.701ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 6056 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(3500.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(4556,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>，也就是说要保证程序中有640个该计算操作才能完全隐藏算术延迟。</p>
<p>我们再假设每个线程中仅执行一次该算术操作，则可以进一步得到线程束数量为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="13.701ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 6056 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5056,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>个。</p>
<p>观察上述例子会发现，算术延迟隐藏所需的并行数可以用操作数量来表示，也可以用线程束数量来表示。这表明我们可以有两个不同的层次来提高并行：</p>
<ul>
<li>指令级并行（ILP）：一个线程中有很多独立的指令；</li>
<li>线程级并行（TLP）：很多并发地符合条件的线程。</li>
</ul>
<h4 id="内存延迟隐藏">内存延迟隐藏</h4>
<p>对于内存操作，所需的并行数可以表示为在每个周期内隐藏内存延迟所需的字节数。</p>
<p>假设某个内存指令延迟为800个周期，我们想要令设备保持200GB/s的吞吐量，根据内存频率可以将吞吐量的单位由GB/s转换为B/CP（字节/周期）。笔者的设备内存频率为10.501GHz，所以转换后为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="33.509ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14811 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mtext" transform="translate(1500,0)"><path data-c="47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z" transform="translate(785,0)"></path><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z" transform="translate(1493,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(1993,0)"></path></g><g data-mml-node="mo" transform="translate(4109.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(5109.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(1000,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(1278,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1778,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(2278,0)"></path></g><g data-mml-node="mtext" transform="translate(7887.4,0)"><path data-c="47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path data-c="48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z" transform="translate(785,0)"></path><path data-c="7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z" transform="translate(1535,0)"></path></g><g data-mml-node="mo" transform="translate(10144.2,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mn" transform="translate(11200,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path></g><g data-mml-node="mtext" transform="translate(12200,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z" transform="translate(708,0)"></path><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z" transform="translate(1208,0)"></path><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(1930,0)"></path></g></g></g></svg></mjx-container></span>。接着根据利特尔法则，我们可以得到所需的并行数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="18.697ex" height="1.731ex" role="img" focusable="false" viewBox="0 -683 8264 765"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5056,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mtext" transform="translate(7556,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></g></g></g></svg></mjx-container></span>。</p>
<blockquote>
<p>使用如下命令来获取内存频率。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">nvidia-smi -a -q -d CLOCK | grep -A 3 <span class="hljs-string">"Max Clocks"</span> | grep <span class="hljs-string">"Memory"</span><br></code></pre></td></tr></table></figure>
</blockquote>
<p>我们再假设每个线程中仅从全局内存中读取一个浮点数到SM上用于计算，则根据并行数可以计算出所需的线程数，即<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="20.299ex" height="1.731ex" role="img" focusable="false" viewBox="0 -683 8972 765"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mtext" transform="translate(2500,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></g><g data-mml-node="mo" transform="translate(3430.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(4430.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mtext" transform="translate(4930.4,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></g><g data-mml-node="mo" transform="translate(5916.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6972,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>个线程。进一步得到线程束数量为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.973ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7944 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2308" d="M174 734Q178 746 190 750H298H369Q400 750 411 747T422 730T411 713T372 709Q365 709 345 709T310 710H214V-235Q206 -248 196 -250Q192 -250 189 -249T184 -247T180 -244T178 -241T176 -237T174 -234V734Z"></path></g><g data-mml-node="mn" transform="translate(444,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g><g data-mml-node="mo" transform="translate(2666.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(3666.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4666.4,0)"><path data-c="2309" d="M21 717T21 730T32 746T75 750H147H256Q266 742 269 735V-235Q262 -248 251 -250Q247 -250 244 -249T239 -247T235 -244T233 -241T231 -237T229 -234V710H133Q119 710 99 710T71 709Q43 709 32 713Z"></path></g><g data-mml-node="mo" transform="translate(5388.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6444,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>个。若每个线程执行多个独立的4字节加载，则隐藏内存延迟所需的线程就可以更少。</p>
<blockquote>
<p>上述计算出的线程束数量只是下界，也就是说在相同假设下，提供更多的线程数量同样能够达到延迟隐藏的效果。</p>
</blockquote>
<h3 id="占用率">占用率</h3>
<p>占用率是每个SM中活跃的线程束占最大线程束数量的比值。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex;" xmlns="http://www.w3.org/2000/svg" width="26.637ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 11773.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">占</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">率</text></g><g data-mml-node="mo" transform="translate(3277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4333.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">活</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">跃</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">线</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">程</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">束</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">大</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">线</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">程</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g><rect width="7200" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span> 最大线程束数量可以通过<code>cudaGetDeviceProperties()</code>获取到设备属性后，由其成员<code>maxThreadsPerMultiProcessor / 32</code>取得。详细代码参考<a href=""></a>，笔者的设备获取到的结果如下所示。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Device</span> <span class="hljs-number">0</span>: NVIDIA GeForce RTX <span class="hljs-number">4070</span><br><span class="hljs-attribute">Number</span> of multiprocessors: <span class="hljs-number">46</span><br><span class="hljs-attribute">Total</span> amount of constant memory: <span class="hljs-number">64</span>.<span class="hljs-number">00</span> KB<br><span class="hljs-attribute">Total</span> amount of shared memory per block: <span class="hljs-number">48</span>.<span class="hljs-number">00</span> KB<br><span class="hljs-attribute">Total</span> amount of registers available per block: <span class="hljs-number">65536</span><br><span class="hljs-attribute">Warp</span> size: <span class="hljs-number">32</span><br><span class="hljs-attribute">Maximum</span> number of threads per block: <span class="hljs-number">1024</span><br><span class="hljs-attribute">Maximum</span> number of threads per multiprocessor: <span class="hljs-number">1536</span><br><span class="hljs-attribute">Maximum</span> number of warps per multiprocessor: <span class="hljs-number">48</span><br></code></pre></td></tr></table></figure>
<p>CUDA官方以前提供一个占用率计算器，是一个Excel表格，可以填入一些核函数资源信息后，自动计算SM占用率。但目前在官网已经找不到该文件的下载途径了，可能是因为当前最新的设备已经不适合用这种方式来计算占用率了。</p>
<blockquote>
<p>若想体验该计算器，笔者在Github上找到一个项目，提供相同的功能，但该项目仅支持计算能力8.6及以前的设备，CUDA版本仅支持11.0和11.1两个版本，链接：<a target="_blank" rel="noopener" href="http://karthikeyann.github.io/cuda-calculator/">cuda-calculator</a>。</p>
</blockquote>
<p>为了提高占用率，需要调整线程块配置或重新调整资源的使用情况，以允许更多的线程束同时处于活跃状态并提高计算资源的利用率。要避免极端的情况：</p>
<ul>
<li>线程块过小：每个块中的线程太少，会在所有资源被充分利用之前导致硬件达到每个SM的线程束数量限制；</li>
<li>线程块过大：每个块中的线程太多，会导致SM中每个线程可用的硬件资源较少。</li>
</ul>
<h3 id="同步">同步</h3>
<p>CUDA中提供了两个级别的同步原语：</p>
<ul>
<li>系统级别：等待主机和设备完成所有工作；</li>
<li>块级别：在设备执行过程中等待一个线程块中所有线程到达同一点。</li>
</ul>
<p>系统级别的同步通过<code>cudaDeviceSynchronize()</code>API实现，块级别的同步通过<code>__syncthreads()</code>实现。线程块中要注意避免各种访存冲突，例如读后写、写后读、写后写等。</p>
<p>不同块之间没有线程同步，实现块间同步可以通过全局变量+原子操作的方式实现。从CUDA 9.x开始提供了协作组的概念，<code>cooperative_groups::grid_group</code>下有一个<code>sync()</code>函数可以提供块间同步的功能。关于块间同步这里不过多展开。</p>
<h3 id="可扩展性">可扩展性</h3>
<p>能够在可变数量的计算核心上执行相同代码的能力被成为透明可扩展性。拥有这种能力的平台能够避免不同的硬件产生的变化，减轻了开发者的负担。</p>
<p>可扩展性比效率更重要，一个可扩展但效率很低的系统可以通过简单添加硬件核心来处理更大的工作负载，一个效率很高但不可扩展的系统可能很快就会达到性能上限。</p>
<p>CUDA核函数启动时，线程块分布在多个SM中，网格中的线程块以并行或连续或任意的顺序执行。这种独立性使得CUDA程序可以在任意数量的计算核心间扩展。</p>
<h2 id="并行性表现">并行性表现</h2>
<p>定义一个二维矩阵求和的核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sumMatrixOnGPU2D</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">int</span> NX, <span class="hljs-type">int</span> NY)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = iy * NX + ix;<br><br>    <span class="hljs-keyword">if</span> (ix &lt; NX &amp;&amp; iy &lt; NY)<br>        C[idx] = A[idx] + B[idx];<br>}<br></code></pre></td></tr></table></figure>
<blockquote>
<p>详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/03_parallelism.cu">parallelism.cu</a>。</p>
</blockquote>
<h3 id="检测活跃线程束">检测活跃线程束</h3>
<p>我们利用不同的线程块大小设计来执行上面的核函数，统计核函数执行事件，并使用<code>ncu</code>分析不同情况下的占用率。</p>
<blockquote>
<p>这里的占用率指的是：每周期内活跃线程束的平均数量与一个SM支持的线程束最大数量的比值。</p>
</blockquote>
<p>这里对线程块采用四种不同的设计：<code>(32, 32)</code>、<code>(32, 16)</code>、<code>(16, 32)</code>、<code>(16, 16)</code>，得到的分析结果如下所示。</p>
<p>核函数耗时情况如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">0817</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">512</span>, <span class="hljs-number">1024</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">16</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">02669</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03258</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03968</span> ms<br></code></pre></td></tr></table></figure>
<p>占用率分析结果如下。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>占用率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt;</code></td>
<td>48.07%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt;</code></td>
<td>59.31%</td>
</tr>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt;</code></td>
<td>63.41%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt;</code></td>
<td>67.98%</td>
</tr>
</tbody>
</table>
<p>观察上述结果：</p>
<ul>
<li>情况二<code>(32, 16)</code>中的线程块比情况一<code>(32, 32)</code>更多，所以设备可以有更多活跃的线程束，是其占用率更高可能的原因之一；</li>
<li>情况四<code>(16, 16)</code>的占用率最高，但并不是最快的，因此，更高的占用率并不一定代表更高的性能。</li>
</ul>
<h3 id="检测内存操作">检测内存操作</h3>
<p>上面提到的矩阵求和的核函数中有三个内存操作，两次加载和一次存储。同样使用<code>ncu</code>来分析核函数的内存读取效率和全局加载效率，分析结果如下。</p>
<blockquote>
<p>全局加载效率指的是被请求的全局加载吞吐量占所需的全局加载吞吐量的比值，它衡量了程序的加载操作利用设备内存带宽的程度。</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th></th>
<th>内存读取效率</th>
<th>全局加载效率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt;</code></td>
<td>296.77 GB/s</td>
<td>100%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt;</code></td>
<td>297.72 GB/s</td>
<td>100%</td>
</tr>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt;</code></td>
<td>295.40 GB/s</td>
<td>100%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt;</code></td>
<td>297.79 GB/s</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>如果阅读过《CUDA C编程权威指南》一书中的相关介绍，会发现我们这里得到的分析结果与书中提到的截然不同。书中描述的情况三和情况四下，全局加载效率会有明显的下降。但这里不同的线程块设计并没有导致太大的内存操作性能波动，笔者推测是因为nvcc编译器在这方面做了比以前更多的优化，来保证线程在SM中的调度更加合理。</p>
<p>根据书中的描述，在一节分析到的结果是，对网格和线程块的启发式算法来说，最内层的维数（<code>block.x</code>）应该是线程束大小的整倍数，这一结论还是有参考意义的。</p>
<h3 id="增大并行性">增大并行性</h3>
<p>我们来探讨一个问题，根据上一节得到的结论，继续增加<code>block.x</code>会增大吞吐量吗？同样是利用上一节中的例子，使用不同的线程块设计来执行核函数。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">256</span>, <span class="hljs-number">8192</span>), (<span class="hljs-number">64</span>, <span class="hljs-number">2</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03245</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">256</span>, <span class="hljs-number">4096</span>), (<span class="hljs-number">64</span>, <span class="hljs-number">4</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">05654</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">256</span>, <span class="hljs-number">2048</span>), (<span class="hljs-number">64</span>, <span class="hljs-number">8</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">02928</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">8192</span>), (<span class="hljs-number">128</span>, <span class="hljs-number">2</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03757</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">4096</span>), (<span class="hljs-number">128</span>, <span class="hljs-number">4</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03094</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">2048</span>), (<span class="hljs-number">128</span>, <span class="hljs-number">8</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">04643</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">64</span>, <span class="hljs-number">8192</span>), (<span class="hljs-number">256</span>, <span class="hljs-number">2</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">10362</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">64</span>, <span class="hljs-number">4096</span>), (<span class="hljs-number">256</span>, <span class="hljs-number">4</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03165</span> ms<br></code></pre></td></tr></table></figure>
<p>虽然笔者这里的测试结果差距并不明显，不必过多纠结，了解思想即可。</p>
<p>分析结果可以得出几条规律：</p>
<ul>
<li>情况一<code>(64, 2)</code>中启动的线程块数量最多，但并不是速度最快的；</li>
<li>情况二<code>(64, 4)</code>与情况四<code>(128, 2)</code>相比，两者有相同数量的线程块（<code>(256, 4096)</code>与<code>(128, 8192)</code>），但情况四的表现优于情况二。这恰好印证了前一节中的结论，线程块最内层的维数对性能起着关键作用；</li>
<li>除了情况一、二、四外，其余情况的线程块数量均比最优情况少。故增大并行性是性能优化的一个重要因素。</li>
</ul>
<p>接下来分析上述各个情况的占用率，分析方法同之前的<a href="#检测活跃线程束">检测活跃线程束</a>。分析结果如下。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>占用率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(256, 8192), (64, 2)&gt;&gt;&gt;</code></td>
<td>82.38%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(256, 4096), (64, 4)&gt;&gt;&gt;</code></td>
<td>73.27%</td>
</tr>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(256, 2048), (64, 8)&gt;&gt;&gt;</code></td>
<td>61.94%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(128, 8192), (128, 2)&gt;&gt;&gt;</code></td>
<td>79.33%</td>
</tr>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(128, 4096), (128, 4)&gt;&gt;&gt;</code></td>
<td>64.16%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(128, 2048), (128, 8)&gt;&gt;&gt;</code></td>
<td>50.34%</td>
</tr>
<tr class="odd">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(64, 8192), (256, 2)&gt;&gt;&gt;</code></td>
<td>73.05%</td>
</tr>
<tr class="even">
<td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(64, 4096), (256, 4)&gt;&gt;&gt;</code></td>
<td>52.63%</td>
</tr>
</tbody>
</table>
<p>书中描述的情况一<code>(64, 2)</code>是占用率最低的情况，因为线程块是最多的，触及到了书作者当时的硬件瓶颈。但在笔者的环境下，情况一反而占用率是最高的，这也体现了硬件进步带来的效果。</p>
<p>虽然与书中描述的情况有所不同，但这也恰恰印证了提高并行性的重要程度，当硬件资源不再是限制和瓶颈的时候，更大的并行程度将带来更高的性能。</p>
<p>经过上面一系列的分析我们能够发现，性能最好的线程块设计，既没有最高的占用率，也没有最高的加载吞吐量。<strong>可见，没有一个单独的指标可以直接优化性能，我们需要在几个相关的指标之间寻找一个平衡来获得全局最优性能。</strong></p>
<h2 id="避免分支分化">避免分支分化</h2>
<h3 id="并行归约问题">并行归约问题</h3>
<p>一般的并行求和是将较多的数据分块计算，每个线程负责一个数据块的求和，再对每个数据块的和求和即为最终结果。一个常用方法是使用迭代成对实现，一个数据块只包含一对元素，每个线程求得这对元素的和，作为下一次迭代的输入。当输出向量长度为1时，表明最终结果已经被计算出来了。</p>
<p>成对的并行求和可以进一步分为两种类型：</p>
<ul>
<li>相邻配对：元素与它们相邻的元素配对；</li>
<li>交错配对：根据给定的步长配对元素。</li>
</ul>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/1cb84e0d-3bff-4d8e-8014-eccf15ef7f19"></p>
<p>虽然上述介绍的是加法，但任何满足交换律和结合律的运算都可以采用这种思路。</p>
<p>在向量中执行满足交换律和结合律的运算，被称为归约问题。并行归约问题是这种归约运算的并行执行。</p>
<h3 id="并行归约中的分化">并行归约中的分化</h3>
<p>首先实现一个相邻配对的并行归约求和核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceNeighbored</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + tid;<br><br>    <span class="hljs-comment">// 将全局数据指针转换为当前block的局部数据指针</span><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br><br>    <span class="hljs-comment">// 边界检查</span><br>    <span class="hljs-keyword">if</span> (idx &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-comment">// 在全局内存中原地归约</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = <span class="hljs-number">1</span>; stride &lt; blockDim.x; stride *= <span class="hljs-number">2</span>)<br>    {<br>        <span class="hljs-keyword">if</span> ((tid % (<span class="hljs-number">2</span> * stride)) == <span class="hljs-number">0</span>)<br>            idata[tid] += idata[tid + stride];<br>        __syncthreads(); <span class="hljs-comment">// 同步线程，保证下一轮迭代正确</span><br>    }<br><br>    <span class="hljs-comment">// 将当前block的结果写入全局内存</span><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure>
<p>两个相邻元素之间的距离成为步长（stride），初始化为1。每次归约循环后，步长被乘以2。由于块间同步很不方便，所以将每个块的求和结果拷贝回主机之后再进行串行求和。</p>
<p>具体求和过程如图所示。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/bced3cb3-c047-4e97-9c44-126d312cf1ce"></p>
<p>测试后得到的性能如下所示。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">2122</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">628512</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这里采用一维网格与一维线程块，详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/04_reduction.cu">reduction.cu</a>，后面将以这个核函数的表现作为性能基准。这个<code>cu</code>文件将伴随整个<a href="#避免分支分化">避免分支分化</a>和<a href="#展开循环">展开循环</a>两个小节。</p>
</blockquote>
<h3 id="改善并行归约的分化">改善并行归约的分化</h3>
<p>注意上面核函数中的条件表达式。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> ((tid % (<span class="hljs-number">2</span> * stride)) == <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure>
<p>我们在前面也介绍过，这会导致非常严重的线程束分化。第一次迭代只有ID为偶数的线程是活跃的，第二次迭代就只有四分之一的线程活跃了，但那些不活跃的线程依旧会被调度。</p>
<p>改进这一现象的方法是强制ID相邻的线程执行求和操作，线程束分化就可以被归约了。将核函数修改为如下形式。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceNeighboredLess</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> tid = threadIdx.x;<br>    <span class="hljs-type">unsigned</span> idx = blockIdx.x * blockDim.x + tid;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br><br>    <span class="hljs-keyword">if</span> (idx &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = <span class="hljs-number">1</span>; stride &lt; blockDim.x; stride *= <span class="hljs-number">2</span>)<br>    {<br>        <span class="hljs-comment">// 将tid转换为局部数组索引</span><br>        <span class="hljs-type">int</span> index = <span class="hljs-number">2</span> * stride * tid;<br>        <span class="hljs-keyword">if</span> (index &lt; blockDim.x)<br>            idata[index] += idata[index + stride];<br>        __syncthreads();<br>    }<br><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure>
<p>这样就将具体的运算过程变为了如下所示的状态。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/6f8f03cc-7ed9-40b2-a971-696e77bfc3a6"></p>
<p>虽然这种改进在一定程度上降低了线程束分化的程度，但在最后几轮迭代中，还是会存在线程束分化的情况。例如对于一个有512个线程的块来说，第一轮迭代由前8个线程束完成，后8个线程束不处于活跃状态。前几轮迭代都同理，但当最后五轮迭代中，活跃的线程数量小于线程束大小的时候，还是会发生线程束分化。</p>
<p>性能测试的表现如下所示。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">167</span> ms       cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">67648</span> ms      gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> neighboredL elapsed <span class="hljs-number">0</span>.<span class="hljs-number">424576</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>虽然在最后几轮还是会发生线程束分化，但依旧比不做任何处理快了1.6倍左右。我们可以利用<code>ncu</code>来分析每个线程束中执行的指令数量和内存读取效率来解释这种现象，分析结果如下所示。</p>
<table>
<colgroup>
<col style="width: 66%">
<col style="width: 20%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>每线程束执行指令数</th>
<th>内存读取效率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>reduceNeighbored(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1)</code></td>
<td>341.94 inst/warp</td>
<td>690.98 GB/s</td>
</tr>
<tr class="even">
<td><code>reduceNeighboredLess(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1)</code></td>
<td>115.38 inst/warp</td>
<td>1.27 TB/s</td>
</tr>
</tbody>
</table>
<p>可以观察到，在改善线程束分化后，每个线程束执行的指令数量大幅下降。而且拥有更大的加载吞吐量，因为虽然I/O操作数量相同，但耗时更短。</p>
<h3 id="交错配对的归约">交错配对的归约</h3>
<p>与相邻配对的方法相比，交错配对的方法反转了元素步长的变化，初始化为数据块大小的一半，然后每轮迭代减少一半。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceInterleaved</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + tid;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br><br>    <span class="hljs-keyword">if</span> (idx &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = blockDim.x / <span class="hljs-number">2</span>; stride &gt; <span class="hljs-number">0</span>; stride &gt;&gt;= <span class="hljs-number">1</span>)<br>    {<br>        <span class="hljs-keyword">if</span> (tid &lt; stride)<br>            idata[tid] += idata[tid + stride];<br>        __syncthreads();<br>    }<br><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure>
<p>具体运算过程如下图所示。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/c6a05582-869a-471f-bdeb-059989948cf8"></p>
<p>性能测试表现如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">15</span>.<span class="hljs-number">991</span> ms       cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">676736</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> neighboredL elapsed <span class="hljs-number">0</span>.<span class="hljs-number">422176</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> interleaved elapsed <span class="hljs-number">0</span>.<span class="hljs-number">364032</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>虽然交错配对的方式与优化后的相邻配对方式拥有相同的线程束分化情况，但仍然有性能的提升。这种性能提升是由全局内存加载 / 存储模式导致的，在后续的文章中会进一步讨论。</p>
<h2 id="展开循环">展开循环</h2>
<p>循环展开是一种尝试减少分支出现频率和循环维护指令来优化循环的技术。在循环展开中，循环主体在代码中要多次编写，任何封闭循环都可以将它的迭代次数减少或完全消除。循环体的复制数量被成为循环展开因子，迭代次数以下列公式得到。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex;" xmlns="http://www.w3.org/2000/svg" width="31.162ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 13773.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">迭</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">代</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">次</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(4277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(5333.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">原</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">始</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">循</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">环</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">迭</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">代</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">次</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g></g><g data-mml-node="mrow" transform="translate(1220,-710)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">循</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">环</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">展</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">开</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">因</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">子</text></g></g><rect width="8200" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span> 为了方便理解，观察如下示例。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++) {<br>    a[i] = b[i] + c[i];<br>}<br></code></pre></td></tr></table></figure>
<p>如果像下面这样重复一次循环体，迭代次数就可以减少一半。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i += <span class="hljs-number">2</span>) {<br>    a[i] = b[i] + c[i];<br>    a[i + <span class="hljs-number">1</span>] = b[i + <span class="hljs-number">1</span>] + c[i + <span class="hljs-number">1</span>];<br>}<br></code></pre></td></tr></table></figure>
<h3 id="展开的归约">展开的归约</h3>
<p>我们用上面的思路来将之前提到的交错配对的归约求和操作进行循环展开。</p>
<p>先将两个数据块汇聚到一个线程块中，每个线程作用于多个数据块，并处理每个数据块的一个元素。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceUnrolling2</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x * <span class="hljs-number">2</span> + tid;<br><br>    <span class="hljs-comment">// 与之前不同，这里将两个数据库汇总到一个线程块中</span><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x * <span class="hljs-number">2</span>;<br><br>    <span class="hljs-keyword">if</span> (idx + blockDim.x &lt; size)<br>        g_idata[idx] += g_idata[idx + blockDim.x];<br>    __syncthreads();<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = blockDim.x / <span class="hljs-number">2</span>; stride &gt; <span class="hljs-number">0</span>; stride &gt;&gt;= <span class="hljs-number">1</span>)<br>    {<br>        <span class="hljs-keyword">if</span> (tid &lt; stride)<br>            idata[tid] += idata[tid + stride];<br>        __syncthreads();<br>    }<br><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure>
<p>比较关键的修改如下，每个线程都添加一个来自于相邻数据块的元素。可以把它作为归约循环的一个迭代，可以在数据块间进行归约。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (idx + blockDim.x &lt; size)<br>        g_idata[idx] += g_idata[idx + blockDim.x];<br></code></pre></td></tr></table></figure>
<p>然后调整全局数组索引，只需要一半的线程块来处理数据。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x * <span class="hljs-number">2</span> + tid;<br><span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x * <span class="hljs-number">2</span>;<br></code></pre></td></tr></table></figure>
<p>进行性能测试，结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">2422</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> interleaved elapsed <span class="hljs-number">0</span>.<span class="hljs-number">364096</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling2  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">28352</span> ms      gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">16384</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>可以观察到性能得到了进一步的提升，我们尝试进一步提高展开程度，性能测试结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">0142</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> interleaved elapsed <span class="hljs-number">0</span>.<span class="hljs-number">364608</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling2  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">281024</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">16384</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling4  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">262944</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling8  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">256736</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>可以观察到，在一个线程中有更多的独立内存操作会得到更好的性能，因为内存延迟可以得到很好的隐藏。我们利用<code>ncu</code>来分析设备内存读取吞吐量来解释性能提升的理由。</p>
<table>
<colgroup>
<col style="width: 76%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>设备内存读取吞吐量</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>reduceInterleaved(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1)</code></td>
<td>187.98 GB/s</td>
</tr>
<tr class="even">
<td><code>reduceUnrolling2(int *, int *, unsigned int) (16384, 1, 1)x(512, 1, 1)</code></td>
<td>293.78 GB/s</td>
</tr>
<tr class="odd">
<td><code>reduceUnrolling4(int *, int *, unsigned int) (8192, 1, 1)x(512, 1, 1)</code></td>
<td>335.35 GB/s</td>
</tr>
<tr class="even">
<td><code>reduceUnrolling8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1)</code></td>
<td>342.42 GB/s</td>
</tr>
</tbody>
</table>
<p>这里可以得到一个结论，归约的循环展开程度和设备读取吞吐量之间是成正比的。</p>
<h3 id="展开线程的归约">展开线程的归约</h3>
<p>上面提到过，当最后几轮迭代的时候，线程数量少于线程束大小时，线程束分化依旧会发生。由于线程束的执行时SIMT的模式，每条指令之后有隐式的线程束内同步。所以可以借助这一隐式同步，将最后几轮迭代用下列语句展开。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (tid &lt; <span class="hljs-number">32</span>)<br>{<br>    <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> *vmem = idata;<br>    vmem[tid] += vmem[tid + <span class="hljs-number">32</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">16</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">8</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">4</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">2</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">1</span>];<br>}<br></code></pre></td></tr></table></figure>
<blockquote>
<p>注意：变量<code>vmem</code>是被<code>volatile</code>修饰符修饰的，它告诉编译器每次赋值时必须将<code>vmem[tid]</code>的值存回全局内存中。如果省略了<code>volatile</code>修饰符，编译器或缓存可能优化对全局或共享内存的读写。若位于全局或共享内存中的变量有<code>volatile</code>修饰符，则编译器会假定其值可以被其他线程在任何时间修改或使用。故任何带有<code>volatile</code>修饰符的变量会强制直接读写内存，而不是简单的读写缓存或寄存器。</p>
</blockquote>
<p>性能测试结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">gpu</span> unrolling8  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">22992</span> ms      gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolWarps8 elapsed <span class="hljs-number">0</span>.<span class="hljs-number">227296</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br></code></pre></td></tr></table></figure>
<p>我们可以通过分析被阻塞线程束的占比来作证这个性能提升。</p>
<table>
<colgroup>
<col style="width: 81%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>阻塞线程束占比</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>reduceUnrolling8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1)</code></td>
<td>20.83%</td>
</tr>
<tr class="even">
<td><code>reduceUnrollWarps8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1)</code></td>
<td>12.56%</td>
</tr>
</tbody>
</table>
<p>可以观察到，通过展开最后的线程束，被阻塞的线程束占比大幅度下降，所以进一步提升了性能。</p>
<h3 id="完全展开的归约">完全展开的归约</h3>
<p>由于当前计算能力的设备，每个线程块最大的线程束是1024，且上述的归约核函数中循环迭代次数是基于一维网格与一维线程块的，所以完全展开归约循环是可行的。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceCompleteUnrollWarps8</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    ...<br>    <span class="hljs-comment">// 完全展开</span><br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">512</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">256</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">128</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">64</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (tid &lt; <span class="hljs-number">32</span>)<br>    {<br>        <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> *vmem = idata;<br>        vmem[tid] += vmem[tid + <span class="hljs-number">32</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">16</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">8</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">4</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">2</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">1</span>];<br>    }<br>	...<br>}<br></code></pre></td></tr></table></figure>
<p>性能测试的结果如下所示，又有小小的提升。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">gpu</span> unrolWarps8 elapsed <span class="hljs-number">0</span>.<span class="hljs-number">227264</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> CmptUnroll8 elapsed <span class="hljs-number">0</span>.<span class="hljs-number">224992</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br></code></pre></td></tr></table></figure>
<h3 id="模板函数的归约">模板函数的归约</h3>
<p>虽然可以手动展开循环，但使用模板函数有助于进一步减小分支消耗，关键代码如下。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">template</span> &lt;<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iBlockSize&gt;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceCompleteUnroll</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>	...<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">512</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">256</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">128</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">64</span>];<br>    __syncthreads();<br>	...<br>}<br></code></pre></td></tr></table></figure>
<p>这样做的好处是，检查块大小的<code>if</code>语句在编译时会被评估，若这一条件为<code>false</code>，则该分支块在编译时就会被删除。这类核函数一定要在<code>switch-case</code>结构中被调用，这样可以使编译器为特定大小的线程块自动优化代码。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">switch</span> (blocksize)<br>{<br><span class="hljs-keyword">case</span> <span class="hljs-number">1024</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">1024</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">512</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">512</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">256</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">256</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">128</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">128</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">64</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">64</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br>}<br></code></pre></td></tr></table></figure>
<h2 id="归约小结">归约小结</h2>
<p>至此，我们借助归约求和探讨了核函数的几个优化方案，大致分为避免分支分化和展开循环两个思路，细节上述部分已经充分讨论过了。下表中展示了从一开始的相邻配对归约，到改善了线程束分化问题，最后到完全展开循环核函数的性能对比。</p>
<table>
<thead>
<tr class="header">
<th>核函数描述</th>
<th>耗时 (ms)</th>
<th>单步加速</th>
<th>累计加速</th>
<th>加载效率</th>
<th>存储效率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>相邻配对（分化）</td>
<td>0.674112</td>
<td></td>
<td></td>
<td>25.02</td>
<td>25</td>
</tr>
<tr class="even">
<td>相邻配对（改善分化）</td>
<td>0.581312</td>
<td>1.16</td>
<td>1.16</td>
<td>25.02</td>
<td>25</td>
</tr>
<tr class="odd">
<td>交错配对</td>
<td>0.364192</td>
<td>1.60</td>
<td>1.85</td>
<td>96.15</td>
<td>95.52</td>
</tr>
<tr class="even">
<td>循环展开（2块）</td>
<td>0.255392</td>
<td>1.43</td>
<td>2.64</td>
<td>98.04</td>
<td>97.71</td>
</tr>
<tr class="odd">
<td>循环展开（4块）</td>
<td>0.252832</td>
<td>1.01</td>
<td>2.67</td>
<td>98.68</td>
<td>97.71</td>
</tr>
<tr class="even">
<td>循环展开（8块）</td>
<td>0.229664</td>
<td>1.10</td>
<td>2.94</td>
<td>99.21</td>
<td>97.71</td>
</tr>
<tr class="odd">
<td>循环展开（8块）+ 最后线程束展开</td>
<td>0.225184</td>
<td>1.02</td>
<td>2.99</td>
<td>99.43</td>
<td>99.40</td>
</tr>
<tr class="even">
<td>循环展开（8块）+ 完全循环展开 + 最后线程束展开</td>
<td>0.224096</td>
<td>1.00</td>
<td>3.01</td>
<td>99.43</td>
<td>99.40</td>
</tr>
<tr class="odd">
<td>模板化核函数</td>
<td>0.211616</td>
<td>1.06</td>
<td>3.19</td>
<td>99.43</td>
<td>99.40</td>
</tr>
</tbody>
</table>
<h2 id="动态并行">动态并行</h2>
<p>CUDA的动态并行允许在GPU端直接创建和同步新的GPU核函数，可以在一个核函数的任意点动态增加并行性。动态并行可以在运行时才决定网格和线程块的大小。</p>
<h3 id="嵌套执行">嵌套执行</h3>
<p>在GPU进行核函数调用的方法与主机端的调用方法相同。</p>
<p>在动态并行中，核函数执行分为双亲和孩子两种类型。父线程、父线程块或父网格启动一个新的网格，即子网格。子线程、子线程块或子网格被双亲启动。子网格必须在父线程、父线程块或父网格完成之前完成。只有在所有子网格都完成后，双亲才会完成。</p>
<blockquote>
<p>若调用的线程没有显式地同步子网格，则CUDA运行时会保证双亲与孩子之间的隐式同步。</p>
</blockquote>
<p>当双亲启动一个子网格，父线程块与孩子显式同步后，孩子才能开始执行。</p>
<p>关于动态并行的内存访问有以下几点：</p>
<ul>
<li>父网格和子网格共享相同的全局和常量内存，但它们有不同的局部内存和共享内存；</li>
<li>双亲和孩子之间以弱一致性为保证，使得父子网格可以对全局内存并发存取；</li>
<li>在子网格开始和完成两个时刻，子网格和它的父线程见到的内存完全相同；</li>
<li>当父线程优先于子网格调用时，所有的全局内存操作要保证子网格可见；</li>
<li>当双亲在子网格完成时进行同步后，子网格所有的内存操作要保证双亲可见；</li>
</ul>
<h3 id="在gpu上嵌套hello-world">在GPU上嵌套Hello World</h3>
<p>实现一个嵌套调用的核函数来在GPU上输出Hello World，具体的嵌套调用方式如下图所示。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/27c38e9d-785d-420e-962a-2b60899e6d83"></p>
<p>实现核函数如下。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">nestedHelloWorld</span><span class="hljs-params">(<span class="hljs-type">int</span> <span class="hljs-type">const</span> size, <span class="hljs-type">int</span> depth)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"Recursion=%d: Hello World from thread %d block %d\n"</span>, depth, tid, threadIdx.x);<br><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-type">int</span> threads = size &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span> &amp;&amp; threads &gt; <span class="hljs-number">0</span>)<br>    {<br>        nestedHelloWorld&lt;&lt;&lt;<span class="hljs-number">1</span>, threads&gt;&gt;&gt;(threads, ++depth);<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">"-------&gt; nested execution depth: %d\n"</span>, depth);<br>    }<br>}<br></code></pre></td></tr></table></figure>
<blockquote>
<p>详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/05_nestedHelloWorld.cu">nestedHelloWorld.cu</a>。注意需要编译选项-rdc为true，一些资料中提到还需要链接cudadevrt库，但笔者这里没有显式链接也正常执行了，推测是自动链接了。</p>
</blockquote>
<h3 id="嵌套归约">嵌套归约</h3>
<p>由于CUDA从11.6开始就不允许在设备端执行<code>cudaDeviceSynchronize()</code>来同步子网格，并且CUDA 12.x开始CDP（CUDA Dynamic Parallelism）替换成了CDP2，在细节上与CDP1有所不同。</p>
<p>首先我们实现一个嵌套归约求和的核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">gpuRecursiveReduce</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = threadIdx.x;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br>    <span class="hljs-type">int</span> *odata = &amp;g_odata[blockIdx.x];<br><br>    <span class="hljs-comment">// 递归中止条件</span><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">2</span> &amp;&amp; tid == <span class="hljs-number">0</span>)<br>    {<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>] + idata[<span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">return</span>;<br>    }<br><br>    <span class="hljs-type">int</span> stride = size &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (stride &gt; <span class="hljs-number">1</span> &amp;&amp; tid &lt; stride)<br>        idata[tid] += idata[tid + stride];<br>    __syncthreads();<br><br>    <span class="hljs-comment">// 嵌套调用生成子网格</span><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        gpuRecursiveReduce&lt;&lt;&lt;<span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride);<br>    __syncthreads();<br>}<br></code></pre></td></tr></table></figure>
<p>注意下面的语句。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">gpuRecursiveReduce&lt;&lt;&lt;<span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride);<br></code></pre></td></tr></table></figure>
<p>这里迫使该核函数在<code>cudaStreamTailLaunch</code>特殊流中执行，这是CDP2的新特性，这个流允许父网格在完成工作后才启动新网格。在大多数情况下，可以使用该流来实现与<code>cudaDeviceSynchronize()</code>相同的功能。</p>
<p><strong>在实际的实验过程中，笔者发现大多数情况下，这种嵌套的归约计算结果是错误的，但在小数据量的情况下是正确的，具体原因还有待分析。</strong></p>
<blockquote>
<p>详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/06_nested_reduce.cu">nested_reduce.cu</a>。</p>
</blockquote>
<p>对该核函数进行性能测试，结果如下所示。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> size: <span class="hljs-number">524288</span><br><span class="hljs-attribute">Execution</span> Configuration: grid <span class="hljs-number">1024</span> block <span class="hljs-number">512</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">470947</span> ms     cpu_sum: <span class="hljs-number">6451596</span><br><span class="hljs-attribute">gpu</span> nested      elapsed <span class="hljs-number">83</span>.<span class="hljs-number">5106</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>CUDA官方文档对于CDP2的同步有如下描述：</p>
<p>任何线程的CUDA运行时操作，包括核函数启动，在网格中的所有线程中都是可见的。这意味着父网格中的调用线程可以执行同步，以控制由网格中的任意线程在网格中的任何线程创建的流上启动网格的顺序。直到网格中所有线程的所有任务都已完成，网格的执行才被视为完成。如果网格中的所有线程在所有子网格完成之前退出，则将自动触发隐式同步操作。</p>
<p>大概意思就是，从CDP2开始，开发者已经不需要再核函数内进行显式的同步操作了，一切同步交给流和编译器来控制。去掉显式同步后的核函数实现如下所示。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">gpuRecursiveReduceNosync</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> tid = threadIdx.x;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br>    <span class="hljs-type">int</span> *odata = &amp;g_odata[blockIdx.x];<br><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">2</span> &amp;&amp; tid == <span class="hljs-number">0</span>)<br>    {<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>] + idata[<span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">return</span>;<br>    }<br><br>    <span class="hljs-type">int</span> stride = size &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (stride &gt; <span class="hljs-number">1</span> &amp;&amp; tid &lt; stride)<br>    {<br>        idata[tid] += idata[tid + stride];<br>        <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>            gpuRecursiveReduceNosync&lt;&lt;&lt;<span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride);<br>    }<br>}<br></code></pre></td></tr></table></figure>
<p>性能测试如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> size: <span class="hljs-number">524288</span><br><span class="hljs-attribute">Execution</span> Configuration: grid <span class="hljs-number">1024</span> block <span class="hljs-number">512</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">496094</span> ms     cpu_sum: <span class="hljs-number">6451596</span><br><span class="hljs-attribute">gpu</span> nested      elapsed <span class="hljs-number">78</span>.<span class="hljs-number">52</span> ms        gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> nestedNosyn elapsed <span class="hljs-number">69</span>.<span class="hljs-number">1308</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>可以观察到性能有一些提升。在这个版本的实现中，每个线程块产生一个子网格，并引起了大量的调用，具体过程如下图所示。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/4730c47f-e3ca-44d9-ac45-31d59345574b"></p>
<p>为了减少其创建的子网格数量，可以将启动方式改为下图所示的方法。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/792ec296-6651-4df4-a97c-a3838098cc35"></p>
<p>即只令第一个线程块的第一个线程来启动子网格，每次嵌套调用时，子线程块大小就会减小到其父线程块的一半。对于之前的实现来说，每个嵌套层的核函数执行过程都会有一半的线程空闲。但在这种实现方式中，所有空闲线程都会在每次核函数启动时被移除。这样会释放更多的计算资源，使得更多的线程块活跃起来。</p>
<p>同时，由于子线程块的大小是父线程块的一半，为了正确的计算数据的偏移，必须将一开始父线程块的大小传递进去。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">gpuRecursiveReduce2</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">int</span> stride, <span class="hljs-type">int</span> <span class="hljs-type">const</span> dim)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * dim;<br><br>    <span class="hljs-keyword">if</span> (stride == <span class="hljs-number">1</span> &amp;&amp; threadIdx.x == <span class="hljs-number">0</span>)<br>    {<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>] + idata[<span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">return</span>;<br>    }<br><br>    idata[threadIdx.x] += idata[threadIdx.x + stride];<br><br>    <span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span> &amp;&amp; blockIdx.x == <span class="hljs-number">0</span>)<br>        gpuRecursiveReduce2&lt;&lt;&lt;gridDim.x, stride / <span class="hljs-number">2</span>&gt;&gt;&gt;(g_idata, g_odata, stride / <span class="hljs-number">2</span>, dim);<br>}<br></code></pre></td></tr></table></figure>
<p>性能测试如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> size: <span class="hljs-number">524288</span><br><span class="hljs-attribute">Execution</span> Configuration: grid <span class="hljs-number">1024</span> block <span class="hljs-number">512</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">48291</span> ms      cpu_sum: <span class="hljs-number">6451596</span><br><span class="hljs-attribute">gpu</span> nested      elapsed <span class="hljs-number">76</span>.<span class="hljs-number">7643</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> nestedNosyn elapsed <span class="hljs-number">69</span>.<span class="hljs-number">8579</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> nested2     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">082464</span> ms     gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">025632</span> ms     gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure>
<p>虽然对比之前的嵌套归约提升很大，但其性能甚至不如之前实现的性能最差的相邻匹配的归约。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>CUDA编程——执行模型</p><p><a href="https://deleter-d.github.io/posts/47225/">https://deleter-d.github.io/posts/47225/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="https://deleter-d.github.io"><p>亦初</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-02-20</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-03-23</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/posts/9782/" target="_blank">CUDA编程——GPU加速库和OpenACC</a><br></span><span>  2.<a class="is-size-6" href="/posts/53610/" target="_blank">CUDA编程——调整指令集原语</a><br></span><span>  3.<a class="is-size-6" href="/posts/4919/" target="_blank">CUDA编程——流和并发</a><br></span><span>  4.<a class="is-size-6" href="/posts/50255/" target="_blank">CUDA编程——性能分析工具</a><br></span><span>  5.<a class="is-size-6" href="/posts/38038/" target="_blank">CUDA编程——共享内存和常量内存</a><br></span><span>  6.<a class="is-size-6" href="/posts/47184/" target="_blank">CUDA编程——全局内存</a><br></span><span>  7.<a class="is-size-6" href="/posts/50741/" target="_blank">CUDA编程——NVCC编译器</a><br></span><span>  8.<a class="is-size-6" href="/posts/57516/" target="_blank">CUDA编程模型概述</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://user-images.githubusercontent.com/56388518/194691384-1d4515ba-79ae-4e83-a485-bfaa5c64033e.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://user-images.githubusercontent.com/56388518/194691371-ad26d43d-b3b5-4fe5-9fc0-52a31333ca98.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/47184/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">CUDA编程——全局内存</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/50741/"><span class="level-item">CUDA编程——NVCC编译器</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: 'daa95f3554c2779420c5910516ab94d0',
            repo: 'Deleter-D.github.io',
            owner: 'Deleter-D',
            clientID: 'd087baa8a532e3b31fba',
            clientSecret: 'faec4c1d7046247c200bca62c9930d0799ce58a5',
            admin: ["Deleter-D"],
            createIssueManually: true,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cloudflare-cors-anywhere.wyp867909454.workers.dev/?https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex is-mobile" href="#cuda运行时"><span>CUDA运行时</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#初始化"><span>初始化</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#cuda执行模型概述"><span>CUDA执行模型概述</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#gpu架构概述"><span>GPU架构概述</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#线程束的本质"><span>线程束的本质</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#线程束和线程块"><span>线程束和线程块</span></a></li><li><a class="is-flex is-mobile" href="#线程束分化"><span>线程束分化</span></a></li><li><a class="is-flex is-mobile" href="#资源分配"><span>资源分配</span></a></li><li><a class="is-flex is-mobile" href="#延迟隐藏"><span>延迟隐藏</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#算术延迟隐藏"><span>算术延迟隐藏</span></a></li><li><a class="is-flex is-mobile" href="#内存延迟隐藏"><span>内存延迟隐藏</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#占用率"><span>占用率</span></a></li><li><a class="is-flex is-mobile" href="#同步"><span>同步</span></a></li><li><a class="is-flex is-mobile" href="#可扩展性"><span>可扩展性</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#并行性表现"><span>并行性表现</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#检测活跃线程束"><span>检测活跃线程束</span></a></li><li><a class="is-flex is-mobile" href="#检测内存操作"><span>检测内存操作</span></a></li><li><a class="is-flex is-mobile" href="#增大并行性"><span>增大并行性</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#避免分支分化"><span>避免分支分化</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#并行归约问题"><span>并行归约问题</span></a></li><li><a class="is-flex is-mobile" href="#并行归约中的分化"><span>并行归约中的分化</span></a></li><li><a class="is-flex is-mobile" href="#改善并行归约的分化"><span>改善并行归约的分化</span></a></li><li><a class="is-flex is-mobile" href="#交错配对的归约"><span>交错配对的归约</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#展开循环"><span>展开循环</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#展开的归约"><span>展开的归约</span></a></li><li><a class="is-flex is-mobile" href="#展开线程的归约"><span>展开线程的归约</span></a></li><li><a class="is-flex is-mobile" href="#完全展开的归约"><span>完全展开的归约</span></a></li><li><a class="is-flex is-mobile" href="#模板函数的归约"><span>模板函数的归约</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#归约小结"><span>归约小结</span></a></li><li><a class="is-flex is-mobile" href="#动态并行"><span>动态并行</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#嵌套执行"><span>嵌套执行</span></a></li><li><a class="is-flex is-mobile" href="#在gpu上嵌套hello-world"><span>在GPU上嵌套Hello World</span></a></li><li><a class="is-flex is-mobile" href="#嵌套归约"><span>嵌套归约</span></a></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg" alt="亦初"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">亦初</p><p class="is-size-6 is-block">落霞与孤鹜齐飞，秋水共长天一色</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>冰岛</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">75</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">76</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Deleter-D" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Deleter-D"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:18735855248@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Telegram" href="https://t.me/GoldPancake687"><i class="fab fa-telegram"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"来源《"+data.from+"》</p><p>提供者-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-25T02:07:10.000Z">2024-03-25</time></p><p class="title"><a href="/posts/43333/">深度学习框架机制及分布式并行</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/AI%E7%B3%BB%E7%BB%9F/">AI系统</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:49:53.000Z">2024-02-20</time></p><p class="title"><a href="/posts/9782/">CUDA编程——GPU加速库和OpenACC</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:45:21.000Z">2024-02-20</time></p><p class="title"><a href="/posts/53610/">CUDA编程——调整指令集原语</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:36:28.000Z">2024-02-20</time></p><p class="title"><a href="/posts/4919/">CUDA编程——流和并发</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:29:56.000Z">2024-02-20</time></p><p class="title"><a href="/posts/50255/">CUDA编程——性能分析工具</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/"><span class="level-start"><span class="level-item">前端</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/Vue/"><span class="level-start"><span class="level-item">Vue</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/axios/"><span class="level-start"><span class="level-item">axios</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/nodejs/"><span class="level-start"><span class="level-item">nodejs</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%8A%98%E8%85%BE/"><span class="level-start"><span class="level-item">折腾</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E5%AD%A6/"><span class="level-start"><span class="level-item">数学</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E5%AD%A6/%E7%9F%A9%E9%98%B5%E8%AE%BA/"><span class="level-start"><span class="level-item">矩阵论</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/03/"><span class="level-start"><span class="level-item">三月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag is-grey-lightest">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"><span class="tag">异构计算</span><span class="tag is-grey-lightest">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CUDA/"><span class="tag">CUDA</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"><span class="tag">毕昇编译器</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"><span class="tag">高性能计算</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue/"><span class="tag">Vue</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%9B%E6%89%A3/"><span class="tag">力扣</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/"><span class="tag">矩阵论</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/axios/"><span class="tag">axios</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"><span class="tag">异构编程</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/3D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/"><span class="tag">3D人体姿态估计</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87/"><span class="tag">论文</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ITK/"><span class="tag">ITK</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CVPR/"><span class="tag">CVPR</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag is-grey-lightest">2</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg" alt="亦初" height="28"></a><p class="size-small"><span>&copy; 2024 亦初</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作，如有侵权，请<a href="/message" target="_blank">留言</a>，笔者会立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2022/03/13 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="475747480" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('d087baa8a532e3b31fba','faec4c1d7046247c200bca62c9930d0799ce58a5','Deleter-D','Deleter-D.github.io',false);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('d087baa8a532e3b31fba','faec4c1d7046247c200bca62c9930d0799ce58a5','Deleter-D','Deleter-D.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>
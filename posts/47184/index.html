<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>CUDA编程——全局内存 - 亦初</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="亦初"><meta name="msapplication-TileImage" content="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="亦初"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由"><meta property="og:type" content="blog"><meta property="og:title" content="亦初"><meta property="og:url" content="https://deleter-d.github.io/"><meta property="og:site_name" content="亦初"><meta property="og:description" content="很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><meta property="article:published_time" content="2024-02-20T08:09:37.000Z"><meta property="article:modified_time" content="2024-02-27T09:37:44.297Z"><meta property="article:author" content="亦初"><meta property="article:tag" content="异构计算"><meta property="article:tag" content="CUDA"><meta property="article:tag" content="高性能计算"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://deleter-d.github.io/posts/47184/"},"headline":"亦初","image":[],"datePublished":"2024-02-20T08:09:37.000Z","dateModified":"2024-02-27T09:37:44.297Z","author":{"@type":"Person","name":"亦初"},"description":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由"}</script><link rel="canonical" href="https://deleter-d.github.io/posts/47184/"><link rel="icon" href="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.2"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="亦初" type="application/atom+xml">
</head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg" alt="亦初" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/music">音乐</a><a class="navbar-item" href="/message">留言</a><a class="navbar-item" href="/self-talking">碎碎念</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2024-02-20  <a class="commentCountImg" href="/posts/47184/#comment-container"><span class="display-none-class">d31f1ee1553dd170dce2551721fa9e93</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d31f1ee1553dd170dce2551721fa9e93">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 小时  <i class="fas fa-pencil-alt"> </i>15.6 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">CUDA编程——全局内存</h1><div class="content"><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p>
<span id="more"></span>
<h2 id="cuda内存模型概述">CUDA内存模型概述</h2>
<h3 id="cuda内存模型">CUDA内存模型</h3>
<p>对于开发者来说，存储器分为两大类：</p>
<ul>
<li>可编程的：需要显式控制哪些数据存放在可编程内存中；</li>
<li>不可编程的：不能决定数据的存放位置，由程序自动生成存放位置。</li>
</ul>
<p>CUDA内存模型提出了多种可编程内存：</p>
<ul>
<li>寄存器；</li>
<li>共享内存；</li>
<li>本地内存；</li>
<li>常量内存；</li>
<li>纹理内存；</li>
<li>全局内存。</li>
</ul>
<p>这些内存空间的层次结构如下图所示。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/f3635cc5-2ef0-43a1-bd3d-23f7cb7d0601"></p>
<h4 id="寄存器">寄存器</h4>
<p>寄存器是GPU上速度最快的内存空间，在核函数中声明一个没有其他修饰符的变量，通常存储在寄存器中。在核函数中声明的数组，若用于引用该数组的索引是常量且能在编译时确定，则该数组也存储在寄存器中。</p>
<p>寄存器是线程私有的，寄存器变量与核函数生命周期相同。若核函数使用的寄存器超过了硬件限制，则会用本地内存替代多占用的寄存器。nvcc编译器使用启发式策略来最小化寄存器使用，以免寄存器溢出。也可以手动显式添加额外信息来辅助编译器优化。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__global__ <span class="hljs-type">void</span> __launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor) <span class="hljs-built_in">kernel</span>(...) {}<br></code></pre></td></tr></table></figure>
<p><code>maxThreadsPerBlock</code>指出每个线程块可以包含的最大线程数，<code>minBlocksPerMultiprocessor</code>是可选参数，指出在每个SM中预期的最小常驻线程块数量。</p>
<p>还可以使用编译器选项<code>maxrregcount</code>来控制一个编译单元中所有核函数使用的寄存器的最大数量，例如<code>-maxrregcount=32</code>。</p>
<h4 id="本地内存">本地内存</h4>
<p>核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有：</p>
<ul>
<li>在编译时使用未知索引引用的本地数组；</li>
<li>可能会占用大量寄存器空间的较大本地结构体或数组；</li>
<li>任何不满足核函数寄存器限定条件的变量。</li>
</ul>
<p>溢出到本地内存中的变量本质上与全局内存在同一存储区域，因此本地内存的访问特点是高延迟和低带宽。</p>
<h4 id="共享内存">共享内存</h4>
<p>在核函数中使用<code>__shared__</code>修饰符修饰的变量存放在共享内存中。</p>
<p>由于共享内存是片上内存，所以与本地内存和全局内存相比，具有更高的带宽和更低的延迟，是可编程的。每个SM都有一定数量的由线程块分配的共享内存，因此不能过度使用共享内存，避免在不经意间限制活跃线程束的数量。共享内存在核函数内声明，生命周期伴随整个线程块。</p>
<p>共享内存是线程之间通信的基本方式，访问共享内存必须使用<code>__syncthreads()</code>来进行同步。该函数设置了一个执行障碍点，使得同一线程块中的所有线程必须在其他线程开始执行前到达该处。</p>
<p>SM中的一级缓存和共享内存都使用64KB的片上内存，它通过静态划分，但在运行时可以使用<code>cudaFuncSetCacheConfig()</code>来进行动态配置。该API传入两个参数，第一个是函数指针，第二个是CUDA提供的一个枚举类<code>cudaFuncCache</code>成员，它包含4个成员：</p>
<ul>
<li><code>cudaFuncCachePreferNone</code>：没有参考值（默认）；</li>
<li><code>cudaFuncCachePreferShared</code>：建议48KB共享内存和16KB一级缓存；</li>
<li><code>cudaFuncCachePreferL1</code>：建议48KB一级缓存和16KB共享内存；</li>
<li><code>cudaFuncCachePreferEqual</code>：建议相同尺寸的一级缓存和共享内存，均为32KB。</li>
</ul>
<blockquote>
<p>这里的<code>cudaFuncSetCacheConfig()</code>API已经是比较旧的方式了，在计算能力7.x及以上的设备中，更推荐使用<code>cudaFuncSetAttribute()</code>来配置。该API传入三个参数，第一个参数是函数指针，第二个是CUDA提供的一个枚举类<code>cudaFuncAttribute</code>成员，第三个是具体的提示值。</p>
<p><code>cudaFuncAttribute</code>有9个成员，但常用的只有两个（其它成员是关于线程块集群的，这里不多描述）：</p>
<ul>
<li><code>cudaFuncAttributeMaxDynamicSharedMemorySize</code>：指定最大动态共享内存大小；</li>
<li><code>cudaFuncAttributePreferredSharedMemoryCarveout</code>：首选的共享内存和一级缓存拆分大小；</li>
</ul>
<p>通过第三个参数来指定第二个参数成员的具体值，例如下面的语句提示编译器将片上内存的50%分配给共享内存。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaFuncSetAttribute</span>(MyKernel, cudaFuncAttributePreferredSharedMemoryCarveout, <span class="hljs-number">50</span>);<br></code></pre></td></tr></table></figure>
<p><code>cudaFuncSetAttribute()</code>放松了对指定共享内存容量的强制，分割被视为一种提示。而旧的<code>cudaFuncSetCacheConfig()</code>将共享内存容量视为核函数启动的硬性要求。因此，使用不同共享内存配置的核函数将进行一些不必要地序列化。</p>
</blockquote>
<h4 id="常量内存">常量内存</h4>
<p>常量内存驻留在设备内存中，并在每个SM专用的常量缓存中缓存，使用<code>__constant__</code>来修饰。</p>
<p>常量变量必须在全局空间内和所有核函数之外进行声明，所有计算能力的设备都只能声明64KB的常量内存。常量内存是静态声明的，并对同一编译单元中的所有核函数可见。</p>
<p>核函数只能从常量内存中读取数据，因此常量内存必须在主机端使用<code>cudaMemcpyToSymbol()</code>来初始化，大多数情况下这个函数是同步的。</p>
<p>线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。</p>
<h4 id="纹理内存">纹理内存</h4>
<p>纹理内存驻留在设备内存中，并在每个SM的只读缓存中缓存。纹理内存是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对二维空间局部性的优化，所以线程束中使用纹理内存访问二维数据的线程可以达到最优性能。</p>
<h4 id="全局内存">全局内存</h4>
<p>全局内存是GPU中最大、延迟最高且最常使用的内存。它的声明可以在任何SM设备上被访问到，并贯穿程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明，可以使用<code>__device__</code>在设备代码中静态声明一个变量。</p>
<p>从多个线程访问全局内存时要注意，由于线程的执行不能跨线程块同步，不同线程块内的多个线程并发修改全局内存的同一位置可能会导致未定义的行为。</p>
<p>全局内存常驻于设备内存中，可通过32字节、64字节或128字节的内存事务进行访问。这些内存事务必须自然对齐，也就是说首地址必须是32字节、64字节或128字节的倍数。当一个线程束执行内存加载 / 存储时，需要满足的传输数量取决于两个因素：</p>
<ul>
<li>跨线程的内存地址分布；</li>
<li>每个事务内存地址的对齐方式。</li>
</ul>
<p>一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就导致了数据吞吐率的降低。</p>
<h4 id="gpu缓存">GPU缓存</h4>
<p>GPU缓存是不可编程的内存，有四种类型的缓存：</p>
<ul>
<li>一级缓存；</li>
<li>二级缓存；</li>
<li>只读常量缓存；</li>
<li>只读纹理缓存。</li>
</ul>
<p>每个SM都有一个一级缓存，所有的SM共享一个二级缓存。一级和二级缓存用于存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。GPU上只有内存加载操作可以被缓存，内存存储操作不能被缓存。每个SM有一个只读常量缓存和只读纹理缓存，用于在设备内存只提高来自于各自内存空间中的读取性能。</p>
<h4 id="cuda变量声明小结">CUDA变量声明小结</h4>
<p>CUDA变量和类型修饰符总结如下表。</p>
<table>
<thead>
<tr class="header">
<th>修饰符</th>
<th>变量类型</th>
<th>存储器</th>
<th>作用域</th>
<th>生命周期</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>标量</td>
<td>寄存器</td>
<td>线程</td>
<td>线程</td>
</tr>
<tr class="even">
<td></td>
<td>数组</td>
<td>本地内存</td>
<td>线程</td>
<td>线程</td>
</tr>
<tr class="odd">
<td><code>__shared__</code></td>
<td>标量 / 数组</td>
<td>共享内存</td>
<td>线程块</td>
<td>线程块</td>
</tr>
<tr class="even">
<td><code>__device__</code></td>
<td>标量 / 数组</td>
<td>全局内存</td>
<td>全局</td>
<td>应用程序</td>
</tr>
<tr class="odd">
<td><code>__constant__</code></td>
<td>标量 / 数组</td>
<td>常量内存</td>
<td>全局</td>
<td>应用程序</td>
</tr>
</tbody>
</table>
<p>设备存储器的特征总结如下表。</p>
<table>
<thead>
<tr class="header">
<th>存储器</th>
<th>位置</th>
<th>缓存</th>
<th>存取</th>
<th>范围</th>
<th>生命周期</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>寄存器</td>
<td>片上</td>
<td>n/a</td>
<td>R/W</td>
<td>一个线程</td>
<td>线程</td>
</tr>
<tr class="even">
<td>本地内存</td>
<td>片外</td>
<td>Yes (2.x以上)</td>
<td>R/W</td>
<td>一个线程</td>
<td>线程</td>
</tr>
<tr class="odd">
<td>共享内存</td>
<td>片上</td>
<td>n/a</td>
<td>R/W</td>
<td>块内所有线程</td>
<td>线程块</td>
</tr>
<tr class="even">
<td>全局内存</td>
<td>片外</td>
<td>Yes (2.x以上)</td>
<td>R/W</td>
<td>所有线程+主机</td>
<td>主机配置</td>
</tr>
<tr class="odd">
<td>常量内存</td>
<td>片外</td>
<td>Yes</td>
<td>R</td>
<td>所有线程+主机</td>
<td>主机配置</td>
</tr>
<tr class="even">
<td>纹理内存</td>
<td>片外</td>
<td>Yes</td>
<td>R</td>
<td>所有线程+主机</td>
<td>主机配置</td>
</tr>
</tbody>
</table>
<h4 id="静态全局内存">静态全局内存</h4>
<p>实现一段静态声明全局内存变量的代码，在主机端传入值，在核函数中对值进行修改，再传回主机端，核心代码如下。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__device__ <span class="hljs-type">float</span> devData;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">checkGlobalVariable</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    devData += <span class="hljs-number">2.0f</span>;<br>}<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> <span class="hljs-type">const</span> *argv[])</span></span><br><span class="hljs-function"></span>{<br>	...<br>    <span class="hljs-type">float</span> value = <span class="hljs-number">3.14f</span>;<br>    <span class="hljs-built_in">cudaMemcpyToSymbol</span>(devData, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    checkGlobalVariable&lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>&gt;&gt;&gt;();<br>    <span class="hljs-built_in">cudaMemcpyFromSymbol</span>(&amp;value, devData, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>	...<br>}<br></code></pre></td></tr></table></figure>
<p>值的注意的是，尽管设备的全局变量声明与主机代码在同一文件中，主机代码也不能直接访问设备变量。类似地，设备代码也不能直接访问主机变量。</p>
<p>唯一比较像是主机代码访问设备变量的地方是<code>(devData, &amp;value, sizeof(float))</code>，但该接口是在CUDA运行时API中的，内部可以隐式的使用GPU来访问。而且在这里<code>devData</code>作为一个标识符，并不是全局内存变量的地址。在核函数中，<code>devData</code>被当作全局内存中的一个变量。</p>
<p><code>cudaMemcpy()</code>并不能直接以下面语句中的变量地址传递数据给<code>devData</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaMemcpy</span>(&amp;devData, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br></code></pre></td></tr></table></figure>
<p>我们无法在主机端的设备变量中使用<code>&amp;</code>运算符，因为它只是一个在GPU上表示物理位置的符号。但可以通过下面的语句显式获取一个全局变量的地址。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">float</span> *dptr;<br><span class="hljs-built_in">cudaGetSymbolAddress</span>((<span class="hljs-type">void</span> **)&amp;dptr, devData);<br></code></pre></td></tr></table></figure>
<p>然后就可以使用<code>cudaMemcpy()</code>来进行拷贝操作。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaMemcpy</span>(dptr, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice)<br></code></pre></td></tr></table></figure>
<blockquote>
<p>详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/01_global_variable.cu">global_variable.cu</a>，其中展示了<code>cudaMemcpyToSymbol()</code>和<code>cudaMemcpy()</code>两种操作方式。</p>
</blockquote>
<p>有一种例外可以直接从主机引用GPU内存：CUDA固定内存。将会在后续进行介绍。</p>
<h2 id="内存管理">内存管理</h2>
<h3 id="设备内存">设备内存</h3>
<p>设备内存可以作为线性内存分配，也可以作为CUDA 数组来分配。CUDA数组是为了纹理获取而优化过的不透明内存布局。</p>
<p>线性内存是由一个统一的地址空间分配的，分开分配的实体可以通过指针相互引用。地址空间的大小取决于主机系统（CPU）和所用GPU的计算能力。</p>
<table>
<thead>
<tr class="header">
<th>计算能力</th>
<th>x86_64 (AMD64)</th>
<th>POWER (ppc64le)</th>
<th>ARM64</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>5.3及之前</td>
<td>40bit</td>
<td>40bit</td>
<td>40bit</td>
</tr>
<tr class="even">
<td>6.0及以后</td>
<td>47bit</td>
<td>49bit</td>
<td>48bit</td>
</tr>
</tbody>
</table>
<p>线性内存使用<code>cudaMalloc()</code>分配，使用<code>cudaFree()</code>释放，主机内存与设备内存之间的数据搬移通过<code>cudaMemcpy()</code>完成。</p>
<p>下面以向量加法为例。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">VecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> N)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span> (i &lt; N)<br>        C[i] = A[i] + B[i];<br>}<br><br><span class="hljs-comment">// 主机代码</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> N = ...;<br>    <span class="hljs-type">size_t</span> size = N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-comment">// 在主机端申请输入向量h_A和h_B及结果向量h_C的内存</span><br>    <span class="hljs-type">float</span>* h_A = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-type">float</span>* h_B = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-type">float</span>* h_C = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-comment">// 初始化输入向量</span><br>    ...<br>    <span class="hljs-comment">// 在设备端申请向量内存</span><br>    <span class="hljs-type">float</span>* d_A; <span class="hljs-built_in">cudaMalloc</span>(&amp;d_A, size);<br>    <span class="hljs-type">float</span>* d_B; <span class="hljs-built_in">cudaMalloc</span>(&amp;d_B, size);<br>    <span class="hljs-type">float</span>* d_C; <span class="hljs-built_in">cudaMalloc</span>(&amp;d_C, size);<br>    <span class="hljs-comment">// 从主机端拷贝数据到设备端</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-comment">// 核函数调用</span><br>    <span class="hljs-type">int</span> threadsPerBlock = <span class="hljs-number">256</span>;<br>    <span class="hljs-type">int</span> blocksPerGrid = (N + threadsPerBlock - <span class="hljs-number">1</span>) / threadsPerBlock;<br>    VecAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);<br>    <span class="hljs-comment">// 从设备端拷贝数据到主机端</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);<br>    <span class="hljs-comment">// 释放设备内存</span><br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br>    <span class="hljs-comment">// 释放主机内存</span><br>    ...<br>}<br></code></pre></td></tr></table></figure>
<blockquote>
<p>上例详细代码见<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/00_CUDA_official_documentation/02_example_vec_add.cu">example_vec_add.cu</a>，代码中的注释是关于GPU算子开发的基本思路。</p>
</blockquote>
<p>也可以通过<code>cudaMallocPitch()</code>和<code>cudaMalloc3D()</code>来分配线性内存。推荐用于2D或3D数组的分配，这样可以确保分配被适当填充，以满足内存对齐要求。同时可以保证在访问行地址或者执行2D数组与其他设备内存区域的拷贝操作时的性能（2D或3D内存拷贝使用<code>cudaMemcpy2D()</code>与<code>cudaMemcpy3D()</code>）。</p>
<p>必须使用返回的pitch（或stride）来访问数组元素，下面以分配一个<code>width * height</code>的二维浮点型数组为例。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 主机代码</span><br><span class="hljs-type">int</span> width = <span class="hljs-number">64</span>, height = <span class="hljs-number">64</span>;<br><span class="hljs-type">float</span>* devPtr;<br><span class="hljs-type">size_t</span> pitch;<br><span class="hljs-built_in">cudaMallocPitch</span>(&amp;devPtr, &amp;pitch, width * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height);<br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;(devPtr, pitch, width, height);<br><br><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MyKernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* devPtr, <span class="hljs-type">size_t</span> pitch, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> r = <span class="hljs-number">0</span>; r &lt; height; ++r) {<br>        <span class="hljs-type">float</span>* row = (<span class="hljs-type">float</span>*)((<span class="hljs-type">char</span>*)devPtr + r * pitch);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> c = <span class="hljs-number">0</span>; c &lt; width; ++c) {<br>            <span class="hljs-type">float</span> element = row[c];<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure>
<p>下面以分配<code>width * height * depth</code>的三维浮点型数组为例。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 主机代码</span><br><span class="hljs-type">int</span> width = <span class="hljs-number">64</span>, height = <span class="hljs-number">64</span>, depth = <span class="hljs-number">64</span>;<br>cudaExtent extent = <span class="hljs-built_in">make_cudaExtent</span>(width * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height, depth);<br>cudaPitchedPtr devPitchedPtr;<br><span class="hljs-built_in">cudaMalloc3D</span>(&amp;devPitchedPtr, extent);<br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;(devPitchedPtr, width, height, depth);<br><br><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MyKernel</span><span class="hljs-params">(cudaPitchedPtr devPitchedPtr, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height, <span class="hljs-type">int</span> depth)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">char</span>* devPtr = devPitchedPtr.ptr;<br>    <span class="hljs-type">size_t</span> pitch = devPitchedPtr.pitch;<br>    <span class="hljs-type">size_t</span> slicePitch = pitch * height;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> z = <span class="hljs-number">0</span>; z &lt; depth; ++z) {<br>        <span class="hljs-type">char</span>* slice = devPtr + z * slicePitch;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> y = <span class="hljs-number">0</span>; y &lt; height; ++y) {<br>            <span class="hljs-type">float</span>* row = (<span class="hljs-type">float</span>*)(slice + y * pitch);<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> x = <span class="hljs-number">0</span>; x &lt; width; ++x) {<br>                <span class="hljs-type">float</span> element = row[x];<br>            }<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure>
<p>下面是通过运行时API访问全局变量的各种方式的例子。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++">__constant__ <span class="hljs-type">float</span> constData[<span class="hljs-number">256</span>];<br><span class="hljs-type">float</span> data[<span class="hljs-number">256</span>];<br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(constData, data, <span class="hljs-built_in">sizeof</span>(data));<br><span class="hljs-built_in">cudaMemcpyFromSymbol</span>(data, constData, <span class="hljs-built_in">sizeof</span>(data));<br><br>__device__ <span class="hljs-type">float</span> devData;<br><span class="hljs-type">float</span> value = <span class="hljs-number">3.14f</span>;<br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(devData, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><br>__device__ <span class="hljs-type">float</span>* devPointer;<br><span class="hljs-type">float</span>* ptr;<br><span class="hljs-built_in">cudaMalloc</span>(&amp;ptr, <span class="hljs-number">256</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(devPointer, &amp;ptr, <span class="hljs-built_in">sizeof</span>(ptr));<br></code></pre></td></tr></table></figure>
<p><code>cudaGetSymbolAddress()</code>可以获取声明在全局内存空间中的已分配内存的变量地址，通过<code>cudaGetSymbolSize()</code>来获取分配内存的大小。</p>
<h3 id="内存传输">内存传输</h3>
<p>内存传输使用<code>cudaMemcpy()</code>函数，其最后一个参数用来指定数据拷贝方向，有四个取值：</p>
<ul>
<li><code>cudaMemcpyHostToHost</code>；</li>
<li><code>cudaMemcpyHostToDevice</code>；</li>
<li><code>cudaMemcpyDeviceToHost</code>；</li>
<li><code>cudaMemcpyDeviceToDevice</code>。</li>
</ul>
<p>如果目的地址和源地址与最后一个参数指定的方向不一致，则<code>cudaMemcpy()</code>的行为是未定义的。大多数情况下该函数是同步的。</p>
<h3 id="锁页主机内存固定主机内存">锁页主机内存（固定主机内存）</h3>
<p>CUDA运行时提供了一些函数，来允许使用锁页主机内存（Page-Locked Host Memory）,也称为固定主机内存（Pinned Host Memory），与<code>malloc()</code>分配的可分页主机内存相对。</p>
<ul>
<li><code>cudaHostAlloc()</code>和<code>cudaFreeHost()</code>分配并释放锁页主机内存；</li>
<li><code>cudaHostRegister()</code>将<code>malloc()</code>分配的内存中某范围内的页面锁定。</li>
</ul>
<p>使用锁页主机内存的优势：</p>
<ul>
<li>锁页主机内存与设备内存之间的数据搬移可以与<a href="https://deleter-d.github.io/posts/4919/#异步并发执行">异步并发执行</a>中提到的某些设备的核函数并发执行；</li>
<li>在某些设备上，锁页主机内存可以映射到设备的地址空间中，无需在主机和设备之间搬移数据，<a href="#映射内存（零拷贝内存）">映射内存</a>中有详细说明；</li>
<li>在具有前端总线（Front-side Bus, FSB）的系统上，若主机内存被分配为锁页内存，则主机内存和设备内存之间的带宽会变高；若主机内存还被分配为写组合内存，则带宽会更大，详见<a href="#写组合内存">写组合内存</a>。</li>
</ul>
<blockquote>
<p>分配的主机内存默认是可分页的（pageable），但GPU不能在可分页主机内存上安全地访问数据。因为当主机的操作系统在物理位置上移动这些数据的时候，GPU时无法控制的。</p>
<p>当从可分页主机内存传输数据到设备时，CUDA驱动程序首先分配临时的锁页内存，将主机源数据拷贝到锁页内存中后，再将锁页内存中的数据拷贝到设备中。</p>
<p>我们对比在相同数据量下，可分页内存与设备内存之间的拷贝性能与锁页内存与设备内存之间的拷贝性能，详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/02_pageable_memory.cu">pageable_memory.cu</a>与<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/03_page_locked_memory.cu">page_locked_memory.cu</a>。使用<code>nsys</code>中的<code>nvprof</code>来分析内存拷贝操作的耗时。</p>
<p>可分页内存与设备内存之间的拷贝耗时如下。</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dns">Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)      Operation     <br>--------  ---------------  -----  -----------  -----------  ---------  ---------  -----------  ------------------<br>  <span class="hljs-number">50</span>.<span class="hljs-number">0</span>        <span class="hljs-number">1,144,966</span>      <span class="hljs-number">1</span>  <span class="hljs-number">1,144,966</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,144,966</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,144,966</span>  <span class="hljs-number">1,144,966</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy HtoD]<br>  <span class="hljs-number">50</span>.<span class="hljs-number">0</span>        <span class="hljs-number">1,142,693</span>      <span class="hljs-number">1</span>  <span class="hljs-number">1,142,693</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,142,693</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,142,693</span>  <span class="hljs-number">1,142,693</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy DtoH]<br></code></pre></td></tr></table></figure>
<p>锁页内存与设备内存之间的拷贝耗时如下。</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dns">Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)      Operation     <br>--------  ---------------  -----  ---------  ---------  --------  --------  -----------  ------------------<br>  <span class="hljs-number">51</span>.<span class="hljs-number">9</span>          <span class="hljs-number">686,915</span>      <span class="hljs-number">1</span>  <span class="hljs-number">686,915</span>.<span class="hljs-number">0</span>  <span class="hljs-number">686,915</span>.<span class="hljs-number">0</span>   <span class="hljs-number">686,915</span>   <span class="hljs-number">686,915</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy HtoD]<br>  <span class="hljs-number">48</span>.<span class="hljs-number">1</span>          <span class="hljs-number">637,475</span>      <span class="hljs-number">1</span>  <span class="hljs-number">637,475</span>.<span class="hljs-number">0</span>  <span class="hljs-number">637,475</span>.<span class="hljs-number">0</span>   <span class="hljs-number">637,475</span>   <span class="hljs-number">637,475</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy DtoH]<br></code></pre></td></tr></table></figure>
<p>可以观察到，锁页内存与设备内存之间的拷贝耗时要大幅度小于可分页内存与设备内存之间的拷贝操作。</p>
</blockquote>
<h4 id="可移植内存">可移植内存</h4>
<p>锁页内存可以与系统中的任何设备结合使用，但默认情况下，上述提到的锁页内存的优势只有分配这片锁页内存的设备可以享受到（如有与该设备共享统一地址空间（详见<a href="#统一虚拟地址空间">统一虚拟地址空间</a>）的设备，则这些设备也能享受这些优势）。</p>
<p>可以通过将<code>cudaHostAllocPortable</code>标志传给<code>cudaHostAlloc()</code>来分配锁页内存，或将<code>cudaHostRegisterPortable</code>标志传给<code>cudaHostRegister()</code>来锁定页面，使得所有设备都能够享受上面提到的优势。</p>
<h4 id="写组合内存">写组合内存</h4>
<p>默认情况下，锁页主机内存是作为可缓存状态申请的。此外有一种可选的申请方式，通过将<code>cudaHostAllocWriteCombined</code>标志传给<code>cudaHostAlloc()</code>来申请写组合内存（Write-Combining Memory）。</p>
<p>写组合内存释放了主机的L1和L2缓存，使程序的其他部分可以使用更多的缓存。此外，在PCI-E总线上传输时，写组合内存不会被窥探，使得传输性能提高40%。</p>
<p>从主机的写组合内存中读取数据速度非常慢，故写组合内存通常只用于仅主机写入内存的情况。</p>
<p>应该避免在写组合内存上使用CPU原子指令，因为不是所有CPU实现都能保证该功能。</p>
<h4 id="映射内存零拷贝内存">映射内存（零拷贝内存）</h4>
<blockquote>
<p>通常情况下，主机不能直接访问设备变量，设备也不能直接访问主机变量。但有一种主机和设备都可以访问的内存——零拷贝内存。</p>
</blockquote>
<p>通过将<code>cudaHostAllocMapped</code>标志传给<code>cudaHostAlloc()</code>，或将<code>cudaHostRegisterMapped</code>标志传给<code>cudaHostRegister()</code>，可以使锁页主机内存映射到设备的地址空间中。因此，这样的内存区域通常有两个地址：一个在主机内存中，由<code>cudaHostAllco()</code>或<code>malloc()</code>返回；另一个在设备内存中，可以使用<code>cudaHostGetDevicePointer()</code>来检索，从而在核函数中访问该内存空间。</p>
<p>唯一的例外是使用<code>cudaHostAlloc()</code>分配的指针，以及主机和设备使用统一地址空间（详见<a href="#统一虚拟地址空间">统一虚拟地址空间</a>）的情况下。</p>
<p>直接从核函数中访问主机内存并不能提供与设备内存相同的带宽，但确实具有一些优势：</p>
<ul>
<li>无需在设备内存中分配空间，也不需要在主机内存和设备内存之间搬移数据，会根据核函数的需要隐式地进行数据传输；</li>
<li>无需使用流（详见<a href="https://deleter-d.github.io/posts/4919/#并发数据传输">并发数据传输</a>）来使数据传输和核函数同时执行，核函数发起的数据传输将自动地与核函数同时执行。</li>
</ul>
<p>但是，由于主机和设备共享映射后的锁页内存，因此程序必须使用流或事件同步内存访问（详见<a href="https://deleter-d.github.io/posts/4919/#异步并发执行">异步并发执行</a>），以避免任何写后读、读后写或写后写等潜在危险行为。</p>
<p>为了能够检索到所有映射后的锁页内存的设备指针，在执行任何CUDA调用之前，必须通过将<code>cudaDeviceMapHost</code>标志传给<code>cudaSetDeviceFlags()</code>来启动锁页内存映射。否则<code>cudaHostGetDevicePointer()</code>将返回一个错误。</p>
<p>如果设备不支持锁页内存的映射，<code>cudaHostGetDevicePointer()</code>也会返回一个错误。程序可以通过检查设备属性<code>canMapHostMemory</code>来判断是否支持该功能，若支持，则该属性为1。</p>
<p>值得注意的是，从主机或其他设备的角度来看，在映射后的锁页内存上的原子操作并不是原子操作（详见官方文档<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions">Atomic Functions</a>）。</p>
<p>还要注意的是，从主机和其他设备的角度来看，CUDA运行时要求由设备发起的对主机内存的1字节、2字节、4字节和8字节天然对齐的加载和存储保留为单一访问。在某些平台上，对内存的原子操作可能会被设备分解为单独的加载和存储操作。这些加载和存储操作对天然对齐访问的保留有相同的要求。例如，某PCI-E拓扑将8字节天然对齐写入拆分为两个4字节写入，CUDA运行时不支持在主机和设备之间基于这种PCI-E总线拓扑进行访问。</p>
<blockquote>
<p>我们尝试利用映射内存来执行一个向量求和的操作，对比使用设备内存和映射内存的情况，详细代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/04_mapped_memory.cu">mapped_memory.cu</a>。经过分析不同数据量情况下的性能，计算减速比，可以总结出下表。<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.158ex;" xmlns="http://www.w3.org/2000/svg" width="25.198ex" height="3.447ex" role="img" focusable="false" viewBox="0 -1011.8 11137.5 1523.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">减</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">速</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">比</text></g><g data-mml-node="mo" transform="translate(3277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4333.6,0)"><g data-mml-node="mrow" transform="translate(220,481.4) scale(0.707)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">使</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">映</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">射</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">内</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">耗</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g></g><g data-mml-node="mrow" transform="translate(220,-370.3) scale(0.707)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">使</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">设</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">备</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">内</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">耗</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g></g><rect width="6564" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>。</p>
<table>
<thead>
<tr class="header">
<th>数据量</th>
<th>设备内存（ns）</th>
<th>映射内存（ns）</th>
<th>减速比</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1KB</td>
<td>1,312</td>
<td>2,688</td>
<td>2.0488</td>
</tr>
<tr class="even">
<td>4KB</td>
<td>1,344</td>
<td>3,200</td>
<td>2.3810</td>
</tr>
<tr class="odd">
<td>16KB</td>
<td>1,312</td>
<td>4,800</td>
<td>3.6585</td>
</tr>
<tr class="even">
<td>64KB</td>
<td>1,472</td>
<td>8,351</td>
<td>5.6732</td>
</tr>
<tr class="odd">
<td>256KB</td>
<td>1,856</td>
<td>24,511</td>
<td>13.2064</td>
</tr>
<tr class="even">
<td>1MB</td>
<td>5,312</td>
<td>89,950</td>
<td>16.9334</td>
</tr>
<tr class="odd">
<td>4MB</td>
<td>27,232</td>
<td>350,232</td>
<td>12.8610</td>
</tr>
<tr class="even">
<td>16MB</td>
<td>105,405</td>
<td>1,377,504</td>
<td>13.0687</td>
</tr>
<tr class="odd">
<td>64MB</td>
<td>428,246</td>
<td>5,514,658</td>
<td>12.8773</td>
</tr>
</tbody>
</table>
<p>从这样的结果可以看出，如果想要在主机和设备间共享的少量数据，映射内存是一个不错的选择。但对于大的数据量来说，映射内存并不是好的选择，会导致性能显著的下降。</p>
</blockquote>
<h3 id="统一虚拟地址空间">统一虚拟地址空间</h3>
<p>从CUDA 4.0开始引入了一种特殊的寻址方式，成为统一虚拟寻址（UVA）。通过CUDA API分配的所有主机内存以及支持UVA的设备分配的所有设备内存都在此虚拟地址范围内。</p>
<ul>
<li>通过CUDA分配的任何主机内存，或使用统一地址空间的设备内存，可以使用<code>cudaPointerGetAttributes()</code>来获取指针的信息。</li>
<li>当与使用统一地址空间的任何设备之间发生内存拷贝时，<code>cudaMemcpy*()</code>的<code>cudaMemcpyKind</code>参数可以设置为<code>cudaMemcpyDefault</code>。这也适用于未通过CUDA分配的主机指针，只要当前设备使用统一寻址即可。</li>
<li>通过<code>cudaHostAlloc()</code>分配的内存可以自动移植到使用统一地址空间的设备上（详见<a href="#可移植内存">可移植内存</a>），并且<code>cudaHostAlloc()</code>返回的指针可以直接从这些设备上运行的核函数中使用，即不需要像映射内存中描述的那样通过<code>cudaHostGetDevicePointer()</code>获取设备指针。</li>
</ul>
<p>应用程序可以通过检查<code>unifiedAddressing</code>设备属性是否等于1来查询设备是否支持统一地址空间。</p>
<blockquote>
<p>详细示例代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/05_unified_virtual_address.cu">unified_virtual_address.cu</a>。</p>
</blockquote>
<h3 id="统一内存寻址">统一内存寻址</h3>
<p>CUDA 6.0中引入了统一内存寻址，用于简化CUDA中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的指针在CPU和GPU上访问。底层在统一内存空间中自动在主机和设备之间进行数据传输。</p>
<p>统一内存寻址依赖于统一虚拟寻址（UVA），但它们是完全不同的技术。UAV只是为系统中所有处理器提供了单一的虚拟内存地址空间。但UAV不会自动改变数据的物理位置，这是统一内存寻址的一个特有功能。</p>
<p>托管内存指的是由底层系统自动分配的统一内存，与特定设备的分配内存可以互操作，如它们的创建都使用<code>cudaMalloc()</code>。故可以在核函数中使用两种内存：</p>
<ul>
<li>由系统控制的托管内存；</li>
<li>由程序明确分配和调用的未托管内存。</li>
</ul>
<p>在设备内存上的有效CUDA操作也同样适用于托管内存，主要区别是主机也能引用和访问托管内存。</p>
<p>托管内存可以被静态分配，也可以被动态分配。使用<code>__managed__</code>修饰符静态声明一个设备变量作为托管变量，该变量可以从主机或设备代码中直接被引用。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__device__ __managed__ <span class="hljs-type">int</span> y;<br></code></pre></td></tr></table></figure>
<p>也可以使用CUDA运行时API<code>cudaMallocManaged()</code>来动态分配托管内存。</p>
<h3 id="设备内存l2访问管理">设备内存L2访问管理</h3>
<p>当CUDA核心反复访问全局内存中的数据区域时，这种数据访问是持久化的。若数据只被访问一次，则这种数据访问是流式的。从CUDA 11.0开始，计算能力8.0及以上的设备能够影响L2缓存中的数据持久化，从而提供更高的带宽和更低的全局内存访问延迟。</p>
<h4 id="为持久化访问预留的l2缓存">为持久化访问预留的L2缓存</h4>
<p>可以预留一部分L2缓存用于持久化全局内存的数据访问，持久化访问优先使用L2缓存的这个部分。只有当持久化访问未使用这一部分时，普通或流式访问才能使用L2缓存。</p>
<p>用于持久化访问的L2预留缓存大小可以在一定范围内调整。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, device_id);<br><span class="hljs-type">size_t</span> size = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">int</span>(prop.l2CacheSize * <span class="hljs-number">0.75</span>), prop.persistingL2CacheMaxSize);<br><span class="hljs-comment">// 预留3/4的L2缓存用于持久化访问，或用最大L2持久化缓存大小</span><br><span class="hljs-built_in">cudaDeviceSetLimit</span>(cudaLimitPersistingL2CacheSize, size);<br></code></pre></td></tr></table></figure>
<p>当GPU配置为多实例GPU（MIG）模式时，将禁用L2缓存预留功能。当使用多进程服务（MPS）时，<code>cudaDeviceSetLimit()</code>无法改变L2缓存的预留大小，只能通过MPS服务器启动时的环境变量<code>CUDA_DEVICE_DEFAULT_PERSISTING_L2_CACHE_PERCENTAGE_LIMIT</code>来指定。</p>
<h4 id="l2持久化访问策略">L2持久化访问策略</h4>
<p>访问策略窗口指定了一个连续的全局内存区域及其持久化属性。</p>
<p>下面的例子使用CUDA流（CUDA Stream）设置L2持久化访问窗口。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 流级别属性数据结构</span><br>cudaStreamAttrValue stream_attribute;<br><span class="hljs-comment">// 全局内存数据指针</span><br>stream_attribute.accessPolicyWindow.base_ptr  = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(ptr);<br><span class="hljs-comment">// 持久化访问的总字节数，必须小于cudaDeviceProp::accessPolicyMaxWindowSize</span><br>stream_attribute.accessPolicyWindow.num_bytes = num_bytes;<br><br><span class="hljs-comment">// 缓存命中率</span><br>stream_attribute.accessPolicyWindow.hitRatio  = <span class="hljs-number">0.6</span>;<br><span class="hljs-comment">// 缓存命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting;<br><span class="hljs-comment">// 缓存未命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;<br><br><span class="hljs-comment">// 将属性配置到cudaStream_t类型的CUDA流中</span><br><span class="hljs-built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);<br></code></pre></td></tr></table></figure>
<p>当核函数在CUDA流中执行时，全局内存范围<code>[ptr..ptr+num_bytes)</code>内的数据比其他地方的数据更有可能被持久化在L2缓存中。</p>
<p>下面的例子是L2缓存持久化在CUDA图核结点（CUDA Graph Kernel Node）中的应用。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 核级别的属性数据结构</span><br>cudaKernelNodeAttrValue node_attribute;<br><span class="hljs-comment">// 全局内存数据指针</span><br>node_attribute.accessPolicyWindow.base_ptr  = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(ptr);<br><span class="hljs-comment">// 持久化访问的总字节数，必须小于cudaDeviceProp::accessPolicyMaxWindowSize</span><br>node_attribute.accessPolicyWindow.num_bytes = num_bytes;<br><br><span class="hljs-comment">// 缓存命中率</span><br>node_attribute.accessPolicyWindow.hitRatio  = <span class="hljs-number">0.6</span>;<br><span class="hljs-comment">// 缓存命中时的访存方式</span><br>node_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting; <br><span class="hljs-comment">// 缓存未命中时的访存方式</span><br>node_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;<br><br><span class="hljs-comment">// 将属性配置到cudaGraphNode_t类型的CUDA图核结点中</span><br><span class="hljs-built_in">cudaGraphKernelNodeSetAttribute</span>(node, cudaKernelNodeAttributeAccessPolicyWindow, &amp;node_attribute);<br></code></pre></td></tr></table></figure>
<p><code>hitRatio</code>参数可以指定以<code>hitProp</code>方式访存的占比。在上面两个例子中，全局内存区域<code>[ptr..ptr+num_bytes)</code>内，60%的内存访问是持久化的，40%的访问是流式的。具体哪些内存访问是<code>hitProp</code>方式是随机的，这个概率是接近<code>hitRatio</code>的，概率分布取决于硬件结构和存储范围。</p>
<p>例如，若L2预留预测大小为16KB，<code>accessPolicyWindow.num_bytes</code>为32KB：</p>
<ul>
<li>当<code>hitRatio = 0.5</code>时，硬件将随机选择32KB窗口中的16KB作为持久化缓存存入预留的L2缓存中；</li>
<li>当<code>hitRatio = 1</code>时，硬件会尝试在预留的L2缓存区中缓存整个32KB的窗口。但由于预留区小于窗口，缓存行将被移除，以将最近使用的32KB数据中的16KB持久化在L2缓存的预留区中。</li>
</ul>
<p><code>hitRatio</code>可以用来避免缓存行抖动，从宏观上减少进出L2缓存的数据量。可以利用低于1的<code>hitRatio</code>来手动控制不同<code>accessPolicyWindow</code>的并发CUDA流能够缓存在L2中的数据量。例如，假设L2的预留缓存大小为16KB，两个不同CUDA流中的核函数是并发的，每个核函数的<code>accessPolicyWindow</code>均为16KB，<code>hitRatio</code>均为1，在竞争共享的L2缓存时可能会移除彼此的缓存行。但如果两个<code>accessPolicyWindow</code>的<code>hitRatio</code>均为0.5，则不太可能会清楚自己或对方的持久缓存行。</p>
<h4 id="l2访问属性">L2访问属性</h4>
<p>针对不同的全局内存数据访问，定义了3种类型的访问属性：</p>
<ul>
<li><code>cudaAccessPropertyStreaming</code>：伴随流式属性发生的内存访问不太可能持久化在L2缓存中，因为这些访问会被优先清除；</li>
<li><code>cudaAccessPropertyPersisting</code>：伴随持久化属性发生的内存访问更可能持久化在L2缓存中，因为这些访问会优先被保留在L2缓存中的预留区；</li>
<li><code>cudaAccessPropertyNormal</code>：该访问属性会将之前持久化的访问强制重置为正常访问。之前CUDA核函数中的持久化属性的内存访问可能会在很长时间内留在L2缓存中，这个时间是远超预期的使用时间的。这种情况会导致后续的核函数不强制使用持久化属性内存访问时可用的L2缓存空间。而使用<code>cudaAccessPropertyNormal</code>可以重置访问属性，改变其持久状态，使得后续的核函数可以利用更多的L2缓存。</li>
</ul>
<h4 id="l2持久化示例">L2持久化示例</h4>
<p>下面是为持久访问预留L2缓存的例子，通过CUDA流在CUDA核函数中使用预留的L2缓存并重置。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaStream_t stream;<br><span class="hljs-comment">// 创建CUDA流</span><br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream);<br><br><span class="hljs-comment">// CUDA设备属性变量</span><br>cudaDeviceProp prop;<br><span class="hljs-comment">// 查询GPU属性</span><br><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, device_id);<br><span class="hljs-type">size_t</span> size = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">int</span>(prop.l2CacheSize * <span class="hljs-number">0.75</span>) , prop.persistingL2CacheMaxSize);<br><span class="hljs-comment">// 预留3/4的L2缓存用于持久化访问，或用最大L2持久化缓存大小</span><br><span class="hljs-built_in">cudaDeviceSetLimit</span>(cudaLimitPersistingL2CacheSize, size);<br><br><span class="hljs-comment">// 取用户定义的num_bytes和最大窗口大小的较小值作为最终窗口大小</span><br><span class="hljs-type">size_t</span> window_size = <span class="hljs-built_in">min</span>(prop.accessPolicyMaxWindowSize, num_bytes);<br><br><span class="hljs-comment">// 流级别属性数据结构</span><br>cudaStreamAttrValue stream_attribute;<br><span class="hljs-comment">// 全局内存数据指针</span><br>stream_attribute.accessPolicyWindow.base_ptr  = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(data1);<br><span class="hljs-comment">// 持久化访问的总字节数</span><br>stream_attribute.accessPolicyWindow.num_bytes = window_size;<br><span class="hljs-comment">// 缓存命中率</span><br>stream_attribute.accessPolicyWindow.hitRatio  = <span class="hljs-number">0.6</span>;<br><span class="hljs-comment">// 缓存命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting;<br><span class="hljs-comment">// 缓存未命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;<br><br><span class="hljs-comment">// 将属性配置到CUDA流中</span><br><span class="hljs-built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);<br><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) {<br>    <span class="hljs-comment">// data1被核函数多次使用</span><br>    cuda_kernelA&lt;&lt;&lt;grid_size,block_size,<span class="hljs-number">0</span>,stream&gt;&gt;&gt;(data1);<br>} <span class="hljs-comment">// [data1..data1 + num_bytes)范围内的数据受益于L2持久化</span><br><span class="hljs-comment">// 在同一个CUDA流中的不同核函数也能受益于data1的持久化</span><br>cuda_kernelB&lt;&lt;&lt;grid_size,block_size,<span class="hljs-number">0</span>,stream&gt;&gt;&gt;(data1);<br><br><span class="hljs-comment">// 将窗口总字节数设置为0来禁用持久化</span><br>stream_attribute.accessPolicyWindow.num_bytes = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// 覆写CUDA流的访问属性</span><br><span class="hljs-built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);<br><span class="hljs-comment">// 将L2中的所有持久化缓存行重置为普通状态</span><br><span class="hljs-built_in">cudaCtxResetPersistingL2Cache</span>();<br><br><span class="hljs-comment">// 由于之前的清除操作，data2当前也可以以普通访存模式受益于L2持久化访问</span><br>cuda_kernelC&lt;&lt;&lt;grid_size,block_size,<span class="hljs-number">0</span>,stream&gt;&gt;&gt;(data2);<br></code></pre></td></tr></table></figure>
<h4 id="将l2访问重置为普通">将L2访问重置为普通</h4>
<p>主要有三种方式：</p>
<ul>
<li>通过<code>cudaAccessPropertyNormal</code>访问属性来重置支持持久化内存区域的访存属性；</li>
<li>通过<code>cudaCtxResetPersistingL2Cache()</code>调用将所有持久化L2缓存行重置为普通状态；</li>
<li>最终未受影响的缓存行将自动重置为普通状态，在开发过程中不应该依赖于自动重置，因为自动重置所需的时间是不确定的。</li>
</ul>
<h4 id="管理l2预留缓存的利用率">管理L2预留缓存的利用率</h4>
<p>不同CUDA流中并发执行的多个CUDA核函数可能分配不同的访问策略窗口，但L2的预留缓存部分在所有核函数之间共享，故L2预留区的使用量是所有并发CUDA核函数使用量的总和。当持久化访问的容量超过了L2缓存的容量时，将内存访问指定为持久化状态的收益就会降低。</p>
<p>综上，程序应该考虑以下因素：</p>
<ul>
<li>L2缓存预留区的大小；</li>
<li>可能并发执行的CUDA核函数；</li>
<li>所有可能并发执行的核函数的访问策略窗口；</li>
<li>重置L2的时机和方式，以允许普通访问或流式访问以同等优先级利用L2缓存的预留区。</li>
</ul>
<h4 id="查询l2缓存属性">查询L2缓存属性</h4>
<p>与L2缓存相关的属性是<code>cudaDeviceProp</code>结构体的一部分，可以通过CUDA运行时API<code>cudaGetDeviceProperties</code>获取。</p>
<p>CUDA设备属性包括：</p>
<ul>
<li><code>l2CacheSize</code>：GPU上可用的L2缓存容量；</li>
<li><code>persistingL2CacheMaxSize</code>：L2缓存中可用于持久化访存的最大预留容量；</li>
<li><code>accessPolicyMaxWindowSize</code>：访问策略窗口的最大大小。</li>
</ul>
<h4 id="控制持久化访存的l2缓存预留大小">控制持久化访存的L2缓存预留大小</h4>
<p>用于持久化访存的L2预留缓存大小可以使用CUDA运行时API<code>cudaDeviceGetLimit</code>查询，使用<code>cudaLimit</code>通过<code>cudaDeviceSetLimit</code>设置预留区大小。该设置的最大值是<code>cudaDeviceProp::persistingL2CacheMaxSize</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaLimit</span> {<br>    <span class="hljs-comment">/* other fields not shown */</span><br>    cudaLimitPersistingL2CacheSize<br>};<br></code></pre></td></tr></table></figure>
<h2 id="内存访问模式">内存访问模式</h2>
<p>CUDA执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行，存储操作也是同样的。在执行内存指令时，线程束中每个线程都提供了一个正在加载或存储的内存地址。在线程束的32个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以分为不同的模式。</p>
<h3 id="对齐与合并访问">对齐与合并访问</h3>
<p>全局内存通过缓存来实现加载 / 存储。全局内存是一个逻辑内存空间，可以通过核函数来访问。所有的程序数据最初存在DRAM上，即物理设备内存中。核函数的内存请求通常是在DRAM设备和片上内存间以128字节或32字节的内存事务来实现的。</p>
<ul>
<li>若一个内存访问同时用到了一级和二级缓存，则该访问由128字节的内存事务实现；</li>
<li>若一个内存访问只用到了二级缓存，则该访问由32字节的内存事务实现。</li>
</ul>
<blockquote>
<p>对于允许使用一级缓存的设备，可以在编译时选择是否启用一级缓存。</p>
</blockquote>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/64c5a79c-ade5-4bc5-9da7-52ba127047bd"></p>
<p>一个一级缓存行是128字节，它映射到设备内存中的一个128字节对齐段。若线程束中的每个线程请求4字节的值，则每次请求就会获取128字节的数据，这恰好与一级缓存行大小一致。在优化程序时，需要注意内存访问的两个特性：</p>
<ul>
<li>对齐内存访问：当设备内存事务的第一个地址是缓存粒度的偶数倍时（32B的L2或128B的L1），就会出现对齐内存访问，非对齐的加载会造成带宽浪费；</li>
<li>合并内存访问：当一个线程束中全部的32个线程访问一个连续的内存块时，就会出现合并内存访问。</li>
</ul>
<p>对齐合并内存访问的理想状态是线程束从对齐内存地址开始访问一个连续的内存块。一个理想的对齐合并访问如下图所示。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/afebf968-8c53-4a8f-a11b-e4b444616387"></p>
<p>这种情况下，只需要一个128字节的内存事务就可以从设备内存中完成读取。但下面这种情况就可能需要3个128字节的内存事务，大大浪费了带宽。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/0c9782e0-53cf-45c9-817b-9ccf148de8e5"></p>
<h3 id="全局内存读取">全局内存读取</h3>
<p>在SM中，数据通过一级和二级缓存、常量缓存、只读缓存3种缓存路径进行传输，具体使用哪种方式取决于所引用的设备内存类型。一、二级缓存是默认路径。若想通过其他两种路径传递数据则需要显式说明，但若想提升性能还要取决于使用的访问模式。全局内存加载是否通过一级缓存取决于设备的计算能力和编译器选项两个因素。使用编译器选项<code>-Xptxas -dlcm=fg</code>来禁用一级缓存，<code>-Xptxas -dlcm=ca</code>来启动一级缓存。</p>
<p>若一级缓存被禁用，所有对全局内存的加载请求将直接进入二级缓存。若二级缓存未命中，则由DRAM完成请求。每次内存事务可由一个、两个或四个部分执行，每个部分32字节。</p>
<p>若一级缓存被启用，全局内存加载请求首先尝试通过一级缓存。若一级缓存未命中，则请求转向二级缓存。若二级缓存也未命中，则请求由DRAM完成。这种模式下，一个内存加载请求由一个128字节的设备内存事务实现。</p>
<h4 id="缓存加载">缓存加载</h4>
<p>缓存加载操作经过一级缓存，在粒度为128字节的一级缓存行上由设备内存事务进行传输。缓存加载可以分为对齐、非对齐、合并、非合并几种情况。</p>
<p>下图为一个理性情况，即对齐与合并内存访问。线程束中的所有请求均在128字节的缓存行范围内。只需要一个128字节的事务，总线利用率为100%，事务中没有未使用数据。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/0b6a8546-c455-4079-9075-b204a276f655"></p>
<p>而下图则是另一种情况，访问是对齐的，但引用的地址不是连续的线程ID，是128字节内的随机值。只需要一个128字节的事务，总线利用率为100%，只有每个线程请求的地址均不同的情况下，该事务中才没有未使用数据。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/fc2d0442-43db-48ad-9f65-fd1b5f469210"></p>
<p>下图中线程束请求32个连续的4字节非对齐数据。需要两个128字节的事务，总线利用率为50%，两个事务中各有一半的数据是未使用的。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/49798f58-2d10-4625-a09c-aa090c8a0977"></p>
<p>下图线程束中的所有线程都请求相同的地址。需要一个128字节的事务，若请求的值是4字节的，则总线利用率为3.125%（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.613ex" role="img" focusable="false" viewBox="0 -677 3222.4 713"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>）。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/2b99e9cc-fbf9-4478-98c8-d8d1dc259eae"></p>
<p>下图则是最坏的情况，线程束中线程请求分散于全局内存中的32个不同地点。地址需要占用N个缓存行（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex;" xmlns="http://www.w3.org/2000/svg" width="11.437ex" height="1.857ex" role="img" focusable="false" viewBox="0 -683 5055.1 821"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(777.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mi" transform="translate(1833.6,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(2999.3,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(4055.1,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>），需要N个128字节的事务。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/c1d31787-147f-4fd0-bfd0-69c57914c87a"></p>
<h4 id="没有缓存的加载">没有缓存的加载</h4>
<p>没有缓存的加载不经过一级缓存，它在内存段的粒度上（32B）而非缓存池的粒度（128B）执行。这种更细粒度的加载，可以为非对齐或非合并的内存访问带来更好的总线利用率。</p>
<p>下图是对齐与合并的内存访问，128字节请求的地址占用了4个内存段，总线利用率为100%。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/f2e25ece-afa2-405d-98a0-333c93154d87"></p>
<p>下图的内存访问是对齐的，但线程访问是不连续的，而是在128个字节范围内随机进行。只要每个线程请求唯一的地址，则地址将占用4个内存段，且不会有加载浪费。这样的随机访问不会抑制核函数性能。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/b7bfd208-dcbc-4dcc-997c-f20c754d44f0"></p>
<p>下图中线程束请求32个连续的4字节元素，但加载没有对齐。请求的地址最多落在5个内存段内，总线利用率至少为80%。与类似情况的缓存加载相比，非缓存加载会提升性能，因为加载了更少的未请求字节。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/5b731cec-9862-4e87-be38-a15915a688ae"></p>
<p>下图线程束中所有线程请求相同的数据。地址落在一个内存段内，总线利用率为12.5%（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="6.159ex" height="1.613ex" role="img" focusable="false" viewBox="0 -677 2722.4 713"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>）。在这种情况下，非缓存加载的性能也是优于缓存加载的。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/de2ad730-291b-44fd-9df8-98adfb3fc56c"></p>
<p>下图则是最坏的情况，线程束请求32个分散在全局内存中的不同地方。请求的128个字节最多落在N个32字节的内存段内，而不是N个128字节的缓存行内，所以相比于缓存加载，即便是最坏情况也有所改善。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/0c36a2e3-aa91-47e0-a49d-10c359b5849f"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/06_read_segment.cu">read_segment.cu</a>是一个非对齐读取的示例，实现一个带偏移量的向量求和核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sumArraysReadOffset</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">const</span> <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> offset)</span></span><br><span class="hljs-function"></span>{<br> <span class="hljs-type">unsigned</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br> <span class="hljs-type">unsigned</span> j = tid + offset;<br> <span class="hljs-keyword">if</span> (tid &lt; size)<br>     C[tid] = A[j] + B[j];<br>}<br></code></pre></td></tr></table></figure>
<p>这样可以通过<code>offset</code>来强制其进行非对齐内存访问，对不同的<code>offset</code>性能测试的结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">readOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">094464</span> ms<br><span class="hljs-attribute">readOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">102912</span> ms<br><span class="hljs-attribute">readOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">094112</span> ms<br></code></pre></td></tr></table></figure>
<p>可以看到在<code>offset</code>为11的情况下速度是最慢的，此时两个输入向量的读取是非对齐的。我们借助<code>ncu</code>来分析这三种情况的全局加载效率和全局加载事务。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">												全局加载效率	全局加载事务<br>readOffset&lt;&lt;&lt;<span class="hljs-string">8192, 512&gt;&gt;&gt;       offset    0       100%		1048576</span><br><span class="hljs-string">readOffset&lt;&lt;&lt;8192</span>, 512&gt;&gt;&gt;       offset   11        80%		1310716<br>readOffset&lt;&lt;&lt;<span class="hljs-string">8192, 512&gt;&gt;&gt;       offset  128       100%		1048544</span><br></code></pre></td></tr></table></figure>
<p>关于这里的全局加载效率，在《CUDA C编程权威指南》一书中，在开启一级缓存的情况下，全局加载效率仅有50%左右，但禁用一级缓存后提升到了80%。但笔者测试了开启和禁用一级缓存两种情况，加载效率均为80%。</p>
</blockquote>
<h4 id="只读缓存">只读缓存</h4>
<p>只读缓存最初是预留给纹理内存加载使用的，对计算能力3.5以上的GPU，只读缓存也支持使用全局内存加载代替一级缓存。</p>
<p>只读缓存的加载粒度是32字节，有两种方式可以指导内存通过只读缓存读取：</p>
<ul>
<li>使用函数<code>__ldg</code>；</li>
<li>在间接引用的指针上使用修饰符。</li>
</ul>
<p>例如下面的核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *out, <span class="hljs-type">int</span> *in)</span> </span>{<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    out[idx] = in[idx];<br>}<br></code></pre></td></tr></table></figure>
<p>可以通过在核函数内部使用<code>__ldg</code>来通过只读缓存直接对数组进行读取访问。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *out, <span class="hljs-type">int</span> *in)</span> </span>{<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    out[idx] = __ldg(&amp;in[idx]);<br>}<br></code></pre></td></tr></table></figure>
<p>也可以将限制修饰符<code>__restrict__</code>应用到指针上，该修饰符会使<code>nvcc</code>编译器将指针识别为无别名指针。<code>nvcc</code>将自动通过只读缓存来指导无别名指针的加载。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> * __restrict__ out, <span class="hljs-type">const</span> <span class="hljs-type">int</span> * __restrict__ in)</span> </span>{<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    out[idx] = in[idx];<br>}<br></code></pre></td></tr></table></figure>
<h3 id="全局内存写入">全局内存写入</h3>
<p>内存的存储操作相对简单，存储操作不能使用一级缓存进行，在发送到设备内存之前只通过二级缓存。存储操作在32字节段的粒度上被执行。内存事务可以同时被分为一段、两段或四段。</p>
<p>下图中为最理想的情况，内存访问是对齐的，且线程束中的所有线程访问一个连续的128字节范围。存储请求由一个四段事务实现。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/520844ca-de46-4121-a6f6-bec28934665e"></p>
<p>下图的内存访问是对齐的，但地址分散在192字节范围内，存储请求由三个一段事务实现。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/356bc0e5-565a-4a11-b1de-7672cf29146a"></p>
<p>下图中内存访问同样是对齐的，且地址访问在一个连续的64字节范围内，存储请求由一个两段事务实现。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/96106945-ac2c-447e-9382-ff21603fa0ef"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/07_write_segment.cu">write_segment.cu</a>是一个非对齐写入的示例，实现一个带偏移量的向量求和核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sumArraysWriteOffset</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">const</span> <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> offset)</span></span><br><span class="hljs-function"></span>{<br> <span class="hljs-type">unsigned</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br> <span class="hljs-type">unsigned</span> j = tid + offset;<br> <span class="hljs-keyword">if</span> (j &lt; size)<br>     C[j] = A[tid] + B[tid];<br>}<br></code></pre></td></tr></table></figure>
<p>与上面非对齐读取的例子不同，这次将<code>C</code>与<code>A</code>、<code>B</code>的索引颠倒了过来。通过<code>offset</code>来强制其进行非对齐写入，性能测试结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">writeOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">109920</span> ms<br><span class="hljs-attribute">writeOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">111616</span> ms<br><span class="hljs-attribute">writeOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">110592</span> ms<br></code></pre></td></tr></table></figure>
<p>类似地，利用<code>ncu</code>来分析全局存储效率和全局存储事务。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">												全局存储效率	全局存储事务<br>writeOffset&lt;&lt;&lt;<span class="hljs-string">8192, 512&gt;&gt;&gt;       offset    0       100%		 524288</span><br><span class="hljs-string">writeOffset&lt;&lt;&lt;8192</span>, 512&gt;&gt;&gt;       offset   11        80%		 655358<br>writeOffset&lt;&lt;&lt;<span class="hljs-string">8192, 512&gt;&gt;&gt;       offset  128       100%		 524272</span><br></code></pre></td></tr></table></figure>
</blockquote>
<p>值的注意的是，若写入的两个地址同属于一个128字节区域，但不属于一个对齐的64字节区域，则会执行一个四段事务，而不是两个一段事务。</p>
<h3 id="结构体数组与数组结构体">结构体数组与数组结构体</h3>
<p>C语言中有两种数据组织方式：</p>
<ul>
<li>数组结构体（AoS）；</li>
<li>结构体数组（SoA）。</li>
</ul>
<p>假设要存储一组成对的浮点数，两种不同的方式如下。</p>
<p>AoS方式：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerStruct</span> {<br>    <span class="hljs-type">float</span> x;<br>    <span class="hljs-type">float</span> y;<br>};<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerStruct</span> myAoS[N];<br></code></pre></td></tr></table></figure>
<p>SoA方式：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerArray</span> {<br>    <span class="hljs-type">float</span> x[N];<br>    <span class="hljs-type">float</span> y[N];<br>};<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerArray</span> mySoA;<br></code></pre></td></tr></table></figure>
<p>观察两种存储方式的内存布局。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/b71b43ca-fd5e-40d8-a1f9-3001d48eb20b"></p>
<p>可以发现SoA模式充分利用了GPU的内存带宽，由于没有相同字段元素的交叉存取，GPU上的SoA布局提供了合并内存访问，可以对全局内存实现更高效的利用。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/08_array_of_structure.cu">array_of_structure.cu</a>和<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/09_structure_of_array.cu">structure_of_array.cu</a>是使用AoS模式和SoA模式下的对比，性能测试结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">AoS</span>		innerStruct&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">033280</span> ms<br><span class="hljs-attribute">SoA</span>		innerArray&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;       elapsed <span class="hljs-number">0</span>.<span class="hljs-number">032640</span> ms<br></code></pre></td></tr></table></figure>
<p>通过分析它们的全局加载和存储效率可以印证上面的观点，即SoA布局充分利用了GPU的内存带宽。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">									  全局加载效率	全局存储效率<br>AoS		innerStruct&lt;&lt;&lt;<span class="hljs-string">8192, 128&gt;&gt;&gt;		 50%	 	   50%</span><br><span class="hljs-string">SoA		innerArray&lt;&lt;&lt;8192</span>, 128&gt;&gt;&gt;       100%		  100%<br></code></pre></td></tr></table></figure>
</blockquote>
<h3 id="性能调整">性能调整</h3>
<p>优化设备内存带宽利用率有两个目标：</p>
<ul>
<li>对齐及合并内存访问，以减少带宽的浪费；</li>
<li>足够的并发内存操作，以隐藏内存延迟。</li>
</ul>
<h4 id="展开技术">展开技术</h4>
<p>将之前提到的非对齐读取的例子<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/06_read_segment.cu">read_segment.cu</a>，将其循环展开。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">readOffsetUnroll4</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">const</span> <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> offset)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x * <span class="hljs-number">4</span> + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> j = tid + offset;<br>    <span class="hljs-keyword">if</span> (j + <span class="hljs-number">3</span> * blockDim.x &lt; size)<br>    {<br>        C[tid] = A[j] + B[j];<br>        C[tid + blockDim.x] = A[j + blockDim.x] + B[j + blockDim.x];<br>        C[tid + blockDim.x * <span class="hljs-number">2</span>] = A[j + blockDim.x * <span class="hljs-number">2</span>] + B[j + blockDim.x * <span class="hljs-number">2</span>];<br>        C[tid + blockDim.x * <span class="hljs-number">3</span>] = A[j + blockDim.x * <span class="hljs-number">3</span>] + B[j + blockDim.x * <span class="hljs-number">3</span>];<br>    }<br>}<br></code></pre></td></tr></table></figure>
<p>性能测试结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">offset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;   offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">107520</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">099104</span> ms<br><span class="hljs-attribute">offset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;   offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">109216</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">100640</span> ms<br><span class="hljs-attribute">offset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;   offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">108352</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">098976</span> ms<br></code></pre></td></tr></table></figure>
<p>分析其全局加载和存储效率，以及全局加载和存储事务。</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gcode">										    全局加载效率 全局存储效率 全局加载事务 全局存储事务<br>offset&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;		offset   <span class="hljs-number">11</span>        <span class="hljs-number">80</span><span class="hljs-meta">%</span>	     <span class="hljs-number">100</span><span class="hljs-meta">%</span>	   <span class="hljs-number">1310704</span>	  <span class="hljs-number">524284</span><br>u<span class="hljs-symbol">nroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;		offset   <span class="hljs-number">11</span>        <span class="hljs-number">80</span><span class="hljs-meta">%</span>	     <span class="hljs-number">100</span><span class="hljs-meta">%</span>	   <span class="hljs-number">1310716</span>	  <span class="hljs-number">524287</span><br></code></pre></td></tr></table></figure>
<blockquote>
<p>这里笔者的测试结果没有太大的差距，原因是笔者开启和禁用一级缓存两种情况下，未展开的核函数差别本就不大。所以即使展开之后，性能提升也不明显，但这个优化手段是值的参考的。</p>
</blockquote>
<h4 id="增大并行性">增大并行性</h4>
<p>用不同的线程块大小测试上面展开的核函数，结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>&gt;&gt;&gt; offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">099104</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">095840</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">256</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">096096</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">096320</span> ms<br><br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>&gt;&gt;&gt; offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">098624</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">097504</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">256</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">097568</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">097408</span> ms<br></code></pre></td></tr></table></figure>
<p>不管是对齐的还是非对齐的访问，增大并行性都可以带来一些提升。</p>
<h2 id="核函数可达到的带宽">核函数可达到的带宽</h2>
<h3 id="内存带宽">内存带宽</h3>
<p>大多数核函数对内存带宽非常敏感，也就是说它们有内存带宽限制。全局内存中数据的排布方式，以及线程束访问该数据的方式都对带宽有显著的影响。一般分为两个概念：</p>
<ul>
<li>理论带宽：当前硬件可以实现的绝对最大带宽；</li>
<li>有效带宽：核函数实际达到的带宽，是测量带宽，公式如下。</li>
</ul>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex;" xmlns="http://www.w3.org/2000/svg" width="48.349ex" height="5.543ex" role="img" focusable="false" viewBox="0 -1540 21370.1 2450"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">有</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">效</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">带</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">宽</text></g><g data-mml-node="mtext" transform="translate(4000,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z" transform="translate(389,0)"></path><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z" transform="translate(1174,0)"></path><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z" transform="translate(1882,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(2382,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(2776,0)"></path></g><g data-mml-node="mo" transform="translate(7442.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(8498.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">读</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">字</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">节</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(4222.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">写</text></g><g data-mml-node="mi" transform="translate(6222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">字</text></g><g data-mml-node="mi" transform="translate(7222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">节</text></g><g data-mml-node="mi" transform="translate(8222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(9444.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(10444.9,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(4435.8,-710)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">运</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">行</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">间</text></g></g><rect width="12631.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p>
<h3 id="矩阵转置问题">矩阵转置问题</h3>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/56e8a8e5-3dec-440f-a1a9-24342d83fad2"></p>
<p>在主机端利用错位转置算法可以很容易的实现上述操作。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">transposeHost</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> iy = <span class="hljs-number">0</span>; iy &lt; ny; iy++)<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ix = <span class="hljs-number">0</span>; ix &lt; nx; ix++)<br>            out[ix * ny + iy] = in[iy * nx + ix];<br>}<br></code></pre></td></tr></table></figure>
<p>观察原矩阵和转置矩阵的内存数据排布。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/6918a8de-27cf-4a21-a9f7-8abfc8cb11f9"></p>
<p>可以很容易的分析出，读取过程是访问原矩阵的行，是合并访问，写入过程是访问转置矩阵的列，是交叉访问。</p>
<p>核函数有两种主要方式来实现矩阵的转置：</p>
<ul>
<li>按行读取，按列存储；<img src="https://github.com/Deleter-D/Images/assets/56388518/5f600f4f-92db-4800-aa22-1179c1ea0b3f"></li>
<li>按列读取，按行存储。<img src="https://github.com/Deleter-D/Images/assets/56388518/2f4e86e1-caf1-4398-b895-0cac22b44565"></li>
</ul>
<h4 id="为转置核函数设置性能的上限和下限">为转置核函数设置性能的上限和下限</h4>
<p>实现两个核函数，一个读取和存储都按行，另一个读取和存储都按列。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyRow</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[iy * nx + ix] = in[iy * nx + ix];<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyCol</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[ix * ny + iy] = in[ix * ny + iy];<br>}<br></code></pre></td></tr></table></figure>
<p>这两个核函数可以分别测得与转置操作相同内存操作情况下，全部使用合并访问（按行读写）以及全部使用交叉访问（按列读写）的有效带宽。</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>带宽（GB/s）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>CopyRow</code></td>
<td>1367.11</td>
<td>上限</td>
</tr>
<tr class="even">
<td><code>CopyCol</code></td>
<td>595.78</td>
<td>下限</td>
</tr>
</tbody>
</table>
<h4 id="朴素转置">朴素转置</h4>
<p>分别实现<a href="#矩阵转置问题">矩阵转置问题</a>中提到的两种转置方式，即按行加载按列存储与按列加载按行存储。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeNaiveRow</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[ix * ny + iy] = in[iy * nx + ix];<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeNaiveCol</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[iy * nx + ix] = in[ix * ny + iy];<br>}<br></code></pre></td></tr></table></figure>
<p>像上面那样测试有效带宽，对比结果如下，同时分析其全局加载、存储吞吐量和全局加载、存储效率。</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>带宽（GB/s）</th>
<th>加载吞吐量（GB/s）</th>
<th>存储吞吐量（GB/s）</th>
<th>加载效率（%）</th>
<th>存储效率（%）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>NaiveRow</code></td>
<td>321.25</td>
<td>126.85</td>
<td>507.42</td>
<td>100</td>
<td>25</td>
<td>合并读取，交叉存储</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>911.80</td>
<td>609.64</td>
<td>152.41</td>
<td>25</td>
<td>100</td>
<td>交叉读取，合并存储</td>
</tr>
</tbody>
</table>
<p>可以发现两种方式的性能相近，这是因为在交叉读取的过程中，会有数据进入一级缓存。虽然读取的数据不连续，但在后续的读取过程中，仍然有可能发生缓存命中。禁用一级缓存后，有效带宽表现如下，</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>带宽（GB/s）</th>
<th>加载吞吐量（GB/s）</th>
<th>存储吞吐量（GB/s）</th>
<th>加载效率（%）</th>
<th>存储效率（%）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>NaiveRow</code></td>
<td>330.99</td>
<td>128.38</td>
<td>513.50</td>
<td>100</td>
<td>25</td>
<td>合并读取，交叉存储，禁用一级缓存</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>489.07</td>
<td>472.76</td>
<td>118.19</td>
<td>25</td>
<td>100</td>
<td>交叉读取，合并存储，禁用一级缓存</td>
</tr>
</tbody>
</table>
<p>可以看到，没有一级缓存的帮助后，交叉读取的有效带宽下降了。对于<code>NaiveCol</code>实现来说，由于写入是合并的，存储请求未被重复执行。但由于交叉读取，多次重复执行了加载请求。即使不是最好的加载方式，但有一级缓存的帮助，也能限制交叉读取对性能的负面影响。</p>
<blockquote>
<p>后面的讨论都默认启用一级缓存。</p>
</blockquote>
<h4 id="展开转置">展开转置</h4>
<p>利用循环展开技术改进两个朴素转置核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeUnroll4Row</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ti = iy * nx + ix;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> to = ix * ny + iy;<br><br>    <span class="hljs-keyword">if</span> (ix + blockDim.x * <span class="hljs-number">3</span> &lt; nx &amp;&amp; iy &lt; ny)<br>    {<br>        out[to] = in[ti];<br>        out[to + ny * blockDim.x] = in[ti + blockDim.x];<br>        out[to + ny * blockDim.x * <span class="hljs-number">2</span>] = in[ti + blockDim.x * <span class="hljs-number">2</span>];<br>        out[to + ny * blockDim.x * <span class="hljs-number">3</span>] = in[ti + blockDim.x * <span class="hljs-number">3</span>];<br>    }<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeUnroll4Col</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ti = ix * ny + iy;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> to = iy * nx + ix;<br>    <span class="hljs-keyword">if</span> (ix + blockDim.x * <span class="hljs-number">3</span> &lt; nx &amp;&amp; iy &lt; ny)<br>    {<br>        out[to] = in[ti];<br>        out[to + blockDim.x] = in[ti + ny * blockDim.x];<br>        out[to + blockDim.x * <span class="hljs-number">2</span>] = in[ti + ny * blockDim.x * <span class="hljs-number">2</span>];<br>        out[to + blockDim.x * <span class="hljs-number">3</span>] = in[ti + ny * blockDim.x * <span class="hljs-number">3</span>];<br>    }<br>}<br></code></pre></td></tr></table></figure>
<p>进行性能测试，总结如下。</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>带宽（GB/s）</th>
<th>加载吞吐量（GB/s）</th>
<th>存储吞吐量（GB/s）</th>
<th>加载效率（%）</th>
<th>存储效率（%）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>Unroll4Row</code></td>
<td>72.88</td>
<td>117.29</td>
<td>469.16</td>
<td>100</td>
<td>25</td>
<td>合并读取，交叉存储，展开</td>
</tr>
<tr class="even">
<td><code>Unroll4Col</code></td>
<td>324.44</td>
<td>1843.45</td>
<td>465.67</td>
<td>25</td>
<td>100</td>
<td>交叉读取，合并存储，展开</td>
</tr>
</tbody>
</table>
<p>启用一级缓存，并展开后，可以观察到<code>Unroll4Col</code>的加载吞吐量有了质的提升。</p>
<h4 id="对角转置">对角转置</h4>
<p>当启动一个线程块网格时，线程块会被分配给SM。虽然编程模型可能将网格抽象成一维、二维或三维，但在硬件看来所有块都是一维的。当启动一个核函数时，线程块被分配给SM的顺序由块ID来确定。一开始可能还会以顺序来分配线程块，直到所有SM被完全占满。由于线程块完成的速度和顺序是不确定的，随着核函数的执行，活跃的线程块ID将变得不太连续。</p>
<p>虽然无法直接调控线程块的顺序，但可以利用对角坐标来间接调控，下图展示了直角坐标与对角坐标的区别。</p>
<p><img src="https://github.com/Deleter-D/Images/assets/56388518/eeb536e8-ace6-494b-8e52-72ac1016e711"></p>
<p>可以利用对角坐标来确定线程块的ID，但仍需要直角坐标来访问数据。将<code>blockIdx.x</code>和<code>blockIdx.y</code>当作对角坐标后，对于方阵来说，可以用如下映射关系来访问正确的数据块。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">blk_x</span> = (blockIdx.x + blockIdx.y) % gridDim.x<span class="hljs-comment">;</span><br><span class="hljs-attr">blk_y</span> = blockIdx.x<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure>
<p>这里的<code>blk_x</code>和<code>blk_y</code>即为线程块对应的直角坐标。下面分别实现行读列写和列读行写的对角转置核函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeDiagonalRow</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_y = blockIdx.x;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockDim.x * blk_x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockDim.y * blk_y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[ix * ny + iy] = in[iy * nx + ix];<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeDiagonalCol</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_y = blockIdx.x;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockDim.x * blk_x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockDim.y * blk_y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[iy * nx + ix] = in[ix * ny + iy];<br>}<br></code></pre></td></tr></table></figure>
<p>性能测试结果如下。</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>带宽（GB/s）</th>
<th>加载吞吐量（GB/s）</th>
<th>存储吞吐量（GB/s）</th>
<th>加载效率（%）</th>
<th>存储效率（%）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>DiagonalRow</code></td>
<td>330.99</td>
<td>133.47</td>
<td>533.90</td>
<td>100</td>
<td>25</td>
<td>合并读取，交叉存储，对角</td>
</tr>
<tr class="even">
<td><code>DiagonalCol</code></td>
<td>910.22</td>
<td>592.08</td>
<td>148.02</td>
<td>25</td>
<td>100</td>
<td>交叉读取，合并存储，对角</td>
</tr>
</tbody>
</table>
<p>通过使用对角坐标来修改线程块的执行顺序，使得基于行读列写的核函数性能大幅度提升，但列读行写的核函数没有什么提升。对角核函数的实现依然可以使用展开技术来优化，但不像直角坐标那样直观。</p>
<p>这种性能的提升与DRAM的并行访问有关。核函数发起的全局内存请求由DRAM分区完成，设备内存中连续的256字节区域被分配到连续的分区。当使用直角坐标线程块时，全局内存的访问无法被均匀分配到DRAM的分区中，就可能发生分区冲突。进而导致内存请求在某些分区中排队，而某些分区一直未被调用。由于对角坐标是一种线程块与数据块之间的非线性映射，所以交叉访问不太可能会落入同一个分区中，进而带来了性能的提升。</p>
<h4 id="使用瘦块增加并行性">使用瘦块增加并行性</h4>
<p>对之前实现的列读行写的朴素转置进行测试，分别使用不同的块大小设计，测试结果如下。</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>块大小</th>
<th>带宽（GB/s）</th>
<th>加载吞吐量（GB/s）</th>
<th>存储吞吐量（GB/s）</th>
<th>加载效率（%）</th>
<th>存储效率（%）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>NaiveCol</code></td>
<td>(32, 32)</td>
<td>491.14</td>
<td>1073.98</td>
<td>133.64</td>
<td>12.5</td>
<td>100</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>(32, 16)</td>
<td>718.69</td>
<td>1076.43</td>
<td>133.88</td>
<td>12.5</td>
<td>100</td>
</tr>
<tr class="odd">
<td><code>NaiveCol</code></td>
<td>(32, 8)</td>
<td>739.48</td>
<td>872.00</td>
<td>109.00</td>
<td>12.5</td>
<td>100</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>(16, 32)</td>
<td>1061.31</td>
<td>778.74</td>
<td>194.69</td>
<td>25</td>
<td>100</td>
</tr>
<tr class="odd">
<td><code>NaiveCol</code></td>
<td>(16, 16)</td>
<td>963.76</td>
<td>583.35</td>
<td>145.84</td>
<td>25</td>
<td>100</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>(16, 8)</td>
<td>910.22</td>
<td>432.14</td>
<td>108.03</td>
<td>25</td>
<td>100</td>
</tr>
<tr class="odd">
<td><code>NaiveCol</code></td>
<td>(8, 32)</td>
<td>1057.03</td>
<td>410.24</td>
<td>205.12</td>
<td>50</td>
<td>100</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>(8, 16)</td>
<td>1064.54</td>
<td>327.78</td>
<td>163.89</td>
<td>50</td>
<td>100</td>
</tr>
<tr class="odd">
<td><code>NaiveCol</code></td>
<td>(8, 8)</td>
<td>731.22</td>
<td>233.07</td>
<td>116.53</td>
<td>50</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>性能最佳的为<code>(16, 32)</code>、<code>(8, 32)</code>和<code>(8, 16)</code>的块，这种性能提升是由瘦块带来的。可以观察到<code>(8, 32)</code>的存储吞吐量是最高的。</p>
<p>我们进一步测试<code>(8, 32)</code>的块在各个核函数下的性能表现。</p>
<table>
<thead>
<tr class="header">
<th>核函数</th>
<th>块大小</th>
<th>带宽（GB/s）</th>
<th>加载吞吐量（GB/s）</th>
<th>存储吞吐量（GB/s）</th>
<th>加载效率（%）</th>
<th>存储效率（%）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>CopyRow</code></td>
<td>(8, 32)</td>
<td>1071.06</td>
<td>206.66</td>
<td>206.66</td>
<td>100</td>
<td>100</td>
<td>合并读取，合并存储</td>
</tr>
<tr class="even">
<td><code>CopyCol</code></td>
<td>(8, 32)</td>
<td>1057.03</td>
<td>422.47</td>
<td>422.47</td>
<td>50</td>
<td>50</td>
<td>交叉读取，交叉存储</td>
</tr>
<tr class="odd">
<td><code>NaiveRow</code></td>
<td>(8, 32)</td>
<td>627.13</td>
<td>197.70</td>
<td>395.39</td>
<td>100</td>
<td>50</td>
<td>合并读取，交叉存储</td>
</tr>
<tr class="even">
<td><code>NaiveCol</code></td>
<td>(8, 32)</td>
<td>1097.98</td>
<td>426.77</td>
<td>213.39</td>
<td>50</td>
<td>100</td>
<td>交叉读取，合并存储</td>
</tr>
<tr class="odd">
<td><code>Unroll4Row</code></td>
<td>(8, 32)</td>
<td>138.26</td>
<td>239.83</td>
<td>479.65</td>
<td>100</td>
<td>50</td>
<td>合并读取，交叉存储，展开</td>
</tr>
<tr class="even">
<td><code>Unroll4Col</code></td>
<td>(8, 32)</td>
<td>341.33</td>
<td>1236.83</td>
<td>598.49</td>
<td>50</td>
<td>100</td>
<td>交叉读取，合并存储，展开</td>
</tr>
</tbody>
</table>
<p>笔者的测试结果与书中有所不同，书中测试结果最好的是<code>Unroll4Col</code>，但笔者这里最好的是<code>NaiveCol</code>。但从加载吞吐量来说，的确是<code>Unroll4Col</code>最优秀。</p>
<h2 id="使用统一内存的矩阵加法">使用统一内存的矩阵加法*</h2>
<p>用统一内存的方式实现矩阵加法，可以提高代码的可读性和易维护性，消除所有的显式内存副本。</p>
<blockquote>
<p>具体代码参考<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/11_matrix_sum_managed.cu">matrix_sum_managed.cu</a>和<a target="_blank" rel="noopener" href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/12_matrix_sum_manual.cu">matrix_sum_manual.cu</a>。</p>
</blockquote>
<p>性能测试结果如下。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sum</span> matrix managed&lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">17</span>.<span class="hljs-number">284096</span> ms<br><span class="hljs-attribute">sum</span> matrix manual&lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">0</span>.<span class="hljs-number">470016</span> ms<br></code></pre></td></tr></table></figure>
<p>可以观察到，虽然使用统一内存减少了编程的工作量，但性能却大幅度下降。更具体的性能测试如下。</p>
<table>
<thead>
<tr class="header">
<th>任务</th>
<th>使用托管内存（ms）</th>
<th>不使用托管内存（ms）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>数据初始化</td>
<td>355.60</td>
<td>354.77</td>
</tr>
<tr class="even">
<td>CPU侧计算</td>
<td>7.07</td>
<td>15.02</td>
</tr>
<tr class="odd">
<td>CUDA memcpy HtoD</td>
<td>14.73</td>
<td>10.16</td>
</tr>
<tr class="even">
<td>GPU侧计算（核函数）</td>
<td>19.90</td>
<td>0.50</td>
</tr>
<tr class="odd">
<td>CUDA memcpy DtoH</td>
<td>2.90</td>
<td>4.92</td>
</tr>
</tbody>
</table>
<p>可以观察到，在使用托管内存的情况下，<code>HtoD</code>任务要花费更长的时间，核函数计算也需要更长的时间。</p>
<blockquote>
<p>有趣的一点是，在关于数据初始化耗时的测试结果上，笔者与书中的描述相差甚远。在书中，使用托管内存的情况下，数据初始化的耗时要大于不使用托管内存的情况，但笔者的两种方式却相差无几。通过这一点可以看到CUDA在统一内存方面的优化痕迹。</p>
</blockquote>
</div><div class="article-licensing box"><div class="licensing-title"><p>CUDA编程——全局内存</p><p><a href="https://deleter-d.github.io/posts/47184/">https://deleter-d.github.io/posts/47184/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="https://deleter-d.github.io"><p>亦初</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-02-20</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-02-27</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/posts/9782/" target="_blank">CUDA编程——GPU加速库和OpenACC</a><br></span><span>  2.<a class="is-size-6" href="/posts/53610/" target="_blank">CUDA编程——调整指令集原语</a><br></span><span>  3.<a class="is-size-6" href="/posts/4919/" target="_blank">CUDA编程——流和并发</a><br></span><span>  4.<a class="is-size-6" href="/posts/50255/" target="_blank">CUDA编程——性能分析工具</a><br></span><span>  5.<a class="is-size-6" href="/posts/38038/" target="_blank">CUDA编程——共享内存和常量内存</a><br></span><span>  6.<a class="is-size-6" href="/posts/47225/" target="_blank">CUDA编程——执行模型</a><br></span><span>  7.<a class="is-size-6" href="/posts/50741/" target="_blank">CUDA编程——NVCC编译器</a><br></span><span>  8.<a class="is-size-6" href="/posts/57516/" target="_blank">CUDA编程模型概述</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://user-images.githubusercontent.com/56388518/194691384-1d4515ba-79ae-4e83-a485-bfaa5c64033e.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://user-images.githubusercontent.com/56388518/194691371-ad26d43d-b3b5-4fe5-9fc0-52a31333ca98.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/38038/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">CUDA编程——共享内存和常量内存</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/47225/"><span class="level-item">CUDA编程——执行模型</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: 'd31f1ee1553dd170dce2551721fa9e93',
            repo: 'Deleter-D.github.io',
            owner: 'Deleter-D',
            clientID: 'd087baa8a532e3b31fba',
            clientSecret: 'faec4c1d7046247c200bca62c9930d0799ce58a5',
            admin: ["Deleter-D"],
            createIssueManually: true,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cloudflare-cors-anywhere.wyp867909454.workers.dev/?https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex is-mobile" href="#cuda内存模型概述"><span>CUDA内存模型概述</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#cuda内存模型"><span>CUDA内存模型</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#寄存器"><span>寄存器</span></a></li><li><a class="is-flex is-mobile" href="#本地内存"><span>本地内存</span></a></li><li><a class="is-flex is-mobile" href="#共享内存"><span>共享内存</span></a></li><li><a class="is-flex is-mobile" href="#常量内存"><span>常量内存</span></a></li><li><a class="is-flex is-mobile" href="#纹理内存"><span>纹理内存</span></a></li><li><a class="is-flex is-mobile" href="#全局内存"><span>全局内存</span></a></li><li><a class="is-flex is-mobile" href="#gpu缓存"><span>GPU缓存</span></a></li><li><a class="is-flex is-mobile" href="#cuda变量声明小结"><span>CUDA变量声明小结</span></a></li><li><a class="is-flex is-mobile" href="#静态全局内存"><span>静态全局内存</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#内存管理"><span>内存管理</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#设备内存"><span>设备内存</span></a></li><li><a class="is-flex is-mobile" href="#内存传输"><span>内存传输</span></a></li><li><a class="is-flex is-mobile" href="#锁页主机内存固定主机内存"><span>锁页主机内存（固定主机内存）</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#可移植内存"><span>可移植内存</span></a></li><li><a class="is-flex is-mobile" href="#写组合内存"><span>写组合内存</span></a></li><li><a class="is-flex is-mobile" href="#映射内存零拷贝内存"><span>映射内存（零拷贝内存）</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#统一虚拟地址空间"><span>统一虚拟地址空间</span></a></li><li><a class="is-flex is-mobile" href="#统一内存寻址"><span>统一内存寻址</span></a></li><li><a class="is-flex is-mobile" href="#设备内存l2访问管理"><span>设备内存L2访问管理</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#为持久化访问预留的l2缓存"><span>为持久化访问预留的L2缓存</span></a></li><li><a class="is-flex is-mobile" href="#l2持久化访问策略"><span>L2持久化访问策略</span></a></li><li><a class="is-flex is-mobile" href="#l2访问属性"><span>L2访问属性</span></a></li><li><a class="is-flex is-mobile" href="#l2持久化示例"><span>L2持久化示例</span></a></li><li><a class="is-flex is-mobile" href="#将l2访问重置为普通"><span>将L2访问重置为普通</span></a></li><li><a class="is-flex is-mobile" href="#管理l2预留缓存的利用率"><span>管理L2预留缓存的利用率</span></a></li><li><a class="is-flex is-mobile" href="#查询l2缓存属性"><span>查询L2缓存属性</span></a></li><li><a class="is-flex is-mobile" href="#控制持久化访存的l2缓存预留大小"><span>控制持久化访存的L2缓存预留大小</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#内存访问模式"><span>内存访问模式</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#对齐与合并访问"><span>对齐与合并访问</span></a></li><li><a class="is-flex is-mobile" href="#全局内存读取"><span>全局内存读取</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#缓存加载"><span>缓存加载</span></a></li><li><a class="is-flex is-mobile" href="#没有缓存的加载"><span>没有缓存的加载</span></a></li><li><a class="is-flex is-mobile" href="#只读缓存"><span>只读缓存</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#全局内存写入"><span>全局内存写入</span></a></li><li><a class="is-flex is-mobile" href="#结构体数组与数组结构体"><span>结构体数组与数组结构体</span></a></li><li><a class="is-flex is-mobile" href="#性能调整"><span>性能调整</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#展开技术"><span>展开技术</span></a></li><li><a class="is-flex is-mobile" href="#增大并行性"><span>增大并行性</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#核函数可达到的带宽"><span>核函数可达到的带宽</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#内存带宽"><span>内存带宽</span></a></li><li><a class="is-flex is-mobile" href="#矩阵转置问题"><span>矩阵转置问题</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#为转置核函数设置性能的上限和下限"><span>为转置核函数设置性能的上限和下限</span></a></li><li><a class="is-flex is-mobile" href="#朴素转置"><span>朴素转置</span></a></li><li><a class="is-flex is-mobile" href="#展开转置"><span>展开转置</span></a></li><li><a class="is-flex is-mobile" href="#对角转置"><span>对角转置</span></a></li><li><a class="is-flex is-mobile" href="#使用瘦块增加并行性"><span>使用瘦块增加并行性</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#使用统一内存的矩阵加法"><span>使用统一内存的矩阵加法*</span></a></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg" alt="亦初"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">亦初</p><p class="is-size-6 is-block">落霞与孤鹜齐飞，秋水共长天一色</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>冰岛</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">74</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">22</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">72</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Deleter-D" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Deleter-D"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:18735855248@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Telegram" href="https://t.me/GoldPancake687"><i class="fab fa-telegram"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"来源《"+data.from+"》</p><p>提供者-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:49:53.000Z">2024-02-20</time></p><p class="title"><a href="/posts/9782/">CUDA编程——GPU加速库和OpenACC</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:45:21.000Z">2024-02-20</time></p><p class="title"><a href="/posts/53610/">CUDA编程——调整指令集原语</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:36:28.000Z">2024-02-20</time></p><p class="title"><a href="/posts/4919/">CUDA编程——流和并发</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:29:56.000Z">2024-02-20</time></p><p class="title"><a href="/posts/50255/">CUDA编程——性能分析工具</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-20T08:22:30.000Z">2024-02-20</time></p><p class="title"><a href="/posts/38038/">CUDA编程——共享内存和常量内存</a></p><p class="categories"><a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a> / <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/">CUDA</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/"><span class="level-start"><span class="level-item">前端</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/Vue/"><span class="level-start"><span class="level-item">Vue</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/axios/"><span class="level-start"><span class="level-item">axios</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/nodejs/"><span class="level-start"><span class="level-item">nodejs</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%8A%98%E8%85%BE/"><span class="level-start"><span class="level-item">折腾</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E5%AD%A6/"><span class="level-start"><span class="level-item">数学</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E5%AD%A6/%E7%9F%A9%E9%98%B5%E8%AE%BA/"><span class="level-start"><span class="level-item">矩阵论</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/08/"><span class="level-start"><span class="level-item">八月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag is-grey-lightest">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"><span class="tag">异构计算</span><span class="tag is-grey-lightest">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CUDA/"><span class="tag">CUDA</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"><span class="tag">毕昇编译器</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"><span class="tag">高性能计算</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue/"><span class="tag">Vue</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%9B%E6%89%A3/"><span class="tag">力扣</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/"><span class="tag">矩阵论</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/axios/"><span class="tag">axios</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"><span class="tag">异构编程</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/3D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/"><span class="tag">3D人体姿态估计</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87/"><span class="tag">论文</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ITK/"><span class="tag">ITK</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CVPR/"><span class="tag">CVPR</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag is-grey-lightest">2</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://user-images.githubusercontent.com/56388518/193990104-d040c2b4-1b96-4636-b410-b2ccd6360665.jpg" alt="亦初" height="28"></a><p class="size-small"><span>&copy; 2024 亦初</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作，如有侵权，请<a href="/message" target="_blank">留言</a>，笔者会立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2022/03/13 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="475747480" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('d087baa8a532e3b31fba','faec4c1d7046247c200bca62c9930d0799ce58a5','Deleter-D','Deleter-D.github.io',false);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('d087baa8a532e3b31fba','faec4c1d7046247c200bca62c9930d0799ce58a5','Deleter-D','Deleter-D.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>
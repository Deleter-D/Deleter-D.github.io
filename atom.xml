<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>亦初</title>
  
  
  <link href="https://deleter-d.github.io/atom.xml" rel="self"/>
  
  <link href="https://deleter-d.github.io/"/>
  <updated>2024-02-27T09:37:44.297Z</updated>
  <id>https://deleter-d.github.io/</id>
  
  <author>
    <name>亦初</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CUDA编程——GPU加速库和OpenACC</title>
    <link href="https://deleter-d.github.io/posts/9782/"/>
    <id>https://deleter-d.github.io/posts/9782/</id>
    <published>2024-02-20T08:49:53.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="cuda库概述">CUDA库概述</h2><p>CUDA支持的库及其作用域如下表所示。</p><table><colgroup><col style="width: 26%"><col style="width: 23%"><col style="width: 50%"></colgroup><thead><tr class="header"><th>库名</th><th>作用域</th><th>官方文档</th></tr></thead><tbody><tr class="odd"><td>NVIDIA CUDA Math Library</td><td>数学运算</td><td>https://docs.nvidia.com/cuda/cuda-math-api/index.html</td></tr><tr class="even"><td>NVIDIA cuBLAS</td><td>线性代数</td><td>https://docs.nvidia.com/cuda/cublas/index.html</td></tr><tr class="odd"><td>NVIDIA cuSPARSE</td><td>稀疏线性代数</td><td>https://docs.nvidia.com/cuda/cusparse/index.html</td></tr><tr class="even"><td>NVIDIA CUSP</td><td>稀疏线性代数和图形计算</td><td>https://cusplibrary.github.io/index.html</td></tr><tr class="odd"><td>NVIDIA cuFFT</td><td>快速傅里叶变换</td><td>https://docs.nvidia.com/cuda/cufft/index.html</td></tr><tr class="even"><td>NVIDIA cuRAND</td><td>随机数生成</td><td>https://docs.nvidia.com/cuda/curand/index.html</td></tr><tr class="odd"><td>NVIDIA NPP</td><td>图像和信号处理</td><td>https://docs.nvidia.com/cuda/npp/index.html</td></tr><tr class="even"><td></td><td></td><td></td></tr><tr class="odd"><td>MAGMA</td><td>新一代线性代数</td><td>https://icl.utk.edu/magma/</td></tr><tr class="even"><td>IMSL Fortran Numerical Library</td><td>数学与统计学</td><td>https://www.imsl.com/products/imsl-fortran-libraries</td></tr><tr class="odd"><td>AccelerEyes ArrayFire</td><td>数学，信号和图像处理，统计学</td><td>https://arrayfire.com/</td></tr><tr class="even"><td>Thrust</td><td>并行算法和数据结构</td><td>https://docs.nvidia.com/cuda/thrust/index.html</td></tr><tr class="odd"><td>Geometry Performance Primitives</td><td>计算几何</td><td>https://developer.nvidia.com/geometric-performance-primitives-gpp</td></tr><tr class="even"><td>Paralution</td><td>稀疏迭代方法</td><td>https://www.paralution.com/</td></tr><tr class="odd"><td>AmgX</td><td>核心求解</td><td>https://github.com/NVIDIA/AMGX</td></tr></tbody></table><p>CUDA的库有一些通用的工作流：</p><ul><li>在库操作中创建一个特定的库句柄来管理上下文信息；</li><li>为库函数的输入输出分配设备内存；</li><li>如果输入格式不是函数库支持的格式则需要进行转换；</li><li>将输入以支持的格式填入预先分配的设备内存中；</li><li>配置要执行的库运算；</li><li>执行一个将计算部分交付给GPU的库函数调用；</li><li>取回设备内存中的计算结果（结果可能是库设定的格式）；</li><li>如有必要，将取回的数据转换成应用程序的原始格式；</li><li>释放CUDA资源；</li><li>继续完成应用程序的其他工作。</li></ul><h2 id="cusparse库">cuSPARSE库</h2><p>较新版本的cuSPARSE将API分为了两大类：</p><ul><li>Legacy：这部分接口是为了兼容旧版本所保留的，在未来的版本也不会改进；</li><li>Generic：这部分是cuSPARSE的标准接口。</li></ul><p>下面的讨论都基于Generic系列接口。</p><p>Generic系列接口大体分为几类：</p><ul><li>稀疏向量与稠密向量之间的操作（<code>Axpby</code>、<code>Gather</code>、<code>Scatter</code>、求和、点积）；</li><li>稀疏向量与稠密矩阵之间的操作（乘积）；</li><li>稀疏矩阵与稠密向量之间的操作（乘积、三角线性方程求解、三对角、五对角线性方程求解）；</li><li>稀疏矩阵与稠密矩阵之间的操作（乘积、三角线性方程求解、三对角、五对角线性方程求解）；</li><li>稀疏矩阵与稀疏矩阵之间的操作（求和、乘积）；</li><li>稠密矩阵与稠密矩阵之间的操作，输出一个稀疏矩阵（乘积）；</li><li>稀疏矩阵预处理（不完全Cholesky分解、不完全LU分解）；</li><li>不同稀疏矩阵存储格式的相互转换。</li></ul><h3 id="cusparse数据存储格式">cuSPARSE数据存储格式</h3><p>cuSPARSE的索引有两种，从零开始和从一开始的，这是为了兼容<code>C/C++</code>和<code>Fortran</code>。</p><h4 id="向量存储格式">向量存储格式</h4><p>稠密向量不过多介绍，与<code>C/C++</code>的数组存储方式是一致的。</p><p>稀疏向量是借助两个数组表示的：</p><ul><li>值数组<code>values</code>：存储向量中的非零值；</li><li>索引数组<code>indices</code>：存储向量中非零值在等价稠密向量中的索引。</li></ul><p>官方文档中的图片很好的解释了这种存储方式。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5356cf8f-d236-4e1f-b18e-2348c6d0943a" style="zoom:25%;"></p><h4 id="矩阵存储格式">矩阵存储格式</h4><h5 id="稠密矩阵">稠密矩阵</h5><p>稠密矩阵有行优先和列优先两种组织方式，通过几个参数来表示：</p><ul><li>矩阵行数<code>rows</code>；</li><li>矩阵列数<code>columns</code>；</li><li>主维度<code>leading_dimension</code>：主维度在行优先模式下必须大于等于列数，在列优先模式下必须大于等于行数；</li><li>值数组指针：该数组的长度在行优先模式下为<code>rows * leading_dimension</code>，在列优先模式下为<code>columns * leading_dimension</code>。</li></ul><p>下图是一个<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 2222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></svg></mjx-container></span>的稠密矩阵在两种模式下的内存布局。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/c0295ca3-e6c7-4f35-a6eb-b7ec254b0df4" style="zoom: 25%;"></p><p>这里比较特殊的一个参数就是主维度<code>leading_dimension</code>，这个参数的存在是为了更好的表示子矩阵。下图是官方文档中的示例。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/405673bc-5fd7-4208-ae44-a0094fe79547" style="zoom:25%;"></p><p>我们推广这个示例，将一个<code>rows * columns</code>的矩阵以行优先存储，并令其<code>leading_dimension</code>为<code>columns</code>。此时取它的一个<code>m * n</code>的子矩阵，起始元素指针为<code>sub</code>，想要得到其<code>(i, j)</code>位置的元素，只需要利用如下计算公式：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs perl">sub_ij = <span class="hljs-function"><span class="hljs-keyword">sub</span> + <span class="hljs-title">j</span> * <span class="hljs-title">leading_dimension</span> + <span class="hljs-title">i</span></span>;<br></code></pre></td></tr></table></figure><p>列优先存储同理。</p><h5 id="稀疏矩阵">稀疏矩阵</h5><h6 id="坐标存储coordinate-coo">坐标存储Coordinate (COO)</h6><p>COO是一种利用非零元素及其坐标来存储稀疏矩阵的方式，主要有如下参数表示：</p><ul><li>矩阵行数<code>rows</code>；</li><li>矩阵列数<code>columns</code>；</li><li>非零元素个数<code>nnz</code>；</li><li>行索引数组指针<code>row_indices</code>：其长度为<code>nnz</code>，存放了非零元素在等价稠密矩阵中的行索引；</li><li>列索引数组指针<code>column_indices</code>：其长度为<code>nnz</code>，存放了非零元素在等价稠密矩阵中的列索引；</li><li>值数组指针<code>values</code>：其长度为<code>nnz</code>，存放了矩阵的非零元素，按照等价稠密矩阵行优先的顺序排列。</li></ul><p>COO的每一项由一个<code>&lt;row, column&gt;</code>的二元组表示，COO默认是按照行的顺序排序的。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5bb89fb8-5c28-4ad2-9eff-742ee6966220"></p><p>若想计算COO格式下的元素在等价稠密矩阵中的位置，可以通过如下公式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 行优先</span><br>rows_indices[i] * leading_dimension + column_indices[i];<br><br><span class="hljs-comment">// 列优先</span><br>column_indices[i] * leading_dimension + row_indices[i];<br></code></pre></td></tr></table></figure><h6 id="压缩稀疏行compressed-sparse-row-csr">压缩稀疏行Compressed Sparse Row (CSR)</h6><p>CSR和COO非常类似，只是将行索引数组进行了压缩，用一个行偏移数组来代替了。</p><ul><li>行偏移数组<code>row_offsets</code>：其长度为<code>rows + 1</code>，存储了每一行起始元素在列索引数组和值索引数组中的位置；</li><li>其余参数与COO一致。</li></ul><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b1e1c0e8-83a0-4b8c-a689-803396446ac9"></p><p>若想计算CSR格式下的元素在等价稠密矩阵中的位置，可以通过如下公式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 行优先</span><br>row * leading_dimension + column_indices[row_offsets[row] + k]<br><br><span class="hljs-comment">// 列优先</span><br>column_indices[row_offsets[row] + k] * leading_dimension + row<br></code></pre></td></tr></table></figure><blockquote><p>其中，<code>row</code>表示稠密矩阵的第几行，<code>k</code>的范围是<code>k = 0; k &lt; row_offsets[row + 1] - row_offsets[row]</code>。</p></blockquote><p>此外还有CSC、SELL、BSR、BLOCKED-ELL等稀疏矩阵的存储方式，详细参考官方文档的介绍。</p><h3 id="具体示例">具体示例</h3><p>我们来实现一个比较常见的操作<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="18.01ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 7960.4 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D418" d="M605 0Q581 3 434 3Q286 3 262 0H250V62H358V275L126 624H19V686H30Q54 683 189 683Q361 685 370 686H383V624H308L319 608Q330 591 353 556T396 491L484 359L660 623Q660 624 623 624H585V686H595Q613 683 728 683Q832 683 841 686H849V624H742L509 274V62H618V0H605Z"></path></g></g><g data-mml-node="mo" transform="translate(1146.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2202.6,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2842.6,0)"><g data-mml-node="mi"><path data-c="1D400" d="M296 0Q278 3 164 3Q58 3 49 0H40V62H92Q144 62 144 64Q388 682 397 689Q403 698 434 698Q463 698 471 689Q475 686 538 530T663 218L724 64Q724 62 776 62H828V0H817Q796 3 658 3Q509 3 485 0H472V62H517Q561 62 561 63L517 175H262L240 120Q218 65 217 64Q217 62 261 62H306V0H296ZM390 237L492 238L440 365Q390 491 388 491Q287 239 287 237H390Z"></path></g><g data-mml-node="mo" transform="translate(1091.2,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(1591.4,0)"><path data-c="1D417" d="M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z"></path></g></g><g data-mml-node="mo" transform="translate(5525.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(6525.4,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7091.4,0)"><g data-mml-node="mi"><path data-c="1D418" d="M605 0Q581 3 434 3Q286 3 262 0H250V62H358V275L126 624H19V686H30Q54 683 189 683Q361 685 370 686H383V624H308L319 608Q330 591 353 556T396 491L484 359L660 623Q660 624 623 624H585V686H595Q613 683 728 683Q832 683 841 686H849V624H742L509 274V62H618V0H605Z"></path></g></g></g></g></svg></mjx-container></span>，也就是<code>SpMV</code>函数。接下来的内容重点在于cuSPARSE库一些通用操作。</p><p>首先需要创建一个句柄。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cusparseHandle_t handle;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseCreate</span>(&amp;handle));<br></code></pre></td></tr></table></figure><p>由于我们的数据大部分是在主机端准备的，所以生成的数据自然而然地是以稠密的形式存储的。所以需要进行稠密矩阵到稀疏矩阵的转换。这一部分的工作可能有一些复杂，总体步骤包含：</p><ul><li>创建cuSPARSE的稠密和稀疏矩阵；</li><li>判断是否需要额外的buffer；</li><li>分析非零元素个数；</li><li>准备特定稀疏矩阵格式所需要的空间；</li><li>执行转换。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 创建稠密矩阵</span><br>cusparseDnMatDescr_t dn_mat;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseCreateDnMat</span>(&amp;dn_mat, rows, columns, ld, d_A, CUDA_R_32F, CUSPARSE_ORDER_ROW));<br><br><span class="hljs-comment">// 创建稀疏矩阵</span><br>cusparseSpMatDescr_t sp_mat;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseCreateCsr</span>(&amp;sp_mat, rows, columns, <span class="hljs-number">0</span>, d_row_offsets_A, <span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>, CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I, CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F));<br><br><span class="hljs-comment">// 若有必要，为转换工作申请额外的buffer</span><br><span class="hljs-type">size_t</span> buffer_size = <span class="hljs-number">0</span>;<br><span class="hljs-type">void</span> *d_buffer     = <span class="hljs-literal">NULL</span>;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseDenseToSparse_bufferSize</span>(handle, dn_mat, sp_mat, CUSPARSE_DENSETOSPARSE_ALG_DEFAULT, &amp;buffer_size)); <span class="hljs-comment">// 该函数返回所需的buffer大小</span><br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMalloc</span>(&amp;d_buffer, buffer_size));<br><br><span class="hljs-comment">// 分析矩阵中的非零元素个数</span><br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseDenseToSparse_analysis</span>(handle, dn_mat, sp_mat, CUSPARSE_DENSETOSPARSE_ALG_DEFAULT, d_buffer));<br><span class="hljs-comment">// 获取非零元素个数</span><br><span class="hljs-type">int64_t</span> rows_tmp, cols_tmp, nnz;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseSpMatGetSize</span>(sp_mat, &amp;rows_tmp, &amp;cols_tmp, &amp;nnz));<br><br><span class="hljs-comment">// 申请CSR中的列索引数组和值数组</span><br><span class="hljs-type">int</span> *d_column_indices_A;<br><span class="hljs-type">float</span> *d_values_A;<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_column_indices_A, nnz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>)));<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_values_A, nnz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br><br><span class="hljs-comment">// 为稀疏矩阵设置各个数组指针</span><br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseCsrSetPointers</span>(sp_mat, d_row_offsets_A, d_column_indices_A, d_values_A));<br><br><span class="hljs-comment">// 执行稠密矩阵到稀疏矩阵的转换</span><br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseDenseToSparse_convert</span>(handle, dn_mat, sp_mat, CUSPARSE_DENSETOSPARSE_ALG_DEFAULT, d_buffer));<br></code></pre></td></tr></table></figure><p>准备好矩阵后，接着准备参与运算的两个稠密向量。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cusparseDnVecDescr_t dn_vec_X, dn_vec_Y;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseCreateDnVec</span>(&amp;dn_vec_X, columns, d_X, CUDA_R_32F));<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseCreateDnVec</span>(&amp;dn_vec_Y, rows, d_Y, CUDA_R_32F));<br></code></pre></td></tr></table></figure><p>最后就是执行计算，但在执行真正的计算之前，依然需要判断是否需要额外的buffer。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 若有必要，为SpMV计算申请额外的buffer</span><br><span class="hljs-type">float</span> alpha = <span class="hljs-number">3.0f</span>;<br><span class="hljs-type">float</span> beta  = <span class="hljs-number">4.0f</span>;<br><span class="hljs-type">size_t</span> spmv_buffer_size;<br><span class="hljs-type">void</span> *d_spmv_buffer;<br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseSpMV_bufferSize</span>(handle, CUSPARSE_OPERATION_NON_TRANSPOSE, &amp;alpha, sp_mat, dn_vec_X, &amp;beta, dn_vec_Y, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, &amp;spmv_buffer_size));<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMalloc</span>(&amp;d_spmv_buffer, spmv_buffer_size));<br><br><span class="hljs-comment">// 执行SpMV计算</span><br><span class="hljs-built_in">ERROR_CHECK_CUSPARSE</span>(<span class="hljs-built_in">cusparseSpMV</span>(handle, CUSPARSE_OPERATION_NON_TRANSPOSE, &amp;alpha, sp_mat, dn_vec_X, &amp;beta, dn_vec_Y, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, d_spmv_buffer));<br></code></pre></td></tr></table></figure><blockquote><p>注意，无论是计算之前，还是前面提到的稠密转稀疏之前，它们判断是否需要额外buffer的操作，全部交给库来自行判断，不需要人为干预。程序员需要做的只是写一个像上面一样较为通用的代码，使其能够在需要buffer的时候申请得到即可。</p></blockquote><blockquote><p>示例完整代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/01_cusparse.cu">cusparse.cu</a>。关于其他API就不过多阐述了，用到的时候查官方文档即可。</p></blockquote><h2 id="cublas库">cuBLAS库</h2><p>cuBLAS库与cuSPARSE库最大的不同在于，cuBLAS库并不支持多种稀疏矩阵类型，它更擅长处理稠密矩阵和稠密向量的运算。</p><p>当前的cuBLAS库将接口分为了四类：</p><ul><li>cuBLAS API（CUDA 6.0开始）；</li><li>cuBLASXt API（CUDA 6.0开始）；</li><li>cuBLASLt API（CUDA 10.1开始）；</li><li>cuBLASDx API（未包含在CUDA Toolkit中）。</li></ul><p>上面四套API的主要区别在于：</p><ul><li>cuBLAS API需要将数据搬移到设备上进行运算；</li><li>cuBLASXt API可以将数据放在主机或参与运算的任何设备上，库会承担运算和数据分发的责任；</li><li>cuBLASLt API是一套专注于通用矩阵乘（GEMM）的灵活的轻量级API，该API可以通过参数来灵活指定矩阵数据布局、输入类型、计算类型以及算法的实现。用户指定了一组预期的GEMM操作后，这组操作可以根据不同的输入来复用；</li><li>cuBLASDx API则是一个设备端API扩展，可以在核函数中执行BLAS计算。通过融合数值运算，可以减少延迟并进一步提高性能。目前该组API还在preview阶段。</li></ul><p>同时，cuBLAS API存在新旧两套API，后面的所有讨论都基于定义在<code>cublas_v2.h</code>头文件中的新版API，旧版API定义在<code>cublas.h</code>中。具体的区别这里不过多讨论，有兴趣可以查看官方文档<a href="https://docs.nvidia.com/cuda/cublas/index.html#new-and-legacy-cublas-api">New and Legacy cuBLAS API</a>。</p><h3 id="cublas数据存储格式">cuBLAS数据存储格式</h3><p>cuBLAS有两套数据排布方式，一套为了兼容Fortran从1开始的索引，另一套是兼容C从0开始的索引。可以通过以下两个宏来计算全局索引。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> IDX2C(i,j,ld) (((j)*(ld))+(i))</span><br></code></pre></td></tr></table></figure><p>要记住最核心的一点，cuBLAS是以<strong>列主序</strong>的形式存储矩阵的。</p><h3 id="具体示例-1">具体示例</h3><p>在熟悉了cuSPARSE的使用之后，你会发现cuBLAS要简洁很多，因为少了很多配置稀疏矩阵的过程，下面以通用矩阵乘法为例说明。</p><p>同样地，首先创建句柄。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cublasHandle_t handle;<br><span class="hljs-built_in">ERROR_CHECK_CUBLAS</span>(<span class="hljs-built_in">cublasCreate</span>(&amp;handle));<br></code></pre></td></tr></table></figure><p>然后就可以直接进行计算了，如果需要的话，可以使用<code>cublasSetStream()</code>来绑定一个流。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">ERROR_CHECK_CUBLAS</span>(<span class="hljs-built_in">cublasSgemm</span>(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, &amp;alpha, d_A, lda, d_B, ldb, &amp;beta, d_C, ldc));<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/02_cublas.cu">cublas.cu</a>。</p></blockquote><h2 id="cufft库">cuFFT库</h2><p>cuFFT库由两部分组成：</p><ul><li>cuFFT：提供GPU上的高性能快速傅里叶变换操作，它需要提前将数据搬移到设备端；</li><li>cuFFTW：为FFTW的用户提供快速移植到GPU的能力，为了这种快速移植能力，cuFFTW支持主机端的数据传入，它将自动为用户处理如<code>cudaMalloc</code>、<code>cudaMemcpy</code>等操作。</li></ul><p>下面的内容重点介绍cuFFT。cuFFT提供一种简单易用的配置机制称为<code>plan</code>，它使用内部构建的block来优化给定配置和特定GPU硬件之间的转化。一旦创建了一个<code>plan</code>，库将自动保存多次执行该<code>plan</code>所需的所有状态，无需重新配置。不同类型的FFT需要不同的线程配置和GPU资源，<code>plan</code>接口提供了这样一种简单的配置重用方式。</p><p>cuFFT支持多种类型的变换，如复数-复数变换（C2C）、复数-实数变换（C2R）、实数-复数变换（R2C）。由于变换的不同，需要的输入输出数据布局也就不同。</p><h3 id="cufft数据存储格式">cuFFT数据存储格式</h3><p>在cuFFT中，数据布局严格取决于配置和变换的类型。一般地，C2C变换情况下，输入输出数据应为<code>cufftComplex</code>或<code>cufftDoubleComplex</code>，具体取决于计算精度。而C2R变换，只需要非冗余的复数元素组成的向量作为输入，输出则是由<code>cufftReal</code>或<code>cufftDouble</code>元素组成的向量。对于R2C变换，需要一个实数向量作为输入，输出一个非冗余复数元素组成的向量。</p><p>在C2R和R2C变换中，输入输出的大小是不同的。对于非就地变换，创建一个大小合适的输出数组即可。但对于就地变换，程序员应当使用填充的数据布局，这种布局与FFTW兼容。无论是就地C2R还是R2C变换，输出的起始地址都与输入的起始地址一致，所有应当填充R2C中的输入或C2R中的输出数据。</p><p>以一维变换为例，期望的输入输出大小以及类型如下表所示。</p><table><thead><tr class="header"><th>FFT类型</th><th>输入数据大小（类型）</th><th>输出数据大小（类型）</th></tr></thead><tbody><tr class="odd"><td>C2C</td><td><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（<code>cufftComplex</code>）</td><td><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（<code>cufftComplex</code>）</td></tr><tr class="even"><td>C2R</td><td><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex;" xmlns="http://www.w3.org/2000/svg" width="7.817ex" height="2.477ex" role="img" focusable="false" viewBox="0 -750 3454.9 1095"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="230A" d="M174 734Q174 735 175 737T177 740T180 744T184 747T189 749T196 750Q206 748 214 735V-210H310H373Q401 -210 411 -213T422 -230T411 -247T369 -251Q362 -251 338 -251T298 -250H190Q178 -246 174 -234V734Z"></path></g><g data-mml-node="mfrac" transform="translate(444,0)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(245.5,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="604.5" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1288.5,0)"><path data-c="230B" d="M229 734Q229 735 230 737T232 740T235 744T239 747T244 749T251 750Q262 748 269 735V-235Q266 -240 256 -249L147 -250H77Q43 -250 32 -247T21 -230T32 -213T72 -209Q79 -209 99 -209T133 -210H229V734Z"></path></g><g data-mml-node="mo" transform="translate(1954.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2954.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>（<code>cufftComplex</code>）</td><td><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（<code>cufftReal</code>）</td></tr><tr class="odd"><td>R2C</td><td><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（<code>cufftReal</code>）</td><td><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex;" xmlns="http://www.w3.org/2000/svg" width="7.817ex" height="2.477ex" role="img" focusable="false" viewBox="0 -750 3454.9 1095"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="230A" d="M174 734Q174 735 175 737T177 740T180 744T184 747T189 749T196 750Q206 748 214 735V-210H310H373Q401 -210 411 -213T422 -230T411 -247T369 -251Q362 -251 338 -251T298 -250H190Q178 -246 174 -234V734Z"></path></g><g data-mml-node="mfrac" transform="translate(444,0)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(245.5,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="604.5" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1288.5,0)"><path data-c="230B" d="M229 734Q229 735 230 737T232 740T235 744T239 747T244 749T251 750Q262 748 269 735V-235Q266 -240 256 -249L147 -250H77Q43 -250 32 -247T21 -230T32 -213T72 -209Q79 -209 99 -209T133 -210H229V734Z"></path></g><g data-mml-node="mo" transform="translate(1954.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2954.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>（<code>cufftComplex</code>）</td></tr></tbody></table><p>对于多维的情况，参考官方文档<a href="https://docs.nvidia.com/cuda/cufft/index.html#multidimensional-transforms">multidimensional-transforms</a>。</p><h3 id="具体示例-2">具体示例</h3><p>关于傅里叶变换算法本身这里不过多展开，下面用一个比较基本的一维复数-复数FFT来说明。</p><p>首先依旧是创建句柄，这里之所以将句柄命名为<code>plan</code>是因为，后续创建cuFFT的<code>plan</code>时，是基于这个句柄的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cufftHandle plan;<br><span class="hljs-built_in">ERROR_CHECK_CUFFT</span>(<span class="hljs-built_in">cufftCreate</span>(&amp;plan));<br></code></pre></td></tr></table></figure><p>创建<code>plan</code>，这个<code>plan</code>可以复用。如果需要的话，可以使用<code>cufftSetStream()</code>来绑定一个流。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">ERROR_CHECK_CUFFT</span>(<span class="hljs-built_in">cufftPlan1d</span>(&amp;plan, fft_size, CUFFT_C2C, batch_size));<br></code></pre></td></tr></table></figure><p>执行变换操作，这里进行了一次正向变换，归一化后又进行了逆向变换。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 执行正向变换</span><br><span class="hljs-built_in">ERROR_CHECK_CUFFT</span>(<span class="hljs-built_in">cufftExecC2C</span>(plan, d_data, d_data, CUFFT_FORWARD));<br><span class="hljs-comment">// 归一化</span><br>scaling_kernel&lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;(d_data, element_count, <span class="hljs-number">1.f</span> / fft_size);<br><span class="hljs-comment">// 执行逆向变换</span><br><span class="hljs-built_in">ERROR_CHECK_CUFFT</span>(<span class="hljs-built_in">cufftExecC2C</span>(plan, d_data, d_data, CUFFT_INVERSE));<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/03_cufft.cu">cufft.cu</a>。</p></blockquote><h2 id="curand库">cuRAND库</h2><p>介绍cuRAND库之前要引入两个与随机数生成相关的概念：</p><ul><li>PRNG：伪随机数生成器；</li><li>QRNG：拟随机数生成器。</li></ul><p>PRNG和QRNG的最大区别就在于，生成每一个随机数的事件是否为独立事件。PRNG每次采样均为独立统计事件，这意味着每次采样，所得到某个数的概率是相同的。而QRNG每次采样并不是独立事件，它会尽可能的均匀填充输出类型的范围。一个更具体的例子是，假设第一个生成的随机数是2的概率为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.44ex" height="1.92ex" role="img" focusable="false" viewBox="0 -683 1078.6 848.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mn" transform="translate(675,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container></span>，下一个生成的随机数同样是2的概率为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.44ex" height="1.885ex" role="img" focusable="false" viewBox="0 -683 1078.6 833"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mn" transform="translate(675,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></span>。在PRNG中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.44ex" height="1.885ex" role="img" focusable="false" viewBox="0 -683 1078.6 833"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mn" transform="translate(675,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></span>不会因为上一次取得的数是2就变小，它与<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.44ex" height="1.92ex" role="img" focusable="false" viewBox="0 -683 1078.6 848.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mn" transform="translate(675,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container></span>是完全相等的，但在QRNG中，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.44ex" height="1.885ex" role="img" focusable="false" viewBox="0 -683 1078.6 833"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mn" transform="translate(675,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></span>会由于<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.44ex" height="1.92ex" role="img" focusable="false" viewBox="0 -683 1078.6 848.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mn" transform="translate(675,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container></span>的成立而变小。</p><p>cuRAND库与其他库最大的不同就是，它提供了主机端和设备端两套API。</p><p>主机端API定义在头文件<code>curand.h</code>中。但要注意的是，主机端API允许两种生成方式：主机生成和设备生成。若生成时传入的数据指针是主机内存指针，则生成过程由CPU在主机端完成，结果也存储在主机内存中。若生成时传入的数据指针是设备内存指针，则生成过程由设备端完成，结果存储在设备的全局内存中。</p><p>设备端API定义在头文件<code>curand_kernel.h</code>中，可以在核函数中直接生成随机数并使用，而不需要将生成结果存入全局内存后再读取。</p><p>cuRAND库的RNG有9种，分别有5种PRNG和4种QRNG：</p><ul><li>PRNG：<ul><li>CURAND_RNG_PSEUDO_XORWOW：使用XORWOW算法实现的，XORWOW算法是伪随机数生成器xor-shift系列的成员；</li><li>CURAND_RNG_PSEUDO_MRG32K3A：组合多重递归伪随机数生成器系列的成员；</li><li>CURAND_RNG_PSEUDO_MTGP32：Mersenne Twister伪随机数生成器系列的成员，具有为GPU定制的参数；</li><li>CURAND_RNG_PSEUDO_MT19937：Mersenne Twister伪随机数生成器系列的成员，参数与CPU版本相同，但顺序不同，仅支持主机API，并且只能在架构sm_35或更高版本上使用；</li><li>CURAND_RNG_PSEUDO_PHILOX4_32_10：Philox系列的成员，三大基于非加密计数器的随机数生成器之一。</li></ul></li><li>QRNG：<ul><li>CURAND_RNG_QUASI_SOBOL32：32位序列的Sobol生成器；</li><li>CURAND_RNG_QUASI_SCRAMBLED_SOBOL32：添加扰乱的32位序列的Sobol生成器；</li><li>CURAND_RNG_QUASI_SOBOL64：64位序列的Sobol生成器；</li><li>CURAND_RNG_QUASI_SCRAMBLED_SOBOL64：添加扰乱的64位序列的Sobol生成器。</li></ul></li></ul><blockquote><p>cuRAND中的QRNG都是基于Sobol算法的，它以方向向量作为种子，上述的四种变体每种都能产生高达20000维的序列。</p></blockquote><h3 id="具体示例-3">具体示例</h3><h4 id="主机端api">主机端API</h4><p>主机端API调用流程如下：</p><ul><li>创建生成器并指定RNG类型；</li><li>设置偏移量（<code>offset</code>）、排序方式（<code>ordering</code>）、种子（<code>seed</code>）；</li><li>从指定分布中执行生成任务；</li><li>若在设备端生成，根据需要确定是否将生成结果拷贝回主机端；</li></ul><p>具体示例如下，首先创建生成器。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">ERROR_CHECK_CURAND</span>(<span class="hljs-built_in">curandCreateGeneratorHost</span>(&amp;gen, CURAND_RNG_PSEUDO_XORWOW)); <span class="hljs-comment">// 主机端生成</span><br><span class="hljs-built_in">ERROR_CHECK_CURAND</span>(<span class="hljs-built_in">curandCreateGenerator</span>(&amp;gen, CURAND_RNG_PSEUDO_XORWOW)); <span class="hljs-comment">// 设备端生成</span><br></code></pre></td></tr></table></figure><p>设置<code>offset</code>、<code>ordering</code>、<code>seed</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 设置偏移量</span><br><span class="hljs-built_in">ERROR_CHECK_CURAND</span>(<span class="hljs-built_in">curandSetGeneratorOffset</span>(gen, <span class="hljs-number">0ULL</span>));<br><span class="hljs-comment">// 设置排序方式</span><br><span class="hljs-built_in">ERROR_CHECK_CURAND</span>(<span class="hljs-built_in">curandSetGeneratorOrdering</span>(gen, CURAND_ORDERING_PSEUDO_BEST));<br><span class="hljs-comment">// 设置种子</span><br><span class="hljs-built_in">ERROR_CHECK_CURAND</span>(<span class="hljs-built_in">curandSetPseudoRandomGeneratorSeed</span>(gen, <span class="hljs-number">1234ULL</span>));<br></code></pre></td></tr></table></figure><p>从指定分布中执行生成任务。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 以正态分布为例，此外还有均匀分布、对数正态分布和泊松分布</span><br><span class="hljs-built_in">ERROR_CHECK_CURAND</span>(<span class="hljs-built_in">curandGenerateNormal</span>(gen, data, n, mean, stddev));<br></code></pre></td></tr></table></figure><h4 id="设备端api">设备端API</h4><p>设备端API调用主要有以下几个步骤：</p><ul><li>根据RNG算法创建状态；</li><li>初始化状态；</li><li>生成随机值；</li></ul><p>每个支持的RNG算法都有对应的状态。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">curandStateXORWOW_t rand_state;<br></code></pre></td></tr></table></figure><p>根据不同的RNG算法调用不同的<code>curand_init</code>重载。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> seed = threadIdx.x;<br><span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> subsequence = <span class="hljs-number">1ULL</span>;<br><span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> offset      = <span class="hljs-number">0ULL</span>;<br><span class="hljs-built_in">curand_init</span>(seed, subsequence, offset, &amp;rand_state);<br></code></pre></td></tr></table></figure><blockquote><p>值得注意的是，由于线程的高度并发，所以应当避免在不同线程中使用相同的种子，也应当避免使用当前时间戳作为种子。</p><p>这里的<code>subsequence</code>会使得<code>curand_init()</code>返回的序列是调用了<code>(2^67 * subsequence + offset)</code>次<code>curand()</code>的结果。</p></blockquote><p>最后生成随机值。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">float</span> x = <span class="hljs-built_in">curand_normal</span>(&amp;rand_state);<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/04_curand.cu">curand.cu</a>。</p></blockquote><h2 id="openacc">OpenACC</h2><h3 id="基本概念">基本概念</h3><p>OpenACC是一个基于编译器指令的API，它的工作方式和OpenMP非常类似，都是使用<code>#pragma</code>开头的编译器指令作为指导。OpenACC的并行粒度分为<code>gang</code>、<code>worker</code>、<code>vector</code>，这些概念可以和CUDA一一对应。</p><table><thead><tr class="header"><th>OpenACC</th><th>CUDA</th></tr></thead><tbody><tr class="odd"><td><code>gang</code></td><td><code>block</code></td></tr><tr class="even"><td><code>worker</code></td><td><code>warp</code>（未显式指出）</td></tr><tr class="odd"><td><code>vector</code></td><td><code>thread</code></td></tr></tbody></table><p>一个<code>gang</code>可以包含一个或多个执行线程，每个<code>gang</code>内部都包含一个或多个<code>worker</code>。每个<code>worker</code>都有一个向量宽度，由一个或多个同时执行相同指令的向量元素构成，简单理解就是一个<code>worker</code>可以包含一个或多个<code>vector</code>。每个<code>vector</code>都是一个单一的执行流，类似于CUDA线程。</p><p>OpenACC的目标是建立一个单线程的主机程序，该主机程序将核函数下放至多处理单元（PU），每个PU一次只运行一个<code>gang</code>，但可以同时执行多个独立的<code>worker</code>。在OpenACC中，<code>gang</code>并行使用多个PU，每个<code>gang</code>中的多线程并行即为<code>worker</code>并行。每个<code>worker</code>中的并行以及一个跨向量操作的并行称为<code>vector</code>并行。这里的PU有点类似于NVIDIA GPU中的SM。</p><h3 id="并行模式">并行模式</h3><p>根据任务是否通过<code>gang</code>、<code>worker</code>、<code>vector</code>并行执行，OpenACC将执行分为几种模式。</p><p>假设一个OpenACC程序的并行计算区域创建了<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.778ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 786 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g></g></g></svg></mjx-container></span>个<code>gang</code>，每个<code>gang</code>包含<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="2.371ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1048 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></svg></mjx-container></span>个<code>worker</code>，每个<code>worker</code>的向量宽度为<code>V</code>。此时总共有<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="11.421ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 5047.9 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mo" transform="translate(1008.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2008.4,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(3278.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(4278.9,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></svg></mjx-container></span>个执行线程来处理这个并行区域。</p><h4 id="gang冗余模式"><code>gang</code>冗余模式</h4><p>开始执行并行区域时，<code>gang</code>以冗余模式执行，可以在并行执行前对<code>gang</code>的状态进行初始化。在该模式下，每个<code>gang</code>中只有一个活跃的<code>worker</code>和一个活跃的<code>vector</code>元素，其他<code>worker</code>和<code>vector</code>元素是闲置的，因此只有<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.778ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 786 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g></g></g></svg></mjx-container></span>个活跃执行线程。用CUDA伪核函数来表示如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">()</span> </span>{<br>    <span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span>)<br>        <span class="hljs-built_in">foo</span>();<br>}<br></code></pre></td></tr></table></figure><h4 id="gang分裂模式"><code>gang</code>分裂模式</h4><p>在OpenACC并行区域的某些地方，程序可能通过<code>gang</code>转换为并行执行，这种情况下程序以<code>gang</code>分裂模式执行。该模式下每个<code>gang</code>中仍然只有一个活跃的<code>worker</code>和一个活跃的<code>vector</code>元素，因此同样只有<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.778ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 786 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g></g></g></svg></mjx-container></span>个活跃执行线程。但每个活跃的<code>vector</code>执行不同的并行区域，故计算任务被分散到各个<code>gang</code>中。以向量加法为例，CUDA伪核函数表达如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">(<span class="hljs-type">int</span>* v1, <span class="hljs-type">int</span>* v2, <span class="hljs-type">int</span>* out, <span class="hljs-type">int</span> N)</span> </span>{<br>    <span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span>) {<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = blockIdx.x; i &lt; N; i += gridDim.x) {<br>            out[i] = v1[i] + v2[i];<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure><blockquote><p>每个<code>gang</code>只有一个活跃<code>worker</code>时，程序处于单一<code>worker</code>模式，当<code>worker</code>中只有一个活跃<code>vector</code>时，程序处于单一<code>vector</code>模式。所以<code>gang</code>冗余模式和<code>gang</code>分裂模式也可以被称作单一<code>worker</code>模式和单一<code>vector</code>模式。</p></blockquote><h4 id="worker分裂模式"><code>worker</code>分裂模式</h4><p>在该模式下，并行区域的工作被划分到多个<code>gang</code>的多个<code>worker</code>中，可以提供<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="6.915ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 3056.4 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mo" transform="translate(1008.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2008.4,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></svg></mjx-container></span>路并行。CUDA伪核函数表达如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">(<span class="hljs-type">int</span>* v1, <span class="hljs-type">int</span>* v2, <span class="hljs-type">int</span>* out, <span class="hljs-type">int</span> N)</span> </span>{<br>    <span class="hljs-keyword">if</span> (threadIdx.x % warpSize == <span class="hljs-number">0</span>) {<br>        <span class="hljs-type">int</span> warpId = threadIdx.x / warpSize;<br>        <span class="hljs-type">int</span> warpsPerBlock = blockDim.x / warpSize;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = blockIdx.x * warpsPerBlock + warpId; i &lt; N; i += gridDim.x * warpsPerBlock) {<br>            out[i] = v1[i] + v2[i];<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure><h4 id="vector分裂模式"><code>vector</code>分裂模式</h4><p>该模式将工作在<code>gang</code>、<code>worker</code>、<code>vector</code>通道上进行划分，提供<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="11.421ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 5047.9 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mo" transform="translate(1008.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2008.4,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(3278.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(4278.9,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></svg></mjx-container></span>路并行。该模式最接近CUDA核函数的行为模式，CUDA伪核函数表达如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">(<span class="hljs-type">int</span>* v1, <span class="hljs-type">int</span>* v2, <span class="hljs-type">int</span>* out, <span class="hljs-type">int</span> N)</span> </span>{<br>    <span class="hljs-keyword">if</span> (threadIdx.x &lt; N)<br>        out[i] = v1[i] + v2[i];<br>}<br></code></pre></td></tr></table></figure><h3 id="基本用法">基本用法</h3><p>前面提到了OpenACC的工作方式与OpenMP的极为相似，在源代码中加入<code>#pragma acc</code>即可指导编译器对源代码进行翻译，使其能够在GPU上并行执行。</p><h4 id="计算指令">计算指令</h4><h5 id="核函数指令">核函数指令</h5><p><code>#pragma acc kernels</code>会自动分析代码块中的可并行循环。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels</span><br>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        C[i] = A[i] + B[i];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>核函数指令可以有条件子句来修饰，当条件为<code>false</code>时，代码块不会在设备上执行。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels <span class="hljs-keyword">if</span>(N &gt; 128)</span><br>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        C[i] = A[i] + B[i];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>默认情况下，核函数指令结束时会有一个隐式同步，但可以通过添加<code>async</code>子句来使执行不被阻塞。</p><p><code>async</code>子句接受一个可选的整型参数，若传入ID则可以使用指令来等待。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels async(3)</span><br>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        C[i] = A[i] + B[i];<br>    }<br>}<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc wait(3) <span class="hljs-comment">// 或通过运行时API来等待 acc_async_wait(3)</span></span><br><span class="hljs-comment">// 或者使用空等待指令，等待所以异步任务完成</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc wait <span class="hljs-comment">// 或通过运行时API来等待 acc_async_wait_all</span></span><br></code></pre></td></tr></table></figure><p>也可以将<code>async</code>子句和<code>wait</code>子句结合起来，实现链式异步工作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels async(0)</span><br>{<br>    ...<br>}<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels wait(0) async(1)</span><br>{<br>    ...<br>}<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels wait(1) async(2)</span><br>{<br>    ...<br>}<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc wait(2)</span><br></code></pre></td></tr></table></figure><p>而检查异步任务在没有阻塞的情况下是否完成只能通过运行时API来完成。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">acc_async_test</span>(<span class="hljs-type">int</span>); <span class="hljs-comment">// 已结束返回非零值，否则返回零</span><br></code></pre></td></tr></table></figure><blockquote><p>目前想要编译OpenACC的代码，推荐使用PGI编译器。PGI被英伟达收购之后，编译器就纳入了NVIDIA HPC SDK中了。需要安装HPC SDK后使用<code>pgcc</code>命令来编译代码。详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/05_openacc_kernels.c">openacc_kernels.c</a>。</p></blockquote><h5 id="并行指令">并行指令</h5><p>上面提到的核函数指令是一个强大的工具，编译器会自动分析代码并选择一个合适的并行策略，在这个过程中，程序员对程序的控制是较少的。但并行指令<code>#pragma acc parallel</code>则可以提供更多的控制选项。</p><p>并行指令同样支持核函数指令的一些子句，如<code>if</code>、<code>async</code>、<code>wait</code>。此外可以使用<code>num_gangs(int)</code>来设置<code>gang</code>数量，<code>num_workers(int)</code>设置<code>worker</code>数量，<code>vector_length(int)</code>设置每个<code>worker</code>的向量宽度。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel num_gangs(32) num_workers(32) vector_length(64)</span><br>{<br>    ...<br>}<br></code></pre></td></tr></table></figure><p>并行指令还支持<code>reduction</code>子句，格式为<code>#pragma acc parallel reduction(op:var1, var2, ...)</code>，支持的<code>op</code>有<code>+</code>、<code>*</code>、<code>max</code>、<code>min</code>、<code>&amp;</code>、<code>|</code>、<code>^</code>、<code>&amp;&amp;</code>、<code>||</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel reduction(+ : result)</span><br>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        result += A[i];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>并行指令还支持<code>private</code>和<code>firstprivate</code>子句。<code>private</code>会为每个<code>gang</code>创建一个<code>private</code>型复制变量，只有该<code>gang</code>可以使用该变量的拷贝，因此该值的改变对其他<code>gang</code>或主机程序是不可见的。<code>firstprivate</code>功能和<code>private</code>相同，只是会将每个<code>gang</code>中的<code>private</code>型变量的值初始化为主机上该变量当前的值。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel private(a)</span><br>{<br>    ...<br>}<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel firstprivate(a)</span><br>{<br>...<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/06_openacc_parallel.c">openacc_parallel.c</a>。</p></blockquote><h5 id="循环指令">循环指令</h5><p>并行指令需要程序员为编译器明确标注并行性，并行区域总是以<code>gang</code>冗余模式开始的，执行并行模式之间的转换需要对编译器有明确的指示，这种指示可以通过循环指令<code>#pragma acc loop</code>来完成。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel</span><br>{<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        C[i] = A[i] + B[i];<br>    }<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        D[i] = C[i] * A[i];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>上面的代码并没有为循环指令添加子句，所以编译器可以自由使用它认为的最优循环调度。也可以通过<code>gang</code>、<code>worker</code>或<code>vector</code>子句来显式控制每一级的并行性。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel</span><br>{<br>    <span class="hljs-type">int</span> a = <span class="hljs-number">1</span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop gang</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        vec2[i] = a;<br>    }<br>}<br></code></pre></td></tr></table></figure><p>上述代码中，并行区域以<code>gang</code>冗余模式开始，遇到带有<code>gang</code>子句的循环指令后，转换为了<code>gang</code>分裂模式。</p><p>考虑下列代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel</span><br>{<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        ...<br>    }<br>}<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels</span><br>{<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>    {<br>        ...<br>    }<br>}<br></code></pre></td></tr></table></figure><p>可以简写为下列形式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel loop</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>{<br>    ...<br>}<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels loop</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>{<br>    ...<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/06_openacc_parallel.c">openacc_parallel.c</a>。</p></blockquote><p>循环指令<code>loop</code>不仅可以和并行指令<code>paralle</code>结合，还可以与核函数指令<code>kernels</code>结合，但某些循环指令的子句在并行指令和核函数指令下会有所不同。</p><table><colgroup><col style="width: 13%"><col style="width: 43%"><col style="width: 43%"></colgroup><thead><tr class="header"><th>子句</th><th>并行指令下的行为</th><th>核函数指令下的行为</th></tr></thead><tbody><tr class="odd"><td><code>collapse(int)</code></td><td>指明循环指令适用于多重嵌套循环</td><td>与并行指令下相同</td></tr><tr class="even"><td><code>gang(int)</code></td><td>指明循环应通过<code>gang</code>划分到并行区域，<code>gang</code>数量由并行指令决定</td><td>说明循环应通过<code>gang</code>进行划分，<code>gang</code>有选择的使用整型参数</td></tr><tr class="odd"><td><code>worker(int)</code></td><td>指明循环应通过每个<code>gang</code>中的<code>worker</code>划分到并行区域，将每个<code>gang</code>由单一<code>worker</code>模式转换到<code>worker</code>分裂模式</td><td>说明循环应通过每个<code>gang</code>中的<code>worker</code>划分到并行区域，<code>worker</code>有选择的使用整型参数</td></tr><tr class="even"><td><code>vector(int)</code></td><td>指明循环应通过<code>vector</code>通道进行分配，是一个<code>worker</code>由单一<code>vector</code>模式转换到<code>vector</code>分裂模式</td><td>说明循环应通过<code>vector</code>通道进行分配，<code>vector</code>有选择的使用整型参数</td></tr><tr class="odd"><td><code>seq</code></td><td>为了按序执行，使用<code>seq</code>对循环进行标记</td><td>与并行指令下相同</td></tr><tr class="even"><td><code>auto</code></td><td>指明编译器应为相关的循环选择<code>gang</code>、<code>worker</code>或<code>vector</code>并行</td><td>与并行指令下相同</td></tr><tr class="odd"><td><code>tile(int, ...)</code></td><td>指明编译器应将嵌套循环中的每个循环拆分为两个循环：外层的<code>tile</code>循环和内层的<code>element</code>循环。内层循环次数为<code>tile_size</code>，外层循环次数取决于串行代码。若附加到多个紧密的嵌套循环中，<code>tile</code>可以使用多个<code>tile_size</code>，并自动将所有外部循环放在内部循环之外</td><td>与并行指令下相同</td></tr><tr class="even"><td><code>device_type(type)</code></td><td><code>type</code>是一个逗号分隔的列表，分隔不同设备类型的子句。所有子句都遵循<code>device_type</code>的设定，只有当循环在指定设备类型上执行时，才可能有指令结束，或在下一个<code>type</code>的设备上执行的情况。</td><td>与并行指令下相同</td></tr><tr class="odd"><td><code>independent</code></td><td>该子句声称被标记的循环为并行的且编译器分析高于一切</td><td>与并行指令下相同</td></tr></tbody></table><h4 id="数据指令">数据指令</h4><p><code>#pragma acc data</code>可以在主机和设备之间进行显式的数据传输。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc data copyin(A[0 : N], B[0 : N]) copyout(C[0 : N], D[0 : N])</span><br>{<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel</span><br>    {<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>        {<br>            C[i] = A[i] + B[i];<br>        }<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>        {<br>            D[i] = C[i] * A[i];<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure><p>上面的代码告知编译器，只有<code>A</code>和<code>B</code>应该被拷贝到设备，只有<code>C</code>和<code>D</code>应该被拷贝回主机。同时指明了数组的范围，某些情况下，编译器能够推断要复制的数组大小，可以将代码简化为下面的样子。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc data copyin(A, B) copyout(C, D)</span><br></code></pre></td></tr></table></figure><p>除了上述指定代码块的方法，还可以使用<code>enter data</code>指令和<code>exit data</code>指令来标记在任意节点传入和传出设备的数组。<code>enter data</code>指明的数据会持续保留在设备端，直到遇到将其传回的<code>exit data</code>指令。这两个指令可以与<code>async</code>和<code>wait</code>子句结合发挥最大作用。</p><blockquote><p>注意，单纯的<code>data</code>指令不支持<code>async</code>和<code>wait</code>子句。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp">    <span class="hljs-built_in">init</span>(vec1);<br>    <span class="hljs-built_in">init</span>(vec2);<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc enter data copyin(vec1[0 : N], vec2[0 : N]) async(0)</span><br><br><span class="hljs-built_in">process</span>(vec3);<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc kernels wait(0) async(1)</span><br>    {<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++)<br>        {<br>            vec1[i] = <span class="hljs-built_in">do_something</span>(vec2[i]);<br>        }<br>    }<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc exit data copyout(vec1[0 : N]) wait(1) async(2)</span><br><br>    <span class="hljs-built_in">process</span>(vec4);<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc wait(2)</span><br></code></pre></td></tr></table></figure><p>考虑如下代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc data copyin(A[0 : N], B[0 : N]) copyout(C[0 : N], D[0 : N])</span><br>{<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel</span><br>    {<br>...<br>    }<br>}<br></code></pre></td></tr></table></figure><p>可以简写为下列形式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel copyin(A[0 : N], B[0 : N]) copyout(C[0 : N], D[0 : N])</span><br>{<br>    ...<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/07_openacc_data.c">openacc_data.c</a>。</p></blockquote><p>数据指令支持的子句见下表。</p><table><colgroup><col style="width: 23%"><col style="width: 45%"><col style="width: 7%"><col style="width: 12%"><col style="width: 11%"></colgroup><thead><tr class="header"><th>子句</th><th>行为</th><th><code>data</code>支持</th><th><code>enter data</code>支持</th><th><code>exit data</code>支持</th></tr></thead><tbody><tr class="odd"><td><code>if(cond)</code></td><td>若<code>cond</code>为<code>true</code>则执行数据搬移</td><td>Y</td><td>Y</td><td>Y</td></tr><tr class="even"><td><code>copy(var1, ...)</code></td><td>在进入数据区域时将变量拷贝至设备端，离开数据区域时拷贝回主机端</td><td>Y</td><td>N</td><td>N</td></tr><tr class="odd"><td><code>copyin(var1, ...)</code></td><td>指明变量只能被拷贝至设备端</td><td>Y</td><td>Y</td><td>N</td></tr><tr class="even"><td><code>copyout(var1, ...)</code></td><td>指明变量只能被拷贝回主机端</td><td>Y</td><td>N</td><td>Y</td></tr><tr class="odd"><td><code>create(var1, ...)</code></td><td>指明列出的变量需要在设备端分配内存，但变量值不必传入或传出设备</td><td>Y</td><td>Y</td><td>N</td></tr><tr class="even"><td><code>present(var1, ...)</code></td><td>指明列出的变量已经在设备端了，不必再次传入。运行时，编译器会发现并使用这些已经存在于设备端的数据</td><td>Y</td><td>N</td><td>N</td></tr><tr class="odd"><td><code>present_or_copy(var1,...)</code></td><td>若列出的变量已经在设备端了，则功能与<code>present</code>一致；若不在设备端，则功能与<code>copy</code>一致</td><td>Y</td><td>N</td><td>N</td></tr><tr class="even"><td><code>present_or_copyin(var1, ...)</code></td><td>若列出的变量已经在设备端了，则功能与<code>present</code>一致；若不在设备端，则功能与<code>copyin</code>一致</td><td>Y</td><td>Y</td><td>N</td></tr><tr class="odd"><td><code>present_or_copyout(var1, ...)</code></td><td>若列出的变量已经在设备端了，则功能与<code>present</code>一致；若不在设备端，则功能与<code>copyout</code>一致</td><td>Y</td><td>N</td><td>N</td></tr><tr class="even"><td><code>present_or_create(var1, ...)</code></td><td>若列出的变量已经在设备端了，则功能与<code>present</code>一致；若不在设备端，则功能与<code>create</code>一致</td><td>Y</td><td>Y</td><td>N</td></tr><tr class="odd"><td><code>deviceptr(var1, ...)</code></td><td>指明列出的变量是设备内存指针，不必再为该指针指向的数据分配空间，也不必在主机和设备之间传输。</td><td>Y</td><td>N</td><td>N</td></tr><tr class="even"><td><code>delete(var1, ...)</code></td><td>可以与<code>exit data</code>结合使用，显式释放设备内存</td><td>N</td><td>N</td><td>Y</td></tr></tbody></table><blockquote><p>更多指令和运行时API可以参考官方文档<a href="https://www.openacc.org/specification">Specification | OpenACC</a>。</p></blockquote><h3 id="与cuda结合">与CUDA结合</h3><p>要结合CUDA与OpenACC，需要通过<code>deviceptr</code>子句来实现CUDA和OpenACC之间的数据共享。核心代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc parallel loop gang deviceptr(d_A, d_B, d_C)</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M; i++)<br>{<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> acc loop worker vector</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; P; j++)<br>    {<br>        <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; N; k++)<br>        {<br>            sum += d_A[i * N + k] * d_B[k * P + j];<br>        }<br>        d_C[i * P + j] = sum;<br>    }<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/07_acceleration_library_and_OpenACC/08_cuda_openacc.cu">cuda_openacc.cu</a>。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——调整指令集原语</title>
    <link href="https://deleter-d.github.io/posts/53610/"/>
    <id>https://deleter-d.github.io/posts/53610/</id>
    <published>2024-02-20T08:45:21.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="cuda指令概述">CUDA指令概述</h2><h3 id="浮点指令">浮点指令</h3><blockquote><p>一些前值知识：</p><ul><li>浮点型数值无法精确存储，只能在四舍五入后再存储；</li><li>浮点数存在粒度问题，即浮点数只能在离散的区间间隔里存储数据。随着浮点数离零越来越远，表示数值的区间将随之增大；</li><li>C语言中的数学函数<code>nextafterf()</code>可以从给定值找到下一个最高位浮点数。</li></ul></blockquote><p>在浮点数值上进行操作的指令被成为浮点指令。CUDA支持所有在浮点数上常见的算术元算。CUDA遵循IEEE-754标准，支持32位和64位两种浮点精度。所有CUDA设备都支持单精度，计算能力1.3及以上的设备均支持双精度。</p><h3 id="内部函数和标准函数">内部函数和标准函数</h3><p>CUDA将所有算术函数分为内部函数和标准函数。</p><ul><li>标准函数：可对主机和设备进行访问并标准化主机和设备的操作；</li><li>内部函数：只能对设备代码进行访问，在编译时对内部函数的行为会有特殊响应，从而产生更积极的优化和更专业化的指令生成。</li></ul><p>在CUDA中，很多内部函数和标准函数是有关联的，存在着与内部函数功能相同的标准函数。如标准函数<code>sqrt()</code>对应的内部函数是<code>__dsqrt_rn()</code>。内部函数分解成了比与它们等价的标准函数更少的指令。这会导致内部函数比等价的标准函数更快，但数值精度更低。</p><h3 id="原子操作指令">原子操作指令</h3><p>CUDA提供了在32位或64位全局内存或共享内存上执行“读-改-写”操作的原子函数。所有计算能力1.1及以上的设备都支持原子操作。</p><p>与标准函数和内部函数类似，每个原子函数都能实现一个基本的数学运算。不同于其他指令类型，当原子操作指令在两个竞争线程共享的内存空间进行操作时，会有一个定义好的行为。</p><p>原子运算函数分为3种：</p><ul><li>算术运算函数：在目标内存位置上执行简单的算术运算；</li><li>按位运算函数：在目标内存位置上执行按位操作；</li><li>替换函数：可以用一个新值来替换内存位置上原有的值，可以是有条件的也可以是无条件的，无论成功与否，原子替换函数均返回最初的值。<ul><li><code>atomicExch()</code>可以无条件的替换已有的值；</li><li><code>atomicCAS()</code>可以有条件的替换已有的值。</li></ul></li></ul><p>虽然原子函数没有精度上的顾虑，但它们的使用可能会严重降低性能。</p><h2 id="程序优化指令">程序优化指令</h2><h3 id="单精度与双精度">单精度与双精度</h3><p>这里进行一个简单的实验，在主机端和设备端分别将一个单精度浮点数和一个双精度浮点数的值设为12.1，分别对比两种精度的浮点数。</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs smali">Host single-precision representation of 12.1   = 12.10000038146972656250<br>Host<span class="hljs-built_in"> double-precision </span>representation of 12.1   = 12.09999999999999964473<br>Device single-precision representation of 12.1 = 12.10000038146972656250<br>Device<span class="hljs-built_in"> double-precision </span>representation of 12.1 = 12.09999999999999964473<br>Device<span class="hljs-built_in"> and </span>host single-precision representation equal? yes<br>Device<span class="hljs-built_in"> and </span>host<span class="hljs-built_in"> double-precision </span>representation equal? yes<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/01_floating_point_accuracy.cu">floating_point_accuracy.cu</a>。</p></blockquote><p>可以发现，主机和设备上的数值都是近似于12.1，都不是精确值。这个例子中，双精度数值比单精度数值更接近于真实值。</p><p>双精度数值的精确性是以空间和性能消耗为代价的。这里再进行一个简单的实验进行验证。将一批单精度和双精度浮点数置于GPU中进行大量的数学运算，再将结果搬移回主机。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">Input   Diff Between Single- <span class="hljs-keyword">and</span> Double-Precision<br>------  -----------------------------------------<br><span class="hljs-number">0</span>       <span class="hljs-number">3.13614849292207509279</span>e-<span class="hljs-number">02</span><br><span class="hljs-number">1</span>       <span class="hljs-number">2.67553565208800137043</span>e-<span class="hljs-number">03</span><br><span class="hljs-number">2</span>       <span class="hljs-number">2.57291377056390047073</span>e-<span class="hljs-number">03</span><br><span class="hljs-number">3</span>       <span class="hljs-number">7.82136313500814139843</span>e-<span class="hljs-number">03</span><br><span class="hljs-number">4</span>       <span class="hljs-number">3.38051875296514481306</span>e-<span class="hljs-number">02</span><br><span class="hljs-number">5</span>       <span class="hljs-number">4.95682619221042841673</span>e-<span class="hljs-number">02</span><br><span class="hljs-number">6</span>       <span class="hljs-number">1.57542112574446946383</span>e-<span class="hljs-number">02</span><br><span class="hljs-number">7</span>       <span class="hljs-number">1.02473393344553187490</span>e-<span class="hljs-number">02</span><br><span class="hljs-number">8</span>       <span class="hljs-number">1.06261099135736003518</span>e-<span class="hljs-number">02</span><br><span class="hljs-number">9</span>       <span class="hljs-number">2.36870593798812478781</span>e-<span class="hljs-number">02</span><br><br>For single-precision floating point, mean times for:<br>  Copy to device:   <span class="hljs-number">178.990894</span> <span class="hljs-keyword">ms</span><br>  <span class="hljs-title">Kernel</span> execution: <span class="hljs-number">39.176985</span> <span class="hljs-keyword">ms</span><br>  <span class="hljs-title">Copy</span> from device: <span class="hljs-number">673.705701</span> <span class="hljs-keyword">ms</span><br><span class="hljs-title">For</span> double-precision floating point, mean times for:<br>  Copy to device:   <span class="hljs-number">356.848785</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">(1</span>.<span class="hljs-number">99</span>x slower than single-precision)<br>  Kernel execution: <span class="hljs-number">1922.416699</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">(49</span>.<span class="hljs-number">07</span>x slower than single-precision)<br>  Copy from device: <span class="hljs-number">1347.894141</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">(2</span>.<span class="hljs-number">00</span>x slower than single-precision)<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/02_floating_point_perf.cu">floating_point_perf.cu</a>。</p></blockquote><p>这个例子说明单精度和双精度浮点运算在通信和计算上的性能差异是不可忽略的。同时也说明了单精度与双精度的结果有较大的数值差异，这些结果可能在迭代过程中不断被积累，导致最终结果偏差很大。</p><p>由于双精度数值所占空间是单精度数值的两倍，所以当在寄存器中存储一个双精度数值时，一个线程块总的共享寄存器空间会比使用单精度浮点数小的多。</p><h3 id="标准函数与内部函数">标准函数与内部函数</h3><p>为了比较标准函数和内部函数的差异，我们需要将代码编译成PTX代码来观察生成的类汇编指令。以下面两个核函数为例。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">standardKernel</span><span class="hljs-params">(<span class="hljs-type">float</span> a, <span class="hljs-type">float</span>* out)</span></span><br><span class="hljs-function"></span>{<br>*out = <span class="hljs-built_in">powf</span>(a, <span class="hljs-number">2.0f</span>);<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">intrinsicKernel</span><span class="hljs-params">(<span class="hljs-type">float</span> a, <span class="hljs-type">float</span>* out)</span></span><br><span class="hljs-function"></span>{<br>*out = <span class="hljs-built_in">powf</span>(a, <span class="hljs-number">2.0f</span>);<br>}<br></code></pre></td></tr></table></figure><p>在编译时加上<code>--ptx</code>选项可以将该代码编译成PTX代码。</p><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/03_intrinsic_standard_comp.cu">intrinsic_standard_comp.cu</a>，对应的PTX代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/03_intrinsic_standard_comp.ptx">intrinsic_standard_comp.ptx</a>。</p></blockquote><p>通过观察二者的PTX代码，最为明显的一点就是，标准函数的PTX代码量要远大于内部函数。进一步测试其性能表现。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Host</span> calculated                 <span class="hljs-number">18345290</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">Standard</span> Device calculated      <span class="hljs-number">18345290</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">Intrinsic</span> Device calculated     <span class="hljs-number">18345288</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">Host</span> equals Standard?           Yes diff=<span class="hljs-number">0</span>.<span class="hljs-number">000000</span>e+<span class="hljs-number">00</span><br><span class="hljs-attribute">Host</span> equals Intrinsic?          No diff=<span class="hljs-number">2</span>.<span class="hljs-number">000000</span>e+<span class="hljs-number">00</span><br><span class="hljs-attribute">Standard</span> equals Intrinsic?      No diff=<span class="hljs-number">2</span>.<span class="hljs-number">000000</span>e+<span class="hljs-number">00</span><br><br><span class="hljs-attribute">Mean</span> execution time for standard function powf:    <span class="hljs-number">0</span>.<span class="hljs-number">249888</span> ms<br><span class="hljs-attribute">Mean</span> execution time for intrinsic function __powf: <span class="hljs-number">0</span>.<span class="hljs-number">070720</span> ms<br></code></pre></td></tr></table></figure><p>观察精度及性能表现可以发现，内部函数的性能比标准函数要好，但精度不如标准函数。</p><p>虽然CUDA代码转化为GPU指令集这一过程通常是编译器完成的，但可以通过一些手段来引导编译器倾向于精度或性能，或两者的平衡。主要有两种方法可以引导指令级优化的类型：</p><ul><li>编译器标志；</li><li>内部或标准函数调用。</li></ul><p>内部或标准函数调用在上面的例子中已经体现了，下面介绍通过编译器标志来引导编译器的代码生成。</p><p>有如下核函数，实现一个乘加运算。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">fmad</span><span class="hljs-params">(<span class="hljs-type">float</span>* ptr)</span></span><br><span class="hljs-function"></span>{<br>    *ptr = (*ptr) * (*ptr) + (*ptr);<br>}<br></code></pre></td></tr></table></figure><p><code>nvcc</code>编译器中提供一个选项<code>--fmad</code>来控制乘加运算是否融合，默认情况下为<code>true</code>。观察上述核函数的PTX代码可以发现，乘加运算被编译器融合为了一个运算。这样可以提高性能，但精度会有所损失。</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">fma.rn.f32</span> %<span class="hljs-built_in">f2</span>, %<span class="hljs-built_in">f1</span>, %<span class="hljs-built_in">f1</span>, %<span class="hljs-built_in">f1</span><span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>接着使用<code>--fmad=false</code>编译同样的代码，PTX代码如下。</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs llvm"><span class="hljs-keyword">mul</span>.rn.f<span class="hljs-number">32</span> <span class="hljs-variable">%f2</span><span class="hljs-punctuation">,</span> <span class="hljs-variable">%f1</span><span class="hljs-punctuation">,</span> <span class="hljs-variable">%f1</span><span class="hljs-comment">;</span><br><span class="hljs-keyword">add</span>.rn.f<span class="hljs-number">32</span> <span class="hljs-variable">%f3</span><span class="hljs-punctuation">,</span> <span class="hljs-variable">%f1</span><span class="hljs-punctuation">,</span> <span class="hljs-variable">%f2</span><span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/04_manipulation_instruction_generation.cu">manipulation_instruction_generation.cu</a>，对应的PTX代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/04_manipulation_instruction_generation.ptx">manipulation_instruction_generation.ptx</a>。</p></blockquote><p>类似于<code>--fmad</code>的控制指令生成的选项还有很多。</p><table style="width:100%;"><colgroup><col style="width: 10%"><col style="width: 31%"><col style="width: 3%"><col style="width: 27%"><col style="width: 27%"></colgroup><thead><tr class="header"><th>选项</th><th>描述</th><th>默认值</th><th>性能影响</th><th>精度影响</th></tr></thead><tbody><tr class="odd"><td><code>--ftz=[bool]</code></td><td>将所有单精度非正规浮点数置为零。</td><td><code>false</code></td><td><code>true</code>时可能会提高性能，具体取决于待处理的值和算法。</td><td><code>false</code>时可能会提高精度，具体取决于待处理的值和算法。</td></tr><tr class="even"><td><code>--prec-div=[bool]</code></td><td>提高了所有单精度除法和倒数数值的精度。</td><td><code>true</code></td><td><code>true</code>时可能会降低性能。</td><td><code>true</code>时可能会提高与IEEE标准数值的兼容性。</td></tr><tr class="odd"><td><code>--prec-sqrt=[bool]</code></td><td>强制执行精度更高的平方根函数。</td><td><code>true</code></td><td><code>true</code>时可能会降低性能。</td><td><code>true</code>时可能会提高与IEEE标准数值的兼容性。</td></tr><tr class="even"><td><code>--fmad=[bool]</code></td><td>控制编译器是否将乘加运算融合到一个FMAD指令中。</td><td><code>true</code></td><td>若程序中存在浮点型变量的MAD运算，启动FMAD会提高性能。</td><td>启用FMAD可能会降低精度。</td></tr><tr class="odd"><td><code>--use_fast_math</code></td><td>用等价的内部函数替换程序中所有的标准函数。<br>同时设置<code>--ftz=true</code>、<code>--prec-div=false</code>和<code>--prec-sqrt=false</code>。</td><td><code>false</code></td><td>启用该选项则表明启动了一系列提高性能的优化。</td><td>启用该选项可能会降低精度。</td></tr></tbody></table><p>除了<code>--fmad</code>选项，CUDA还包含一对控制FMAD指令生成的内部函数：<code>__fmul</code>和<code>__dmul</code>。这些函数不会影响乘法运算的性能，在有<code>*</code>运算符的地方调用可以组织编译器将乘法作为乘加优化的一部分来使用。</p><p>还是之前的乘加例子，除了使用<code>--fmad=false</code>来阻止乘加优化外，还可以用下列方式来实现相同的效果。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">fmadBlocked</span><span class="hljs-params">(<span class="hljs-type">float</span>* ptr)</span></span><br><span class="hljs-function"></span>{<br>    *ptr = __fmul_rn((*ptr), (*ptr)) + (*ptr);<br>}<br></code></pre></td></tr></table></figure><blockquote><p>这里调用函数时，实际调用的是<code>__fmul_rn()</code>，这个后缀显式地表达了四舍五入的模式，具体如下表所示。</p><table><thead><tr class="header"><th>后缀</th><th>含义</th></tr></thead><tbody><tr class="odd"><td><code>rn</code></td><td>在当前浮点模式（单或双精度）下不能精确表示的数值，用可表示的最近似值来表示。这是默认模式。</td></tr><tr class="even"><td><code>rz</code></td><td>总是向零取整。</td></tr><tr class="odd"><td><code>ru</code></td><td>总是向上取整到正无穷。</td></tr><tr class="even"><td><code>rd</code></td><td>总数向下取整到负无穷。</td></tr></tbody></table></blockquote><p>这样就可以通过这些内部函数的调用来单独控制某些计算的精度，提升某些数值的健壮性，从而可以全局启用MAD优化。</p><h3 id="原子指令">原子指令</h3><h4 id="原子函数">原子函数</h4><p>一个很重要的操作就是原子级CAS，它可以令程序员在CUDA中自定义原子函数。CAS接受三个参数：</p><ul><li>内存地址；</li><li>存储在此地址中的期望值；</li><li>实际想要存储在此位置的新值。</li></ul><p>CAS的整体流程为：</p><ul><li>读取目标地址并将其存储值与预期值进行比较。<ul><li>若存储值与预期值相等，则新值将存入目标位置；</li><li>若存储值与预期值不等，则目标位置不发生变化；</li></ul></li><li>无论发生什么情况，CAS总是返回目标地址的值。使用返回值可以检查是否替换成功。若返回值等于预期值，则CAS一定成功了。</li></ul><p>下面借助CAS来实现一个原子加操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__device__ <span class="hljs-type">int</span> <span class="hljs-title">myAtomicAdd</span><span class="hljs-params">(<span class="hljs-type">int</span> *address, <span class="hljs-type">int</span> incr)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> expected = *address;                                      <span class="hljs-comment">// 记录当前内存地址的值</span><br>    <span class="hljs-type">int</span> oldValue = <span class="hljs-built_in">atomicCAS</span>(address, expected, expected + incr); <span class="hljs-comment">// 尝试增加incr，CAS会返回目标地址的值</span><br><br>    <span class="hljs-keyword">while</span> (oldValue != expected) <span class="hljs-comment">// 如果返回值与预期值不等，则CAS没有成功</span><br>    {<br>        <span class="hljs-comment">// 重复执行CAS直到成功</span><br>        expected = oldValue;                                      <span class="hljs-comment">// 获取目标地址的新值</span><br>        oldValue = <span class="hljs-built_in">atomicCAS</span>(address, expected, expected + incr); <span class="hljs-comment">// 继续尝试增加incr</span><br>    }<br><br>    <span class="hljs-keyword">return</span> oldValue; <span class="hljs-comment">// 为了匹配其他CUDA原子函数的语义，这里返回目标地址的值</span><br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/05_atomic_operation.cu">atomic_operation.cu</a>。</p></blockquote><p>CUDA中内置了一系列的原子函数，如下表所示。</p><table><thead><tr class="header"><th>函数</th><th>操作</th><th>支持的数据类型</th></tr></thead><tbody><tr class="odd"><td><code>atomicAdd</code></td><td>加法</td><td><code>int, unsigned int, unsigned long long int, float</code></td></tr><tr class="even"><td><code>atomicSub</code></td><td>减法</td><td><code>int, unsigned int</code></td></tr><tr class="odd"><td><code>atomicExch</code></td><td>无条件替换</td><td><code>int, unsigned int, unsigned long long int, float</code></td></tr><tr class="even"><td><code>atomicMin</code></td><td>最小值</td><td><code>int, unsigned int, unsigned long long int</code></td></tr><tr class="odd"><td><code>atomicMax</code></td><td>最大值</td><td><code>int, unsigned int, unsigned long long int</code></td></tr><tr class="even"><td><code>atomicInc</code></td><td>增量</td><td><code>unsigned int</code></td></tr><tr class="odd"><td><code>atomicDec</code></td><td>减量</td><td><code>unsigned int</code></td></tr><tr class="even"><td><code>atomicCAS</code></td><td>CAS</td><td><code>int, unsigned int, unsigned long long int</code></td></tr><tr class="odd"><td><code>atomicAnd</code></td><td>与</td><td><code>int, unsigned int, unsigned long long int</code></td></tr><tr class="even"><td><code>atomicOr</code></td><td>或</td><td><code>int, unsigned int, unsigned long long int</code></td></tr><tr class="odd"><td><code>atomicXor</code></td><td>异或</td><td><code>int, unsigned int, unsigned long long int</code></td></tr></tbody></table><h4 id="原子操作的代价">原子操作的代价</h4><p>原子操作可能会付出很高的代价：</p><ul><li>当在全局或共享内存中执行原子操作时，能保证所有的数值变化对所有线程都是立即可见的。如果原子指令操作成功，则必须把实际需要的值写入到全局或共享内存中；</li><li>共享地址冲突的原子访问可能要求发生冲突的线程不断地重试；</li><li>当线程在同一个线程束中时必须执行不同的指令，线程束执行是序列化的。若一个线程束中的多个线程在相同的内存地址发出一个原子操作，就会产生类似于线程冲突的问题；</li></ul><p>下面用一个例子来展示原子操作的代价。实现一个核函数不断累加一个共享变量，然后实现一个功能类似，但线程不安全的核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">atomics</span><span class="hljs-params">(<span class="hljs-type">int</span>* shared_var, <span class="hljs-type">int</span>* values_read, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> iterations)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br><br>    <span class="hljs-keyword">if</span> (tid &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    values_read[tid] = <span class="hljs-built_in">atomicAdd</span>(shared_var, <span class="hljs-number">1</span>);<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; iterations; i++)<br>    {<br>        <span class="hljs-built_in">atomicAdd</span>(shared_var, <span class="hljs-number">1</span>);<br>    }<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">unsafe</span><span class="hljs-params">(<span class="hljs-type">int</span>* shared_var, <span class="hljs-type">int</span>* values_read, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> iterations)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br><br>    <span class="hljs-keyword">if</span> (tid &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-type">int</span> old          = *shared_var;<br>    *shared_var      = old + <span class="hljs-number">1</span>;<br>    values_read[tid] = old;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; iterations; i++)<br>    {<br>        old         = *shared_var;<br>        *shared_var = old + <span class="hljs-number">1</span>;<br>    }<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/06_adjusting_instruction-level_primitives/06_atomic_ordering.cu">atomic_ordering.cu</a>。</p></blockquote><p>测试两个核函数，结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">In</span> total, <span class="hljs-number">30</span> runs using atomic operations took <span class="hljs-number">18</span>.<span class="hljs-number">691618</span> ms<br>  <span class="hljs-attribute">Using</span> atomic operations also produced an output of <span class="hljs-number">6400064</span><br><span class="hljs-attribute">In</span> total, <span class="hljs-number">30</span> runs using unsafe operations took <span class="hljs-number">2</span>.<span class="hljs-number">103617</span> ms<br>  <span class="hljs-attribute">Using</span> unsafe operations also produced an output of <span class="hljs-number">100001</span><br><span class="hljs-attribute">Threads</span> performing atomic operations read values <span class="hljs-number">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span> <span class="hljs-number">7</span> <span class="hljs-number">8</span> <span class="hljs-number">9</span><br><span class="hljs-attribute">Threads</span> performing unsafe operations read values <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>发现原子操作保证了数值的正确性，但性能却大幅度下降。</p><p>为了应对上述情况，可以使用局部操作来增强全局原子操作，这些局部操作能从同一线程块的线程中产生一个中间结果。这些操作必须是顺序无关的，即操作的顺序不应影响最终的结果。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——流和并发</title>
    <link href="https://deleter-d.github.io/posts/4919/"/>
    <id>https://deleter-d.github.io/posts/4919/</id>
    <published>2024-02-20T08:36:28.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="异步并发执行">异步并发执行</h2><p>CUDA将以下几个操作暴露为可以互相并发执行的操作：</p><ul><li>主极端的运算；</li><li>设备端的运算；</li><li>从主机端到设备端的数据传输；</li><li>从设备端到主机端的数据传输；</li><li>给定设备内的数据传输；</li><li>设备之间的数据传输。</li></ul><p>这些操作之间实现的并发级别将取决于设备的特性集和计算能力，如下所述。</p><h3 id="主机和设备之间的并发执行">主机和设备之间的并发执行</h3><p>主机和设备的并发执行是通过在设备完成所请求的任务之前，将控制权交还给主机线程完成的，这一过程由异步库函数实现。使用异步调用，多个设备可以同时排队，以便在设备资源满足时，由CUDA驱动程序执行。这减轻了主机线程管理设备的责任，使其有更多的精力去执行其他操作。</p><p>以下设备操作对于主机是异步的：</p><ul><li>核函数启动；</li><li>在单个设备内的内存拷贝；</li><li>从主机到设备的64KB或更小的内存拷贝；</li><li>由带有<code>Async</code>后缀的函数发起的内存拷贝；</li><li>内存集合（Memory Set）函数调用。</li></ul><p>可以将环境变量<code>CUDA_LAUNCH_BLOCKING</code>设为1来全局禁用所有CUDA程序的核函数异步启动。该功能仅用于调试，不应该用于生产环境。</p><p>若通过分析软件（Nsight，Visual Profiler等）收集硬件计数器，则核函数启动时同步的，除非启用了并发核函数分析。若异步内存拷贝没有涉及锁页内存，则该拷贝也可能是同步的。</p><h3 id="并发核函数执行">并发核函数执行</h3><p>部分计算能力2.x以及更高的设备能够并发执行多个核函数。程序可以通过设备属性<code>concurrentKernels</code>来检查这种能力，该属性为1则表示支持该功能。</p><p>核函数的最大并发量取决于设备的计算能力，详见<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications-technical-specifications-per-compute-capability">官方文档表格</a>。</p><p>来自一个CUDA上下文中的核函数无法与另一个CUDA上下文中的核函数并发执行。GPU可能以时间划分来为每个上下文提供前向过程。若用户想在SM上同时执行多个过程的核函数，则必须启动MPS。</p><p>若核函数使用了很多纹理内存或大量的本地内存，则与其他核函数并发执行的可能性会更小。</p><h3 id="数据传输与核函数的交叠">数据传输与核函数的交叠</h3><p>一些设备可以利用核函数并发地执行（与设备之间的）异步内存拷贝。可以通过设备属性<code>asyncEngineCount</code>来检查这种能力，若该值大于0则表明设备支持该功能。如果内存拷贝涉及到了主机内存，则必须是锁页内存。</p><p>通过核函数同时执行设备内部的内存拷贝（需要设备支持设备属性<code>concurrentKernels</code>）和与设备之间的内存拷贝（需要设备支持设备属性<code>asyncEngineCount</code>）也是可能的。设备内部的内存拷贝通过使用目的地址与源地址处于同一设备的标准内存拷贝函数发起。</p><h3 id="并发数据传输">并发数据传输</h3><p>部分计算能力2.x以及更高的设备可以将与设备之间的内存拷贝操作交叠。可以通过设备属性<code>asyncEngineCount</code>来检查这种能力，若该值为2则表明设备支持该功能。为了实现这种交叠，任何涉及到的主机内存必须是锁页内存。</p><h2 id="流和事件">流和事件</h2><p>CUDA流是一系列异步的CUDA操作，这些操作按照主机代码确定的顺序在设备上执行。流可以封装这些操作，保持操作的顺序，允许操作在流中排队，并使其在先前的所有操作之后执行，并且可以查询排队操作的状态。流中操作的执行相对于主机总是异步的。在同一个CUDA流中的操作有严格的执行顺序，而不同流中的操作在执行顺序上不受限制。</p><p>CUDA的API函数一般分为同步和异步。具有同步行为的函数会阻塞主机端线程，直到它们完成。具有异步行为的函数被调用后，会立即将控制权归还给主机。</p><h3 id="cuda流">CUDA流</h3><h5 id="创建和销毁流">创建和销毁流</h5><p>通过创建一个流对象并将其指定为一系列核函数启动与<code>host &lt;-&gt; device</code>间内存拷贝的参数来定义流。下列代码创建了两个流对象，并在锁页主机内存中分配一个<code>float</code>型的数组<code>hostPtr</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cudaStream_t stream[<span class="hljs-number">2</span>];<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; ++i)<br>    <span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream[i]);<br><span class="hljs-type">float</span>* hostPtr;<br><span class="hljs-built_in">cudaMallocHost</span>(&amp;hostPtr, <span class="hljs-number">2</span> * size);<br></code></pre></td></tr></table></figure><p>下面的代码通过三个操作定义了一系列流，三个操作分别是<code>host -&gt; device</code>内存拷贝、核函数启动、<code>device -&gt; host</code>内存拷贝。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; ++i) {<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(inputDevPtr + i * size, hostPtr + i * size, size, cudaMemcpyHostToDevice, stream[i]);<br>    MyKernel &lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>, <span class="hljs-number">0</span>, stream[i]&gt;&gt;&gt;(outputDevPtr + i * size, inputDevPtr + i * size, size);<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(hostPtr + i * size, outputDevPtr + i * size, size, cudaMemcpyDeviceToHost, stream[i]);<br>}<br></code></pre></td></tr></table></figure><p>上面的例子中，每个流将输入数组<code>HostPtr</code>的一部分拷贝到设备内存中的数组<code>InputDevPtr</code>，通过调用核函数<code>MyKernel()</code>来处理这些数据，最后将结果<code>outputDevPtr</code>拷贝回<code>HostPtr</code>的同一位置。注意：<code>hostPtr</code>必须指向锁页内存才会发生交叠行为。</p><p>通过调用<code>cudaStreamDestroy()</code>来释放流。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; ++i)<br>    <span class="hljs-built_in">cudaStreamDestroy</span>(stream[i]);<br></code></pre></td></tr></table></figure><p>如果在调用<code>cudaStreamDestroy()</code>时设备仍在流中工作，则该函数将立即返回，并且一旦设备完成流中的所有工作，与流关联的资源将被自动释放。</p><blockquote><p>CUDA提供两个API来检查流中的操作是否都已完成：</p><ul><li><code>cudaStreamSynchronize()</code>：强制阻塞主机，直到所给流中的操作全部完成；</li><li><code>cudaStreamQuery()</code>：检查流中的所有操作是否完成，在完成之前不会阻塞主机。所有操作都完成时会返回<code>cudaSuccess</code>，当还有操作仍在执行或等待执行时返回<code>cudaErrorNotReady</code>。</li></ul></blockquote><h5 id="默认流">默认流</h5><p>当启动核函数与执行<code>host &lt;-&gt; device</code>间内存拷贝时未指定流参数，或将流参数指定为0，命令将提交到默认流。他们是顺序执行的。</p><p>使用编译选项<code>--default-stream per-thread</code>编译的代码，或在引入CUDA头文件之间定义了宏<code>CUDA_API_PER_THREAD_DEFAULT_STREAM</code>的代码，默认流是常规流，每个主机线程均有自己的默认流。</p><p>对于使用了编译选项<code>--default-stream legacy</code>编译的代码，默认流是称为空流（NULL Stream）的特殊流，每个设备都有一个用于所有主机线程的空流。空流是特殊的，因为它会导致<a href="#隐式同步">隐式同步</a>。</p><p>对于未指定编译选项<code>--default-stream</code>的代码，默认值为<code>--default-stream legacy</code>。</p><h3 id="流调度">流调度</h3><p>从逻辑上看，所有流都可以同时执行，但映射到硬件上时并不总是这样。</p><h4 id="虚假的依赖关系">虚假的依赖关系</h4><p>虽然GPU支持多个<code>grid</code>同时执行，但所有流最终是被多路复用到单一的硬件工作队列中的。当选择一个<code>grid</code>执行时，在队列前面的任务由CUDA运行时调度。运行时会检查任务的依赖关系，若仍有任务在执行，则将等待该任务依赖的任务执行完成。当所有依赖关系都执行结束后，新任务才会被调度到可用的SM上。</p><p>上述的这种单一流水线可能会导致虚假的依赖关系。图中的A、P与X本来没有依赖关系，但由于队列是单一的，故P只能等待A-B均执行完成才会和C一起被并发调度，X同理。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/ea7d2a6b-8ceb-4f99-8abb-bf705846ee7d"></p><h4 id="hyper-q技术">Hyper-Q技术</h4><p>Hyper-Q使用多个硬件工作队列，从而减少虚假的依赖关系。该技术通过在主机和设备之间维持多个硬件管理上的连接，允许多个CPU线程或进程在单一GPU上同时启动工作。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/baccc996-b6f1-44ea-a7c6-98d07d642c58"></p><p>这种技术可以实现全流级并发，并具有最小的虚假流间依赖关系。</p><h3 id="流的优先级">流的优先级</h3><p>流的相对优先级可以在创建时使用<code>cudaStreamCreateWithPriority()</code>来指定。可以使用<code>cudaDeviceGetStreamPriorityRange()</code>函数获取允许的优先级范围，按 [最高优先级，最低优先级] 排序。在运行时，较高优先级流中的挂起工作优先于较低优先级流中的挂起工作。</p><p>下面的代码展示了如何获取当前设备允许的优先级范围，并创建具有最高和最低优先级的流。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 获取当前设备允许的优先级范围</span><br><span class="hljs-type">int</span> priority_high, priority_low;<br><span class="hljs-built_in">cudaDeviceGetStreamPriorityRange</span>(&amp;priority_low, &amp;priority_high);<br><span class="hljs-comment">// 创建具有最高和最低优先级的流</span><br>cudaStream_t st_high, st_low;<br><span class="hljs-built_in">cudaStreamCreateWithPriority</span>(&amp;st_high, cudaStreamNonBlocking, priority_high);<br><span class="hljs-built_in">cudaStreamCreateWithPriority</span>(&amp;st_low, cudaStreamNonBlocking, priority_low);<br></code></pre></td></tr></table></figure><blockquote><p>流优先级不会影响数据传输操作，只对计算核函数有影响。</p><p>如果指定的优先级超出了设备定义的范围，它会被自动限制为定义范围内的最低值或最高值。</p></blockquote><h3 id="cuda事件">CUDA事件</h3><p>CUDA运行时提供了一种方法来密切监视设备的进度，并通过让应用程序异步记录程序中任意点的事件并查询这些事件何时完成来执行准确的计时。当事件之前的所有任务（或者给定流中的所有命令）都完成时，事件就完成了。在所有流中的所有前面的任务和命令完成之后，流0中的事件才会完成。</p><h4 id="创建和销毁事件">创建和销毁事件</h4><p>下面的代码创建两个事件。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cudaEvent_t start, stop;<br><span class="hljs-built_in">cudaEventCreate</span>(&amp;start);<br><span class="hljs-built_in">cudaEventCreate</span>(&amp;stop);<br></code></pre></td></tr></table></figure><p>用如下方式销毁。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaEventDestroy</span>(start);<br><span class="hljs-built_in">cudaEventDestroy</span>(stop);<br></code></pre></td></tr></table></figure><blockquote><p>对于事件，CUDA也提供了检查先前操作是否完成的API：</p><ul><li><code>cudaEventSynchronize()</code>：强制阻塞主机，直到该事件所在流中先前的操作执行结束，与<code>cudaStreamSynchronize()</code>类似；</li><li><code>cudaEventQuery()</code>：不阻塞主机，与<code>cudaStreamQuery()</code>类似。</li></ul></blockquote><h4 id="记录事件和计算运行时间">记录事件和计算运行时间</h4><p>下面的代码展示了如何利用事件统计运行时间。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaEventRecord</span>(start, <span class="hljs-number">0</span>);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; ++i) {<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(inputDev + i * size, inputHost + i * size, size, cudaMemcpyHostToDevice, stream[i]);<br>    MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>, <span class="hljs-number">0</span>, stream[i]&gt;&gt;&gt;(outputDev + i * size, inputDev + i * size, size);<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(outputHost + i * size, outputDev + i * size, size, cudaMemcpyDeviceToHost, stream[i]);<br>}<br><span class="hljs-built_in">cudaEventRecord</span>(stop, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">cudaEventSynchronize</span>(stop);<br><span class="hljs-type">float</span> elapsedTime;<br><span class="hljs-built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);<br></code></pre></td></tr></table></figure><blockquote><p>事件的启动和停止不必在同一个流中。</p><p>注意：若在非默认流中记录启动事件或停止事件，返回的时间可能比预期的要大。因为<code>cudaEventRecord()</code>函数是异步的，并且不能保证计算的延迟正好处于两个事件之间。</p></blockquote><h3 id="流同步">流同步</h3><p>在非默认流中，所有操作对于主机线程都是非阻塞的，因此会遇到需要在同一个流中令主机和运算操作同步的情况。</p><p>从主机角度来讲，CUDA操作可以分为两大类：</p><ul><li>内存操作；</li><li>核函数启动。</li></ul><p>对于主机来说，核函数启动总是异步的。很多内存操作本质上是同步的，但CUDA也提供了异步版本。</p><p>CUDA的流可以分为两种：</p><ul><li>异步流（非默认流）；</li><li>同步流（默认流）。</li></ul><p>在主机上，非默认流是异步流，其上所有操作都不阻塞主机执行。而被隐式声明的默认流是同步流，大多数添加到默认流上的操作都会导致主机在先前所有的操作上阻塞。</p><p>非默认流可以进一步分为两种：</p><ul><li>阻塞流；</li><li>非阻塞流。</li></ul><p>虽然非默认流对于主机是非阻塞的，但非默认流中的操作可以被默认流中的操作所阻塞。若一个非默认流是阻塞流，则默认流可以阻塞该非默认流中的操作。若一个非默认流是非阻塞流，则它不会阻塞默认流中的操作。</p><h4 id="阻塞流和非阻塞流">阻塞流和非阻塞流</h4><p>使用<code>cudaStreamCreate()</code>创建的流是阻塞流，即这些流中的操作可以被阻塞，一直等到默认流中先前的操作执行结束。默认流是隐式流，在相同的CUDA上下文中它和其他所有的阻塞流同步。一般情况下，当操作被发布到默认流中，在该操作被执行之前，CUDA上下文会等待所有先前的操作发布到所有的阻塞流中。此外，任何发布到阻塞流中的操作会被挂起等待，指导默认流中先前的操作执行结束才开始执行。</p><p>CUDA运行时提供了一个函数：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaStreamCreateWithFlags</span><span class="hljs-params">(cudaStream_t* pStream, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> flags)</span></span>;<br></code></pre></td></tr></table></figure><p>参数<code>flags</code>决定了所创建流的行为，可选如下两个值：</p><ul><li><code>cudaStreamDefault</code>；</li><li><code>cudaStreamNonBlocking</code>。</li></ul><p>指定为<code>cudaStreamNonBlocking</code>使得默认流对于非默认流的阻塞行为失效。</p><h4 id="隐式同步">隐式同步</h4><p>若主机线程在来自不同流的两个命令之间发出以下任何一个操作，它们均不能同时执行：</p><ul><li>锁页主机内存分配；</li><li>设备内存分配；</li><li>设备内存初始化；</li><li>同一设备内存地址之间的内存拷贝；</li><li>任何提交至空流的CUDA命令；</li><li>L1/共享内存配置之间的切换（见<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x">计算能力7.x</a>）。</li></ul><p>一些操作需要依赖关系检查，这些操作包括与被检查的启动项相同流中的任何其他命令，以及该流上对<code>cudaStreamQuery()</code>的任何调用。故程序应该遵循以下原则，以提高核函数的并发潜力：</p><ul><li>所有独立操作应该在有依赖关系的操作之前提交；</li><li>任何形式的同步操作都应该尽可能的延迟。</li></ul><h4 id="显式同步">显式同步</h4><p>以下多种方法可以显式同步流。</p><ul><li><code>cudaDeviceSynchronize()</code>：会等待此调用前的所有主机线程中的所有流中的所有命令全部完成；</li><li><code>cudaStreamSynchronize()</code>：接受一个流作为参数，等待给定流中的此调用前的所有命令全部完成。可以用于使主机与特定流同步，从而允许其他流继续在设备上执行；</li><li><code>cudaStreamWaitEvent()</code>：接受流和事件作为参数，使该调用之后添加到给定流的所有命令延迟执行，直到给定事件完成。该函数允许跨流同步；</li><li><code>cudaStreamQuery()</code>：返回流中此调用前的所有命令的完成情况。</li></ul><h4 id="可配置事件">可配置事件</h4><p>与流类似，CUDA也提供了API来创建不同行为的事件：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaEventCreateWithFlags</span><span class="hljs-params">(cudaEvent_t* event, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> flags)</span></span>;<br></code></pre></td></tr></table></figure><p>参数<code>flags</code>的可选项有4个：</p><ul><li><code>cudaEventDefault</code>；</li><li><code>cudaEventBlockingSync</code>；</li><li><code>cudaEventDisableTiming</code>；</li><li><code>cudaEventInterprocess</code>。</li></ul><p>指定为<code>cudaEventBlockingSync</code>的事件在同步时会阻塞调用的线程。<code>cudaEventSynchronize()</code>函数的默认操作是围绕事件进行的，使用CPU周期不断检查事件的状态。而指定为<code>cudaEventBlockingSync</code>后，会将这种轮询交给另一个线程，而调用线程本身继续执行，直到事件依赖关系满足才通知调用线程。这样可以减少CPU周期的浪费，但也会使得事件满足依赖关系与激活调用线程之间的延迟被拉长。</p><p>指定为<code>cudaEventDisableTiming</code>表明事件只能用来同步，节省了记录时间戳带来的开销。</p><p>指定为<code>cudaEventInterprocess</code>表明时间可能被用作进程间事件。</p><h2 id="并发核函数执行-1">并发核函数执行</h2><h3 id="非默认流中的并发核函数">非默认流中的并发核函数</h3><p>现在已经几乎不存在不支持Hyper-Q的GPU设备了。想要实现核函数的并发执行，必须要令核函数在非默认流中执行。使用类似如下代码使核函数在不同的非默认流中并发执行。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>{<br>    kernel_1&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_2&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_3&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_4&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/05_stream_and_concurrence/01_hyper-Q_depth.cu">hyper-Q_depth.cu</a>。</p></blockquote><p>通过<code>NVIDIA Nsight System</code>分析核函数在流中的执行情况，可以借助可视化流水线来观察核函数在各个流中的执行情况，分析结果如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/169eb417-183d-483f-bee3-d5588c6b8e1a"></p><p>可以观察到核函数在<code>stream 14</code>，<code>stream 15</code>，<code>stream 16</code>中是并发执行的。</p><blockquote><p>关于这里有一些待解决和讨论的问题，为什么<code>stream 13</code>中的核函数没有和其他三个流中的核函数并发执行。我们来尝试一下每个流执行一个、两个和三个核函数，分别得到了如下结果。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/03e3a790-e45f-4bd0-9f2e-ec729631ca99"></p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/18f080d8-528b-44e3-abc6-ba5ce23d8bd0"></p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/9263efa6-cd30-4809-b329-a33b0614fef1"></p><p>可以观察到，每个流只有一个核函数时，并发执行情况是符合预期的。但每个流中执行的核函数超过一个，就会先在某个流中全部执行一遍，然后在其他流中并发执行。在英伟达开发者论坛中询问后，官方人员给出了解释，这是由于核函数初始化时机导致的，这里放上帖子的<a href="https://forums.developer.nvidia.com/t/kernels-executing-concurrently-in-different-streams-do-not-behave-as-expected/276389">链接</a>。</p><p>从CUDA 11.7开始，引入了一种懒加载机制，并在CUDA 11.8中进行了重大更新，相见官方文档<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading">Lazy Loading</a>。懒加载会使得核函数在真正要执行之前才进行初始化，而不是先全部初始化后再根据安排来执行。我们可以通过环境变量<code>CUDA_MODULE_LOADING</code>来控制是否开启懒加载，开启则设为<code>LAZY</code>，不开启则设为<code>EAGER</code>。</p><p>我们将环境变量设置为<code>EAGER</code>便可以得到所有流同时启动核函数的结果。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/82ab2a82-9340-4056-8efc-0e817910f0e1"></p></blockquote><h3 id="虚假依赖关系的并发核函数">虚假依赖关系的并发核函数</h3><p>接下来我们模拟一下不支持Hyper-Q技术的设备。可以通过环境变量<code>CUDA_DEVICE_MAX_CONNECTIONS</code>来控制队列个数，这里设为1来模拟只有一个硬件队列的情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">setenv</span>(<span class="hljs-string">"CUDA_DEVICE_MAX_CONNECTIONS"</span>, <span class="hljs-string">"32"</span>, <span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure><p>在此基础上使用<code>nsys</code>分析核函数执行情况。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/dd30ae2d-d4c9-4e5f-a81a-286ccff6cb8a"></p><p>可以观察到，如同<a href="#虚假的依赖关系">虚假的依赖关系</a>中介绍的那样，核函数的并发执行只发生在了流的边缘。在这种情况下，可以通过广度优先的调用方式来缓解。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>    kernel_1&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>    kernel_2&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>    kernel_3&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>    kernel_4&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/05_stream_and_concurrence/02_hyper-Q_breadth.cu">hyper-Q_breadth.cu</a>。</p></blockquote><p>深度优先和广度优先的调用方式的区别可以通过下图来理解。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/52e64391-7d1b-454e-9847-974df653fdf2"></p><p>这样就可以在只有一个硬件队列的情况下，实现核函数的并发执行。不过鉴于现代的GPU设备基本都支持Hyper-Q，所以此处简单了解即可。通过<code>nsys</code>分析来佐证上述的观点。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b03d99e9-397d-402d-a5e3-ee222f5f41d1"></p><h3 id="使用openmp的调度操作">使用OpenMP的调度操作</h3><p>借助OpenMP开启多线程，每个线程来管理一个流。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">omp_set_num_threads</span>(stream_count);<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp parallel</span><br>{<br>    <span class="hljs-type">int</span> i = <span class="hljs-built_in">omp_get_thread_num</span>();<br>    kernel_1&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_2&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_3&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_4&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/05_stream_and_concurrence/03_hyper-Q_OpenMP.cu">hyper-Q_OpenMP.cu</a>。</p></blockquote><p>注意，主机代码中若包含OpenMP的内容，则在编译CUDA程序时需要添加如下几个编译器选项。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-Xcompiler -fopenmp -lgomp</span><br></code></pre></td></tr></table></figure><h3 id="默认流的阻塞行为">默认流的阻塞行为</h3><p>将<a href="#非默认流中的并发核函数">非默认流中的并发核函数</a>中提到的<code>kernel_3</code>放在默认流中调用，以此来理解默认流的阻塞行为。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>{<br>    kernel_1&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_2&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_3&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_data);<br>    kernel_4&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>}<br></code></pre></td></tr></table></figure><p>核函数执行情况如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/8fd6a798-48e9-4509-a772-23309ad473b2"></p><p>可以观察到，由于<code>kernel_3</code>在默认流中启动，所以在非默认流上的所有之后的操作都会被阻塞，直到默认流中的操作完成。</p><h3 id="创建流间依赖关系">创建流间依赖关系</h3><p>在复杂的应用程序中，引入流间依赖关系是非常有用的，它可以在一个流中阻塞操作，直到另一个流中的指定操作完成。事件可以用来添加流间依赖关系。</p><p>通过如下代码来创建同步事件。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cudaEvent_t* kernelEvent = (cudaEvent_t*)<span class="hljs-built_in">malloc</span>(stream_count * <span class="hljs-built_in">sizeof</span>(cudaEvent_t));<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>{<br>    <span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaEventCreateWithFlags</span>(&amp;kernelEvent[i], cudaEventDisableTiming));<br>}<br></code></pre></td></tr></table></figure><p>通过如下方式调用，令每个流完成时记录不同的事件，然后使最后一个流等待其他所有流完成。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; stream_count; i++)<br>{<br>    kernel_1&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_2&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_3&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br>    kernel_4&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data);<br><br>    <span class="hljs-comment">// 每个流完成时记录不同的事件</span><br>    <span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaEventRecord</span>(kernelEvent[i], streams[i]));<br>    <span class="hljs-comment">// 使最后一个流等待其他所有流</span><br>    <span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaStreamWaitEvent</span>(streams[stream_count - <span class="hljs-number">1</span>], kernelEvent[i], <span class="hljs-number">0</span>));<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/05_stream_and_concurrence/04_hyper-Q_dependence.cu">hyper-Q_dependence.cu</a>。</p></blockquote><p>观察下图可以看出，最后一个流被其他流阻塞，直到所有流都完成操作后，最后一个流才执行。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5e746b78-49ee-495a-8fff-2da8bc5f1820"></p><h2 id="核函数执行与数据传输的交叠">核函数执行与数据传输的交叠</h2><p>想要令核函数执行与数据传输交叠，不仅需要设备支持，还需要在内存申请和搬移的时候注意。要实现交叠，必须使用异步的内存搬移函数，而异步的内存搬移函数所搬移的内存又需要通过<code>cudaHostAlloc</code>来申请。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaHostAlloc</span>((<span class="hljs-type">void</span> **)&amp;h_A, bytes, cudaHostAllocDefault));<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaHostAlloc</span>((<span class="hljs-type">void</span> **)&amp;h_B, bytes, cudaHostAllocDefault));<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaHostAlloc</span>((<span class="hljs-type">void</span> **)&amp;hostRef, bytes, cudaHostAllocDefault));<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaHostAlloc</span>((<span class="hljs-type">void</span> **)&amp;gpuRef, bytes, cudaHostAllocDefault));<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/05_stream_and_concurrence/05_multi_add_depth.cu">multi_add_depth.cu</a>。</p></blockquote><p>这里以向量加法为例，实现一个向量加法的核函数，并分别使用不交叠和交叠的调用方式来观察其执行情况。</p><p>下图是不交叠的调用方式，可以观察到核函数的执行必须要等到<code>H2D</code>的内存搬移完成后才能开始，<code>D2H</code>的内存搬移也只能等核函数执行完毕后才可以开始。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/c8e60104-8ccc-4a23-90f8-a144d7b59cd6"></p><p>但当我们使用多个流，将这些操作分散在各个流中，同时使用异步的内存搬移操作后，效果如下。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b8ff4b3b-53e9-4f9a-ac91-aa21f8e6ace5"></p><p>可以观察到，不同流中的内存搬移操作和核函数执行产生了交叠，大大提高了并发度。</p><h2 id="流回调">流回调</h2><p>流回调是另一种可以到CUDA流中排列等待的操作。一旦流回调之前所有的流操作全部完成，被流回调指定的主机端函数就会被CUDA运行时调用。流回调允许任意主机端逻辑插入到CUDA流中。</p><p>在较老版本的CUDA中通过如下函数来调用。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaStreamAddCallback</span><span class="hljs-params">(cudaStream_t stream, cudaStreamCallback_t callback, <span class="hljs-type">void</span> *userData, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> flags)</span></span>;<br></code></pre></td></tr></table></figure><ul><li><code>callback</code>：传入自定义的回调函数；</li><li><code>userData</code>：传入回调函数的数据；</li><li><code>flags</code>：是保留参数，必须指定为0。</li></ul><p>回调函数以如下格式定义。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">void</span> CUDART_CB <span class="hljs-title">my_callback</span><span class="hljs-params">(cudaStream_t stream, cudaError_t status, <span class="hljs-type">void</span>* data)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"callback from stream %d\n"</span>, (<span class="hljs-type">int</span>*)data);<br>}<br></code></pre></td></tr></table></figure><p>上述的流回调方式会在未来被弃用，但目前还没有代替方案，所以依然是有效的。</p><p>在较新版本的CUDA中通过如下函数来调用。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaLaunchHostFunc</span><span class="hljs-params">(cudaStream_t stream, cudaHostFn_t fn, <span class="hljs-type">void</span> *userData)</span></span>;<br></code></pre></td></tr></table></figure><p>回调函数以如下格式定义。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">void</span> CUDART_CB <span class="hljs-title">my_callback</span><span class="hljs-params">(<span class="hljs-type">void</span>* data)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"callback from stream %d\n"</span>, (<span class="hljs-type">int</span>*)data);<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/05_stream_and_concurrence/06_stream_callback.cu">stream_callback.cu</a>。同时，关于上述问题，Stack Overflow上有一个<a href="https://stackoverflow.com/questions/56448390/how-to-recover-from-cuda-errors-when-using-cudalaunchhostfunc-instead-of-cudastr">帖子</a>提到了。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——性能分析工具</title>
    <link href="https://deleter-d.github.io/posts/50255/"/>
    <id>https://deleter-d.github.io/posts/50255/</id>
    <published>2024-02-20T08:29:56.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="概述">概述</h2><p>在之前的CUDA版本中，所附带的性能分析工具主要是<code>nvvp</code>（NVIDIA Visual Profiler）和<code>nvprof</code>，前者是带有图形界面的分析工具，后者是命令行工具。</p><p>在CUDA官方文档中有这样一段描述：</p><blockquote><p><strong>Note that Visual Profiler and nvprof will be deprecated in a future CUDA release.</strong> The NVIDIA Volta platform is the last architecture on which these tools are fully supported. It is recommended to use next-generation tools <a href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems</a> for GPU and CPU sampling and tracing and <a href="https://developer.nvidia.com/nsight-compute">NVIDIA Nsight Compute</a> for GPU kernel profiling.</p></blockquote><p>所以<code>nvvp</code>与<code>nvprof</code>已经是过去时了，后面的介绍都围绕新的性能分析工具<code>nsys</code>（Nsight System）和<code>ncu</code>（Nsight Compute）。</p><p><code>nsys</code>是系统层面的分析工具，可以分析主机与设备端的信息。<code>ncu</code>则是用于分析核函数的工具。两者均有图形界面版本和命令行版本。</p><h2 id="nsight-system">Nsight System</h2><p><code>nsys</code>是系统级别的分析工具，它可以捕捉CPU和GPU上的各种事件以及两者之间的交互。可以通过流水线观察整个应用程序的性能瓶颈，帮助从整体层面优化程序。<code>nsys</code>还支持<code>NVTX</code>，可以更加精准的分析流水线。</p><blockquote><p><code>NVTX</code>即<code>Nvidia Tools Extension</code>，是对CUDA代码的一种注释，使其在profiling过程中能够获取到更加细粒度的信息。在CUDA C代码中只需引入<code>nvToolsExt.h</code>头文件即可，下面是一个示例。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"nvToolsExt.h"</span></span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">Kernel</span><span class="hljs-params">()</span> </span>{<br> ...<br>}<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">kernelLaunch</span><span class="hljs-params">()</span> </span>{<br> <span class="hljs-built_in">nvtxRangePushA</span>(__FUNCTION__);<br> ...<br> <span class="hljs-built_in">nvtxRangePushA</span>(<span class="hljs-string">"Kernel"</span>);<br> Kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;();<br> <span class="hljs-built_in">nvtxRangePop</span>();<br> <span class="hljs-built_in">nvtxRangePop</span>();<br>}<br></code></pre></td></tr></table></figure></blockquote><p>打开<code>nsys</code>后看到如下界面。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/8fd51e06-221e-45a3-ad18-df8e8018dfde"></p><p>左侧是项目管理器，右侧是项目的配置页面。点击<code>Select target for profiling...</code>可以选择要进行性能分析的目标机器。可以选择本机，也可以使用<code>SSH</code>连接远程机器。这里以本机为例，选择本机后看到如下界面。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5ee961e8-d4d6-4c7d-b03d-11fc0e7dd894"></p><p>这里需要先在<code>Command line with arguments</code>中填写执行命令以及所需参数，<code>Working directory</code>指的是执行所填命令的目录，如果所填的命令全部为绝对路径，则<code>Working directory</code>就不是很重要了。填写后往下拉可以看到另一些配置项。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/f9980d3c-e30b-4202-a4f7-6bff2ded3f90"></p><p>上图是默认情况，这些选项就根据需要选择即可。例如在程序中使用了<code>OpenMP</code>，若想将<code>OpenMP</code>带来的影响也体现在分析结果中，则需勾选<code>Collect OpenMP trace</code>，其他的选项同理。</p><p>完成配置后就可以点击右侧的<code>Start</code>开始profiling，结束后就会看到生成了一个分析报告，如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/51d721fe-c71b-41f9-8995-0e880a7f2c5f"></p><p>到此，使用<code>nsys</code>的分析工作就结束了。</p><blockquote><p>使用<code>nsys</code>时可能会遇到如下报错。</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xquery">Collection <span class="hljs-keyword">of</span> CPU IP/backtrace samples <span class="hljs-keyword">or</span> <span class="hljs-keyword">context</span> <span class="hljs-keyword">switch</span> data disabled. perf event paranoid level <span class="hljs-literal">is</span> <span class="hljs-number">4</span>.<br>Change the paranoid level <span class="hljs-keyword">to</span> <span class="hljs-number">2</span> <span class="hljs-keyword">to</span> enable CPU IP/backtrace sample <span class="hljs-keyword">or</span> <span class="hljs-keyword">context</span> <span class="hljs-keyword">switch</span> data<span class="hljs-built_in"> collection</span>. Change the paranoid level <span class="hljs-keyword">to</span> <span class="hljs-number">1</span> <span class="hljs-keyword">to</span> enable CPU kernel sample<span class="hljs-built_in"> collection</span>.<br>Try<br>sudo sh -c <span class="hljs-string">'echo [level] &gt;/proc/sys/kernel/perf_event_paranoid'</span><br><span class="hljs-keyword">where</span> <span class="hljs-string">'level'</span> equals <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> <span class="hljs-number">2</span>.<br></code></pre></td></tr></table></figure><p>根据提示执行命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo sh -c <span class="hljs-string">'echo 1 &gt;/proc/sys/kernel/perf_event_paranoid'</span><br></code></pre></td></tr></table></figure><p>这里建议直接将<code>level</code>修改为1，如果<code>level</code>为2可能还会存在一些警告。</p></blockquote><h2 id="nsight-compute">Nsight Compute</h2><p><code>ncu</code>是核函数级别的分析工具，它可以捕捉核函数执行过程中的各种数据。能够从显存使用、SM占用、<code>warp</code>状态等角度来分析核函数的瓶颈所在。</p><p>打开<code>ncu</code>后看到如下界面。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/f4b6dfc8-4d27-413b-844e-a96261767732"></p><p>左侧是项目管理器，双击项目即可开始配置。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/644fdf63-cd16-48c9-b48b-c75f3b2dda1e"></p><p>这里的必填项是上方带黄色感叹号的<code>Application Executable</code>和下方的<code>Output File</code>。<code>Application Executable</code>和<code>Working Directory</code>与<code>nsys</code>的同理，<code>Output File</code>是指输出的性能分析结果的文件名。填写完成后就可以点击<code>Launch</code>开始性能分析。</p><blockquote><p><code>Output File</code>可以使用<code>%i</code>来在文件名中生成变量，例如<code>output%i.log</code>。这样生成的报告就会以<code>output1.log</code>、<code>output2.log</code>来命令，避免了之前的报告被覆写。</p></blockquote><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b19c5412-e6bd-4e49-8d4c-7e7b4e6cf99c"></p><p>到此，使用<code>ncu</code>的分析工作就结束了。</p><blockquote><p>初次使用<code>ncu</code>可能会遇到权限问题。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">==ERROR== ERR_NVGPUCTRPERM - The <span class="hljs-keyword">user</span> does <span class="hljs-keyword">not</span> have permission <span class="hljs-keyword">to</span> <span class="hljs-keyword">access</span> NVIDIA GPU Performance Counters <span class="hljs-keyword">on</span> the target device <span class="hljs-number">0.</span> <span class="hljs-keyword">For</span> instructions <span class="hljs-keyword">on</span> enabling permissions <span class="hljs-keyword">and</span> <span class="hljs-keyword">to</span> <span class="hljs-keyword">get</span> more information see https://developer.nvidia.com/ERR_NVGPUCTRPERM<br></code></pre></td></tr></table></figure><p>这个问题就参考给出的链接，<code>Linux</code>的解决方案为在<code>/etc/modprobe.d</code>目录下创建一个后缀为<code>.conf</code>的文件，在其中加上下面一行语句。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">options</span> nvidia NVreg_RestrictProfilingToAdminUsers=<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>这样就将访问权限开放给了所有用户，如果想要仅<code>root</code>可用，则将上面的选项修改为<code>1</code>。添加好文件后<code>reboot</code>即可。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——共享内存和常量内存</title>
    <link href="https://deleter-d.github.io/posts/38038/"/>
    <id>https://deleter-d.github.io/posts/38038/</id>
    <published>2024-02-20T08:22:30.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="共享内存概述">共享内存概述</h2><p>GPU中有两种类型的内存：</p><ul><li>板载内存：全局内存是较大的板载内存，延迟相对较高；</li><li>片上内存：共享内存是较小的片上内存，延迟相对较低，同时带宽比全局内存高得多。</li></ul><p>共享内存可以视作一个可编程的缓存，一般用于块内线程的通信，全局内存数据的可编程管理缓存，以及高速暂存存储器，用于转换数据以优化全局内存访问模式。</p><h3 id="共享内存">共享内存</h3><p>使用内存空间说明符<code>__shared__</code>分配共享内存（Shared Memory）。再次回顾下图中的内存层次结构。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/78acbc6e-a8c2-4440-a03d-1d9453aaa3cb"></p><p>共享内存比全局内存快的多，可以当作暂存器或由程序管理的高速缓存来使用，以最小化block对全局内存的访问。</p><p>下面是直接实现矩阵乘法的例子，未使用共享内存，每个线程读取矩阵A的一行和矩阵B的一列进行计算。矩阵A将被从全局内存中读取<code>B.width</code>次，矩阵B将被从全局内存中读取<code>A.height</code>次。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 矩阵为行优先存储</span><br><span class="hljs-comment">// M(row, col) = *(M.elements + row * M.width + col)</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> {<br>    <span class="hljs-type">int</span> width;<br>    <span class="hljs-type">int</span> height;<br>    <span class="hljs-type">float</span>* elements;<br>} Matrix;<br><br><span class="hljs-comment">// 定义block的大小</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 16</span><br><br><span class="hljs-comment">// 矩阵乘法核函数</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulKernel</span><span class="hljs-params">(Matrix A, Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-comment">// 每个线程计算一个C的元素</span><br>    <span class="hljs-type">float</span> Cvalue = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> e = <span class="hljs-number">0</span>; e &lt; A.width; ++e)<br>        Cvalue += A.elements[row * A.width + e * B.elements[e * B.width + col];<br>    C.elements[row * C.width + col] = Cvalue;<br>}<br><br><span class="hljs-comment">// 主机代码</span><br><span class="hljs-comment">// 假设矩阵的维数能够被BLOCK_SIZE整除</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">MatMul</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">const</span> Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-comment">// 将A和B加载到设备内存</span><br>    Matrix d_A;<br>    d_A.width = A.width;<br>    d_A.height = A.height;<br>    <span class="hljs-type">size_t</span> size = A.width * A.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_A.elements, size);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A.elements, A.elements, size, cudaMemcpyHostToDevice);<br>    Matrix d_B;<br>    d_B.width = B.width;<br>    d_B.height = B.height;<br>    size = B.width * B.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_B.elements, size);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B.elements, B.elements, size, cudaMemcpyHostToDevice);<br><br>    <span class="hljs-comment">// 在设备上申请结果矩阵</span><br>    Matrix d_C;<br>    d_C.width = C.width;<br>    d_C.height = C.height;<br>    size = C.width * C.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_C.elements, size);<br><br>    <span class="hljs-comment">// 调用核函数</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">dimBlock</span><span class="hljs-params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">dimGrid</span><span class="hljs-params">(B.width / dimBlock.x, A.height / dimBlock.y)</span></span>;<br>    MatMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_A, d_B, d_C);<br><br>    <span class="hljs-comment">// 从设备内存中读取结果矩阵C</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(C.elements, d_C.elements, size, cudaMemcpyDeviceToHost);<br><br>    <span class="hljs-comment">// 释放设备内存</span><br>    <span class="hljs-built_in">cudaFree</span>(d_A.elements);<br>    <span class="hljs-built_in">cudaFree</span>(d_B.elements);<br>    <span class="hljs-built_in">cudaFree</span>(d_C.elements);<br>}<br></code></pre></td></tr></table></figure><p>整个访存过程如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/9d695d44-1c15-4282-9d99-fedec7f36db6"></p><p>下面是使用共享内存实现矩阵乘法的例子。在下例中，每个block负责计算C的一个子矩阵<code>Csub</code>（方阵），block内的每个线程负责计算<code>Csub</code>的一个元素，<code>Csub</code>等于两个子矩阵的乘积。其中，A的子矩阵维度为<code>(A.width, block_size)</code>，行索引与<code>Csub</code>的行索引相同，B的子矩阵维度为<code>(block_size, A.width)</code>，列索引与<code>Csub</code>的列索引相同。</p><p>为了适配设备的资源，A、B的两个子矩阵被划分为多个维度为<code>block_size</code>的方阵，<code>Csub</code>即为这些方阵的乘积之和。将两个对应的方阵从全局内存中加载到共享内存中，其中每个线程加载两个对应方阵中的各一个元素，然后每个线程计算一个乘积。每个参与计算的线程都将乘积累加到一个寄存器中，完成累加后将结果写入全局内存。</p><p>通过这种方式，利用了共享内存的速度优势，节省了大量全局内存带宽。A只从全局内存中读取<code>(B.width / block_size)</code>次，而B只读取了<code>(A.height / block_size)</code>次。</p><p>下例还引入了stride，可以用相同的类型有效地表示子矩阵。利用了一个设备函数来获取和设置元素，并从矩阵中构建子矩阵。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 矩阵为行优先存储</span><br><span class="hljs-comment">// M(row, col) = *(M.elements + row * M.stride + col)</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> {<br>    <span class="hljs-type">int</span> width;<br>    <span class="hljs-type">int</span> height;<br>    <span class="hljs-type">int</span> stride;<br>    <span class="hljs-type">float</span>* elements;<br>} Matrix;<br><br><span class="hljs-comment">// 获取一个矩阵元素</span><br><span class="hljs-function">__device__ <span class="hljs-type">float</span> <span class="hljs-title">GetElement</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">int</span> row, <span class="hljs-type">int</span> col)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-keyword">return</span> A.elements[row * A.stride + col];<br>}<br><span class="hljs-comment">// 设置一个矩阵元素</span><br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">SetElement</span><span class="hljs-params">(Matrix A, <span class="hljs-type">int</span> row, <span class="hljs-type">int</span> col, <span class="hljs-type">float</span> value)</span></span><br><span class="hljs-function"></span>{<br>    A.elements[row * A.stride + col] = value;<br>}<br><br><span class="hljs-comment">// 获取A的BLOCK_SIZE*BLOCK_SIZE子矩阵Asub，通过row、col以及stride和BLOCK_SIZE来定位</span><br> <span class="hljs-function">__device__ Matrix <span class="hljs-title">GetSubMatrix</span><span class="hljs-params">(Matrix A, <span class="hljs-type">int</span> row, <span class="hljs-type">int</span> col)</span></span><br><span class="hljs-function"></span>{<br>    Matrix Asub;<br>    Asub.width    = BLOCK_SIZE;<br>    Asub.height   = BLOCK_SIZE;<br>    Asub.stride   = A.stride;<br>    Asub.elements = &amp;A.elements[A.stride * BLOCK_SIZE * row + BLOCK_SIZE * col];<br>    <span class="hljs-keyword">return</span> Asub;<br>}<br><br><span class="hljs-comment">// 定义block的大小</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 16</span><br><br><span class="hljs-comment">// 矩阵乘法核函数的前置声明</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulKernel</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix, <span class="hljs-type">const</span> Matrix, Matrix)</span></span>;<br><br><span class="hljs-comment">// 矩阵乘法核函数</span><br> <span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulKernel</span><span class="hljs-params">(Matrix A, Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-comment">// block的行和列</span><br>    <span class="hljs-type">int</span> blockRow = blockIdx.y;<br>    <span class="hljs-type">int</span> blockCol = blockIdx.x;<br>    <span class="hljs-comment">// 每个block计算的子矩阵Csub</span><br>    Matrix Csub = <span class="hljs-built_in">GetSubMatrix</span>(C, blockRow, blockCol);<br>    <span class="hljs-comment">// 每个线程计算Csub的一个元素</span><br>    <span class="hljs-type">float</span> Cvalue = <span class="hljs-number">0</span>;<br>    <span class="hljs-comment">// Csub中的线程的行和列</span><br>    <span class="hljs-type">int</span> row = threadIdx.y;<br>    <span class="hljs-type">int</span> col = threadIdx.x;<br>    <span class="hljs-comment">// 循环计算Csub所需的A和B的所有子矩阵，将每对子矩阵相乘并累加结果</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> m = <span class="hljs-number">0</span>; m &lt; (A.width / BLOCK_SIZE); ++m) {<br>        <span class="hljs-comment">// 获取A的子矩阵Asub</span><br>        Matrix Asub = <span class="hljs-built_in">GetSubMatrix</span>(A, blockRow, m);<br>        <span class="hljs-comment">// 获取B的子矩阵Bsub</span><br>        Matrix Bsub = <span class="hljs-built_in">GetSubMatrix</span>(B, m, blockCol);<br>        <span class="hljs-comment">// 用于分别存储Asub和Bsub的共享内存</span><br>        __shared__ <span class="hljs-type">float</span> As[BLOCK_SIZE][BLOCK_SIZE];<br>        __shared__ <span class="hljs-type">float</span> Bs[BLOCK_SIZE][BLOCK_SIZE];<br>        <span class="hljs-comment">// 将Asub和Bsub从设备内存加载到共享内存</span><br>        <span class="hljs-comment">// 每个线程加载每个子矩阵的一个元素</span><br>        As[row][col] = <span class="hljs-built_in">GetElement</span>(Asub, row, col);<br>        Bs[row][col] = <span class="hljs-built_in">GetElement</span>(Bsub, row, col);<br>        <span class="hljs-comment">// 同步，确保在开始计算之前子矩阵加载完整</span><br>        __syncthreads();<br>        <span class="hljs-comment">// 将Asub和Bsub相乘</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> e = <span class="hljs-number">0</span>; e &lt; BLOCK_SIZE; ++e)<br>            Cvalue += As[row][e] * Bs[e][col];<br>        <span class="hljs-comment">// 同步，确保下一次循环加载A和B的两个新子矩阵之前完成之前的计算</span><br>        __syncthreads();<br>    }<br>    <span class="hljs-comment">// 将Csub写入设备内存，每个线程写入一个元素</span><br>    <span class="hljs-built_in">SetElement</span>(Csub, row, col, Cvalue);<br>}<br><br><span class="hljs-comment">// 主机代码基本一致，此处省略</span><br></code></pre></td></tr></table></figure><p>整个访存过程如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/3e53d361-1acc-4446-ac80-221577541d6a"></p><blockquote><p>物理上，每个SM都有一个小的低延迟内存池，该内存池被当前正在该SM上执行的线程块中的所有线程共享。</p><p>当每个线程块开始工作时，会分配给它一定数量的共享内存。它的内容和创建时所在的线程块具有相同的生命周期。每个线程束发出的共享内存访问请求，理想情况下，每个请求在一个事务中完成。最坏情况下，每个共享内存的请求在32个不同的事务中顺序执行。若多个线程访问共享内存中的同一个字，一个线程读取该字后，会通过多播把它发给其他线程。</p><p>共享内存被SM中所有常驻线程块划分，因此共享内存是限制设备并行性的关键资源。一个核函数使用的共享内存越多，处于并发活跃状态的线程块就越少。</p></blockquote><h3 id="分布式共享内存">分布式共享内存</h3><p>在计算能力9.0中引入的线程块集群为线程块集群中的线程提供了访问集群中所有参与线程块的共享内存能力。属于线程块集群的线程可以在分布式地址空间中读取、写入或执行原子，无论目标地址属于当前线程块还是集群中的其他线程块。无论核函数是否使用分布式共享内存（Distributed Shared Memory），共享内存范围仍然属于各自的线程块。分布式共享内存的大小就是每个集群的线程块数乘以每个线程块的共享内存大小。</p><p>访问分布式共享内存中的数据需要所有线程块都存在。使用<code>cluster Group</code>API中的<code>cluster.sync()</code>可以保证所有线程块都已开始执行。还需要确保所有分布式共享内存操作都发生在线程块退出之前。</p><p>下面是一个计算直方图的例子，以及如何使用线程块集群在GPU上优化计算。计算直方图的一个标准方法是在每个线程块的共享内存中进行计算，然后在全局内存中执行原子操作。这种方法的一个限制是共享内存的容量，如果直方图的数据量无法与共享内存适配，就只能在全局内存中直接进行原子操作。</p><p>而对于分布式共享内存，CUDA提供了一个中间步骤，可以根据直方图的数据量，选择在共享内存、分布式共享内存或全局内存中计算直方图。</p><p>下面的CUDA核函数实现了根据直方图数据量选择计算直方图的内存空间。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cooperative_groups.h&gt;</span></span><br><br><span class="hljs-comment">// 分布式共享内存计算直方图核函数</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">clusterHist_kernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *bins, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nbins, <span class="hljs-type">const</span> <span class="hljs-type">int</span> bins_per_block, </span></span><br><span class="hljs-params"><span class="hljs-function">                                   <span class="hljs-type">const</span> <span class="hljs-type">int</span> *__restrict__ input, <span class="hljs-type">size_t</span> array_size)</span></span><br><span class="hljs-function"></span>{<br>  <span class="hljs-keyword">extern</span> __shared__ <span class="hljs-type">int</span> smem[];<br>  <span class="hljs-keyword">namespace</span> cg = cooperative_groups;<br>  <span class="hljs-type">int</span> tid = cg::<span class="hljs-built_in">this_grid</span>().<span class="hljs-built_in">thread_rank</span>();<br><br>  <span class="hljs-comment">// 集群初始化，获取集群尺寸，并计算局部数据偏移</span><br>  cg::cluster_group cluster = cg::<span class="hljs-built_in">this_cluster</span>();<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> clusterBlockRank = cluster.<span class="hljs-built_in">block_rank</span>();<br>  <span class="hljs-type">int</span> cluster_size = cluster.<span class="hljs-built_in">dim_blocks</span>().x;<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = threadIdx.x; i &lt; bins_per_block; i += blockDim.x)<br>  {<br>    smem[i] = <span class="hljs-number">0</span>; <span class="hljs-comment">//将共享内存中的直方图初始化为0</span><br>  }<br><br>  <span class="hljs-comment">// 集群同步，确保集群中的所有block的共享内存初始化为0，并确保所有block都开始执行且同时存在</span><br>  cluster.<span class="hljs-built_in">sync</span>();<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = tid; i &lt; array_size; i += blockDim.x * gridDim.x)<br>  {<br>    <span class="hljs-type">int</span> ldata = input[i];<br><br>    <span class="hljs-comment">// 寻找正确的直方图数据</span><br>    <span class="hljs-type">int</span> binid = ldata;<br>    <span class="hljs-keyword">if</span> (ldata &lt; <span class="hljs-number">0</span>)<br>      binid = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ldata &gt;= nbins)<br>      binid = nbins - <span class="hljs-number">1</span>;<br><br>    <span class="hljs-comment">// 寻找目标block的行索引和行内偏移，以计算分布式共享内存的直方图</span><br>    <span class="hljs-type">int</span> dst_block_rank = (<span class="hljs-type">int</span>)(binid / bins_per_block);<br>    <span class="hljs-type">int</span> dst_offset = binid % bins_per_block;<br><br>    <span class="hljs-comment">// 指向目标block共享内存的指针</span><br>    <span class="hljs-type">int</span> *dst_smem = cluster.<span class="hljs-built_in">map_shared_rank</span>(smem, dst_block_rank);<br><br>    <span class="hljs-comment">// 执行原子更新操作</span><br>    <span class="hljs-built_in">atomicAdd</span>(dst_smem + dst_offset, <span class="hljs-number">1</span>);<br>  }<br><br>  <span class="hljs-comment">// 这里的集群同步是必须的，以确保所有分布式共享内存的操作都已完成</span><br>  <span class="hljs-comment">// 并确保当某个block在访问分布式共享内存时，不会有其他block结束。</span><br>  cluster.<span class="hljs-built_in">sync</span>();<br><br>  <span class="hljs-comment">// 使用局部分布式内存中的直方图，计算全局内存的直方图</span><br>  <span class="hljs-type">int</span> *lbins = bins + cluster.<span class="hljs-built_in">block_rank</span>() * bins_per_block;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = threadIdx.x; i &lt; bins_per_block; i += blockDim.x)<br>  {<br>    <span class="hljs-built_in">atomicAdd</span>(&amp;lbins[i], smem[i]);<br>  }<br>}<br></code></pre></td></tr></table></figure><p>上面的核函数可以在运行时指定集群大小，集群的大小取决于分布式共享内存的需求。若直方图足够小，只能填满一个block的共享内存，则可以启动集群大小为1的核函数。</p><p>下面的代码实现了根据共享内存需求动态确定集群大小。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Launch via extensible launch</span><br><span class="hljs-comment">// </span><br>{<br>  cudaLaunchConfig_t config = {<span class="hljs-number">0</span>};<br>  config.gridDim = array_size / threads_per_block;<br>  config.blockDim = threads_per_block;<br><br>  <span class="hljs-comment">// 集群大小取决于直方图的大小</span><br>  <span class="hljs-comment">// cluster_size == 1意味着不会有分布式共享内存，只有block局部共享内存</span><br>  <span class="hljs-type">int</span> cluster_size = <span class="hljs-number">2</span>; <span class="hljs-comment">// 以集群大小2为例</span><br>  <span class="hljs-type">int</span> nbins_per_block = nbins / cluster_size; <span class="hljs-comment">// 每个block的动态共享内存大小</span><br>  <br>  <span class="hljs-comment">// 分布式共享内存大小为cluster_size * nbins_per_block * sizeof(int)</span><br>  config.dynamicSmemBytes = nbins_per_block * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>);<br><br>  <span class="hljs-built_in">CUDA_CHECK</span>(::<span class="hljs-built_in">cudaFuncSetAttribute</span>((<span class="hljs-type">void</span> *)clusterHist_kernel, <br>                                    cudaFuncAttributeMaxDynamicSharedMemorySize,<br>                                    config.dynamicSmemBytes));<br><br>  cudaLaunchAttribute attribute[<span class="hljs-number">1</span>];<br>  attribute[<span class="hljs-number">0</span>].id = cudaLaunchAttributeClusterDimension;<br>  attribute[<span class="hljs-number">0</span>].val.clusterDim.x = cluster_size;<br>  attribute[<span class="hljs-number">0</span>].val.clusterDim.y = <span class="hljs-number">1</span>;<br>  attribute[<span class="hljs-number">0</span>].val.clusterDim.z = <span class="hljs-number">1</span>;<br><br>  config.numAttrs = <span class="hljs-number">1</span>;<br>  config.attrs = attribute;<br><br>  <span class="hljs-built_in">cudaLaunchKernelEx</span>(&amp;config, clusterHist_kernel, bins, nbins, nbins_per_block, input, array_size);<br>}<br></code></pre></td></tr></table></figure><h3 id="共享内存的分配">共享内存的分配</h3><p>共享内存可以被静态或动态分配。上面也提到过，使用<code>__shared__</code>修饰符来申请共享内存。</p><p>下面的代码申请了一个共享内存中的二维数组。若该声明在核函数内，则该变量的作用域为该核函数中。若在文件的任何核函数外声明，则作用域对所有核函数来说是全局的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__shared__ <span class="hljs-type">float</span> tile[size_y][size_x];<br></code></pre></td></tr></table></figure><p>若共享内存的大小在编译时无法确定，则可以用<code>extern</code>关键字进行声明。该声明同样可以在核函数内或核函数外。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">extern</span> __shared__ <span class="hljs-type">int</span> tile[];<br></code></pre></td></tr></table></figure><p>由于该数组的大小编译时是未知的，所以在核函数被调用时，需要动态分配共享内存。将所需的共享内存字节数在<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>的第三个参数传入。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">kernel&lt;&lt;&lt;grid, block, <span class="hljs-function">size * <span class="hljs-title">sizeof</span><span class="hljs-params">(<span class="hljs-type">int</span>)</span>&gt;&gt;&gt;<span class="hljs-params">(...)</span></span><br></code></pre></td></tr></table></figure><p>注意：只能动态声明一维数组。</p><h3 id="共享内存存储体和访问模式">共享内存存储体和访问模式</h3><h4 id="内存存储体">内存存储体</h4><p>为了获取高内存带宽，共享内存被分为32个同样大小的内存模型，被成为存储体，它们可以被同时访问。共享内存是一个一维地址空间。根据GPU的计算能力，共享内存的地址在不同模式下会映射到不同的存储体中。</p><p>如果通过线程束发布共享内存加载或存储操作，且在每个存储体上只访问不多于一个的内存地址，则该操作可以由一个内存事务来完成。否则该操作由多个内存事务完成，这样就降低了内存带宽的利用率。</p><h4 id="存储体冲突">存储体冲突</h4><p>在共享内存中，多个地址请求落在同一个存储体时，就会发生存储体冲突，这会导致请求被重复执行。硬件会将存储体冲突的请求分割到尽可能多的独立无冲突事务中。当线程束发出共享内存请求时，有3种典型模式：</p><ul><li>并行访问：多个地址访问多个存储体；</li><li>串行访问：多个地址访问同一个存储体；</li><li>广播访问：单一地址读取单一存储体。</li></ul><p>并行访问是最常见的模式，这种模式下如果访问的不是范围内的所有地址，则至少有一些地址可以在一个内存事务中完成。最佳情况是每个地址都位于一个单独的存储体中，执行无冲突的共享内存访问。</p><p>串行访问是最坏的模式。如果线程束中的32个线程全都访问同一存储体中的不同地址，则需要32个内存事务，且是串行执行的。</p><p>广播访问的情况下，线程束中的所有线程都读取同一存储体的同一地址。若一个内存事务被执行，则被访问的字会广播到所有请求线程中。虽然只需要一个内存事务，但因为只有一小部分字节被读取，所以带宽利用率很差。</p><h4 id="访问模式">访问模式</h4><p>内存存储体的宽度和设备计算能力有关，根据官方文档的描述，总结如下：</p><ul><li>计算能力2.x、5.x、6.x、7.x、8.x存储体数量均为32个，宽度均为32bit；</li><li>计算能力3.x比较特殊，存储体数量为32个，宽度64bit。</li></ul><p>对于32个32位的存储体来说，每个存储体在每两个时钟周期内都有32位的带宽，连续的32位字映射到连续的存储体中，因此共享内存地址到存储体索引的映射可以由下列公式计算。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="33.183ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14667 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">储</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">体</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">索</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">引</text></g><g data-mml-node="mo" transform="translate(5277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(6333.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">字</text></g><g data-mml-node="mi" transform="translate(7722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">节</text></g><g data-mml-node="mi" transform="translate(8722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">地</text></g><g data-mml-node="mi" transform="translate(9722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">址</text></g><g data-mml-node="mo" transform="translate(10944.8,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(11945,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(12445,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(12834,0)"><path data-c="25" d="M465 605Q428 605 394 614T340 632T319 641Q332 608 332 548Q332 458 293 403T202 347Q145 347 101 402T56 548Q56 637 101 693T202 750Q241 750 272 719Q359 642 464 642Q580 642 650 732Q662 748 668 749Q670 750 673 750Q682 750 688 743T693 726Q178 -47 170 -52Q166 -56 160 -56Q147 -56 142 -45Q137 -36 142 -27Q143 -24 363 304Q469 462 525 546T581 630Q528 605 465 605ZM207 385Q235 385 263 427T292 548Q292 617 267 664T200 712Q193 712 186 709T167 698T147 668T134 615Q132 595 132 548V527Q132 436 165 403Q183 385 203 385H207ZM500 146Q500 234 544 290T647 347Q699 347 737 292T776 146T737 0T646 -56Q590 -56 545 0T500 146ZM651 -18Q679 -18 707 24T736 146Q736 215 711 262T644 309Q637 309 630 306T611 295T591 265T578 212Q577 200 577 146V124Q577 -18 647 -18H651Z"></path></g><g data-mml-node="mn" transform="translate(13667,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span> 映射关系如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/58dfa384-6b77-41f3-bb32-5def21815fbc"></p><p>对于计算能力3.x的设备，存储体宽度为64bit，但它有两种地址模式，64位模式与32位模式。</p><p>在64模式下，每个存储体在每两个时钟周期内都有64位的带宽，连续的64位字映射到连续的存储体中，因此共享内存地址到存储体索引的映射可以由下列公式计算。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="33.183ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14667 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">储</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">体</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">索</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">引</text></g><g data-mml-node="mo" transform="translate(5277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(6333.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">字</text></g><g data-mml-node="mi" transform="translate(7722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">节</text></g><g data-mml-node="mi" transform="translate(8722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">地</text></g><g data-mml-node="mi" transform="translate(9722.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">址</text></g><g data-mml-node="mo" transform="translate(10944.8,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(11945,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g><g data-mml-node="mo" transform="translate(12445,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(12834,0)"><path data-c="25" d="M465 605Q428 605 394 614T340 632T319 641Q332 608 332 548Q332 458 293 403T202 347Q145 347 101 402T56 548Q56 637 101 693T202 750Q241 750 272 719Q359 642 464 642Q580 642 650 732Q662 748 668 749Q670 750 673 750Q682 750 688 743T693 726Q178 -47 170 -52Q166 -56 160 -56Q147 -56 142 -45Q137 -36 142 -27Q143 -24 363 304Q469 462 525 546T581 630Q528 605 465 605ZM207 385Q235 385 263 427T292 548Q292 617 267 664T200 712Q193 712 186 709T167 698T147 668T134 615Q132 595 132 548V527Q132 436 165 403Q183 385 203 385H207ZM500 146Q500 234 544 290T647 347Q699 347 737 292T776 146T737 0T646 -56Q590 -56 545 0T500 146ZM651 -18Q679 -18 707 24T736 146Q736 215 711 262T644 309Q637 309 630 306T611 295T591 265T578 212Q577 200 577 146V124Q577 -18 647 -18H651Z"></path></g><g data-mml-node="mn" transform="translate(13667,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span> 在32位模式下，在同一存储体中访问两个32位字不一定是重复操作。在一个时钟周期内读64位并只将32位请求传输给线程是允许的。由于64位宽度的存储体比较少见，这里不过多阐述。</p><h4 id="内存填充">内存填充</h4><p>内存填充是避免存储体冲突的一种方法。以下图为例，假设只有5个存储体，若所有线程都访问bank0的不同地址，则会发生存储体冲突。但在每N个字后添加一个字，会使得原先同在bank0中的字改变位置，从而解决这种冲突。这里的N是存储体的数量。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/799235c7-5a17-467e-9eb2-50c6e449dced"></p><h3 id="配置共享内存容量">配置共享内存容量</h3><p>每个SM都有64KB的片上内存，共享内存和一级缓存共享硬件资源。CUDA为配置一级缓存和共享内存容量提供了两种方法：</p><ul><li>按设备进行配置；</li><li>按核函数进行配置。</li></ul><p>使用<code>cudaDeviceSetCacheConfig()</code>运行时API可以在设备层面设置一级缓存和共享内存大小，可选参数与下面的运行时API一致。</p><p>使用<code>cudaFuncSetCacheConfig()</code>运行时API可以在核函数层面设置，相关参数已经在<a href="https://deleter-d.github.io/posts/47184/#共享内存">共享内存</a>阐述过了。</p><h3 id="同步">同步</h3><p>CUDA提供的块内同步有两个基本方法：</p><ul><li>障碍：所有调用的线程等待其余调用的线程达到障碍点；</li><li>内存栅栏：所有调用的线程必须等到全部内存修改对其余调用线程可见。</li></ul><h4 id="弱排序内存模型">弱排序内存模型</h4><p>GPU线程在不同内存中写入数据的顺序，不一定和这些数据在源代码中访问的顺序相同。一个线程的写入顺序对其他线程可见时，它可能和写操作被执行的实际顺序不一致。</p><p>若指令间是相互独立的，线程从不同内存中读取数据的顺序和读指令在程序中出现的顺序不一定相同。</p><h4 id="显式障碍">显式障碍</h4><p>设置障碍点的方法在前面已经见过了，即<code>__syncthreads()</code>函数。它要求块内的线程必须等待直到所有线程都到达该点。<code>__syncthreads()</code>还确保在障碍点之前，被这些线程访问的所有全局和共享内存对同一块中的所有线程可见。<code>__syncthreads()</code>用于协调同一块中线程间的通信。</p><p>在使用<code>__syncthreads()</code>时，必须保证一个条件能对整个线程块中的线程进行评估，否则执行很可能挂起甚至产生意料之外的问题。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (threadID % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>) {<br>    __syncthreads();<br>} <span class="hljs-keyword">else</span> {<br>    __syncthreads();<br>}<br></code></pre></td></tr></table></figure><p>上面的例子中，可能会导致线程无限期的等待对方，因为块中的所有线程没有到达相同的障碍点。</p><p>如果需要进行块间同步，可以尝试在同步点分割核函数并执行多个核函数启动，其中会产生隐式全局障碍以达到预期效果。</p><h4 id="内存栅栏">内存栅栏</h4><p>CUDA提供3种内存栅栏：</p><ul><li>块：<code>__threadfence_block()</code>；</li><li>网格：<code>__threadfence()</code>；</li><li>系统：<code>__threadfence_system()</code>。</li></ul><p><code>__threadfence_block()</code>保证了栅栏前被调用线程产生的对共享内存和全局内存的所有写操作对栅栏后同一块中的其他线程可见。内存栅栏不执行任何线程同步，所以对于一个块中的所有线程来说，没必要实际执行这个指令。</p><p><code>__threadfence()</code>会挂起调用的线程，直到全局内存中的所有写操作对同一网格内的所有线程均可见。</p><p><code>__threadfence_system()</code>会挂起调用的线程，以确保该线程对全局内存、锁页主机内存和其他设备内存中的所有写操作对全部设备中的线程和主机线程都可见。</p><h4 id="内存同步域">内存同步域</h4><h5 id="内存栅栏实例">内存栅栏实例</h5><p>某些CUDA程序可能会因为内存栅栏/刷新操作等待的事务多于CUDA内存一致性模型所需的事务而导致性能下降。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">__managed__ <span class="hljs-type">int</span> x = <span class="hljs-number">0</span>;<br><span class="hljs-function">__device__ cuda::atomic&lt;<span class="hljs-type">int</span>, cuda::thread_scope_device&gt; <span class="hljs-title">a</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br><span class="hljs-function">__managed__ cuda::atomic&lt;<span class="hljs-type">int</span>, cuda::thread_scope_system&gt; <span class="hljs-title">b</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br></code></pre></td></tr></table></figure><p>Thread 1 (SM)：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">x = <span class="hljs-number">1</span>;<br>a = <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><p>Thread 2 (SM)：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">while</span>(a != <span class="hljs-number">1</span>);<br><span class="hljs-built_in">assert</span>(x == <span class="hljs-number">1</span>);<br>b = <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><p>Thread 3 (CPU)：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">while</span>(b != <span class="hljs-number">1</span>);<br><span class="hljs-built_in">assert</span>(x == <span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure><p>考虑上述例子，CUDA内存一致性模型将保证断言的条件为真，故在线程2写入<code>b</code>之前，线程1对<code>x</code>的写入必须对线程3可见。</p><p>释放和获取<code>a</code>所提供的内存排序仅能够使<code>x</code>对线程2可见，但线程3不可见，因为它是设备范围的操作。故由释放和获取<code>b</code>所提供的系统范围的内存排序需要确保从线程2发起的写入对线程3可见，同时要保证从线程2可见的其他线程发起的写入也是可见的。这要求称为累积性（cumulativity）。由于GPU在执行时不知道哪些写入在源码级别下是可见的，也不知道哪些写入仅在偶然的时间是可见的，所以它必须为所有活动状态的内存操作撒下一个保守的广域网。</p><p>上述情况会使GPU等待源码级别不需要的内存操作，进而使得内存栅栏/刷新操作花费不必要的时间，对整个程序产生干扰。</p><p>注意，内存栅栏可以在代码中显式的作为内部结构或原子操作出现，也可以隐式的实现任务边界上的同步关系。</p><h5 id="用域隔离流量">用域隔离流量</h5><p>从Hopper架构的GPU和CUDA 12.0开始，内存同步域提供了一种减轻上述干扰的方法。使用代码来显式辅助，可以减少GPU的光撒网行为。每次核函数启动都会被赋予一个域ID。写操作和栅栏都用该ID来标识，而栅栏只会对与栅栏域匹配的写操作进行排序。通信的核函数可以放在不同的域中。</p><p>使用域时，代码必须使同一GPU上不同域之间的排序或同步需要系统范围的栅栏。而在同一域中，设备范围的栅栏就足够了。这种栅栏范围要求对于累积性来说是必要的，因为一个核函数的写操作不会被另一个域中的核函数发出的栅栏所包围。本质上，累积性是通过确保跨域流量提前刷新到系统范围来满足的。</p><p>注意，这会修改<code>thread_scope_device</code>的定义。但由于核函数将默认采用域0，所以保证了向后兼容。</p><h5 id="在cuda中使用域">在CUDA中使用域</h5><p>域可以通过新的启动属性<code>cudaLaunchAttributeMemSyncDomain</code>和<code>cudaLaunchAttributeMemSyncDomainMap</code>来访问。前者在逻辑域<code>cudaLaunchMemSyncDomainDefault</code>和<code>cudaLaunchMemSyncDomainRemote</code>之间选择，后者提供从逻辑域到物理域的映射。远程域可供核函数进行远程内存访问，以便将其内存流量与本地核函数隔离。选择特定的域不会影响核函数可以合法执行的内存访问。</p><p>可以通过设备属性<code>cudaDevAttrMemSyncDomainCount</code>来获取域的数量。Hopper有4个域。为了便于代码移植，域功能可以在所有设备上使用，在Hopper架构之前的架构下，该计数将返回1。</p><p>详细参考官方文档<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#using-domains-in-cuda">Using Domains in CUDA</a>。</p><h4 id="volatile修饰符"><code>volatile</code>修饰符</h4><p>在全局或共享内存中使用<code>volatile</code>修饰符声明一个变量，可以防止编译器优化，编译器优化可能会将数据暂时缓存在寄存器或本地内存中。当使用<code>volatile</code>修饰符时，编译器假定任何其他线程在任何时间都可以更改或使用该变量的值。因此，这个变量的任何引用都会直接被编译到全局内存读指令或全局内存写指令中，它们都会忽略缓存。</p><h2 id="共享内存的数据布局">共享内存的数据布局</h2><h3 id="方形共享内存">方形共享内存</h3><p>方形矩阵可以很容易从二维线程索引计算出一维内存偏移，声明一个方形二维共享内存变量。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__shared__ <span class="hljs-type">int</span> tile[N][N];<br></code></pre></td></tr></table></figure><p>它可以有两种访问方式：</p><ul><li><code>tile[threadIdx.y][threadIdx.x]</code></li><li><code>tile[threadIdx.x][threadIdx.y]</code></li></ul><p>显然，两种方式相比，第一种方式拥有更少的存储体冲突，因为邻近线程在最内层数组维度上访问相邻的阵列单元。</p><h4 id="访问方式实例">访问方式实例</h4><p>我们分别实现三种读写共享内存的方法：</p><ul><li>按行写入，按行读取；</li><li>按列写入，按列读取；</li><li>按列写入，按行读取。</li><li>按行写入，按列读取。</li></ul><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/01_square_shared_memory.cu">square_shared_memory.cu</a>。</p></blockquote><p>利用<code>nsys</code>来分析其耗时，并利用<code>ncu</code>来分析它们的共享内存加载和存储事务来体现存储体冲突，结果如下。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs scss">                                                  耗时 加载事务  存储事务<br><span class="hljs-built_in">writeRowReadRow</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1248</span> ns    <span class="hljs-number">32</span>  <span class="hljs-number">32</span><br><span class="hljs-built_in">writeColReadCol</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1920</span> ns<span class="hljs-number">1024</span><span class="hljs-number">1024</span><br><span class="hljs-built_in">writeColReadRow</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1280</span> ns  <span class="hljs-number">32</span><span class="hljs-number">1024</span><br><span class="hljs-built_in">writeRowReadCol</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1280</span> ns<span class="hljs-number">1024</span>  <span class="hljs-number">32</span><br></code></pre></td></tr></table></figure><p>可以看出行读行写的核函数性能最高，加载和存储事务最少，没有存储体冲突。不管是按列读还是写，都会存在存储体冲突，导致加载或存储事务大量增多。</p><h4 id="动态共享内存">动态共享内存</h4><p>使用动态声明共享内存的方式实现与上述功能相同的核函数。动态共享内存必须被声明为一个未定大小的一维数组，因此需要基于二维线程索引来计算内存访问索引。</p><p>再测试其性能，结果如下。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss">                                                    耗时  加载事务  存储事务<br><span class="hljs-built_in">writeRowReadColDynamic</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1280</span> ns<span class="hljs-number">1024</span>  <span class="hljs-number">32</span><br></code></pre></td></tr></table></figure><p>可以发现结果与<code>writeRowReadCol</code>相同。</p><h4 id="填充静态声明的共享内存">填充静态声明的共享内存</h4><p>使用前面提到的<a href="#内存填充">内存填充</a>来解决存储体冲突，并测试其性能。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss">                                                    耗时 加载事务  存储事务<br><span class="hljs-built_in">writeRowReadColPadding</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">896</span> ns<span class="hljs-number">32</span>  <span class="hljs-number">32</span><br></code></pre></td></tr></table></figure><p>可以发现，通过填充完美的解决了存储体冲突。</p><h4 id="填充动态声明的共享内存">填充动态声明的共享内存</h4><p>实现基于动态共享内存填充的核函数，并测试其性能。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss">                                                    耗时 加载事务  存储事务<br><span class="hljs-built_in">writeRowReadColDynPad</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">896</span> ns<span class="hljs-number">32</span>  <span class="hljs-number">32</span><br></code></pre></td></tr></table></figure><p>可以发现基于动态共享内存的填充也是有效的。</p><h3 id="矩形共享内存">矩形共享内存</h3><p>将上述的方形共享内存推广到矩形这个更为一般的情况。实现与上述功能相同的几个核函数，并分析其性能。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scss">                                                    耗时 加载事务  存储事务<br><span class="hljs-built_in">writeRowReadRow</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1119</span> ns    <span class="hljs-number">16</span>  <span class="hljs-number">16</span><br><span class="hljs-built_in">writeColReadCol</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<span class="hljs-number">1248</span> ns <span class="hljs-number">256</span> <span class="hljs-number">256</span><br><span class="hljs-built_in">writeColReadRow</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">928</span> ns  <span class="hljs-number">16</span> <span class="hljs-number">256</span><br><span class="hljs-built_in">writeRowReadCol</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">992</span> ns <span class="hljs-number">256</span>  <span class="hljs-number">16</span><br><span class="hljs-built_in">writeRowReadColDynamic</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">960</span> ns <span class="hljs-number">256</span>  <span class="hljs-number">16</span><br><span class="hljs-built_in">writeRowReadColPadding</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">896</span> ns  <span class="hljs-number">16</span>  <span class="hljs-number">16</span><br><span class="hljs-built_in">writeRowReadColDynPad</span>(int *) (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>) <span class="hljs-number">896</span> ns  <span class="hljs-number">16</span>  <span class="hljs-number">16</span><br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/02_rectangle_shared_memory.cu">rectangle_shared_memory.cu</a>。</p></blockquote><h2 id="减少全局内存访问">减少全局内存访问</h2><h3 id="使用共享内存的并行归约">使用共享内存的并行归约</h3><p>将之前实现的线程束展开的并行归约作为性能基准，利用共享内存的操作代替全军内存的原地操作，观察两者性能差距。</p><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/03_reduce_with_shared_memory.cu">reduce_with_shared_memory.cu</a>。</p></blockquote><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">0859</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> Gemm        elapsed <span class="hljs-number">0</span>.<span class="hljs-number">384192</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">131072</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> Semm        elapsed <span class="hljs-number">0</span>.<span class="hljs-number">278624</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">131072</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">全局加载事务全局存储事务<br>reduce<span class="hljs-constructor">Gmem(<span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">unsigned</span> <span class="hljs-params">int</span>)</span> (<span class="hljs-number">131072</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-number">8912896</span><span class="hljs-number">4325376</span><br>reduce<span class="hljs-constructor">Smem(<span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">unsigned</span> <span class="hljs-params">int</span>)</span> (<span class="hljs-number">131072</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-number">2097152</span> <span class="hljs-number">131072</span><br></code></pre></td></tr></table></figure><p>可以看到，通过使用共享内存代替全局内存的原地操作，大幅度减少了全局内存事务，从而提升了总体性能。</p><h3 id="使用展开的并行归约">使用展开的并行归约</h3><p>在使用共享内存进行归约的基础上，再利用技术展开，每个线程处理4个数据块的元素，再次对比它们的性能。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">0439</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> Gemm        elapsed <span class="hljs-number">0</span>.<span class="hljs-number">384</span> ms        gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">131072</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> Semm        elapsed <span class="hljs-number">0</span>.<span class="hljs-number">278464</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">131072</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> SemmUnroll  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">214976</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>分析其全局加载和存储事务。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">全局加载事务全局存储事务<br>reduce<span class="hljs-constructor">Gmem(<span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">unsigned</span> <span class="hljs-params">int</span>)</span> (<span class="hljs-number">131072</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-number">8912896</span><span class="hljs-number">4325376</span><br>reduce<span class="hljs-constructor">Smem(<span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">unsigned</span> <span class="hljs-params">int</span>)</span> (<span class="hljs-number">131072</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-number">2097152</span> <span class="hljs-number">131072</span><br>reduce<span class="hljs-constructor">SmemUnroll(<span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span> <span class="hljs-operator">*</span>, <span class="hljs-params">unsigned</span> <span class="hljs-params">int</span>)</span> (<span class="hljs-number">32768</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-number">2097152</span>  <span class="hljs-number">32768</span><br></code></pre></td></tr></table></figure><p>观察发现，虽然全局加载事务并没有减少，但全局存储事务却减少到了原来的1/4。</p><h3 id="使用动态共享内存的并行归约">使用动态共享内存的并行归约</h3><p>上述基于共享内存的展开并行归约也可以使用动态共享内存，性能表现与使用静态共享内存时接近，这里不再赘述。</p><h2 id="合并的全局内存访问">合并的全局内存访问</h2><p>使用共享内存可以避免对未合并的全局内存进行访问，矩阵转置是一个典型的例子，读操作是合并的，但写操作是交叉访问的。</p><h3 id="朴素转置">朴素转置</h3><p>实现一个朴素转置，核函数如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INDEX(ROW, COL, INNER) ((ROW) * (INNER) + (COL))</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">naiveGmem</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> rows, <span class="hljs-type">const</span> <span class="hljs-type">int</span> cols)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (row &lt; rows &amp;&amp; col &lt; cols)<br>        out[<span class="hljs-built_in">INDEX</span>(col, row, rows)] = in[<span class="hljs-built_in">INDEX</span>(row, col, cols)];<br>}<br></code></pre></td></tr></table></figure><p>再实现一个读写操作都是合并访问的核函数，用来模拟性能的近似上界。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyGmem</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> rows, <span class="hljs-type">const</span> <span class="hljs-type">int</span> cols)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (row &lt; rows &amp;&amp; col &lt; cols)<br>        out[<span class="hljs-built_in">INDEX</span>(row, col, cols)] = in[<span class="hljs-built_in">INDEX</span>(row, col, cols)];<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/04_transpose_with_shared_memory.cu">transpose_with_shared_memory.cu</a>。</p></blockquote><p>这里使用<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 3222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>的二维线程块来调用，经过测试，上面两个核函数的性能表现如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Kernel</span>          Elapsed time    Effective bandwidth<br><span class="hljs-attribute">copyGmem</span>        <span class="hljs-number">0</span>.<span class="hljs-number">291488</span> ms     <span class="hljs-number">0</span>.<span class="hljs-number">460457</span> GB/s<br><span class="hljs-attribute">naiveGmem</span>       <span class="hljs-number">0</span>.<span class="hljs-number">994176</span> ms     <span class="hljs-number">0</span>.<span class="hljs-number">135004</span> GB/s<br></code></pre></td></tr></table></figure><p>分析其每次请求中的全局内存事务数量，结果如下。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">全局加载事务全局存储事务<br>copy<span class="hljs-constructor">Gmem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">4</span> <span class="hljs-number">4</span><br>naive<span class="hljs-constructor">Gmem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">4</span><span class="hljs-number">32</span><br></code></pre></td></tr></table></figure><p>可以发现，由于朴素转置的写操作是交叉访问的，所以每次请求中的全局存储事务要更多。</p><h3 id="使用共享内存的矩阵转置">使用共享内存的矩阵转置</h3><p>可以使用二维共享内存来缓存原始矩阵的数据，从而避免交叉的全局内存写操作。首先从全局内存中读取块内的一行写入共享内存的一行，然后从共享内存读取一列写入全局内存的一行。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/e10502de-f723-49c2-928c-d672958a7ec0"></p><p>实现该核函数时，需要注意索引的计算方式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeSmem</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> rows, <span class="hljs-type">const</span> <span class="hljs-type">int</span> cols)</span></span><br><span class="hljs-function"></span>{<br>    __shared__ <span class="hljs-type">float</span> tile[BDIMY][BDIMX];<br><br>    <span class="hljs-comment">// 原始矩阵索引</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (row &lt; rows &amp;&amp; col &lt; cols)<br>        tile[threadIdx.y][threadIdx.x] = in[<span class="hljs-built_in">INDEX</span>(row, col, cols)];<br><br>    <span class="hljs-comment">// 由于转置过程中，不仅block需要转置，block内的thread也需要转置</span><br>    <span class="hljs-comment">// 所以利用irow和icol来代替原来的threadIdx的x和y维度</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> bidx = threadIdx.y * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> irow = bidx / blockDim.y;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> icol = bidx % blockDim.y;<br><br>    <span class="hljs-comment">// 转置矩阵中，blockDim和blockIdx的x维度计算列索引，y维度计算行索引，与原始矩阵相反</span><br>    row = blockIdx.x * blockDim.x + irow;<br>    col = blockIdx.y * blockDim.y + icol;<br><br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (row &lt; cols &amp;&amp; col &lt; rows)<br>        out[<span class="hljs-built_in">INDEX</span>(row, col, rows)] = tile[icol][irow];<br>}<br></code></pre></td></tr></table></figure><p>分析其性能与全局内存事务。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Kernel</span>          Elapsed time    Effective bandwidth<br><span class="hljs-attribute">copyGmem</span>        <span class="hljs-number">0</span>.<span class="hljs-number">291072</span> ms     <span class="hljs-number">0</span>.<span class="hljs-number">461115</span> GB/s<br><span class="hljs-attribute">naiveGmem</span>       <span class="hljs-number">1</span>.<span class="hljs-number">007616</span> ms     <span class="hljs-number">0</span>.<span class="hljs-number">133203</span> GB/s<br><span class="hljs-attribute">transposeSmem</span>   <span class="hljs-number">0</span>.<span class="hljs-number">343520</span> ms     <span class="hljs-number">0</span>.<span class="hljs-number">390713</span> GB/s<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">全局加载事务全局存储事务<br>copy<span class="hljs-constructor">Gmem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">4</span> <span class="hljs-number">4</span><br>naive<span class="hljs-constructor">Gmem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">4</span><span class="hljs-number">32</span><br>transpose<span class="hljs-constructor">Smem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">4</span> <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>上面提到了，这种方式虽然在共享内存中读取列的时候依然会发生存储体冲突，但这样的结果已经比直接对全局内存进行交叉写入要好的多。共享内存中的存储体冲突可以通过分析其共享内存事务数量来解释。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">   共享加载事务共享存储事务<br>transpose<span class="hljs-constructor">Smem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">8460165</span>  <span class="hljs-number">533345</span><br></code></pre></td></tr></table></figure><h3 id="使用填充共享内存的矩阵转置">使用填充共享内存的矩阵转置</h3><p>使用之前提到的<a href="#内存填充">内存填充</a>技术来优化上面的核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeSmemPad</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">int</span> rows, <span class="hljs-type">int</span> cols)</span></span><br><span class="hljs-function"></span>{<br>    __shared__ <span class="hljs-type">float</span> tile[BDIMY][BDIMX + PAD];<br><br>    <span class="hljs-comment">// 原始矩阵索引</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (row &lt; rows &amp;&amp; col &lt; cols)<br>        tile[threadIdx.y][threadIdx.x] = in[<span class="hljs-built_in">INDEX</span>(row, col, cols)];<br><br>    <span class="hljs-comment">// 转置block中的线程索引</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> bidx = threadIdx.y * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> irow = bidx / blockDim.y;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> icol = bidx % blockDim.y;<br><br>    row = blockIdx.x * blockDim.x + irow;<br>    col = blockIdx.y * blockDim.y + icol;<br><br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (row &lt; cols &amp;&amp; col &lt; rows)<br>        out[<span class="hljs-built_in">INDEX</span>(row, col, rows)] = tile[icol][irow];<br>}<br></code></pre></td></tr></table></figure><p>这里选择填充2个位置，这样可以完全消除共享内存的存储体冲突。可以通过分析其性能及共享内存事务来证明这一点。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Kernel</span>Elapsed timeEffective bandwidth<br><span class="hljs-attribute">copyGmem</span><span class="hljs-number">0</span>.<span class="hljs-number">292448</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">458946</span> GB/s<br><span class="hljs-attribute">naiveGmem</span><span class="hljs-number">0</span>.<span class="hljs-number">987136</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">135967</span> GB/s<br><span class="hljs-attribute">transposeSmem</span><span class="hljs-number">0</span>.<span class="hljs-number">404192</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">332064</span> GB/s<br><span class="hljs-attribute">transposeSmemPad</span><span class="hljs-number">0</span>.<span class="hljs-number">326272</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">411368</span> GB/s<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">   共享加载事务共享存储事务<br>transpose<span class="hljs-constructor">Smem(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">8460165</span>  <span class="hljs-number">533345</span><br>transpose<span class="hljs-constructor">SmemPad(<span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">float</span> <span class="hljs-operator">*</span>, <span class="hljs-params">int</span>, <span class="hljs-params">int</span>)</span> (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)x(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>) <span class="hljs-number">545540</span>  <span class="hljs-number">533686</span><br></code></pre></td></tr></table></figure><h3 id="使用展开的矩阵转置">使用展开的矩阵转置</h3><p>在上述使用了内存填充的核函数基础上，使用展开技术进行优化，使每个线程处理两个元素。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeSmemUnrollPad</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">int</span> rows, <span class="hljs-type">int</span> cols)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-comment">// 使用一维的共享内存</span><br>    __shared__ <span class="hljs-type">float</span> tile[BDIMY][BDIMX * <span class="hljs-number">2</span> + PAD];<br><br>    <span class="hljs-comment">// 原始矩阵索引</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> col = <span class="hljs-number">2</span> * blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (row &lt; rows &amp;&amp; col + blockDim.x &lt; cols)<br>    {<br>        tile[threadIdx.y][threadIdx.x] = in[<span class="hljs-built_in">INDEX</span>(row, col, cols)];<br>        tile[threadIdx.y][threadIdx.x + blockDim.x] = in[<span class="hljs-built_in">INDEX</span>(row, col + blockDim.x, cols)];<br>    }<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> bidx = threadIdx.y * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> irow = bidx / blockDim.y;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> icol = bidx % blockDim.y;<br><br>    row = <span class="hljs-number">2</span> * blockIdx.x * blockDim.x + irow;<br>    col = blockIdx.y * blockDim.y + icol;<br>    <br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (row + blockDim.x &lt; cols &amp;&amp; col &lt; rows)<br>    {<br>        out[<span class="hljs-built_in">INDEX</span>(row, col, rows)] = tile[icol][irow];<br>        out[<span class="hljs-built_in">INDEX</span>(row + blockDim.x, col, rows)] = tile[icol][irow + blockDim.x];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>进行性能对比后发现，相比使用内存填充的核函数，有略微的提升。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Kernel</span>Elapsed timeEffective bandwidth<br><span class="hljs-attribute">copyGmem</span><span class="hljs-number">0</span>.<span class="hljs-number">292864</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">458294</span> GB/s<br><span class="hljs-attribute">naiveGmem</span><span class="hljs-number">0</span>.<span class="hljs-number">987008</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">135984</span> GB/s<br><span class="hljs-attribute">transposeSmem</span><span class="hljs-number">0</span>.<span class="hljs-number">377856</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">355209</span> GB/s<br><span class="hljs-attribute">transposeSmemPad</span><span class="hljs-number">0</span>.<span class="hljs-number">326656</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">410884</span> GB/s<br><span class="hljs-attribute">transposeSmemUnrollPad</span><span class="hljs-number">0</span>.<span class="hljs-number">322560</span> ms<span class="hljs-number">0</span>.<span class="hljs-number">416102</span> GB/s<br></code></pre></td></tr></table></figure><p>使用展开技术使得更多的内存请求将同时处于运行状态，且会提高读写吞吐量。<code>ncu</code>分析设备内存的读写吞吐量可以佐证这一点。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs scss">    读吞吐量(GB/s)  写吞吐量(GB/s)<br><span class="hljs-built_in">naiveGmem</span>(float *, float *, int, int) (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">55.81</span><span class="hljs-number">52.64</span><br><span class="hljs-built_in">transposeSmem</span>(float *, float *, int, int) (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">193.00</span> <span class="hljs-number">177.18</span><br><span class="hljs-built_in">transposeSmemPad</span>(float *, float *, int, int) (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>) <span class="hljs-number">205.98</span>  <span class="hljs-number">178.52</span><br><span class="hljs-built_in">transposeSmemUnrollPad</span>(float *, float *, int, int) (<span class="hljs-number">64</span>, <span class="hljs-number">256</span>, <span class="hljs-number">1</span>)<span class="hljs-built_in">x</span>(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)<span class="hljs-number">206.65</span><span class="hljs-number">186.28</span><br></code></pre></td></tr></table></figure><h2 id="常量内存">常量内存</h2><p>常量内存对于核函数来说是只读的，但对于主机来说是可读可写的。常量内存位于设备的DRAM上（与全局内存一样），且有一个专用的片上缓存。与一级缓存和共享内存类似，从每个SM的常量缓存中读取的延迟，比直接从常量内存中读取的延迟低得多。每个SM常量缓存大小限制为64KB。</p><p>常量内存与之前提到的所有类型的内存有着不同的最优访问模式。在常量内存中，若线程束中的所有线程都访问相同的位置，则这个访问模式是最优的。若线程束中的线程访问不同地址，则访问需要串行。</p><p>在全局作用域中必须使用<code>__constant__</code>修饰符来声明常量变量。常量内存变量的生命周期与应用程序的生命周期相同，对所有线程都是可访问的，并且可以通过运行时函数对主机也可访问。</p><p>由于设备只能读取常量内存，所以常量内存中的值必须通过运行时函数<code>cudaMemcpyToSymbol()</code>来初始化。</p><h3 id="使用常量内存实现一维模板">使用常量内存实现一维模板</h3><p>在数值分析中，模板计算在点的集合上应用一个函数，并使用该函数的输出更新单一点的值。在一维中，位置<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>周围的的九点模板会给如下位置上的值应用一些函数。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="61.296ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 27092.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1294.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2294.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(2794.4,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(3370.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3815.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(4609.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(5609.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(6109.6,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(6685.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7130.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7924.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(8924.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(9424.7,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(10000.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(10445.3,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(11239.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(12239.8,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(12815.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(13260.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(13832.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(14277.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(15071.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(16071.6,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(16647.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(17092.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(17886.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(18886.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(19386.7,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(19962.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(20407.3,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(21201.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(22201.8,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(22701.8,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(23277.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(23722.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(24516.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(25516.9,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(26016.9,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(26592.9,0)"><path data-c="7D" d="M65 731Q65 745 68 747T88 750Q171 750 216 725T279 670Q288 649 289 635T291 501Q292 362 293 357Q306 312 345 291T417 269Q428 269 431 266T434 250T431 234T417 231Q380 231 345 210T298 157Q293 143 292 121T291 -28V-79Q291 -134 285 -156T256 -198Q202 -250 89 -250Q71 -250 68 -247T65 -230Q65 -224 65 -223T66 -218T69 -214T77 -213Q91 -213 108 -210T146 -200T183 -177T207 -139Q208 -134 209 3L210 139Q223 196 280 230Q315 247 330 250Q305 257 280 270Q225 304 212 352L210 362L209 498Q208 635 207 640Q195 680 154 696T77 713Q68 713 67 716T65 731Z"></path></g></g></g></svg></mjx-container></span> 我们不需要理解这个公式的实际意义，只需要观察到它会将上述的九个点作为输入，产生单一输出。下面使用一个实际公式作为示例。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="116.061ex" height="2.396ex" role="img" focusable="false" viewBox="0 -809 51298.9 1059"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(636,413) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(880.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1269.5,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1841.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2508.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3564,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(4433.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4822.6,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(5372.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5761.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6555.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(7556,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(8056,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(8632,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9243.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(10243.5,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(10793.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(11182.5,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(11976.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(12976.9,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(13476.9,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(14052.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(14441.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(15053.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(16053.3,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(16922.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(17311.9,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(17861.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(18250.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(19045.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(20045.3,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(20545.3,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(21121.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(21732.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(22732.8,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(23282.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(23671.8,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(24466,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(25466.2,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(25966.2,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(26542.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(26931.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(27542.5,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(28542.7,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(29412.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(29801.2,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(30351.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(30740.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(31534.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(32534.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(33034.7,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(33610.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(34221.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(35222.1,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(35772.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(36161.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(36955.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(37955.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(38455.6,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(39031.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(39420.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(40031.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(41032,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g><g data-mml-node="mo" transform="translate(41901.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(42290.6,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(42840.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(43229.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(44023.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(45024,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(45600,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(46211.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(47211.4,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(47761.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(48150.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(48944.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(49944.9,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(50520.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(50909.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 可以比较容易的观察到，公式中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="10.887ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 4812.2 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(869.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1314.2,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(2183.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(2628.4,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(3498,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3942.7,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,-150) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></g></svg></mjx-container></span>这些系数是不变的，所以很适合存入常量内存中。且线程束中的所有线程都是访问这几个常量，这恰好满足常量内存的最优访问模式。</p><p>计算过程如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/64aa9167-0992-4040-bd66-786758dbcd9b"></p><p>借助共享内存来缓存数据，同时在其两侧添加一些光环数据，类似于卷积中的填充操作，是为了计算的合法性。通过如下核函数来实现整个计算过程。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">stancli1DGPU</span><span class="hljs-params">(<span class="hljs-type">float</span>* in, <span class="hljs-type">float</span>* out, <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-comment">// 包含光环的共享内存</span><br>    __shared__ <span class="hljs-type">float</span> smem[BDIM + <span class="hljs-number">2</span> * RADIUS];<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x + RADIUS;<br><br>    <span class="hljs-keyword">while</span> (idx &lt; size + RADIUS)<br>    {<br>        <span class="hljs-comment">// 共享内存的索引，为模板计算作准备</span><br>        <span class="hljs-type">int</span> sidx = threadIdx.x + RADIUS;<br><br>        <span class="hljs-comment">// 将数据部分写入共享内存</span><br>        smem[sidx] = in[idx];<br><br>        <span class="hljs-comment">// 将光环部分度写入共享内存</span><br>        <span class="hljs-keyword">if</span> (threadIdx.x &lt; RADIUS)<br>        {<br>            smem[sidx - RADIUS] = in[idx - RADIUS];<br>            smem[sidx + BDIM]   = in[idx + BDIM];<br>        }<br><br>        __syncthreads();<br><br>        <span class="hljs-type">float</span> tmp = <span class="hljs-number">0.0f</span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= RADIUS; i++)<br>        {<br>            tmp += coef[i] * (smem[sidx + i] - smem[sidx - i]);<br>        }<br><br>        out[idx] = tmp;<br><br>        idx += gridDim.x * blockDim.x;<br>    }<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/05_constant_stencli.cu">constant_stencli.cu</a>。</p></blockquote><h3 id="与只读缓存比较">与只读缓存比较</h3><p>只读缓存实质上是GPU的纹理流水线，用于存储全局内存中的数据。只读缓存是独立的，它拥有从标准全局内存读取的独立内存带宽，所以使用只读缓存可以为受制于内存带宽的核函数提供一些性能优势。</p><p>只读缓存不同于常量内存，其最优访问模式是线程束中的线程访问不同的位置。只读缓存的粒度为32字节。</p><p>当通过只读缓存访问全局内存时，需要在核函数中向编译器指出数据是只读的，可以通过如下两种方式：</p><ul><li>内部函数<code>__ldg()</code>；</li><li>全局内存的限定指针；</li></ul><p>内部函数<code>__ldg()</code>用于代替标准指针解引用，并强制加载通过只读数据缓存。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">float</span>* input)</span> </span>{<br>    ...<br>    output[idx] += __ldg(&amp;input[idx]);<br>    ...<br>}<br></code></pre></td></tr></table></figure><p>也可以限定指针为<code>const __restrict__</code>，以表明它应该通过只读缓存被访问。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">const</span> <span class="hljs-type">float</span>* __restrict__ input)</span> </span>{<br>...<br>    output[idx] += input[idx];<br>    ...<br>}<br></code></pre></td></tr></table></figure><p>在只读缓存需要很多显式控制，或代码非常复杂以至于编译器无法检测到只读缓存的使用是否安全的情况下，内部函数<code>__ldg()</code>是更好的选择。</p><p>通过只读缓存加载的数据可以比较大，且能够在一个非统一的模式下进行访问。利用只读缓存来实现上述模板算法的核函数，唯一的区别就是函数声明。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">stancliReadOnly</span><span class="hljs-params">(<span class="hljs-type">float</span>* in, <span class="hljs-type">float</span>* out, <span class="hljs-type">int</span> size, <span class="hljs-type">const</span> <span class="hljs-type">float</span>* __restrict__ dcoef)</span></span><br><span class="hljs-function"></span>{<br>    ...<br>}<br></code></pre></td></tr></table></figure><p>但要注意的是，不同于常量内存，在核函数调用之前，必须提前分配只读缓存的设备内存。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">const</span> <span class="hljs-type">float</span> h_coef[] = {a0, a1, a2, a3, a4};<br><br><span class="hljs-comment">// 使用常量内存只需要调用如下运行时API，无需申请设备内存</span><br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMemcpyToSymbol</span>(coef, h_coef, (RADIUS + <span class="hljs-number">1</span>) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br><br><span class="hljs-comment">// 使用只读缓存时需要提前申请设备内存</span><br><span class="hljs-type">float</span>* d_coef;<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_coef, (RADIUS + <span class="hljs-number">1</span>) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br><span class="hljs-built_in">ERROR_CHECK</span>(<span class="hljs-built_in">cudaMemcpy</span>(d_coef, h_coef, (RADIUS + <span class="hljs-number">1</span>) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice));<br></code></pre></td></tr></table></figure><p>使用<code>nsys</code>统计两个核函数的耗时可以观察到，对于以广播模式访问的数据来说，常量内存是更适合的。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-type">Time</span> (%)  Total <span class="hljs-type">Time</span> (ns)                         <span class="hljs-type">Name</span>                         <br><span class="hljs-comment">--------  ---------------  -----------------------------------------------------</span><br>    <span class="hljs-number">50.2</span>          <span class="hljs-number">408</span>,<span class="hljs-number">376</span>  stancliReadOnly(<span class="hljs-type">float</span> *, <span class="hljs-type">float</span> *, <span class="hljs-type">int</span>, const <span class="hljs-type">float</span> *)<br>    <span class="hljs-number">49.8</span>          <span class="hljs-number">405</span>,<span class="hljs-number">463</span>  stancliConstant(<span class="hljs-type">float</span> *, <span class="hljs-type">float</span> *, <span class="hljs-type">int</span>)<br></code></pre></td></tr></table></figure><h2 id="线程束洗牌指令">线程束洗牌指令</h2><p>从计算能力3.0开始加入了一种机制称为洗牌指令（shuffle instruction），只要两个线程在相同的线程束中，就允许这两个线程直接读取另一个线程的寄存器。这种直接的数据交换不是通过共享内存或全局内存来进行的，拥有比共享内存更低的延迟，且在执行数据交换时不消耗额外的内存。</p><p>这里引入一个概念——束内线程（lane），线程束中的每一个线程都是束内线程，每个束内线程都有一个唯一的束内线程索引。在一维线程块中，对于一个给定线程的束内线程索引和线程束索引可以通过如下方式计算。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp">laneID = threadIdx.x % <span class="hljs-number">32</span>;<br>warpID = threadIdx.x / <span class="hljs-number">32</span>;<br></code></pre></td></tr></table></figure><p>对于多维的线程块，可以将多维线程坐标转换为一维线程索引，再应用上述公式来计算。</p><h3 id="线程束洗牌指令的不同形式">线程束洗牌指令的不同形式</h3><p>洗牌指令共有两组，一组用于整型变量，另一组用于浮点型变量。每组有4种形式的洗牌指令：</p><ul><li>广播传递；</li><li>向上传递；</li><li>向下传递；</li><li>异或传递。</li></ul><h4 id="广播传递">广播传递</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">int</span> __shfl(<span class="hljs-type">int</span> var, <span class="hljs-type">int</span> srcLane, <span class="hljs-type">int</span> width=warpSize);<br></code></pre></td></tr></table></figure><p>其中<code>var</code>是待传递的变量，<code>srcLane</code>是提高该变量的线程的束内线程索引。最后一个参数<code>width</code>允许将线程束进一步划分为段，每段包含<code>width</code>个线程，取值范围是<code>[2, 32]</code>，每个段上会执行独立的洗牌操作。对于非32的其他<code>width</code>值，线程的束内线程索引可以通过<code>threadIdx.x % width</code>来确定。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/4de2e52e-0207-4644-86a2-392b55b5c9f6"></p><p>上图展示了<code>__shfl(val, 2)</code>的调用示例。</p><h4 id="向上传递和向下传递">向上传递和向下传递</h4><p>向上传递和向下传递非常类似，两者的区别仅是传递方向不同。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">int</span> __shfl_up(<span class="hljs-type">int</span> var, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> delta, <span class="hljs-type">int</span> width=warpSize);<br><span class="hljs-type">int</span> __shfl_down(<span class="hljs-type">int</span> var, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> delta, <span class="hljs-type">int</span> width=warpSize);<br></code></pre></td></tr></table></figure><p><code>delta</code>参数用来计算提供变量的束内线程索引：</p><ul><li>向上传递时，当前束内线程接受来自于束内线程索引为<code>当前束内线程索引 - delta</code>线程中的变量<code>var</code>；</li><li>向下传递时，当前束内线程接受来自于束内线程索引为<code>当前束内线程索引 + delta</code>线程中的变量<code>var</code>；</li></ul><p>若向上或向下传递过程中没有对应的源束内线程，则线程中的变量保持不变。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/24efc65e-2556-49a2-881c-abbe3baea285"></p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/2dc7ebab-592a-423e-9a10-518c46fb3c4f"></p><h4 id="异或传递">异或传递</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">int</span> __shfl_xor(<span class="hljs-type">int</span> var, <span class="hljs-type">int</span> laneMask, <span class="hljs-type">int</span> width=warpSize);<br></code></pre></td></tr></table></figure><p>异或传递较为特殊，它根据自身的束内线程索引与<code>laneMask</code>按位异或来确定源束内线程。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/1ba1eb0e-524c-4cc1-b96b-e49d5b763f9c"></p><p>上图展示了蝴蝶寻址模式的示例。</p><p>上面提到的4种洗牌指令均有单精度浮点数版本。</p><blockquote><p><strong>注意：在6.0以后的PTX ISA中，已经不再支持这一系列的洗牌指令，新版本改为了带有<code>sync</code>的洗牌指令。</strong></p><p>上述的几个函数整体变化不大，只是在参数列表的最前面添加了一个参数<code>mask</code>：</p><ul><li><code>int __shfl_sync(unsigned mask, int var, int srcLane, int width=warpSize);</code></li><li><code>int __shfl_up_sync(unsigned mask, int var, int srcLane, int width=warpSize);</code></li><li><code>int __shfl_down_sync(unsigned mask, int var, int srcLane, int width=warpSize);</code></li><li><code>int __shfl_xor_sync(unsigned mask, int var, int srcLane, int width=warpSize);</code></li></ul><p>当然也有对应的单精度浮点数版本，并且拥有64位的版本，即<code>long</code>与<code>double</code>类型的接口。</p><p>该<code>mask</code>参数用于指定参与洗牌指令的束内线程，每个<code>bit</code>代表一个束内线程。<code>mask</code>给予编译器一个提示，为了保证正确性，所指向的束内线程必须全部参与洗牌指令，这样编译器就会生成一些必要的指令将这些线程重新汇聚起来。</p><p>简单来说，若使用默认的线程束大小，想要使所有束内线程都参与洗牌指令，则<code>mask</code>指定为<code>0xffffffff</code>即可。</p><p>对于<code>mask</code>参数，英伟达官方论坛有一个<a href="https://forums.developer.nvidia.com/t/what-does-mask-mean-in-warp-shuffle-functions-shfl-sync/67697">帖子</a>对此进行了描述。</p><p>以及<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/06_shuffle_instruction.cu">shuffle_instruction.cu</a>和<a href="https://github.com/Deleter-D/CUDA/blob/master/04_shared_and_constant_memory/07_reduce_with_shuffle.cu">reduce_with_shuffle.cu</a>有一系列详细的示例。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——全局内存</title>
    <link href="https://deleter-d.github.io/posts/47184/"/>
    <id>https://deleter-d.github.io/posts/47184/</id>
    <published>2024-02-20T08:09:37.000Z</published>
    <updated>2024-03-24T08:32:32.621Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="cuda内存模型概述">CUDA内存模型概述</h2><h3 id="cuda内存模型">CUDA内存模型</h3><p>对于开发者来说，存储器分为两大类：</p><ul><li>可编程的：需要显式控制哪些数据存放在可编程内存中；</li><li>不可编程的：不能决定数据的存放位置，由程序自动生成存放位置。</li></ul><p>CUDA内存模型提出了多种可编程内存：</p><ul><li>寄存器；</li><li>共享内存；</li><li>本地内存；</li><li>常量内存；</li><li>纹理内存；</li><li>全局内存。</li></ul><p>这些内存空间的层次结构如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/f3635cc5-2ef0-43a1-bd3d-23f7cb7d0601"></p><h4 id="寄存器">寄存器</h4><p>寄存器是GPU上速度最快的内存空间，在核函数中声明一个没有其他修饰符的变量，通常存储在寄存器中。在核函数中声明的数组，若用于引用该数组的索引是常量且能在编译时确定，则该数组也存储在寄存器中。</p><p>寄存器是线程私有的，寄存器变量与核函数生命周期相同。若核函数使用的寄存器超过了硬件限制，则会用本地内存替代多占用的寄存器。nvcc编译器使用启发式策略来最小化寄存器使用，以免寄存器溢出。也可以手动显式添加额外信息来辅助编译器优化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__global__ <span class="hljs-type">void</span> __launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor) <span class="hljs-built_in">kernel</span>(...) {}<br></code></pre></td></tr></table></figure><p><code>maxThreadsPerBlock</code>指出每个线程块可以包含的最大线程数，<code>minBlocksPerMultiprocessor</code>是可选参数，指出在每个SM中预期的最小常驻线程块数量。</p><p>还可以使用编译器选项<code>maxrregcount</code>来控制一个编译单元中所有核函数使用的寄存器的最大数量，例如<code>-maxrregcount=32</code>。</p><h4 id="本地内存">本地内存</h4><p>核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有：</p><ul><li>在编译时使用未知索引引用的本地数组；</li><li>可能会占用大量寄存器空间的较大本地结构体或数组；</li><li>任何不满足核函数寄存器限定条件的变量。</li></ul><p>溢出到本地内存中的变量本质上与全局内存在同一存储区域，因此本地内存的访问特点是高延迟和低带宽。</p><h4 id="共享内存">共享内存</h4><p>在核函数中使用<code>__shared__</code>修饰符修饰的变量存放在共享内存中。</p><p>由于共享内存是片上内存，所以与本地内存和全局内存相比，具有更高的带宽和更低的延迟，是可编程的。每个SM都有一定数量的由线程块分配的共享内存，因此不能过度使用共享内存，避免在不经意间限制活跃线程束的数量。共享内存在核函数内声明，生命周期伴随整个线程块。</p><p>共享内存是线程之间通信的基本方式，访问共享内存必须使用<code>__syncthreads()</code>来进行同步。该函数设置了一个执行障碍点，使得同一线程块中的所有线程必须在其他线程开始执行前到达该处。</p><p>SM中的一级缓存和共享内存都使用64KB的片上内存，它通过静态划分，但在运行时可以使用<code>cudaFuncSetCacheConfig()</code>来进行动态配置。该API传入两个参数，第一个是函数指针，第二个是CUDA提供的一个枚举类<code>cudaFuncCache</code>成员，它包含4个成员：</p><ul><li><code>cudaFuncCachePreferNone</code>：没有参考值（默认）；</li><li><code>cudaFuncCachePreferShared</code>：建议48KB共享内存和16KB一级缓存；</li><li><code>cudaFuncCachePreferL1</code>：建议48KB一级缓存和16KB共享内存；</li><li><code>cudaFuncCachePreferEqual</code>：建议相同尺寸的一级缓存和共享内存，均为32KB。</li></ul><blockquote><p>这里的<code>cudaFuncSetCacheConfig()</code>API已经是比较旧的方式了，在计算能力7.x及以上的设备中，更推荐使用<code>cudaFuncSetAttribute()</code>来配置。该API传入三个参数，第一个参数是函数指针，第二个是CUDA提供的一个枚举类<code>cudaFuncAttribute</code>成员，第三个是具体的提示值。</p><p><code>cudaFuncAttribute</code>有9个成员，但常用的只有两个（其它成员是关于线程块集群的，这里不多描述）：</p><ul><li><code>cudaFuncAttributeMaxDynamicSharedMemorySize</code>：指定最大动态共享内存大小；</li><li><code>cudaFuncAttributePreferredSharedMemoryCarveout</code>：首选的共享内存和一级缓存拆分大小；</li></ul><p>通过第三个参数来指定第二个参数成员的具体值，例如下面的语句提示编译器将片上内存的50%分配给共享内存。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaFuncSetAttribute</span>(MyKernel, cudaFuncAttributePreferredSharedMemoryCarveout, <span class="hljs-number">50</span>);<br></code></pre></td></tr></table></figure><p><code>cudaFuncSetAttribute()</code>放松了对指定共享内存容量的强制，分割被视为一种提示。而旧的<code>cudaFuncSetCacheConfig()</code>将共享内存容量视为核函数启动的硬性要求。因此，使用不同共享内存配置的核函数将进行一些不必要地序列化。</p></blockquote><h4 id="常量内存">常量内存</h4><p>常量内存驻留在设备内存中，并在每个SM专用的常量缓存中缓存，使用<code>__constant__</code>来修饰。</p><p>常量变量必须在全局空间内和所有核函数之外进行声明，所有计算能力的设备都只能声明64KB的常量内存。常量内存是静态声明的，并对同一编译单元中的所有核函数可见。</p><p>核函数只能从常量内存中读取数据，因此常量内存必须在主机端使用<code>cudaMemcpyToSymbol()</code>来初始化，大多数情况下这个函数是同步的。</p><p>线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。</p><h4 id="纹理内存">纹理内存</h4><p>纹理内存驻留在设备内存中，并在每个SM的只读缓存中缓存。纹理内存是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对二维空间局部性的优化，所以线程束中使用纹理内存访问二维数据的线程可以达到最优性能。</p><h4 id="全局内存">全局内存</h4><p>全局内存是GPU中最大、延迟最高且最常使用的内存。它的声明可以在任何SM设备上被访问到，并贯穿程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明，可以使用<code>__device__</code>在设备代码中静态声明一个变量。</p><p>从多个线程访问全局内存时要注意，由于线程的执行不能跨线程块同步，不同线程块内的多个线程并发修改全局内存的同一位置可能会导致未定义的行为。</p><p>全局内存常驻于设备内存中，可通过32字节、64字节或128字节的内存事务进行访问。这些内存事务必须自然对齐，也就是说首地址必须是32字节、64字节或128字节的倍数。当一个线程束执行内存加载 / 存储时，需要满足的传输数量取决于两个因素：</p><ul><li>跨线程的内存地址分布；</li><li>每个事务内存地址的对齐方式。</li></ul><p>一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就导致了数据吞吐率的降低。</p><h4 id="gpu缓存">GPU缓存</h4><p>GPU缓存是不可编程的内存，有四种类型的缓存：</p><ul><li>一级缓存；</li><li>二级缓存；</li><li>只读常量缓存；</li><li>只读纹理缓存。</li></ul><p>每个SM都有一个一级缓存，所有的SM共享一个二级缓存。一级和二级缓存用于存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。GPU上只有内存加载操作可以被缓存，内存存储操作不能被缓存。每个SM有一个只读常量缓存和只读纹理缓存，用于在设备内存只提高来自于各自内存空间中的读取性能。</p><h4 id="cuda变量声明小结">CUDA变量声明小结</h4><p>CUDA变量和类型修饰符总结如下表。</p><table><thead><tr class="header"><th>修饰符</th><th>变量类型</th><th>存储器</th><th>作用域</th><th>生命周期</th></tr></thead><tbody><tr class="odd"><td></td><td>标量</td><td>寄存器</td><td>线程</td><td>线程</td></tr><tr class="even"><td></td><td>数组</td><td>本地内存</td><td>线程</td><td>线程</td></tr><tr class="odd"><td><code>__shared__</code></td><td>标量 / 数组</td><td>共享内存</td><td>线程块</td><td>线程块</td></tr><tr class="even"><td><code>__device__</code></td><td>标量 / 数组</td><td>全局内存</td><td>全局</td><td>应用程序</td></tr><tr class="odd"><td><code>__constant__</code></td><td>标量 / 数组</td><td>常量内存</td><td>全局</td><td>应用程序</td></tr></tbody></table><p>设备存储器的特征总结如下表。</p><table><thead><tr class="header"><th>存储器</th><th>位置</th><th>缓存</th><th>存取</th><th>范围</th><th>生命周期</th></tr></thead><tbody><tr class="odd"><td>寄存器</td><td>片上</td><td>n/a</td><td>R/W</td><td>一个线程</td><td>线程</td></tr><tr class="even"><td>本地内存</td><td>片外</td><td>Yes (2.x以上)</td><td>R/W</td><td>一个线程</td><td>线程</td></tr><tr class="odd"><td>共享内存</td><td>片上</td><td>n/a</td><td>R/W</td><td>块内所有线程</td><td>线程块</td></tr><tr class="even"><td>全局内存</td><td>片外</td><td>Yes (2.x以上)</td><td>R/W</td><td>所有线程+主机</td><td>主机配置</td></tr><tr class="odd"><td>常量内存</td><td>片外</td><td>Yes</td><td>R</td><td>所有线程+主机</td><td>主机配置</td></tr><tr class="even"><td>纹理内存</td><td>片外</td><td>Yes</td><td>R</td><td>所有线程+主机</td><td>主机配置</td></tr></tbody></table><h4 id="静态全局内存">静态全局内存</h4><p>实现一段静态声明全局内存变量的代码，在主机端传入值，在核函数中对值进行修改，再传回主机端，核心代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__device__ <span class="hljs-type">float</span> devData;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">checkGlobalVariable</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    devData += <span class="hljs-number">2.0f</span>;<br>}<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> <span class="hljs-type">const</span> *argv[])</span></span><br><span class="hljs-function"></span>{<br>...<br>    <span class="hljs-type">float</span> value = <span class="hljs-number">3.14f</span>;<br>    <span class="hljs-built_in">cudaMemcpyToSymbol</span>(devData, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    checkGlobalVariable&lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>&gt;&gt;&gt;();<br>    <span class="hljs-built_in">cudaMemcpyFromSymbol</span>(&amp;value, devData, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>...<br>}<br></code></pre></td></tr></table></figure><p>值的注意的是，尽管设备的全局变量声明与主机代码在同一文件中，主机代码也不能直接访问设备变量。类似地，设备代码也不能直接访问主机变量。</p><p>唯一比较像是主机代码访问设备变量的地方是<code>(devData, &amp;value, sizeof(float))</code>，但该接口是在CUDA运行时API中的，内部可以隐式的使用GPU来访问。而且在这里<code>devData</code>作为一个标识符，并不是全局内存变量的地址。在核函数中，<code>devData</code>被当作全局内存中的一个变量。</p><p><code>cudaMemcpy()</code>并不能直接以下面语句中的变量地址传递数据给<code>devData</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaMemcpy</span>(&amp;devData, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br></code></pre></td></tr></table></figure><p>我们无法在主机端的设备变量中使用<code>&amp;</code>运算符，因为它只是一个在GPU上表示物理位置的符号。但可以通过下面的语句显式获取一个全局变量的地址。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">float</span> *dptr;<br><span class="hljs-built_in">cudaGetSymbolAddress</span>((<span class="hljs-type">void</span> **)&amp;dptr, devData);<br></code></pre></td></tr></table></figure><p>然后就可以使用<code>cudaMemcpy()</code>来进行拷贝操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">cudaMemcpy</span>(dptr, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice)<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/01_global_variable.cu">global_variable.cu</a>，其中展示了<code>cudaMemcpyToSymbol()</code>和<code>cudaMemcpy()</code>两种操作方式。</p></blockquote><p>有一种例外可以直接从主机引用GPU内存：CUDA固定内存。将会在后续进行介绍。</p><h2 id="内存管理">内存管理</h2><h3 id="设备内存">设备内存</h3><p>设备内存可以作为线性内存分配，也可以作为CUDA 数组来分配。CUDA数组是为了纹理获取而优化过的不透明内存布局。</p><p>线性内存是由一个统一的地址空间分配的，分开分配的实体可以通过指针相互引用。地址空间的大小取决于主机系统（CPU）和所用GPU的计算能力。</p><table><thead><tr class="header"><th>计算能力</th><th>x86_64 (AMD64)</th><th>POWER (ppc64le)</th><th>ARM64</th></tr></thead><tbody><tr class="odd"><td>5.3及之前</td><td>40bit</td><td>40bit</td><td>40bit</td></tr><tr class="even"><td>6.0及以后</td><td>47bit</td><td>49bit</td><td>48bit</td></tr></tbody></table><p>线性内存使用<code>cudaMalloc()</code>分配，使用<code>cudaFree()</code>释放，主机内存与设备内存之间的数据搬移通过<code>cudaMemcpy()</code>完成。</p><p>下面以向量加法为例。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">VecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> N)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span> (i &lt; N)<br>        C[i] = A[i] + B[i];<br>}<br><br><span class="hljs-comment">// 主机代码</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> N = ...;<br>    <span class="hljs-type">size_t</span> size = N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-comment">// 在主机端申请输入向量h_A和h_B及结果向量h_C的内存</span><br>    <span class="hljs-type">float</span>* h_A = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-type">float</span>* h_B = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-type">float</span>* h_C = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-comment">// 初始化输入向量</span><br>    ...<br>    <span class="hljs-comment">// 在设备端申请向量内存</span><br>    <span class="hljs-type">float</span>* d_A; <span class="hljs-built_in">cudaMalloc</span>(&amp;d_A, size);<br>    <span class="hljs-type">float</span>* d_B; <span class="hljs-built_in">cudaMalloc</span>(&amp;d_B, size);<br>    <span class="hljs-type">float</span>* d_C; <span class="hljs-built_in">cudaMalloc</span>(&amp;d_C, size);<br>    <span class="hljs-comment">// 从主机端拷贝数据到设备端</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-comment">// 核函数调用</span><br>    <span class="hljs-type">int</span> threadsPerBlock = <span class="hljs-number">256</span>;<br>    <span class="hljs-type">int</span> blocksPerGrid = (N + threadsPerBlock - <span class="hljs-number">1</span>) / threadsPerBlock;<br>    VecAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);<br>    <span class="hljs-comment">// 从设备端拷贝数据到主机端</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);<br>    <span class="hljs-comment">// 释放设备内存</span><br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br>    <span class="hljs-comment">// 释放主机内存</span><br>    ...<br>}<br></code></pre></td></tr></table></figure><blockquote><p>上例详细代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/00_CUDA_official_documentation/02_example_vec_add.cu">example_vec_add.cu</a>，代码中的注释是关于GPU算子开发的基本思路。</p></blockquote><p>也可以通过<code>cudaMallocPitch()</code>和<code>cudaMalloc3D()</code>来分配线性内存。推荐用于2D或3D数组的分配，这样可以确保分配被适当填充，以满足内存对齐要求。同时可以保证在访问行地址或者执行2D数组与其他设备内存区域的拷贝操作时的性能（2D或3D内存拷贝使用<code>cudaMemcpy2D()</code>与<code>cudaMemcpy3D()</code>）。</p><p>必须使用返回的pitch（或stride）来访问数组元素，下面以分配一个<code>width * height</code>的二维浮点型数组为例。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 主机代码</span><br><span class="hljs-type">int</span> width = <span class="hljs-number">64</span>, height = <span class="hljs-number">64</span>;<br><span class="hljs-type">float</span>* devPtr;<br><span class="hljs-type">size_t</span> pitch;<br><span class="hljs-built_in">cudaMallocPitch</span>(&amp;devPtr, &amp;pitch, width * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height);<br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;(devPtr, pitch, width, height);<br><br><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MyKernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* devPtr, <span class="hljs-type">size_t</span> pitch, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> r = <span class="hljs-number">0</span>; r &lt; height; ++r) {<br>        <span class="hljs-type">float</span>* row = (<span class="hljs-type">float</span>*)((<span class="hljs-type">char</span>*)devPtr + r * pitch);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> c = <span class="hljs-number">0</span>; c &lt; width; ++c) {<br>            <span class="hljs-type">float</span> element = row[c];<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure><p>下面以分配<code>width * height * depth</code>的三维浮点型数组为例。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 主机代码</span><br><span class="hljs-type">int</span> width = <span class="hljs-number">64</span>, height = <span class="hljs-number">64</span>, depth = <span class="hljs-number">64</span>;<br>cudaExtent extent = <span class="hljs-built_in">make_cudaExtent</span>(width * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height, depth);<br>cudaPitchedPtr devPitchedPtr;<br><span class="hljs-built_in">cudaMalloc3D</span>(&amp;devPitchedPtr, extent);<br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;(devPitchedPtr, width, height, depth);<br><br><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MyKernel</span><span class="hljs-params">(cudaPitchedPtr devPitchedPtr, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height, <span class="hljs-type">int</span> depth)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">char</span>* devPtr = devPitchedPtr.ptr;<br>    <span class="hljs-type">size_t</span> pitch = devPitchedPtr.pitch;<br>    <span class="hljs-type">size_t</span> slicePitch = pitch * height;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> z = <span class="hljs-number">0</span>; z &lt; depth; ++z) {<br>        <span class="hljs-type">char</span>* slice = devPtr + z * slicePitch;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> y = <span class="hljs-number">0</span>; y &lt; height; ++y) {<br>            <span class="hljs-type">float</span>* row = (<span class="hljs-type">float</span>*)(slice + y * pitch);<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> x = <span class="hljs-number">0</span>; x &lt; width; ++x) {<br>                <span class="hljs-type">float</span> element = row[x];<br>            }<br>        }<br>    }<br>}<br></code></pre></td></tr></table></figure><p>下面是通过运行时API访问全局变量的各种方式的例子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++">__constant__ <span class="hljs-type">float</span> constData[<span class="hljs-number">256</span>];<br><span class="hljs-type">float</span> data[<span class="hljs-number">256</span>];<br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(constData, data, <span class="hljs-built_in">sizeof</span>(data));<br><span class="hljs-built_in">cudaMemcpyFromSymbol</span>(data, constData, <span class="hljs-built_in">sizeof</span>(data));<br><br>__device__ <span class="hljs-type">float</span> devData;<br><span class="hljs-type">float</span> value = <span class="hljs-number">3.14f</span>;<br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(devData, &amp;value, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><br>__device__ <span class="hljs-type">float</span>* devPointer;<br><span class="hljs-type">float</span>* ptr;<br><span class="hljs-built_in">cudaMalloc</span>(&amp;ptr, <span class="hljs-number">256</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(devPointer, &amp;ptr, <span class="hljs-built_in">sizeof</span>(ptr));<br></code></pre></td></tr></table></figure><p><code>cudaGetSymbolAddress()</code>可以获取声明在全局内存空间中的已分配内存的变量地址，通过<code>cudaGetSymbolSize()</code>来获取分配内存的大小。</p><h3 id="内存传输">内存传输</h3><p>内存传输使用<code>cudaMemcpy()</code>函数，其最后一个参数用来指定数据拷贝方向，有四个取值：</p><ul><li><code>cudaMemcpyHostToHost</code>；</li><li><code>cudaMemcpyHostToDevice</code>；</li><li><code>cudaMemcpyDeviceToHost</code>；</li><li><code>cudaMemcpyDeviceToDevice</code>。</li></ul><p>如果目的地址和源地址与最后一个参数指定的方向不一致，则<code>cudaMemcpy()</code>的行为是未定义的。大多数情况下该函数是同步的。</p><h3 id="锁页主机内存固定主机内存">锁页主机内存（固定主机内存）</h3><p>CUDA运行时提供了一些函数，来允许使用锁页主机内存（Page-Locked Host Memory）,也称为固定主机内存（Pinned Host Memory），与<code>malloc()</code>分配的可分页主机内存相对。</p><ul><li><code>cudaHostAlloc()</code>和<code>cudaFreeHost()</code>分配并释放锁页主机内存；</li><li><code>cudaHostRegister()</code>将<code>malloc()</code>分配的内存中某范围内的页面锁定。</li></ul><p>使用锁页主机内存的优势：</p><ul><li>锁页主机内存与设备内存之间的数据搬移可以与<a href="https://deleter-d.github.io/posts/4919/#异步并发执行">异步并发执行</a>中提到的某些设备的核函数并发执行；</li><li>在某些设备上，锁页主机内存可以映射到设备的地址空间中，无需在主机和设备之间搬移数据，<a href="#映射内存（零拷贝内存）">映射内存</a>中有详细说明；</li><li>在具有前端总线（Front-side Bus, FSB）的系统上，若主机内存被分配为锁页内存，则主机内存和设备内存之间的带宽会变高；若主机内存还被分配为写组合内存，则带宽会更大，详见<a href="#写组合内存">写组合内存</a>。</li></ul><blockquote><p>分配的主机内存默认是可分页的（pageable），但GPU不能在可分页主机内存上安全地访问数据。因为当主机的操作系统在物理位置上移动这些数据的时候，GPU时无法控制的。</p><p>当从可分页主机内存传输数据到设备时，CUDA驱动程序首先分配临时的锁页内存，将主机源数据拷贝到锁页内存中后，再将锁页内存中的数据拷贝到设备中。</p><p>我们对比在相同数据量下，可分页内存与设备内存之间的拷贝性能与锁页内存与设备内存之间的拷贝性能，详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/02_pageable_memory.cu">pageable_memory.cu</a>与<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/03_page_locked_memory.cu">page_locked_memory.cu</a>。使用<code>nsys</code>中的<code>nvprof</code>来分析内存拷贝操作的耗时。</p><p>可分页内存与设备内存之间的拷贝耗时如下。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dns">Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)      Operation     <br>--------  ---------------  -----  -----------  -----------  ---------  ---------  -----------  ------------------<br>  <span class="hljs-number">50</span>.<span class="hljs-number">0</span>        <span class="hljs-number">1,144,966</span>      <span class="hljs-number">1</span>  <span class="hljs-number">1,144,966</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,144,966</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,144,966</span>  <span class="hljs-number">1,144,966</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy HtoD]<br>  <span class="hljs-number">50</span>.<span class="hljs-number">0</span>        <span class="hljs-number">1,142,693</span>      <span class="hljs-number">1</span>  <span class="hljs-number">1,142,693</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,142,693</span>.<span class="hljs-number">0</span>  <span class="hljs-number">1,142,693</span>  <span class="hljs-number">1,142,693</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy DtoH]<br></code></pre></td></tr></table></figure><p>锁页内存与设备内存之间的拷贝耗时如下。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dns">Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)      Operation     <br>--------  ---------------  -----  ---------  ---------  --------  --------  -----------  ------------------<br>  <span class="hljs-number">51</span>.<span class="hljs-number">9</span>          <span class="hljs-number">686,915</span>      <span class="hljs-number">1</span>  <span class="hljs-number">686,915</span>.<span class="hljs-number">0</span>  <span class="hljs-number">686,915</span>.<span class="hljs-number">0</span>   <span class="hljs-number">686,915</span>   <span class="hljs-number">686,915</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy HtoD]<br>  <span class="hljs-number">48</span>.<span class="hljs-number">1</span>          <span class="hljs-number">637,475</span>      <span class="hljs-number">1</span>  <span class="hljs-number">637,475</span>.<span class="hljs-number">0</span>  <span class="hljs-number">637,475</span>.<span class="hljs-number">0</span>   <span class="hljs-number">637,475</span>   <span class="hljs-number">637,475</span>          <span class="hljs-number">0</span>.<span class="hljs-number">0</span>  [CUDA memcpy DtoH]<br></code></pre></td></tr></table></figure><p>可以观察到，锁页内存与设备内存之间的拷贝耗时要大幅度小于可分页内存与设备内存之间的拷贝操作。</p></blockquote><h4 id="可移植内存">可移植内存</h4><p>锁页内存可以与系统中的任何设备结合使用，但默认情况下，上述提到的锁页内存的优势只有分配这片锁页内存的设备可以享受到（如有与该设备共享统一地址空间（详见<a href="#统一虚拟地址空间">统一虚拟地址空间</a>）的设备，则这些设备也能享受这些优势）。</p><p>可以通过将<code>cudaHostAllocPortable</code>标志传给<code>cudaHostAlloc()</code>来分配锁页内存，或将<code>cudaHostRegisterPortable</code>标志传给<code>cudaHostRegister()</code>来锁定页面，使得所有设备都能够享受上面提到的优势。</p><h4 id="写组合内存">写组合内存</h4><p>默认情况下，锁页主机内存是作为可缓存状态申请的。此外有一种可选的申请方式，通过将<code>cudaHostAllocWriteCombined</code>标志传给<code>cudaHostAlloc()</code>来申请写组合内存（Write-Combining Memory）。</p><p>写组合内存释放了主机的L1和L2缓存，使程序的其他部分可以使用更多的缓存。此外，在PCI-E总线上传输时，写组合内存不会被窥探，使得传输性能提高40%。</p><p>从主机的写组合内存中读取数据速度非常慢，故写组合内存通常只用于仅主机写入内存的情况。</p><p>应该避免在写组合内存上使用CPU原子指令，因为不是所有CPU实现都能保证该功能。</p><h4 id="映射内存零拷贝内存">映射内存（零拷贝内存）</h4><blockquote><p>通常情况下，主机不能直接访问设备变量，设备也不能直接访问主机变量。但有一种主机和设备都可以访问的内存——零拷贝内存。</p></blockquote><p>通过将<code>cudaHostAllocMapped</code>标志传给<code>cudaHostAlloc()</code>，或将<code>cudaHostRegisterMapped</code>标志传给<code>cudaHostRegister()</code>，可以使锁页主机内存映射到设备的地址空间中。因此，这样的内存区域通常有两个地址：一个在主机内存中，由<code>cudaHostAllco()</code>或<code>malloc()</code>返回；另一个在设备内存中，可以使用<code>cudaHostGetDevicePointer()</code>来检索，从而在核函数中访问该内存空间。</p><p>唯一的例外是使用<code>cudaHostAlloc()</code>分配的指针，以及主机和设备使用统一地址空间（详见<a href="#统一虚拟地址空间">统一虚拟地址空间</a>）的情况下。</p><p>直接从核函数中访问主机内存并不能提供与设备内存相同的带宽，但确实具有一些优势：</p><ul><li>无需在设备内存中分配空间，也不需要在主机内存和设备内存之间搬移数据，会根据核函数的需要隐式地进行数据传输；</li><li>无需使用流（详见<a href="https://deleter-d.github.io/posts/4919/#并发数据传输">并发数据传输</a>）来使数据传输和核函数同时执行，核函数发起的数据传输将自动地与核函数同时执行。</li></ul><p>但是，由于主机和设备共享映射后的锁页内存，因此程序必须使用流或事件同步内存访问（详见<a href="https://deleter-d.github.io/posts/4919/#异步并发执行">异步并发执行</a>），以避免任何写后读、读后写或写后写等潜在危险行为。</p><p>为了能够检索到所有映射后的锁页内存的设备指针，在执行任何CUDA调用之前，必须通过将<code>cudaDeviceMapHost</code>标志传给<code>cudaSetDeviceFlags()</code>来启动锁页内存映射。否则<code>cudaHostGetDevicePointer()</code>将返回一个错误。</p><p>如果设备不支持锁页内存的映射，<code>cudaHostGetDevicePointer()</code>也会返回一个错误。程序可以通过检查设备属性<code>canMapHostMemory</code>来判断是否支持该功能，若支持，则该属性为1。</p><p>值得注意的是，从主机或其他设备的角度来看，在映射后的锁页内存上的原子操作并不是原子操作（详见官方文档<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions">Atomic Functions</a>）。</p><p>还要注意的是，从主机和其他设备的角度来看，CUDA运行时要求由设备发起的对主机内存的1字节、2字节、4字节和8字节天然对齐的加载和存储保留为单一访问。在某些平台上，对内存的原子操作可能会被设备分解为单独的加载和存储操作。这些加载和存储操作对天然对齐访问的保留有相同的要求。例如，某PCI-E拓扑将8字节天然对齐写入拆分为两个4字节写入，CUDA运行时不支持在主机和设备之间基于这种PCI-E总线拓扑进行访问。</p><blockquote><p>我们尝试利用映射内存来执行一个向量求和的操作，对比使用设备内存和映射内存的情况，详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/04_mapped_memory.cu">mapped_memory.cu</a>。经过分析不同数据量情况下的性能，计算减速比，可以总结出下表。<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.158ex;" xmlns="http://www.w3.org/2000/svg" width="25.198ex" height="3.447ex" role="img" focusable="false" viewBox="0 -1011.8 11137.5 1523.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">减</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">速</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">比</text></g><g data-mml-node="mo" transform="translate(3277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4333.6,0)"><g data-mml-node="mrow" transform="translate(220,481.4) scale(0.707)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">使</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">映</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">射</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">内</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">耗</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g></g><g data-mml-node="mrow" transform="translate(220,-370.3) scale(0.707)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">使</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">设</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">备</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">内</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">耗</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g></g><rect width="6564" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>。</p><table><thead><tr class="header"><th>数据量</th><th>设备内存（ns）</th><th>映射内存（ns）</th><th>减速比</th></tr></thead><tbody><tr class="odd"><td>1KB</td><td>1,312</td><td>2,688</td><td>2.0488</td></tr><tr class="even"><td>4KB</td><td>1,344</td><td>3,200</td><td>2.3810</td></tr><tr class="odd"><td>16KB</td><td>1,312</td><td>4,800</td><td>3.6585</td></tr><tr class="even"><td>64KB</td><td>1,472</td><td>8,351</td><td>5.6732</td></tr><tr class="odd"><td>256KB</td><td>1,856</td><td>24,511</td><td>13.2064</td></tr><tr class="even"><td>1MB</td><td>5,312</td><td>89,950</td><td>16.9334</td></tr><tr class="odd"><td>4MB</td><td>27,232</td><td>350,232</td><td>12.8610</td></tr><tr class="even"><td>16MB</td><td>105,405</td><td>1,377,504</td><td>13.0687</td></tr><tr class="odd"><td>64MB</td><td>428,246</td><td>5,514,658</td><td>12.8773</td></tr></tbody></table><p>从这样的结果可以看出，如果想要在主机和设备间共享的少量数据，映射内存是一个不错的选择。但对于大的数据量来说，映射内存并不是好的选择，会导致性能显著的下降。</p></blockquote><h3 id="统一虚拟地址空间">统一虚拟地址空间</h3><p>从CUDA 4.0开始引入了一种特殊的寻址方式，成为统一虚拟寻址（UVA）。通过CUDA API分配的所有主机内存以及支持UVA的设备分配的所有设备内存都在此虚拟地址范围内。</p><ul><li>通过CUDA分配的任何主机内存，或使用统一地址空间的设备内存，可以使用<code>cudaPointerGetAttributes()</code>来获取指针的信息。</li><li>当与使用统一地址空间的任何设备之间发生内存拷贝时，<code>cudaMemcpy*()</code>的<code>cudaMemcpyKind</code>参数可以设置为<code>cudaMemcpyDefault</code>。这也适用于未通过CUDA分配的主机指针，只要当前设备使用统一寻址即可。</li><li>通过<code>cudaHostAlloc()</code>分配的内存可以自动移植到使用统一地址空间的设备上（详见<a href="#可移植内存">可移植内存</a>），并且<code>cudaHostAlloc()</code>返回的指针可以直接从这些设备上运行的核函数中使用，即不需要像映射内存中描述的那样通过<code>cudaHostGetDevicePointer()</code>获取设备指针。</li></ul><p>应用程序可以通过检查<code>unifiedAddressing</code>设备属性是否等于1来查询设备是否支持统一地址空间。</p><blockquote><p>详细示例代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/05_unified_virtual_address.cu">unified_virtual_address.cu</a>。</p></blockquote><h3 id="统一内存寻址">统一内存寻址</h3><p>CUDA 6.0中引入了统一内存寻址，用于简化CUDA中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的指针在CPU和GPU上访问。底层在统一内存空间中自动在主机和设备之间进行数据传输。</p><p>统一内存寻址依赖于统一虚拟寻址（UVA），但它们是完全不同的技术。UAV只是为系统中所有处理器提供了单一的虚拟内存地址空间。但UAV不会自动改变数据的物理位置，这是统一内存寻址的一个特有功能。</p><p>托管内存指的是由底层系统自动分配的统一内存，与特定设备的分配内存可以互操作，如它们的创建都使用<code>cudaMalloc()</code>。故可以在核函数中使用两种内存：</p><ul><li>由系统控制的托管内存；</li><li>由程序明确分配和调用的未托管内存。</li></ul><p>在设备内存上的有效CUDA操作也同样适用于托管内存，主要区别是主机也能引用和访问托管内存。</p><p>托管内存可以被静态分配，也可以被动态分配。使用<code>__managed__</code>修饰符静态声明一个设备变量作为托管变量，该变量可以从主机或设备代码中直接被引用。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__device__ __managed__ <span class="hljs-type">int</span> y;<br></code></pre></td></tr></table></figure><p>也可以使用CUDA运行时API<code>cudaMallocManaged()</code>来动态分配托管内存。</p><h3 id="设备内存l2访问管理">设备内存L2访问管理</h3><p>当CUDA核心反复访问全局内存中的数据区域时，这种数据访问是持久化的。若数据只被访问一次，则这种数据访问是流式的。从CUDA 11.0开始，计算能力8.0及以上的设备能够影响L2缓存中的数据持久化，从而提供更高的带宽和更低的全局内存访问延迟。</p><h4 id="为持久化访问预留的l2缓存">为持久化访问预留的L2缓存</h4><p>可以预留一部分L2缓存用于持久化全局内存的数据访问，持久化访问优先使用L2缓存的这个部分。只有当持久化访问未使用这一部分时，普通或流式访问才能使用L2缓存。</p><p>用于持久化访问的L2预留缓存大小可以在一定范围内调整。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, device_id);<br><span class="hljs-type">size_t</span> size = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">int</span>(prop.l2CacheSize * <span class="hljs-number">0.75</span>), prop.persistingL2CacheMaxSize);<br><span class="hljs-comment">// 预留3/4的L2缓存用于持久化访问，或用最大L2持久化缓存大小</span><br><span class="hljs-built_in">cudaDeviceSetLimit</span>(cudaLimitPersistingL2CacheSize, size);<br></code></pre></td></tr></table></figure><p>当GPU配置为多实例GPU（MIG）模式时，将禁用L2缓存预留功能。当使用多进程服务（MPS）时，<code>cudaDeviceSetLimit()</code>无法改变L2缓存的预留大小，只能通过MPS服务器启动时的环境变量<code>CUDA_DEVICE_DEFAULT_PERSISTING_L2_CACHE_PERCENTAGE_LIMIT</code>来指定。</p><h4 id="l2持久化访问策略">L2持久化访问策略</h4><p>访问策略窗口指定了一个连续的全局内存区域及其持久化属性。</p><p>下面的例子使用CUDA流（CUDA Stream）设置L2持久化访问窗口。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 流级别属性数据结构</span><br>cudaStreamAttrValue stream_attribute;<br><span class="hljs-comment">// 全局内存数据指针</span><br>stream_attribute.accessPolicyWindow.base_ptr  = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(ptr);<br><span class="hljs-comment">// 持久化访问的总字节数，必须小于cudaDeviceProp::accessPolicyMaxWindowSize</span><br>stream_attribute.accessPolicyWindow.num_bytes = num_bytes;<br><br><span class="hljs-comment">// 缓存命中率</span><br>stream_attribute.accessPolicyWindow.hitRatio  = <span class="hljs-number">0.6</span>;<br><span class="hljs-comment">// 缓存命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting;<br><span class="hljs-comment">// 缓存未命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;<br><br><span class="hljs-comment">// 将属性配置到cudaStream_t类型的CUDA流中</span><br><span class="hljs-built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);<br></code></pre></td></tr></table></figure><p>当核函数在CUDA流中执行时，全局内存范围<code>[ptr..ptr+num_bytes)</code>内的数据比其他地方的数据更有可能被持久化在L2缓存中。</p><p>下面的例子是L2缓存持久化在CUDA图核结点（CUDA Graph Kernel Node）中的应用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 核级别的属性数据结构</span><br>cudaKernelNodeAttrValue node_attribute;<br><span class="hljs-comment">// 全局内存数据指针</span><br>node_attribute.accessPolicyWindow.base_ptr  = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(ptr);<br><span class="hljs-comment">// 持久化访问的总字节数，必须小于cudaDeviceProp::accessPolicyMaxWindowSize</span><br>node_attribute.accessPolicyWindow.num_bytes = num_bytes;<br><br><span class="hljs-comment">// 缓存命中率</span><br>node_attribute.accessPolicyWindow.hitRatio  = <span class="hljs-number">0.6</span>;<br><span class="hljs-comment">// 缓存命中时的访存方式</span><br>node_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting; <br><span class="hljs-comment">// 缓存未命中时的访存方式</span><br>node_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;<br><br><span class="hljs-comment">// 将属性配置到cudaGraphNode_t类型的CUDA图核结点中</span><br><span class="hljs-built_in">cudaGraphKernelNodeSetAttribute</span>(node, cudaKernelNodeAttributeAccessPolicyWindow, &amp;node_attribute);<br></code></pre></td></tr></table></figure><p><code>hitRatio</code>参数可以指定以<code>hitProp</code>方式访存的占比。在上面两个例子中，全局内存区域<code>[ptr..ptr+num_bytes)</code>内，60%的内存访问是持久化的，40%的访问是流式的。具体哪些内存访问是<code>hitProp</code>方式是随机的，这个概率是接近<code>hitRatio</code>的，概率分布取决于硬件结构和存储范围。</p><p>例如，若L2预留预测大小为16KB，<code>accessPolicyWindow.num_bytes</code>为32KB：</p><ul><li>当<code>hitRatio = 0.5</code>时，硬件将随机选择32KB窗口中的16KB作为持久化缓存存入预留的L2缓存中；</li><li>当<code>hitRatio = 1</code>时，硬件会尝试在预留的L2缓存区中缓存整个32KB的窗口。但由于预留区小于窗口，缓存行将被移除，以将最近使用的32KB数据中的16KB持久化在L2缓存的预留区中。</li></ul><p><code>hitRatio</code>可以用来避免缓存行抖动，从宏观上减少进出L2缓存的数据量。可以利用低于1的<code>hitRatio</code>来手动控制不同<code>accessPolicyWindow</code>的并发CUDA流能够缓存在L2中的数据量。例如，假设L2的预留缓存大小为16KB，两个不同CUDA流中的核函数是并发的，每个核函数的<code>accessPolicyWindow</code>均为16KB，<code>hitRatio</code>均为1，在竞争共享的L2缓存时可能会移除彼此的缓存行。但如果两个<code>accessPolicyWindow</code>的<code>hitRatio</code>均为0.5，则不太可能会清楚自己或对方的持久缓存行。</p><h4 id="l2访问属性">L2访问属性</h4><p>针对不同的全局内存数据访问，定义了3种类型的访问属性：</p><ul><li><code>cudaAccessPropertyStreaming</code>：伴随流式属性发生的内存访问不太可能持久化在L2缓存中，因为这些访问会被优先清除；</li><li><code>cudaAccessPropertyPersisting</code>：伴随持久化属性发生的内存访问更可能持久化在L2缓存中，因为这些访问会优先被保留在L2缓存中的预留区；</li><li><code>cudaAccessPropertyNormal</code>：该访问属性会将之前持久化的访问强制重置为正常访问。之前CUDA核函数中的持久化属性的内存访问可能会在很长时间内留在L2缓存中，这个时间是远超预期的使用时间的。这种情况会导致后续的核函数不强制使用持久化属性内存访问时可用的L2缓存空间。而使用<code>cudaAccessPropertyNormal</code>可以重置访问属性，改变其持久状态，使得后续的核函数可以利用更多的L2缓存。</li></ul><h4 id="l2持久化示例">L2持久化示例</h4><p>下面是为持久访问预留L2缓存的例子，通过CUDA流在CUDA核函数中使用预留的L2缓存并重置。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaStream_t stream;<br><span class="hljs-comment">// 创建CUDA流</span><br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream);<br><br><span class="hljs-comment">// CUDA设备属性变量</span><br>cudaDeviceProp prop;<br><span class="hljs-comment">// 查询GPU属性</span><br><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, device_id);<br><span class="hljs-type">size_t</span> size = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">int</span>(prop.l2CacheSize * <span class="hljs-number">0.75</span>) , prop.persistingL2CacheMaxSize);<br><span class="hljs-comment">// 预留3/4的L2缓存用于持久化访问，或用最大L2持久化缓存大小</span><br><span class="hljs-built_in">cudaDeviceSetLimit</span>(cudaLimitPersistingL2CacheSize, size);<br><br><span class="hljs-comment">// 取用户定义的num_bytes和最大窗口大小的较小值作为最终窗口大小</span><br><span class="hljs-type">size_t</span> window_size = <span class="hljs-built_in">min</span>(prop.accessPolicyMaxWindowSize, num_bytes);<br><br><span class="hljs-comment">// 流级别属性数据结构</span><br>cudaStreamAttrValue stream_attribute;<br><span class="hljs-comment">// 全局内存数据指针</span><br>stream_attribute.accessPolicyWindow.base_ptr  = <span class="hljs-built_in">reinterpret_cast</span>&lt;<span class="hljs-type">void</span>*&gt;(data1);<br><span class="hljs-comment">// 持久化访问的总字节数</span><br>stream_attribute.accessPolicyWindow.num_bytes = window_size;<br><span class="hljs-comment">// 缓存命中率</span><br>stream_attribute.accessPolicyWindow.hitRatio  = <span class="hljs-number">0.6</span>;<br><span class="hljs-comment">// 缓存命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting;<br><span class="hljs-comment">// 缓存未命中时的访存方式</span><br>stream_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;<br><br><span class="hljs-comment">// 将属性配置到CUDA流中</span><br><span class="hljs-built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);<br><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) {<br>    <span class="hljs-comment">// data1被核函数多次使用</span><br>    cuda_kernelA&lt;&lt;&lt;grid_size,block_size,<span class="hljs-number">0</span>,stream&gt;&gt;&gt;(data1);<br>} <span class="hljs-comment">// [data1..data1 + num_bytes)范围内的数据受益于L2持久化</span><br><span class="hljs-comment">// 在同一个CUDA流中的不同核函数也能受益于data1的持久化</span><br>cuda_kernelB&lt;&lt;&lt;grid_size,block_size,<span class="hljs-number">0</span>,stream&gt;&gt;&gt;(data1);<br><br><span class="hljs-comment">// 将窗口总字节数设置为0来禁用持久化</span><br>stream_attribute.accessPolicyWindow.num_bytes = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// 覆写CUDA流的访问属性</span><br><span class="hljs-built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);<br><span class="hljs-comment">// 将L2中的所有持久化缓存行重置为普通状态</span><br><span class="hljs-built_in">cudaCtxResetPersistingL2Cache</span>();<br><br><span class="hljs-comment">// 由于之前的清除操作，data2当前也可以以普通访存模式受益于L2持久化访问</span><br>cuda_kernelC&lt;&lt;&lt;grid_size,block_size,<span class="hljs-number">0</span>,stream&gt;&gt;&gt;(data2);<br></code></pre></td></tr></table></figure><h4 id="将l2访问重置为普通">将L2访问重置为普通</h4><p>主要有三种方式：</p><ul><li>通过<code>cudaAccessPropertyNormal</code>访问属性来重置支持持久化内存区域的访存属性；</li><li>通过<code>cudaCtxResetPersistingL2Cache()</code>调用将所有持久化L2缓存行重置为普通状态；</li><li>最终未受影响的缓存行将自动重置为普通状态，在开发过程中不应该依赖于自动重置，因为自动重置所需的时间是不确定的。</li></ul><h4 id="管理l2预留缓存的利用率">管理L2预留缓存的利用率</h4><p>不同CUDA流中并发执行的多个CUDA核函数可能分配不同的访问策略窗口，但L2的预留缓存部分在所有核函数之间共享，故L2预留区的使用量是所有并发CUDA核函数使用量的总和。当持久化访问的容量超过了L2缓存的容量时，将内存访问指定为持久化状态的收益就会降低。</p><p>综上，程序应该考虑以下因素：</p><ul><li>L2缓存预留区的大小；</li><li>可能并发执行的CUDA核函数；</li><li>所有可能并发执行的核函数的访问策略窗口；</li><li>重置L2的时机和方式，以允许普通访问或流式访问以同等优先级利用L2缓存的预留区。</li></ul><h4 id="查询l2缓存属性">查询L2缓存属性</h4><p>与L2缓存相关的属性是<code>cudaDeviceProp</code>结构体的一部分，可以通过CUDA运行时API<code>cudaGetDeviceProperties</code>获取。</p><p>CUDA设备属性包括：</p><ul><li><code>l2CacheSize</code>：GPU上可用的L2缓存容量；</li><li><code>persistingL2CacheMaxSize</code>：L2缓存中可用于持久化访存的最大预留容量；</li><li><code>accessPolicyMaxWindowSize</code>：访问策略窗口的最大大小。</li></ul><h4 id="控制持久化访存的l2缓存预留大小">控制持久化访存的L2缓存预留大小</h4><p>用于持久化访存的L2预留缓存大小可以使用CUDA运行时API<code>cudaDeviceGetLimit</code>查询，使用<code>cudaLimit</code>通过<code>cudaDeviceSetLimit</code>设置预留区大小。该设置的最大值是<code>cudaDeviceProp::persistingL2CacheMaxSize</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaLimit</span> {<br>    <span class="hljs-comment">/* other fields not shown */</span><br>    cudaLimitPersistingL2CacheSize<br>};<br></code></pre></td></tr></table></figure><h2 id="内存访问模式">内存访问模式</h2><p>CUDA执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行，存储操作也是同样的。在执行内存指令时，线程束中每个线程都提供了一个正在加载或存储的内存地址。在线程束的32个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以分为不同的模式。</p><h3 id="对齐与合并访问">对齐与合并访问</h3><p>全局内存通过缓存来实现加载 / 存储。全局内存是一个逻辑内存空间，可以通过核函数来访问。所有的程序数据最初存在DRAM上，即物理设备内存中。核函数的内存请求通常是在DRAM设备和片上内存间以128字节或32字节的内存事务来实现的。</p><ul><li>若一个内存访问同时用到了一级和二级缓存，则该访问由128字节的内存事务实现；</li><li>若一个内存访问只用到了二级缓存，则该访问由32字节的内存事务实现。</li></ul><blockquote><p>对于允许使用一级缓存的设备，可以在编译时选择是否启用一级缓存。</p></blockquote><p><img src="https://github.com/Deleter-D/Images/assets/56388518/64c5a79c-ade5-4bc5-9da7-52ba127047bd"></p><p>一个一级缓存行是128字节，它映射到设备内存中的一个128字节对齐段。若线程束中的每个线程请求4字节的值，则每次请求就会获取128字节的数据，这恰好与一级缓存行大小一致。在优化程序时，需要注意内存访问的两个特性：</p><ul><li>对齐内存访问：当设备内存事务的第一个地址是缓存粒度的偶数倍时（32B的L2或128B的L1），就会出现对齐内存访问，非对齐的加载会造成带宽浪费；</li><li>合并内存访问：当一个线程束中全部的32个线程访问一个连续的内存块时，就会出现合并内存访问。</li></ul><p>对齐合并内存访问的理想状态是线程束从对齐内存地址开始访问一个连续的内存块。一个理想的对齐合并访问如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/afebf968-8c53-4a8f-a11b-e4b444616387"></p><p>这种情况下，只需要一个128字节的内存事务就可以从设备内存中完成读取。但下面这种情况就可能需要3个128字节的内存事务，大大浪费了带宽。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/0c9782e0-53cf-45c9-817b-9ccf148de8e5"></p><h3 id="全局内存读取">全局内存读取</h3><p>在SM中，数据通过一级和二级缓存、常量缓存、只读缓存3种缓存路径进行传输，具体使用哪种方式取决于所引用的设备内存类型。一、二级缓存是默认路径。若想通过其他两种路径传递数据则需要显式说明，但若想提升性能还要取决于使用的访问模式。全局内存加载是否通过一级缓存取决于设备的计算能力和编译器选项两个因素。使用编译器选项<code>-Xptxas -dlcm=fg</code>来禁用一级缓存，<code>-Xptxas -dlcm=ca</code>来启动一级缓存。</p><p>若一级缓存被禁用，所有对全局内存的加载请求将直接进入二级缓存。若二级缓存未命中，则由DRAM完成请求。每次内存事务可由一个、两个或四个部分执行，每个部分32字节。</p><p>若一级缓存被启用，全局内存加载请求首先尝试通过一级缓存。若一级缓存未命中，则请求转向二级缓存。若二级缓存也未命中，则请求由DRAM完成。这种模式下，一个内存加载请求由一个128字节的设备内存事务实现。</p><h4 id="缓存加载">缓存加载</h4><p>缓存加载操作经过一级缓存，在粒度为128字节的一级缓存行上由设备内存事务进行传输。缓存加载可以分为对齐、非对齐、合并、非合并几种情况。</p><p>下图为一个理性情况，即对齐与合并内存访问。线程束中的所有请求均在128字节的缓存行范围内。只需要一个128字节的事务，总线利用率为100%，事务中没有未使用数据。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/0b6a8546-c455-4079-9075-b204a276f655"></p><p>而下图则是另一种情况，访问是对齐的，但引用的地址不是连续的线程ID，是128字节内的随机值。只需要一个128字节的事务，总线利用率为100%，只有每个线程请求的地址均不同的情况下，该事务中才没有未使用数据。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/fc2d0442-43db-48ad-9f65-fd1b5f469210"></p><p>下图中线程束请求32个连续的4字节非对齐数据。需要两个128字节的事务，总线利用率为50%，两个事务中各有一半的数据是未使用的。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/49798f58-2d10-4625-a09c-aa090c8a0977"></p><p>下图线程束中的所有线程都请求相同的地址。需要一个128字节的事务，若请求的值是4字节的，则总线利用率为3.125%（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.613ex" role="img" focusable="false" viewBox="0 -677 3222.4 713"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>）。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/2b99e9cc-fbf9-4478-98c8-d8d1dc259eae"></p><p>下图则是最坏的情况，线程束中线程请求分散于全局内存中的32个不同地点。地址需要占用N个缓存行（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex;" xmlns="http://www.w3.org/2000/svg" width="11.437ex" height="1.857ex" role="img" focusable="false" viewBox="0 -683 5055.1 821"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(777.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mi" transform="translate(1833.6,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(2999.3,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(4055.1,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>），需要N个128字节的事务。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/c1d31787-147f-4fd0-bfd0-69c57914c87a"></p><h4 id="没有缓存的加载">没有缓存的加载</h4><p>没有缓存的加载不经过一级缓存，它在内存段的粒度上（32B）而非缓存池的粒度（128B）执行。这种更细粒度的加载，可以为非对齐或非合并的内存访问带来更好的总线利用率。</p><p>下图是对齐与合并的内存访问，128字节请求的地址占用了4个内存段，总线利用率为100%。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/f2e25ece-afa2-405d-98a0-333c93154d87"></p><p>下图的内存访问是对齐的，但线程访问是不连续的，而是在128个字节范围内随机进行。只要每个线程请求唯一的地址，则地址将占用4个内存段，且不会有加载浪费。这样的随机访问不会抑制核函数性能。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b7bfd208-dcbc-4dcc-997c-f20c754d44f0"></p><p>下图中线程束请求32个连续的4字节元素，但加载没有对齐。请求的地址最多落在5个内存段内，总线利用率至少为80%。与类似情况的缓存加载相比，非缓存加载会提升性能，因为加载了更少的未请求字节。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5b731cec-9862-4e87-be38-a15915a688ae"></p><p>下图线程束中所有线程请求相同的数据。地址落在一个内存段内，总线利用率为12.5%（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="6.159ex" height="1.613ex" role="img" focusable="false" viewBox="0 -677 2722.4 713"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>）。在这种情况下，非缓存加载的性能也是优于缓存加载的。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/de2ad730-291b-44fd-9df8-98adfb3fc56c"></p><p>下图则是最坏的情况，线程束请求32个分散在全局内存中的不同地方。请求的128个字节最多落在N个32字节的内存段内，而不是N个128字节的缓存行内，所以相比于缓存加载，即便是最坏情况也有所改善。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/0c36a2e3-aa91-47e0-a49d-10c359b5849f"></p><blockquote><p><a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/06_read_segment.cu">read_segment.cu</a>是一个非对齐读取的示例，实现一个带偏移量的向量求和核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sumArraysReadOffset</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">const</span> <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> offset)</span></span><br><span class="hljs-function"></span>{<br><span class="hljs-type">unsigned</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br><span class="hljs-type">unsigned</span> j = tid + offset;<br><span class="hljs-keyword">if</span> (tid &lt; size)<br>  C[tid] = A[j] + B[j];<br>}<br></code></pre></td></tr></table></figure><p>这样可以通过<code>offset</code>来强制其进行非对齐内存访问，对不同的<code>offset</code>性能测试的结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">readOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">094464</span> ms<br><span class="hljs-attribute">readOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">102912</span> ms<br><span class="hljs-attribute">readOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">094112</span> ms<br></code></pre></td></tr></table></figure><p>可以看到在<code>offset</code>为11的情况下速度是最慢的，此时两个输入向量的读取是非对齐的。我们借助<code>ncu</code>来分析这三种情况的全局加载效率和全局加载事务。</p><table><thead><tr class="header"><th></th><th>全局加载效率</th><th>全局加载事务</th></tr></thead><tbody><tr class="odd"><td><code>readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;       offset    0</code></td><td>100%</td><td>1048576</td></tr><tr class="even"><td><code>readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;       offset   11</code></td><td>80%</td><td>1310716</td></tr><tr class="odd"><td><code>readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;       offset  128</code></td><td>100%</td><td>1048544</td></tr></tbody></table><p>关于这里的全局加载效率，在《CUDA C编程权威指南》一书中，在开启一级缓存的情况下，全局加载效率仅有50%左右，但禁用一级缓存后提升到了80%。但笔者测试了开启和禁用一级缓存两种情况，加载效率均为80%。</p></blockquote><h4 id="只读缓存">只读缓存</h4><p>只读缓存最初是预留给纹理内存加载使用的，对计算能力3.5以上的GPU，只读缓存也支持使用全局内存加载代替一级缓存。</p><p>只读缓存的加载粒度是32字节，有两种方式可以指导内存通过只读缓存读取：</p><ul><li>使用函数<code>__ldg</code>；</li><li>在间接引用的指针上使用修饰符。</li></ul><p>例如下面的核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *out, <span class="hljs-type">int</span> *in)</span> </span>{<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    out[idx] = in[idx];<br>}<br></code></pre></td></tr></table></figure><p>可以通过在核函数内部使用<code>__ldg</code>来通过只读缓存直接对数组进行读取访问。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *out, <span class="hljs-type">int</span> *in)</span> </span>{<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    out[idx] = __ldg(&amp;in[idx]);<br>}<br></code></pre></td></tr></table></figure><p>也可以将限制修饰符<code>__restrict__</code>应用到指针上，该修饰符会使<code>nvcc</code>编译器将指针识别为无别名指针。<code>nvcc</code>将自动通过只读缓存来指导无别名指针的加载。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> * __restrict__ out, <span class="hljs-type">const</span> <span class="hljs-type">int</span> * __restrict__ in)</span> </span>{<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    out[idx] = in[idx];<br>}<br></code></pre></td></tr></table></figure><h3 id="全局内存写入">全局内存写入</h3><p>内存的存储操作相对简单，存储操作不能使用一级缓存进行，在发送到设备内存之前只通过二级缓存。存储操作在32字节段的粒度上被执行。内存事务可以同时被分为一段、两段或四段。</p><p>下图中为最理想的情况，内存访问是对齐的，且线程束中的所有线程访问一个连续的128字节范围。存储请求由一个四段事务实现。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/520844ca-de46-4121-a6f6-bec28934665e"></p><p>下图的内存访问是对齐的，但地址分散在192字节范围内，存储请求由三个一段事务实现。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/356bc0e5-565a-4a11-b1de-7672cf29146a"></p><p>下图中内存访问同样是对齐的，且地址访问在一个连续的64字节范围内，存储请求由一个两段事务实现。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/96106945-ac2c-447e-9382-ff21603fa0ef"></p><blockquote><p><a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/07_write_segment.cu">write_segment.cu</a>是一个非对齐写入的示例，实现一个带偏移量的向量求和核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sumArraysWriteOffset</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">const</span> <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> offset)</span></span><br><span class="hljs-function"></span>{<br><span class="hljs-type">unsigned</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br><span class="hljs-type">unsigned</span> j = tid + offset;<br><span class="hljs-keyword">if</span> (j &lt; size)<br>  C[j] = A[tid] + B[tid];<br>}<br></code></pre></td></tr></table></figure><p>与上面非对齐读取的例子不同，这次将<code>C</code>与<code>A</code>、<code>B</code>的索引颠倒了过来。通过<code>offset</code>来强制其进行非对齐写入，性能测试结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">writeOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">109920</span> ms<br><span class="hljs-attribute">writeOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">111616</span> ms<br><span class="hljs-attribute">writeOffset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;       offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">110592</span> ms<br></code></pre></td></tr></table></figure><p>类似地，利用<code>ncu</code>来分析全局存储效率和全局存储事务。</p><table><thead><tr class="header"><th></th><th>全局存储效率</th><th>全局存储事务</th></tr></thead><tbody><tr class="odd"><td><code>writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;       offset    0</code></td><td>100%</td><td>524288</td></tr><tr class="even"><td><code>writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;       offset   11</code></td><td>80%</td><td>655358</td></tr><tr class="odd"><td><code>writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;       offset  128</code></td><td>100%</td><td>524272</td></tr></tbody></table></blockquote><p>值的注意的是，若写入的两个地址同属于一个128字节区域，但不属于一个对齐的64字节区域，则会执行一个四段事务，而不是两个一段事务。</p><h3 id="结构体数组与数组结构体">结构体数组与数组结构体</h3><p>C语言中有两种数据组织方式：</p><ul><li>数组结构体（AoS）；</li><li>结构体数组（SoA）。</li></ul><p>假设要存储一组成对的浮点数，两种不同的方式如下。</p><p>AoS方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerStruct</span> {<br>    <span class="hljs-type">float</span> x;<br>    <span class="hljs-type">float</span> y;<br>};<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerStruct</span> myAoS[N];<br></code></pre></td></tr></table></figure><p>SoA方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerArray</span> {<br>    <span class="hljs-type">float</span> x[N];<br>    <span class="hljs-type">float</span> y[N];<br>};<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">innerArray</span> mySoA;<br></code></pre></td></tr></table></figure><p>观察两种存储方式的内存布局。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b71b43ca-fd5e-40d8-a1f9-3001d48eb20b"></p><p>可以发现SoA模式充分利用了GPU的内存带宽，由于没有相同字段元素的交叉存取，GPU上的SoA布局提供了合并内存访问，可以对全局内存实现更高效的利用。</p><blockquote><p><a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/08_array_of_structure.cu">array_of_structure.cu</a>和<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/09_structure_of_array.cu">structure_of_array.cu</a>是使用AoS模式和SoA模式下的对比，性能测试结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">AoS</span>innerStruct&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">033280</span> ms<br><span class="hljs-attribute">SoA</span>innerArray&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;       elapsed <span class="hljs-number">0</span>.<span class="hljs-number">032640</span> ms<br></code></pre></td></tr></table></figure><p>通过分析它们的全局加载和存储效率可以印证上面的观点，即SoA布局充分利用了GPU的内存带宽。</p><table><thead><tr class="header"><th>存储方式</th><th></th><th>全局加载效率</th><th>全局存储效率</th></tr></thead><tbody><tr class="odd"><td>AoS</td><td><code>innerStruct&lt;&lt;&lt;8192, 128&gt;&gt;&gt;</code></td><td>50%</td><td>50%</td></tr><tr class="even"><td>SoA</td><td><code>innerArray&lt;&lt;&lt;8192, 128&gt;&gt;&gt;</code></td><td>100%</td><td>100%</td></tr></tbody></table></blockquote><h3 id="性能调整">性能调整</h3><p>优化设备内存带宽利用率有两个目标：</p><ul><li>对齐及合并内存访问，以减少带宽的浪费；</li><li>足够的并发内存操作，以隐藏内存延迟。</li></ul><h4 id="展开技术">展开技术</h4><p>将之前提到的非对齐读取的例子<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/06_read_segment.cu">read_segment.cu</a>，将其循环展开。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">readOffsetUnroll4</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">const</span> <span class="hljs-type">int</span> size, <span class="hljs-type">int</span> offset)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x * <span class="hljs-number">4</span> + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> j = tid + offset;<br>    <span class="hljs-keyword">if</span> (j + <span class="hljs-number">3</span> * blockDim.x &lt; size)<br>    {<br>        C[tid] = A[j] + B[j];<br>        C[tid + blockDim.x] = A[j + blockDim.x] + B[j + blockDim.x];<br>        C[tid + blockDim.x * <span class="hljs-number">2</span>] = A[j + blockDim.x * <span class="hljs-number">2</span>] + B[j + blockDim.x * <span class="hljs-number">2</span>];<br>        C[tid + blockDim.x * <span class="hljs-number">3</span>] = A[j + blockDim.x * <span class="hljs-number">3</span>] + B[j + blockDim.x * <span class="hljs-number">3</span>];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>性能测试结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">offset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;   offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">107520</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">099104</span> ms<br><span class="hljs-attribute">offset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;   offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">109216</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">100640</span> ms<br><span class="hljs-attribute">offset</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;   offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">108352</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset  <span class="hljs-number">128</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">098976</span> ms<br></code></pre></td></tr></table></figure><p>分析其全局加载和存储效率，以及全局加载和存储事务。</p><table><thead><tr class="header"><th></th><th>全局加载效率</th><th>全局存储效率</th><th>全局加载事务</th><th>全局存储事务</th></tr></thead><tbody><tr class="odd"><td><code>offset&lt;&lt;&lt;8192, 512&gt;&gt;&gt;        offset   11</code></td><td>80%</td><td>100%</td><td>1310704</td><td>524284</td></tr><tr class="even"><td><code>unroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt;       offset   11</code></td><td>80%</td><td>100%</td><td>1310716</td><td>524287</td></tr></tbody></table><blockquote><p>这里笔者的测试结果没有太大的差距，原因是笔者开启和禁用一级缓存两种情况下，未展开的核函数差别本就不大。所以即使展开之后，性能提升也不明显，但这个优化手段是值的参考的。</p></blockquote><h4 id="增大并行性">增大并行性</h4><p>用不同的线程块大小测试上面展开的核函数，结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>&gt;&gt;&gt; offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">099104</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">095840</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">256</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">096096</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;  offset    <span class="hljs-number">0</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">096320</span> ms<br><br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>&gt;&gt;&gt; offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">098624</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">2048</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">097504</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">256</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">097568</span> ms<br><span class="hljs-attribute">unroll4</span>&lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">128</span>&gt;&gt;&gt;  offset   <span class="hljs-number">11</span>     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">097408</span> ms<br></code></pre></td></tr></table></figure><p>不管是对齐的还是非对齐的访问，增大并行性都可以带来一些提升。</p><h2 id="核函数可达到的带宽">核函数可达到的带宽</h2><h3 id="内存带宽">内存带宽</h3><p>大多数核函数对内存带宽非常敏感，也就是说它们有内存带宽限制。全局内存中数据的排布方式，以及线程束访问该数据的方式都对带宽有显著的影响。一般分为两个概念：</p><ul><li>理论带宽：当前硬件可以实现的绝对最大带宽；</li><li>有效带宽：核函数实际达到的带宽，是测量带宽，公式如下。</li></ul><p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex;" xmlns="http://www.w3.org/2000/svg" width="48.349ex" height="5.543ex" role="img" focusable="false" viewBox="0 -1540 21370.1 2450"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">有</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">效</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">带</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">宽</text></g><g data-mml-node="mtext" transform="translate(4000,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z" transform="translate(389,0)"></path><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z" transform="translate(1174,0)"></path><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z" transform="translate(1882,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(2382,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(2776,0)"></path></g><g data-mml-node="mo" transform="translate(7442.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(8498.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">读</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">字</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">节</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(4222.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">写</text></g><g data-mml-node="mi" transform="translate(6222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">字</text></g><g data-mml-node="mi" transform="translate(7222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">节</text></g><g data-mml-node="mi" transform="translate(8222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(9444.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(10444.9,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(4435.8,-710)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">运</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">行</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">间</text></g></g><rect width="12631.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p><h3 id="矩阵转置问题">矩阵转置问题</h3><p><img src="https://github.com/Deleter-D/Images/assets/56388518/56e8a8e5-3dec-440f-a1a9-24342d83fad2"></p><p>在主机端利用错位转置算法可以很容易的实现上述操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">transposeHost</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> iy = <span class="hljs-number">0</span>; iy &lt; ny; iy++)<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ix = <span class="hljs-number">0</span>; ix &lt; nx; ix++)<br>            out[ix * ny + iy] = in[iy * nx + ix];<br>}<br></code></pre></td></tr></table></figure><p>观察原矩阵和转置矩阵的内存数据排布。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/6918a8de-27cf-4a21-a9f7-8abfc8cb11f9"></p><p>可以很容易的分析出，读取过程是访问原矩阵的行，是合并访问，写入过程是访问转置矩阵的列，是交叉访问。</p><p>核函数有两种主要方式来实现矩阵的转置：</p><ul><li>按行读取，按列存储；<img src="https://github.com/Deleter-D/Images/assets/56388518/5f600f4f-92db-4800-aa22-1179c1ea0b3f"></li><li>按列读取，按行存储。<img src="https://github.com/Deleter-D/Images/assets/56388518/2f4e86e1-caf1-4398-b895-0cac22b44565"></li></ul><h4 id="为转置核函数设置性能的上限和下限">为转置核函数设置性能的上限和下限</h4><p>实现两个核函数，一个读取和存储都按行，另一个读取和存储都按列。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyRow</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[iy * nx + ix] = in[iy * nx + ix];<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">copyCol</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[ix * ny + iy] = in[ix * ny + iy];<br>}<br></code></pre></td></tr></table></figure><p>这两个核函数可以分别测得与转置操作相同内存操作情况下，全部使用合并访问（按行读写）以及全部使用交叉访问（按列读写）的有效带宽。</p><table><thead><tr class="header"><th>核函数</th><th>带宽（GB/s）</th><th>备注</th></tr></thead><tbody><tr class="odd"><td><code>CopyRow</code></td><td>1367.11</td><td>上限</td></tr><tr class="even"><td><code>CopyCol</code></td><td>595.78</td><td>下限</td></tr></tbody></table><h4 id="朴素转置">朴素转置</h4><p>分别实现<a href="#矩阵转置问题">矩阵转置问题</a>中提到的两种转置方式，即按行加载按列存储与按列加载按行存储。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeNaiveRow</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[ix * ny + iy] = in[iy * nx + ix];<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeNaiveCol</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[iy * nx + ix] = in[ix * ny + iy];<br>}<br></code></pre></td></tr></table></figure><p>像上面那样测试有效带宽，对比结果如下，同时分析其全局加载、存储吞吐量和全局加载、存储效率。</p><table><thead><tr class="header"><th>核函数</th><th>带宽（GB/s）</th><th>加载吞吐量（GB/s）</th><th>存储吞吐量（GB/s）</th><th>加载效率（%）</th><th>存储效率（%）</th><th>备注</th></tr></thead><tbody><tr class="odd"><td><code>NaiveRow</code></td><td>321.25</td><td>126.85</td><td>507.42</td><td>100</td><td>25</td><td>合并读取，交叉存储</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>911.80</td><td>609.64</td><td>152.41</td><td>25</td><td>100</td><td>交叉读取，合并存储</td></tr></tbody></table><p>可以发现两种方式的性能相近，这是因为在交叉读取的过程中，会有数据进入一级缓存。虽然读取的数据不连续，但在后续的读取过程中，仍然有可能发生缓存命中。禁用一级缓存后，有效带宽表现如下，</p><table><thead><tr class="header"><th>核函数</th><th>带宽（GB/s）</th><th>加载吞吐量（GB/s）</th><th>存储吞吐量（GB/s）</th><th>加载效率（%）</th><th>存储效率（%）</th><th>备注</th></tr></thead><tbody><tr class="odd"><td><code>NaiveRow</code></td><td>330.99</td><td>128.38</td><td>513.50</td><td>100</td><td>25</td><td>合并读取，交叉存储，禁用一级缓存</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>489.07</td><td>472.76</td><td>118.19</td><td>25</td><td>100</td><td>交叉读取，合并存储，禁用一级缓存</td></tr></tbody></table><p>可以看到，没有一级缓存的帮助后，交叉读取的有效带宽下降了。对于<code>NaiveCol</code>实现来说，由于写入是合并的，存储请求未被重复执行。但由于交叉读取，多次重复执行了加载请求。即使不是最好的加载方式，但有一级缓存的帮助，也能限制交叉读取对性能的负面影响。</p><blockquote><p>后面的讨论都默认启用一级缓存。</p></blockquote><h4 id="展开转置">展开转置</h4><p>利用循环展开技术改进两个朴素转置核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeUnroll4Row</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ti = iy * nx + ix;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> to = ix * ny + iy;<br><br>    <span class="hljs-keyword">if</span> (ix + blockDim.x * <span class="hljs-number">3</span> &lt; nx &amp;&amp; iy &lt; ny)<br>    {<br>        out[to] = in[ti];<br>        out[to + ny * blockDim.x] = in[ti + blockDim.x];<br>        out[to + ny * blockDim.x * <span class="hljs-number">2</span>] = in[ti + blockDim.x * <span class="hljs-number">2</span>];<br>        out[to + ny * blockDim.x * <span class="hljs-number">3</span>] = in[ti + blockDim.x * <span class="hljs-number">3</span>];<br>    }<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeUnroll4Col</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ti = ix * ny + iy;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> to = iy * nx + ix;<br>    <span class="hljs-keyword">if</span> (ix + blockDim.x * <span class="hljs-number">3</span> &lt; nx &amp;&amp; iy &lt; ny)<br>    {<br>        out[to] = in[ti];<br>        out[to + blockDim.x] = in[ti + ny * blockDim.x];<br>        out[to + blockDim.x * <span class="hljs-number">2</span>] = in[ti + ny * blockDim.x * <span class="hljs-number">2</span>];<br>        out[to + blockDim.x * <span class="hljs-number">3</span>] = in[ti + ny * blockDim.x * <span class="hljs-number">3</span>];<br>    }<br>}<br></code></pre></td></tr></table></figure><p>进行性能测试，总结如下。</p><table><thead><tr class="header"><th>核函数</th><th>带宽（GB/s）</th><th>加载吞吐量（GB/s）</th><th>存储吞吐量（GB/s）</th><th>加载效率（%）</th><th>存储效率（%）</th><th>备注</th></tr></thead><tbody><tr class="odd"><td><code>Unroll4Row</code></td><td>72.88</td><td>117.29</td><td>469.16</td><td>100</td><td>25</td><td>合并读取，交叉存储，展开</td></tr><tr class="even"><td><code>Unroll4Col</code></td><td>324.44</td><td>1843.45</td><td>465.67</td><td>25</td><td>100</td><td>交叉读取，合并存储，展开</td></tr></tbody></table><p>启用一级缓存，并展开后，可以观察到<code>Unroll4Col</code>的加载吞吐量有了质的提升。</p><h4 id="对角转置">对角转置</h4><p>当启动一个线程块网格时，线程块会被分配给SM。虽然编程模型可能将网格抽象成一维、二维或三维，但在硬件看来所有块都是一维的。当启动一个核函数时，线程块被分配给SM的顺序由块ID来确定。一开始可能还会以顺序来分配线程块，直到所有SM被完全占满。由于线程块完成的速度和顺序是不确定的，随着核函数的执行，活跃的线程块ID将变得不太连续。</p><p>虽然无法直接调控线程块的顺序，但可以利用对角坐标来间接调控，下图展示了直角坐标与对角坐标的区别。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/eeb536e8-ace6-494b-8e52-72ac1016e711"></p><p>可以利用对角坐标来确定线程块的ID，但仍需要直角坐标来访问数据。将<code>blockIdx.x</code>和<code>blockIdx.y</code>当作对角坐标后，对于方阵来说，可以用如下映射关系来访问正确的数据块。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">blk_x</span> = (blockIdx.x + blockIdx.y) % gridDim.x<span class="hljs-comment">;</span><br><span class="hljs-attr">blk_y</span> = blockIdx.x<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>这里的<code>blk_x</code>和<code>blk_y</code>即为线程块对应的直角坐标。下面分别实现行读列写和列读行写的对角转置核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeDiagonalRow</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_y = blockIdx.x;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockDim.x * blk_x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockDim.y * blk_y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[ix * ny + iy] = in[iy * nx + ix];<br>}<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transposeDiagonalCol</span><span class="hljs-params">(<span class="hljs-type">float</span> *out, <span class="hljs-type">float</span> *in, <span class="hljs-type">const</span> <span class="hljs-type">int</span> nx, <span class="hljs-type">const</span> <span class="hljs-type">int</span> ny)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> blk_y = blockIdx.x;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockDim.x * blk_x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockDim.y * blk_y + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)<br>        out[iy * nx + ix] = in[ix * ny + iy];<br>}<br></code></pre></td></tr></table></figure><p>性能测试结果如下。</p><table><thead><tr class="header"><th>核函数</th><th>带宽（GB/s）</th><th>加载吞吐量（GB/s）</th><th>存储吞吐量（GB/s）</th><th>加载效率（%）</th><th>存储效率（%）</th><th>备注</th></tr></thead><tbody><tr class="odd"><td><code>DiagonalRow</code></td><td>330.99</td><td>133.47</td><td>533.90</td><td>100</td><td>25</td><td>合并读取，交叉存储，对角</td></tr><tr class="even"><td><code>DiagonalCol</code></td><td>910.22</td><td>592.08</td><td>148.02</td><td>25</td><td>100</td><td>交叉读取，合并存储，对角</td></tr></tbody></table><p>通过使用对角坐标来修改线程块的执行顺序，使得基于行读列写的核函数性能大幅度提升，但列读行写的核函数没有什么提升。对角核函数的实现依然可以使用展开技术来优化，但不像直角坐标那样直观。</p><p>这种性能的提升与DRAM的并行访问有关。核函数发起的全局内存请求由DRAM分区完成，设备内存中连续的256字节区域被分配到连续的分区。当使用直角坐标线程块时，全局内存的访问无法被均匀分配到DRAM的分区中，就可能发生分区冲突。进而导致内存请求在某些分区中排队，而某些分区一直未被调用。由于对角坐标是一种线程块与数据块之间的非线性映射，所以交叉访问不太可能会落入同一个分区中，进而带来了性能的提升。</p><h4 id="使用瘦块增加并行性">使用瘦块增加并行性</h4><p>对之前实现的列读行写的朴素转置进行测试，分别使用不同的块大小设计，测试结果如下。</p><table><thead><tr class="header"><th>核函数</th><th>块大小</th><th>带宽（GB/s）</th><th>加载吞吐量（GB/s）</th><th>存储吞吐量（GB/s）</th><th>加载效率（%）</th><th>存储效率（%）</th></tr></thead><tbody><tr class="odd"><td><code>NaiveCol</code></td><td>(32, 32)</td><td>491.14</td><td>1073.98</td><td>133.64</td><td>12.5</td><td>100</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>(32, 16)</td><td>718.69</td><td>1076.43</td><td>133.88</td><td>12.5</td><td>100</td></tr><tr class="odd"><td><code>NaiveCol</code></td><td>(32, 8)</td><td>739.48</td><td>872.00</td><td>109.00</td><td>12.5</td><td>100</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>(16, 32)</td><td>1061.31</td><td>778.74</td><td>194.69</td><td>25</td><td>100</td></tr><tr class="odd"><td><code>NaiveCol</code></td><td>(16, 16)</td><td>963.76</td><td>583.35</td><td>145.84</td><td>25</td><td>100</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>(16, 8)</td><td>910.22</td><td>432.14</td><td>108.03</td><td>25</td><td>100</td></tr><tr class="odd"><td><code>NaiveCol</code></td><td>(8, 32)</td><td>1057.03</td><td>410.24</td><td>205.12</td><td>50</td><td>100</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>(8, 16)</td><td>1064.54</td><td>327.78</td><td>163.89</td><td>50</td><td>100</td></tr><tr class="odd"><td><code>NaiveCol</code></td><td>(8, 8)</td><td>731.22</td><td>233.07</td><td>116.53</td><td>50</td><td>100</td></tr></tbody></table><p>性能最佳的为<code>(16, 32)</code>、<code>(8, 32)</code>和<code>(8, 16)</code>的块，这种性能提升是由瘦块带来的。可以观察到<code>(8, 32)</code>的存储吞吐量是最高的。</p><p>我们进一步测试<code>(8, 32)</code>的块在各个核函数下的性能表现。</p><table><thead><tr class="header"><th>核函数</th><th>块大小</th><th>带宽（GB/s）</th><th>加载吞吐量（GB/s）</th><th>存储吞吐量（GB/s）</th><th>加载效率（%）</th><th>存储效率（%）</th><th>备注</th></tr></thead><tbody><tr class="odd"><td><code>CopyRow</code></td><td>(8, 32)</td><td>1071.06</td><td>206.66</td><td>206.66</td><td>100</td><td>100</td><td>合并读取，合并存储</td></tr><tr class="even"><td><code>CopyCol</code></td><td>(8, 32)</td><td>1057.03</td><td>422.47</td><td>422.47</td><td>50</td><td>50</td><td>交叉读取，交叉存储</td></tr><tr class="odd"><td><code>NaiveRow</code></td><td>(8, 32)</td><td>627.13</td><td>197.70</td><td>395.39</td><td>100</td><td>50</td><td>合并读取，交叉存储</td></tr><tr class="even"><td><code>NaiveCol</code></td><td>(8, 32)</td><td>1097.98</td><td>426.77</td><td>213.39</td><td>50</td><td>100</td><td>交叉读取，合并存储</td></tr><tr class="odd"><td><code>Unroll4Row</code></td><td>(8, 32)</td><td>138.26</td><td>239.83</td><td>479.65</td><td>100</td><td>50</td><td>合并读取，交叉存储，展开</td></tr><tr class="even"><td><code>Unroll4Col</code></td><td>(8, 32)</td><td>341.33</td><td>1236.83</td><td>598.49</td><td>50</td><td>100</td><td>交叉读取，合并存储，展开</td></tr></tbody></table><p>笔者的测试结果与书中有所不同，书中测试结果最好的是<code>Unroll4Col</code>，但笔者这里最好的是<code>NaiveCol</code>。但从加载吞吐量来说，的确是<code>Unroll4Col</code>最优秀。</p><h2 id="使用统一内存的矩阵加法">使用统一内存的矩阵加法*</h2><p>用统一内存的方式实现矩阵加法，可以提高代码的可读性和易维护性，消除所有的显式内存副本。</p><blockquote><p>具体代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/11_matrix_sum_managed.cu">matrix_sum_managed.cu</a>和<a href="https://github.com/Deleter-D/CUDA/blob/master/03_global_memory/12_matrix_sum_manual.cu">matrix_sum_manual.cu</a>。</p></blockquote><p>性能测试结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sum</span> matrix managed&lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">17</span>.<span class="hljs-number">284096</span> ms<br><span class="hljs-attribute">sum</span> matrix manual&lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">0</span>.<span class="hljs-number">470016</span> ms<br></code></pre></td></tr></table></figure><p>可以观察到，虽然使用统一内存减少了编程的工作量，但性能却大幅度下降。更具体的性能测试如下。</p><table><thead><tr class="header"><th>任务</th><th>使用托管内存（ms）</th><th>不使用托管内存（ms）</th></tr></thead><tbody><tr class="odd"><td>数据初始化</td><td>355.60</td><td>354.77</td></tr><tr class="even"><td>CPU侧计算</td><td>7.07</td><td>15.02</td></tr><tr class="odd"><td>CUDA memcpy HtoD</td><td>14.73</td><td>10.16</td></tr><tr class="even"><td>GPU侧计算（核函数）</td><td>19.90</td><td>0.50</td></tr><tr class="odd"><td>CUDA memcpy DtoH</td><td>2.90</td><td>4.92</td></tr></tbody></table><p>可以观察到，在使用托管内存的情况下，<code>HtoD</code>任务要花费更长的时间，核函数计算也需要更长的时间。</p><blockquote><p>有趣的一点是，在关于数据初始化耗时的测试结果上，笔者与书中的描述相差甚远。在书中，使用托管内存的情况下，数据初始化的耗时要大于不使用托管内存的情况，但笔者的两种方式却相差无几。通过这一点可以看到CUDA在统一内存方面的优化痕迹。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——执行模型</title>
    <link href="https://deleter-d.github.io/posts/47225/"/>
    <id>https://deleter-d.github.io/posts/47225/</id>
    <published>2024-02-20T08:02:16.000Z</published>
    <updated>2024-03-23T07:24:06.548Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="cuda运行时">CUDA运行时</h2><p><code>cudart</code>库是CUDA运行时的实现，该库可以通过<code>cudart.lib</code>或<code>libcudart.a</code>静态链接到程序中，也可以通过<code>cudart.dll</code>或<code>libcudart.so</code>动态链接。需要动态链接的该库的程序，通常将<code>cudart.dll</code>或<code>libcudart.so</code>作为程序安装包的一部分。</p><p>只有在链接到同一个CUDA运行时实例的组件之间传递CUDA运行时符号地址才是安全的。</p><p>该库的所有API均带有<code>cuda</code>前缀。</p><h3 id="初始化">初始化</h3><p>从CUDA 12.0开始，<code>cudaInitDevice()</code>和<code>cudaSetDevice()</code>调用会初始化与指定设备关联的运行时和主上下文。如不进行这些调用，运行时会隐式地使用设备0，并按需进行自初始化来执行其他运行时API请求。</p><p>在CUDA 12.0之前，<code>cudaSetDevice()</code>不会初始化运行时，程序通常使用空操作运行时调用<code>cudaFree(0)</code>，将运行时初始化与其他API活动隔离开。</p><p>运行时将会为每个设备创建一个CUDA上下文，称之为主上下文（primary context）。该上下文将在调用第一个需要活动上下文的运行时函数时被初始化。主机端的所有线程共享该上下文。在创建上下文过程中，必要情况下会将设备代码即时编译并加载到设备内存中</p><p>当主机线程调用<code>cudaDeviceReset()</code>时，将销毁该线程当前操作设备的主上下文。任何拥有该设备的主机线程进行下一个运行时函数调用时，将为该设备创建一个新的主上下文。</p><h2 id="cuda执行模型概述">CUDA执行模型概述</h2><h3 id="gpu架构概述">GPU架构概述</h3><p>GPU是围绕流式多处理器（SM）的可扩展阵列搭建的，通过复制这种架构的构建块来实现GPU的硬件并行。</p><p>SM的核心组件如下：</p><ul><li>CUDA核心；</li><li>共享内存 / 一级缓存；</li><li>寄存器文件；</li><li>加载 / 存储单元；</li><li>特殊功能单元；</li><li>线程束调度器。</li></ul><p>每个SM可以支持数百个线程并发执行，每个GPU通常有多个SM，所以一个GPU上并发执行数千个线程是有可能的。启动一个核函数时，线程块被分配在了可用的SM上，线程块一旦被调度到一个SM上，其中的线程只会在当前的SM上执行。多个线程块可能被分配在同一个SM上，是根据SM资源的可用性进行调度的。同一线程值的指令利用指令级并行性进行流水线化。</p><p>CUDA采用单指令多线程（SIMT）架构来管理和执行线程，每32个线程为一组，成为线程束（warp）。</p><p>在并行线程中共享数据可能会引起竞争，CUDA提供了一种用来同步线程块内线程的方法，但没有提供块间同步的原语。</p><p>虽然线程块内的线程束可以任意顺序调度，但活跃的线程束仍会受到SM资源的限制。当线程束闲置时，SM可以从同一SM上的常驻线程块中调度其他可用的线程束。在并发的线程束之间切换没有开销，因为硬件资源已经被分配到了SM上的所有线程和块中。</p><h2 id="线程束的本质">线程束的本质</h2><h3 id="线程束和线程块">线程束和线程块</h3><p>线程束是SM中基本的执行单元。一旦线程块被调度到一个SM上，线程块中的线程会被进一步划分为线程束。一个线程束由32个连续的线程组成，在一个线程束中，所有的线程按照SIMT方式执行。</p><p>虽然线程块可以组织为一维、二维或三维的，但从硬件角度看，所有线程都被组织成了一维的。例如有一个128线程的一维线程块，它将被组织进4个线程束中，如下所示。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Warp</span> <span class="hljs-number">0</span>: thread  <span class="hljs-number">0</span>, thread  <span class="hljs-number">1</span>, thread  <span class="hljs-number">2</span>, ... thread <span class="hljs-number">31</span><br><span class="hljs-attribute">Warp</span> <span class="hljs-number">1</span>: thread <span class="hljs-number">32</span>, thread <span class="hljs-number">33</span>, thread <span class="hljs-number">34</span>, ... thread <span class="hljs-number">63</span><br><span class="hljs-attribute">Warp</span> <span class="hljs-number">2</span>: thread <span class="hljs-number">64</span>, thread <span class="hljs-number">65</span>, thread <span class="hljs-number">66</span>, ... thread <span class="hljs-number">95</span><br><span class="hljs-attribute">Warp</span> <span class="hljs-number">3</span>: thread <span class="hljs-number">96</span>, thread <span class="hljs-number">97</span>, thread <span class="hljs-number">98</span>, ... thread <span class="hljs-number">127</span><br></code></pre></td></tr></table></figure><p>二维、三维的线程块是同理的，只需要计算出其唯一线程ID即可。</p><p>一个线程块的线程束数量由下式确定。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="46.513ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 20558.6 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(556,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(834,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1334,0)"></path><path data-c="6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z" transform="translate(1778,0)"></path></g><g data-mml-node="mi" transform="translate(2306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(3306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mtext" transform="translate(4306,0)"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(722,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1222,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1614,0)"></path></g><g data-mml-node="mi" transform="translate(6476,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(7476,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g><g data-mml-node="mo" transform="translate(8753.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(9809.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="2308" d="M246 -949V1450H571V1388H308V-949H246Z"></path></g><g data-mml-node="mfrac" transform="translate(583,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mtext"><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(556,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(834,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1334,0)"></path><path data-c="6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z" transform="translate(1778,0)"></path></g><g data-mml-node="mi" transform="translate(2306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(3306,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mtext" transform="translate(4306,0)"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1337,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1781,0)"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(2281,0)"></path></g><g data-mml-node="mi" transform="translate(7143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(8143,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g><g data-mml-node="mrow" transform="translate(2706.5,-710)"><g data-mml-node="mtext"><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(722,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1222,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1614,0)"></path></g><g data-mml-node="mi" transform="translate(2170,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">大</text></g><g data-mml-node="mi" transform="translate(3170,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g></g><rect width="9343" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10166,0) translate(0 -0.5)"><path data-c="2309" d="M11 1388V1450H336V-949H274V1388H11Z"></path></g></g></g></g></svg></mjx-container></span> 线程束不会在不同的线程块之间分离，若线程块的大小不是线程束大小的整数倍，则在最后的线程束中会有些线程处于不活跃状态。例如有一个二维的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="6.159ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 2722.4 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></svg></mjx-container></span>的线程块，他会被分配在3个线程束中，最后一个线程束的后半段是不活跃的，但依然会占用SM的资源。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/25ef389c-18fd-4810-bc4a-bcfe47c374a5"></p><h3 id="线程束分化">线程束分化</h3><p>首先要注意一点，一个线程束中的所有线程在同一周期内必须执行相同的指令。考虑下列语句：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (cond) {<br>    ...<br>} <span class="hljs-keyword">else</span> {<br>    ...<br>}<br></code></pre></td></tr></table></figure><p>假设在一个线程束中，有16个线程的<code>cond</code>为<code>true</code>，另外16个线程为<code>false</code>。此时，一半的线程需要执行<code>if</code>语句块中的指令，另一半需要执行<code>else</code>中的指令。这种在同一线程束中的线程执行不同指令的现象，被称为线程束分化。</p><p>当发生线程束分化时，线程束将连续执行每个分支路径，同时禁用不执行这一路径的线程，这会导致性能明显下降。条件分支越多，并行性削弱越严重。</p><blockquote><p>线程束分化只发生在同一线程束中，不同线程束的不同条件值不会引起线程束分化。</p></blockquote><p>这里引入一个概念，分支效率，即未分化分支与全部分支之比。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="43.417ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 19190.4 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">效</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g><g data-mml-node="mo" transform="translate(4277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5333.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(7055.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mrow" transform="translate(8056,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(3222.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mtext" transform="translate(4222.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">化</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g></g><g data-mml-node="mtext" transform="translate(3331.2,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">支</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g><rect width="9422.4" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10398.4,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg></mjx-container></span> 设想以下三种情况：</p><ul><li>情况一：线程ID为偶数的执行<code>if</code>，线程ID为奇数的执行<code>else</code>；</li><li>情况二：线程束ID为偶数的执行<code>if</code>， 线程束ID为奇数的执行<code>else</code>；</li><li>情况三：线程ID为偶数的执行<code>if</code>，线程ID为奇数的执行另一个<code>if</code>。</li></ul><p>具体到代码即为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 线程ID为偶数的执行if，线程ID为奇数的执行else</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">mathKernel1</span><span class="hljs-params">(<span class="hljs-type">float</span> *c)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> a, b;<br>    a = b = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">if</span> (tid % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>)<br>        a = <span class="hljs-number">100.0f</span>;<br>    <span class="hljs-keyword">else</span><br>        b = <span class="hljs-number">200.0f</span>;<br>    c[tid] = a + b;<br>}<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 线程束ID为偶数的执行if， 线程束ID为奇数的执行else</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">mathKernel2</span><span class="hljs-params">(<span class="hljs-type">float</span> *c)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> a, b;<br>    a = b = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">if</span> ((tid / warpSize) % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>)<br>        a = <span class="hljs-number">100.0f</span>;<br>    <span class="hljs-keyword">else</span><br>        b = <span class="hljs-number">200.0f</span>;<br>    c[tid] = a + b;<br>}<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 线程ID为偶数的执行if，线程ID为奇数的执行另一个if</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">mathKernel3</span><span class="hljs-params">(<span class="hljs-type">float</span> *c)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">float</span> a, b;<br>    a = b = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-type">bool</span> ipred = (tid % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">if</span> (ipred)<br>        a = <span class="hljs-number">100.0f</span>;<br>    <span class="hljs-keyword">if</span> (!ipred)<br>        b = <span class="hljs-number">200.0f</span>;<br>    c[tid] = a + b;<br>}<br></code></pre></td></tr></table></figure><p>调用这三个核函数，使用<code>ncu</code>来统计分支效率，结果如下所示。</p><table><thead><tr class="header"><th></th><th>分支效率</th></tr></thead><tbody><tr class="odd"><td><code>mathKernel1(float *) (1, 1, 1)x(64, 1, 1)</code></td><td>80%</td></tr><tr class="even"><td><code>mathKernel2(float *) (1, 1, 1)x(64, 1, 1)</code></td><td>100%</td></tr><tr class="odd"><td><code>mathKernel3(float *) (1, 1, 1)x(64, 1, 1)</code></td><td>71.43%</td></tr></tbody></table><blockquote><p>为了阅读方便，这里简化了<code>ncu</code>的输出信息，实际的输出比上述形式要丰富，后续的<code>ncu</code>分析结果也以同样的方式简化。</p></blockquote><p>可以观察到，情况一由于发生了分支分化，导致分支效率降低。而情况二由于分支分化的粒度是线程束大小的整倍数，所以分支效率统计为100%。情况三在情况一的前提下改造为了两个<code>if</code>，这样可以使得分化分支的数量翻倍。</p><blockquote><p>分化分支数量翻倍但效率没有降低至一半是因为，虽然在编译时加上了<code>-G</code>参数来阻止分支预测优化，但还有其他优化手段，以保证分支效率在50%以上。</p><p>详细代码示例参考<a href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/01_warp_divergence.cu">warp_divergence.cu</a></p></blockquote><h3 id="资源分配">资源分配</h3><p>线程束的本地执行上下文主要由以下资源组成：</p><ul><li>程序计数器；</li><li>寄存器；</li><li>共享内存。</li></ul><p>由SM处理的每个线程束的执行上下文，在整个线程束的生存期中是保存在芯片内的。所以从一个执行上下文切换到另一个执行上下文没有损失。对于一个给定的核函数，同时存在于同一个SM中的线程块和线程束的数量，取决于在SM中可用的与核函数所需的寄存器和共享内存数量。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/49674a9f-2a18-4eae-ae62-0f70dddc6046"></p><p>如上图所示，每个线程消耗的寄存器较少，同一SM上就可以多分配一些线程。同理，每个线程块消耗的共享内存较少，同一SM上就可以多分配一些线程块。</p><p>如果每个SM没有足够的寄存器或共享内存去处理至少一个块，那么核函数就无法启动。</p><p>当计算资源已经分配给线程块时，线程块被称为活跃的块。它所包含的线程束被称为活跃的线程束。活跃的线程束可以分为以下三种类型：</p><ul><li>选定的线程束：正在执行的活跃线程束；</li><li>阻塞的线程束：未准备好执行的线程束；</li><li>符合条件的线程束：准备执行但尚未执行的活跃线程束。</li></ul><p>同时满足以下两个条件则线程束符合执行条件：</p><ul><li>32个CUDA核心可用于执行；</li><li>当前指令中所有的参数都已就绪。</li></ul><h3 id="延迟隐藏">延迟隐藏</h3><p>指令延迟是指在指令发出和完成之间的时钟周期数。指令可以被分为两种基本类型：</p><ul><li>算术指令：一个算术操作从开始到产生输出之间的时钟周期，一般为10～20个周期；</li><li>内存指令：发送出的加载或存储操作和数据到达目的地之间的时钟周期，全局内存访问一般为400～800个周期。</li></ul><p>当每个时钟周期内所有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。在GPU中往往有着大量的线程，通过在其他常驻线程束中发布其他指令来隐藏指令延迟至关重要。</p><p>可以通过利特尔法则来估算隐藏延迟所需的活跃线程束数量。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="51.032ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 22556 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">所</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">需</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">线</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">程</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">束</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text><text data-variant="normal" transform="translate(6000,0) scale(1,-1)" font-size="884px" font-family="serif">量</text></g><g data-mml-node="mo" transform="translate(7277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(8333.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">指</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">令</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">平</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">均</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">延</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">迟</text></g><g data-mml-node="mo" transform="translate(14555.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(15556,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">欲</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">达</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">到</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">的</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">吞</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">吐</text><text data-variant="normal" transform="translate(6000,0) scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g></g></svg></mjx-container></span> 此处是一个粗略化的公式，并不是直接套用即可算出所需线程束数量，后面将具体的介绍如何运用该法则。</p><h4 id="算术延迟隐藏">算术延迟隐藏</h4><p>对于算术运算，所需的并行数可以表示为隐藏算术延迟所需的操作数量。</p><p>假设某个算术指令延迟为20个周期，我们想要令SM保持32个操作的吞吐量，即每个周期进行32次操作。根据上面提到的利特尔法则，我们可以得到所需并行数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="13.701ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 6056 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(3500.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(4556,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>，也就是说要保证程序中有640个该计算操作才能完全隐藏算术延迟。</p><p>我们再假设每个线程中仅执行一次该算术操作，则可以进一步得到线程束数量为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="13.701ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 6056 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5056,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>个。</p><p>观察上述例子会发现，算术延迟隐藏所需的并行数可以用操作数量来表示，也可以用线程束数量来表示。这表明我们可以有两个不同的层次来提高并行：</p><ul><li>指令级并行（ILP）：一个线程中有很多独立的指令；</li><li>线程级并行（TLP）：很多并发地符合条件的线程。</li></ul><h4 id="内存延迟隐藏">内存延迟隐藏</h4><p>对于内存操作，所需的并行数可以表示为在每个周期内隐藏内存延迟所需的字节数。</p><p>假设某个内存指令延迟为800个周期，我们想要令设备保持200GB/s的吞吐量，根据内存频率可以将吞吐量的单位由GB/s转换为B/CP（字节/周期）。笔者的设备内存频率为10.501GHz，所以转换后为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="33.509ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14811 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mtext" transform="translate(1500,0)"><path data-c="47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z" transform="translate(785,0)"></path><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z" transform="translate(1493,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(1993,0)"></path></g><g data-mml-node="mo" transform="translate(4109.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(5109.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(1000,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(1278,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1778,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(2278,0)"></path></g><g data-mml-node="mtext" transform="translate(7887.4,0)"><path data-c="47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path data-c="48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z" transform="translate(785,0)"></path><path data-c="7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z" transform="translate(1535,0)"></path></g><g data-mml-node="mo" transform="translate(10144.2,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mn" transform="translate(11200,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path></g><g data-mml-node="mtext" transform="translate(12200,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z" transform="translate(708,0)"></path><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z" transform="translate(1208,0)"></path><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(1930,0)"></path></g></g></g></svg></mjx-container></span>。接着根据利特尔法则，我们可以得到所需的并行数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="18.697ex" height="1.731ex" role="img" focusable="false" viewBox="0 -683 8264 765"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5056,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mtext" transform="translate(7556,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></g></g></g></svg></mjx-container></span>。</p><blockquote><p>使用如下命令来获取内存频率。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">nvidia-smi -a -q -d CLOCK | grep -A 3 <span class="hljs-string">"Max Clocks"</span> | grep <span class="hljs-string">"Memory"</span><br></code></pre></td></tr></table></figure></blockquote><p>我们再假设每个线程中仅从全局内存中读取一个浮点数到SM上用于计算，则根据并行数可以计算出所需的线程数，即<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="20.299ex" height="1.731ex" role="img" focusable="false" viewBox="0 -683 8972 765"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mtext" transform="translate(2500,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></g><g data-mml-node="mo" transform="translate(3430.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(4430.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mtext" transform="translate(4930.4,0)"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></g><g data-mml-node="mo" transform="translate(5916.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6972,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>个线程。进一步得到线程束数量为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.973ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7944 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2308" d="M174 734Q178 746 190 750H298H369Q400 750 411 747T422 730T411 713T372 709Q365 709 345 709T310 710H214V-235Q206 -248 196 -250Q192 -250 189 -249T184 -247T180 -244T178 -241T176 -237T174 -234V734Z"></path></g><g data-mml-node="mn" transform="translate(444,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g><g data-mml-node="mo" transform="translate(2666.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(3666.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4666.4,0)"><path data-c="2309" d="M21 717T21 730T32 746T75 750H147H256Q266 742 269 735V-235Q262 -248 251 -250Q247 -250 244 -249T239 -247T235 -244T233 -241T231 -237T229 -234V710H133Q119 710 99 710T71 709Q43 709 32 713Z"></path></g><g data-mml-node="mo" transform="translate(5388.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6444,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>个。若每个线程执行多个独立的4字节加载，则隐藏内存延迟所需的线程就可以更少。</p><blockquote><p>上述计算出的线程束数量只是下界，也就是说在相同假设下，提供更多的线程数量同样能够达到延迟隐藏的效果。</p></blockquote><h3 id="占用率">占用率</h3><p>占用率是每个SM中活跃的线程束占最大线程束数量的比值。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex;" xmlns="http://www.w3.org/2000/svg" width="26.637ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 11773.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">占</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">率</text></g><g data-mml-node="mo" transform="translate(3277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4333.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">活</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">跃</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">线</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">程</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">束</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">大</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">线</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">程</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">量</text></g></g><rect width="7200" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span> 最大线程束数量可以通过<code>cudaGetDeviceProperties()</code>获取到设备属性后，由其成员<code>maxThreadsPerMultiProcessor / 32</code>取得。详细代码参考<a href=""></a>，笔者的设备获取到的结果如下所示。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Device</span> <span class="hljs-number">0</span>: NVIDIA GeForce RTX <span class="hljs-number">4070</span><br><span class="hljs-attribute">Number</span> of multiprocessors: <span class="hljs-number">46</span><br><span class="hljs-attribute">Total</span> amount of constant memory: <span class="hljs-number">64</span>.<span class="hljs-number">00</span> KB<br><span class="hljs-attribute">Total</span> amount of shared memory per block: <span class="hljs-number">48</span>.<span class="hljs-number">00</span> KB<br><span class="hljs-attribute">Total</span> amount of registers available per block: <span class="hljs-number">65536</span><br><span class="hljs-attribute">Warp</span> size: <span class="hljs-number">32</span><br><span class="hljs-attribute">Maximum</span> number of threads per block: <span class="hljs-number">1024</span><br><span class="hljs-attribute">Maximum</span> number of threads per multiprocessor: <span class="hljs-number">1536</span><br><span class="hljs-attribute">Maximum</span> number of warps per multiprocessor: <span class="hljs-number">48</span><br></code></pre></td></tr></table></figure><p>CUDA官方以前提供一个占用率计算器，是一个Excel表格，可以填入一些核函数资源信息后，自动计算SM占用率。但目前在官网已经找不到该文件的下载途径了，可能是因为当前最新的设备已经不适合用这种方式来计算占用率了。</p><blockquote><p>若想体验该计算器，笔者在Github上找到一个项目，提供相同的功能，但该项目仅支持计算能力8.6及以前的设备，CUDA版本仅支持11.0和11.1两个版本，链接：<a href="http://karthikeyann.github.io/cuda-calculator/">cuda-calculator</a>。</p></blockquote><p>为了提高占用率，需要调整线程块配置或重新调整资源的使用情况，以允许更多的线程束同时处于活跃状态并提高计算资源的利用率。要避免极端的情况：</p><ul><li>线程块过小：每个块中的线程太少，会在所有资源被充分利用之前导致硬件达到每个SM的线程束数量限制；</li><li>线程块过大：每个块中的线程太多，会导致SM中每个线程可用的硬件资源较少。</li></ul><h3 id="同步">同步</h3><p>CUDA中提供了两个级别的同步原语：</p><ul><li>系统级别：等待主机和设备完成所有工作；</li><li>块级别：在设备执行过程中等待一个线程块中所有线程到达同一点。</li></ul><p>系统级别的同步通过<code>cudaDeviceSynchronize()</code>API实现，块级别的同步通过<code>__syncthreads()</code>实现。线程块中要注意避免各种访存冲突，例如读后写、写后读、写后写等。</p><p>不同块之间没有线程同步，实现块间同步可以通过全局变量+原子操作的方式实现。从CUDA 9.x开始提供了协作组的概念，<code>cooperative_groups::grid_group</code>下有一个<code>sync()</code>函数可以提供块间同步的功能。关于块间同步这里不过多展开。</p><h3 id="可扩展性">可扩展性</h3><p>能够在可变数量的计算核心上执行相同代码的能力被成为透明可扩展性。拥有这种能力的平台能够避免不同的硬件产生的变化，减轻了开发者的负担。</p><p>可扩展性比效率更重要，一个可扩展但效率很低的系统可以通过简单添加硬件核心来处理更大的工作负载，一个效率很高但不可扩展的系统可能很快就会达到性能上限。</p><p>CUDA核函数启动时，线程块分布在多个SM中，网格中的线程块以并行或连续或任意的顺序执行。这种独立性使得CUDA程序可以在任意数量的计算核心间扩展。</p><h2 id="并行性表现">并行性表现</h2><p>定义一个二维矩阵求和的核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sumMatrixOnGPU2D</span><span class="hljs-params">(<span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">int</span> NX, <span class="hljs-type">int</span> NY)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ix = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iy = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = iy * NX + ix;<br><br>    <span class="hljs-keyword">if</span> (ix &lt; NX &amp;&amp; iy &lt; NY)<br>        C[idx] = A[idx] + B[idx];<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/03_parallelism.cu">parallelism.cu</a>。</p></blockquote><h3 id="检测活跃线程束">检测活跃线程束</h3><p>我们利用不同的线程块大小设计来执行上面的核函数，统计核函数执行事件，并使用<code>ncu</code>分析不同情况下的占用率。</p><blockquote><p>这里的占用率指的是：每周期内活跃线程束的平均数量与一个SM支持的线程束最大数量的比值。</p></blockquote><p>这里对线程块采用四种不同的设计：<code>(32, 32)</code>、<code>(32, 16)</code>、<code>(16, 32)</code>、<code>(16, 16)</code>，得到的分析结果如下所示。</p><p>核函数耗时情况如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">0817</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">512</span>, <span class="hljs-number">1024</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">16</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">02669</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03258</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03968</span> ms<br></code></pre></td></tr></table></figure><p>占用率分析结果如下。</p><table><thead><tr class="header"><th></th><th>占用率</th></tr></thead><tbody><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt;</code></td><td>48.07%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt;</code></td><td>59.31%</td></tr><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt;</code></td><td>63.41%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt;</code></td><td>67.98%</td></tr></tbody></table><p>观察上述结果：</p><ul><li>情况二<code>(32, 16)</code>中的线程块比情况一<code>(32, 32)</code>更多，所以设备可以有更多活跃的线程束，是其占用率更高可能的原因之一；</li><li>情况四<code>(16, 16)</code>的占用率最高，但并不是最快的，因此，更高的占用率并不一定代表更高的性能。</li></ul><h3 id="检测内存操作">检测内存操作</h3><p>上面提到的矩阵求和的核函数中有三个内存操作，两次加载和一次存储。同样使用<code>ncu</code>来分析核函数的内存读取效率和全局加载效率，分析结果如下。</p><blockquote><p>全局加载效率指的是被请求的全局加载吞吐量占所需的全局加载吞吐量的比值，它衡量了程序的加载操作利用设备内存带宽的程度。</p></blockquote><table><thead><tr class="header"><th></th><th>内存读取效率</th><th>全局加载效率</th></tr></thead><tbody><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt;</code></td><td>296.77 GB/s</td><td>100%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt;</code></td><td>297.72 GB/s</td><td>100%</td></tr><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt;</code></td><td>295.40 GB/s</td><td>100%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt;</code></td><td>297.79 GB/s</td><td>100%</td></tr></tbody></table><p>如果阅读过《CUDA C编程权威指南》一书中的相关介绍，会发现我们这里得到的分析结果与书中提到的截然不同。书中描述的情况三和情况四下，全局加载效率会有明显的下降。但这里不同的线程块设计并没有导致太大的内存操作性能波动，笔者推测是因为nvcc编译器在这方面做了比以前更多的优化，来保证线程在SM中的调度更加合理。</p><p>根据书中的描述，在一节分析到的结果是，对网格和线程块的启发式算法来说，最内层的维数（<code>block.x</code>）应该是线程束大小的整倍数，这一结论还是有参考意义的。</p><h3 id="增大并行性">增大并行性</h3><p>我们来探讨一个问题，根据上一节得到的结论，继续增加<code>block.x</code>会增大吞吐量吗？同样是利用上一节中的例子，使用不同的线程块设计来执行核函数。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">256</span>, <span class="hljs-number">8192</span>), (<span class="hljs-number">64</span>, <span class="hljs-number">2</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03245</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">256</span>, <span class="hljs-number">4096</span>), (<span class="hljs-number">64</span>, <span class="hljs-number">4</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">05654</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">256</span>, <span class="hljs-number">2048</span>), (<span class="hljs-number">64</span>, <span class="hljs-number">8</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">02928</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">8192</span>), (<span class="hljs-number">128</span>, <span class="hljs-number">2</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03757</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">4096</span>), (<span class="hljs-number">128</span>, <span class="hljs-number">4</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03094</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">128</span>, <span class="hljs-number">2048</span>), (<span class="hljs-number">128</span>, <span class="hljs-number">8</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">04643</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">64</span>, <span class="hljs-number">8192</span>), (<span class="hljs-number">256</span>, <span class="hljs-number">2</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">10362</span> ms<br><span class="hljs-attribute">sumMatrixOnGPU2D</span> &lt;&lt;&lt;(<span class="hljs-number">64</span>, <span class="hljs-number">4096</span>), (<span class="hljs-number">256</span>, <span class="hljs-number">4</span>)&gt;&gt;&gt; elapsed <span class="hljs-number">7</span>.<span class="hljs-number">03165</span> ms<br></code></pre></td></tr></table></figure><p>虽然笔者这里的测试结果差距并不明显，不必过多纠结，了解思想即可。</p><p>分析结果可以得出几条规律：</p><ul><li>情况一<code>(64, 2)</code>中启动的线程块数量最多，但并不是速度最快的；</li><li>情况二<code>(64, 4)</code>与情况四<code>(128, 2)</code>相比，两者有相同数量的线程块（<code>(256, 4096)</code>与<code>(128, 8192)</code>），但情况四的表现优于情况二。这恰好印证了前一节中的结论，线程块最内层的维数对性能起着关键作用；</li><li>除了情况一、二、四外，其余情况的线程块数量均比最优情况少。故增大并行性是性能优化的一个重要因素。</li></ul><p>接下来分析上述各个情况的占用率，分析方法同之前的<a href="#检测活跃线程束">检测活跃线程束</a>。分析结果如下。</p><table><thead><tr class="header"><th></th><th>占用率</th></tr></thead><tbody><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(256, 8192), (64, 2)&gt;&gt;&gt;</code></td><td>82.38%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(256, 4096), (64, 4)&gt;&gt;&gt;</code></td><td>73.27%</td></tr><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(256, 2048), (64, 8)&gt;&gt;&gt;</code></td><td>61.94%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(128, 8192), (128, 2)&gt;&gt;&gt;</code></td><td>79.33%</td></tr><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(128, 4096), (128, 4)&gt;&gt;&gt;</code></td><td>64.16%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(128, 2048), (128, 8)&gt;&gt;&gt;</code></td><td>50.34%</td></tr><tr class="odd"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(64, 8192), (256, 2)&gt;&gt;&gt;</code></td><td>73.05%</td></tr><tr class="even"><td><code>sumMatrixOnGPU2D &lt;&lt;&lt;(64, 4096), (256, 4)&gt;&gt;&gt;</code></td><td>52.63%</td></tr></tbody></table><p>书中描述的情况一<code>(64, 2)</code>是占用率最低的情况，因为线程块是最多的，触及到了书作者当时的硬件瓶颈。但在笔者的环境下，情况一反而占用率是最高的，这也体现了硬件进步带来的效果。</p><p>虽然与书中描述的情况有所不同，但这也恰恰印证了提高并行性的重要程度，当硬件资源不再是限制和瓶颈的时候，更大的并行程度将带来更高的性能。</p><p>经过上面一系列的分析我们能够发现，性能最好的线程块设计，既没有最高的占用率，也没有最高的加载吞吐量。<strong>可见，没有一个单独的指标可以直接优化性能，我们需要在几个相关的指标之间寻找一个平衡来获得全局最优性能。</strong></p><h2 id="避免分支分化">避免分支分化</h2><h3 id="并行归约问题">并行归约问题</h3><p>一般的并行求和是将较多的数据分块计算，每个线程负责一个数据块的求和，再对每个数据块的和求和即为最终结果。一个常用方法是使用迭代成对实现，一个数据块只包含一对元素，每个线程求得这对元素的和，作为下一次迭代的输入。当输出向量长度为1时，表明最终结果已经被计算出来了。</p><p>成对的并行求和可以进一步分为两种类型：</p><ul><li>相邻配对：元素与它们相邻的元素配对；</li><li>交错配对：根据给定的步长配对元素。</li></ul><p><img src="https://github.com/Deleter-D/Images/assets/56388518/1cb84e0d-3bff-4d8e-8014-eccf15ef7f19"></p><p>虽然上述介绍的是加法，但任何满足交换律和结合律的运算都可以采用这种思路。</p><p>在向量中执行满足交换律和结合律的运算，被称为归约问题。并行归约问题是这种归约运算的并行执行。</p><h3 id="并行归约中的分化">并行归约中的分化</h3><p>首先实现一个相邻配对的并行归约求和核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceNeighbored</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + tid;<br><br>    <span class="hljs-comment">// 将全局数据指针转换为当前block的局部数据指针</span><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br><br>    <span class="hljs-comment">// 边界检查</span><br>    <span class="hljs-keyword">if</span> (idx &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-comment">// 在全局内存中原地归约</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = <span class="hljs-number">1</span>; stride &lt; blockDim.x; stride *= <span class="hljs-number">2</span>)<br>    {<br>        <span class="hljs-keyword">if</span> ((tid % (<span class="hljs-number">2</span> * stride)) == <span class="hljs-number">0</span>)<br>            idata[tid] += idata[tid + stride];<br>        __syncthreads(); <span class="hljs-comment">// 同步线程，保证下一轮迭代正确</span><br>    }<br><br>    <span class="hljs-comment">// 将当前block的结果写入全局内存</span><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure><p>两个相邻元素之间的距离成为步长（stride），初始化为1。每次归约循环后，步长被乘以2。由于块间同步很不方便，所以将每个块的求和结果拷贝回主机之后再进行串行求和。</p><p>具体求和过程如图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/bced3cb3-c047-4e97-9c44-126d312cf1ce"></p><p>测试后得到的性能如下所示。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">2122</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">628512</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><blockquote><p>这里采用一维网格与一维线程块，详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/04_reduction.cu">reduction.cu</a>，后面将以这个核函数的表现作为性能基准。这个<code>cu</code>文件将伴随整个<a href="#避免分支分化">避免分支分化</a>和<a href="#展开循环">展开循环</a>两个小节。</p></blockquote><h3 id="改善并行归约的分化">改善并行归约的分化</h3><p>注意上面核函数中的条件表达式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> ((tid % (<span class="hljs-number">2</span> * stride)) == <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>我们在前面也介绍过，这会导致非常严重的线程束分化。第一次迭代只有ID为偶数的线程是活跃的，第二次迭代就只有四分之一的线程活跃了，但那些不活跃的线程依旧会被调度。</p><p>改进这一现象的方法是强制ID相邻的线程执行求和操作，线程束分化就可以被归约了。将核函数修改为如下形式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceNeighboredLess</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> tid = threadIdx.x;<br>    <span class="hljs-type">unsigned</span> idx = blockIdx.x * blockDim.x + tid;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br><br>    <span class="hljs-keyword">if</span> (idx &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = <span class="hljs-number">1</span>; stride &lt; blockDim.x; stride *= <span class="hljs-number">2</span>)<br>    {<br>        <span class="hljs-comment">// 将tid转换为局部数组索引</span><br>        <span class="hljs-type">int</span> index = <span class="hljs-number">2</span> * stride * tid;<br>        <span class="hljs-keyword">if</span> (index &lt; blockDim.x)<br>            idata[index] += idata[index + stride];<br>        __syncthreads();<br>    }<br><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure><p>这样就将具体的运算过程变为了如下所示的状态。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/6f8f03cc-7ed9-40b2-a971-696e77bfc3a6"></p><p>虽然这种改进在一定程度上降低了线程束分化的程度，但在最后几轮迭代中，还是会存在线程束分化的情况。例如对于一个有512个线程的块来说，第一轮迭代由前8个线程束完成，后8个线程束不处于活跃状态。前几轮迭代都同理，但当最后五轮迭代中，活跃的线程数量小于线程束大小的时候，还是会发生线程束分化。</p><p>性能测试的表现如下所示。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">167</span> ms       cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">67648</span> ms      gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> neighboredL elapsed <span class="hljs-number">0</span>.<span class="hljs-number">424576</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>虽然在最后几轮还是会发生线程束分化，但依旧比不做任何处理快了1.6倍左右。我们可以利用<code>ncu</code>来分析每个线程束中执行的指令数量和内存读取效率来解释这种现象，分析结果如下所示。</p><table><colgroup><col style="width: 66%"><col style="width: 20%"><col style="width: 13%"></colgroup><thead><tr class="header"><th></th><th>每线程束执行指令数</th><th>内存读取效率</th></tr></thead><tbody><tr class="odd"><td><code>reduceNeighbored(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1)</code></td><td>341.94 inst/warp</td><td>690.98 GB/s</td></tr><tr class="even"><td><code>reduceNeighboredLess(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1)</code></td><td>115.38 inst/warp</td><td>1.27 TB/s</td></tr></tbody></table><p>可以观察到，在改善线程束分化后，每个线程束执行的指令数量大幅下降。而且拥有更大的加载吞吐量，因为虽然I/O操作数量相同，但耗时更短。</p><h3 id="交错配对的归约">交错配对的归约</h3><p>与相邻配对的方法相比，交错配对的方法反转了元素步长的变化，初始化为数据块大小的一半，然后每轮迭代减少一半。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceInterleaved</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + tid;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br><br>    <span class="hljs-keyword">if</span> (idx &gt;= size) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = blockDim.x / <span class="hljs-number">2</span>; stride &gt; <span class="hljs-number">0</span>; stride &gt;&gt;= <span class="hljs-number">1</span>)<br>    {<br>        <span class="hljs-keyword">if</span> (tid &lt; stride)<br>            idata[tid] += idata[tid + stride];<br>        __syncthreads();<br>    }<br><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure><p>具体运算过程如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/c6a05582-869a-471f-bdeb-059989948cf8"></p><p>性能测试表现如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">15</span>.<span class="hljs-number">991</span> ms       cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">676736</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> neighboredL elapsed <span class="hljs-number">0</span>.<span class="hljs-number">422176</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> interleaved elapsed <span class="hljs-number">0</span>.<span class="hljs-number">364032</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>虽然交错配对的方式与优化后的相邻配对方式拥有相同的线程束分化情况，但仍然有性能的提升。这种性能提升是由全局内存加载 / 存储模式导致的，在后续的文章中会进一步讨论。</p><h2 id="展开循环">展开循环</h2><p>循环展开是一种尝试减少分支出现频率和循环维护指令来优化循环的技术。在循环展开中，循环主体在代码中要多次编写，任何封闭循环都可以将它的迭代次数减少或完全消除。循环体的复制数量被成为循环展开因子，迭代次数以下列公式得到。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex;" xmlns="http://www.w3.org/2000/svg" width="31.162ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 13773.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">迭</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">代</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">次</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">数</text></g><g data-mml-node="mo" transform="translate(4277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(5333.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">原</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">始</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">循</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">环</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">迭</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">代</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">次</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">数</text></g></g><g data-mml-node="mrow" transform="translate(1220,-710)"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">循</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">环</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">展</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">开</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">因</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">子</text></g></g><rect width="8200" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span> 为了方便理解，观察如下示例。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++) {<br>    a[i] = b[i] + c[i];<br>}<br></code></pre></td></tr></table></figure><p>如果像下面这样重复一次循环体，迭代次数就可以减少一半。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i += <span class="hljs-number">2</span>) {<br>    a[i] = b[i] + c[i];<br>    a[i + <span class="hljs-number">1</span>] = b[i + <span class="hljs-number">1</span>] + c[i + <span class="hljs-number">1</span>];<br>}<br></code></pre></td></tr></table></figure><h3 id="展开的归约">展开的归约</h3><p>我们用上面的思路来将之前提到的交错配对的归约求和操作进行循环展开。</p><p>先将两个数据块汇聚到一个线程块中，每个线程作用于多个数据块，并处理每个数据块的一个元素。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceUnrolling2</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x * <span class="hljs-number">2</span> + tid;<br><br>    <span class="hljs-comment">// 与之前不同，这里将两个数据库汇总到一个线程块中</span><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x * <span class="hljs-number">2</span>;<br><br>    <span class="hljs-keyword">if</span> (idx + blockDim.x &lt; size)<br>        g_idata[idx] += g_idata[idx + blockDim.x];<br>    __syncthreads();<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> stride = blockDim.x / <span class="hljs-number">2</span>; stride &gt; <span class="hljs-number">0</span>; stride &gt;&gt;= <span class="hljs-number">1</span>)<br>    {<br>        <span class="hljs-keyword">if</span> (tid &lt; stride)<br>            idata[tid] += idata[tid + stride];<br>        __syncthreads();<br>    }<br><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>];<br>}<br></code></pre></td></tr></table></figure><p>比较关键的修改如下，每个线程都添加一个来自于相邻数据块的元素。可以把它作为归约循环的一个迭代，可以在数据块间进行归约。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (idx + blockDim.x &lt; size)<br>        g_idata[idx] += g_idata[idx + blockDim.x];<br></code></pre></td></tr></table></figure><p>然后调整全局数组索引，只需要一半的线程块来处理数据。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x * <span class="hljs-number">2</span> + tid;<br><span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x * <span class="hljs-number">2</span>;<br></code></pre></td></tr></table></figure><p>进行性能测试，结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">2422</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> interleaved elapsed <span class="hljs-number">0</span>.<span class="hljs-number">364096</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling2  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">28352</span> ms      gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">16384</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>可以观察到性能得到了进一步的提升，我们尝试进一步提高展开程度，性能测试结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> Size: <span class="hljs-number">16777216</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">16</span>.<span class="hljs-number">0142</span> ms      cpu_sum: <span class="hljs-number">206464799</span><br><span class="hljs-attribute">gpu</span> interleaved elapsed <span class="hljs-number">0</span>.<span class="hljs-number">364608</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">32768</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling2  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">281024</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">16384</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling4  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">262944</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">8192</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolling8  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">256736</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>可以观察到，在一个线程中有更多的独立内存操作会得到更好的性能，因为内存延迟可以得到很好的隐藏。我们利用<code>ncu</code>来分析设备内存读取吞吐量来解释性能提升的理由。</p><table><colgroup><col style="width: 76%"><col style="width: 23%"></colgroup><thead><tr class="header"><th></th><th>设备内存读取吞吐量</th></tr></thead><tbody><tr class="odd"><td><code>reduceInterleaved(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1)</code></td><td>187.98 GB/s</td></tr><tr class="even"><td><code>reduceUnrolling2(int *, int *, unsigned int) (16384, 1, 1)x(512, 1, 1)</code></td><td>293.78 GB/s</td></tr><tr class="odd"><td><code>reduceUnrolling4(int *, int *, unsigned int) (8192, 1, 1)x(512, 1, 1)</code></td><td>335.35 GB/s</td></tr><tr class="even"><td><code>reduceUnrolling8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1)</code></td><td>342.42 GB/s</td></tr></tbody></table><p>这里可以得到一个结论，归约的循环展开程度和设备读取吞吐量之间是成正比的。</p><h3 id="展开线程的归约">展开线程的归约</h3><p>上面提到过，当最后几轮迭代的时候，线程数量少于线程束大小时，线程束分化依旧会发生。由于线程束的执行时SIMT的模式，每条指令之后有隐式的线程束内同步。所以可以借助这一隐式同步，将最后几轮迭代用下列语句展开。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (tid &lt; <span class="hljs-number">32</span>)<br>{<br>    <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> *vmem = idata;<br>    vmem[tid] += vmem[tid + <span class="hljs-number">32</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">16</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">8</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">4</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">2</span>];<br>    vmem[tid] += vmem[tid + <span class="hljs-number">1</span>];<br>}<br></code></pre></td></tr></table></figure><blockquote><p>注意：变量<code>vmem</code>是被<code>volatile</code>修饰符修饰的，它告诉编译器每次赋值时必须将<code>vmem[tid]</code>的值存回全局内存中。如果省略了<code>volatile</code>修饰符，编译器或缓存可能优化对全局或共享内存的读写。若位于全局或共享内存中的变量有<code>volatile</code>修饰符，则编译器会假定其值可以被其他线程在任何时间修改或使用。故任何带有<code>volatile</code>修饰符的变量会强制直接读写内存，而不是简单的读写缓存或寄存器。</p></blockquote><p>性能测试结果如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">gpu</span> unrolling8  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">22992</span> ms      gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> unrolWarps8 elapsed <span class="hljs-number">0</span>.<span class="hljs-number">227296</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br></code></pre></td></tr></table></figure><p>我们可以通过分析被阻塞线程束的占比来作证这个性能提升。</p><table><colgroup><col style="width: 81%"><col style="width: 18%"></colgroup><thead><tr class="header"><th></th><th>阻塞线程束占比</th></tr></thead><tbody><tr class="odd"><td><code>reduceUnrolling8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1)</code></td><td>20.83%</td></tr><tr class="even"><td><code>reduceUnrollWarps8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1)</code></td><td>12.56%</td></tr></tbody></table><p>可以观察到，通过展开最后的线程束，被阻塞的线程束占比大幅度下降，所以进一步提升了性能。</p><h3 id="完全展开的归约">完全展开的归约</h3><p>由于当前计算能力的设备，每个线程块最大的线程束是1024，且上述的归约核函数中循环迭代次数是基于一维网格与一维线程块的，所以完全展开归约循环是可行的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceCompleteUnrollWarps8</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    ...<br>    <span class="hljs-comment">// 完全展开</span><br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">512</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">256</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">128</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (blockDim.x &gt;= <span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">64</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (tid &lt; <span class="hljs-number">32</span>)<br>    {<br>        <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> *vmem = idata;<br>        vmem[tid] += vmem[tid + <span class="hljs-number">32</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">16</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">8</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">4</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">2</span>];<br>        vmem[tid] += vmem[tid + <span class="hljs-number">1</span>];<br>    }<br>...<br>}<br></code></pre></td></tr></table></figure><p>性能测试的结果如下所示，又有小小的提升。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">gpu</span> unrolWarps8 elapsed <span class="hljs-number">0</span>.<span class="hljs-number">227264</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> CmptUnroll8 elapsed <span class="hljs-number">0</span>.<span class="hljs-number">224992</span> ms     gpu_sum: <span class="hljs-number">206464799</span>      &lt;&lt;&lt;<span class="hljs-number">4096</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br></code></pre></td></tr></table></figure><h3 id="模板函数的归约">模板函数的归约</h3><p>虽然可以手动展开循环，但使用模板函数有助于进一步减小分支消耗，关键代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">template</span> &lt;<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> iBlockSize&gt;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduceCompleteUnroll</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>...<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">512</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">256</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">128</span>];<br>    __syncthreads();<br>    <span class="hljs-keyword">if</span> (iBlockSize &gt;= <span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)<br>        idata[tid] += idata[tid + <span class="hljs-number">64</span>];<br>    __syncthreads();<br>...<br>}<br></code></pre></td></tr></table></figure><p>这样做的好处是，检查块大小的<code>if</code>语句在编译时会被评估，若这一条件为<code>false</code>，则该分支块在编译时就会被删除。这类核函数一定要在<code>switch-case</code>结构中被调用，这样可以使编译器为特定大小的线程块自动优化代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">switch</span> (blocksize)<br>{<br><span class="hljs-keyword">case</span> <span class="hljs-number">1024</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">1024</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">512</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">512</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">256</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">256</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">128</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">128</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">case</span> <span class="hljs-number">64</span>:<br>    reduceCompleteUnroll&lt;<span class="hljs-number">64</span>&gt;&lt;&lt;&lt;grid.x / <span class="hljs-number">8</span>, block&gt;&gt;&gt;(d_idata, d_odata, size);<br>    <span class="hljs-keyword">break</span>;<br>}<br></code></pre></td></tr></table></figure><h2 id="归约小结">归约小结</h2><p>至此，我们借助归约求和探讨了核函数的几个优化方案，大致分为避免分支分化和展开循环两个思路，细节上述部分已经充分讨论过了。下表中展示了从一开始的相邻配对归约，到改善了线程束分化问题，最后到完全展开循环核函数的性能对比。</p><table><thead><tr class="header"><th>核函数描述</th><th>耗时 (ms)</th><th>单步加速</th><th>累计加速</th><th>加载效率</th><th>存储效率</th></tr></thead><tbody><tr class="odd"><td>相邻配对（分化）</td><td>0.674112</td><td></td><td></td><td>25.02</td><td>25</td></tr><tr class="even"><td>相邻配对（改善分化）</td><td>0.581312</td><td>1.16</td><td>1.16</td><td>25.02</td><td>25</td></tr><tr class="odd"><td>交错配对</td><td>0.364192</td><td>1.60</td><td>1.85</td><td>96.15</td><td>95.52</td></tr><tr class="even"><td>循环展开（2块）</td><td>0.255392</td><td>1.43</td><td>2.64</td><td>98.04</td><td>97.71</td></tr><tr class="odd"><td>循环展开（4块）</td><td>0.252832</td><td>1.01</td><td>2.67</td><td>98.68</td><td>97.71</td></tr><tr class="even"><td>循环展开（8块）</td><td>0.229664</td><td>1.10</td><td>2.94</td><td>99.21</td><td>97.71</td></tr><tr class="odd"><td>循环展开（8块）+ 最后线程束展开</td><td>0.225184</td><td>1.02</td><td>2.99</td><td>99.43</td><td>99.40</td></tr><tr class="even"><td>循环展开（8块）+ 完全循环展开 + 最后线程束展开</td><td>0.224096</td><td>1.00</td><td>3.01</td><td>99.43</td><td>99.40</td></tr><tr class="odd"><td>模板化核函数</td><td>0.211616</td><td>1.06</td><td>3.19</td><td>99.43</td><td>99.40</td></tr></tbody></table><h2 id="动态并行">动态并行</h2><p>CUDA的动态并行允许在GPU端直接创建和同步新的GPU核函数，可以在一个核函数的任意点动态增加并行性。动态并行可以在运行时才决定网格和线程块的大小。</p><h3 id="嵌套执行">嵌套执行</h3><p>在GPU进行核函数调用的方法与主机端的调用方法相同。</p><p>在动态并行中，核函数执行分为双亲和孩子两种类型。父线程、父线程块或父网格启动一个新的网格，即子网格。子线程、子线程块或子网格被双亲启动。子网格必须在父线程、父线程块或父网格完成之前完成。只有在所有子网格都完成后，双亲才会完成。</p><blockquote><p>若调用的线程没有显式地同步子网格，则CUDA运行时会保证双亲与孩子之间的隐式同步。</p></blockquote><p>当双亲启动一个子网格，父线程块与孩子显式同步后，孩子才能开始执行。</p><p>关于动态并行的内存访问有以下几点：</p><ul><li>父网格和子网格共享相同的全局和常量内存，但它们有不同的局部内存和共享内存；</li><li>双亲和孩子之间以弱一致性为保证，使得父子网格可以对全局内存并发存取；</li><li>在子网格开始和完成两个时刻，子网格和它的父线程见到的内存完全相同；</li><li>当父线程优先于子网格调用时，所有的全局内存操作要保证子网格可见；</li><li>当双亲在子网格完成时进行同步后，子网格所有的内存操作要保证双亲可见；</li></ul><h3 id="在gpu上嵌套hello-world">在GPU上嵌套Hello World</h3><p>实现一个嵌套调用的核函数来在GPU上输出Hello World，具体的嵌套调用方式如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/27c38e9d-785d-420e-962a-2b60899e6d83"></p><p>实现核函数如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">nestedHelloWorld</span><span class="hljs-params">(<span class="hljs-type">int</span> <span class="hljs-type">const</span> size, <span class="hljs-type">int</span> depth)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"Recursion=%d: Hello World from thread %d block %d\n"</span>, depth, tid, threadIdx.x);<br><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-type">int</span> threads = size &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span> &amp;&amp; threads &gt; <span class="hljs-number">0</span>)<br>    {<br>        nestedHelloWorld&lt;&lt;&lt;<span class="hljs-number">1</span>, threads&gt;&gt;&gt;(threads, ++depth);<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">"-------&gt; nested execution depth: %d\n"</span>, depth);<br>    }<br>}<br></code></pre></td></tr></table></figure><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/05_nestedHelloWorld.cu">nestedHelloWorld.cu</a>。注意需要编译选项-rdc为true，一些资料中提到还需要链接cudadevrt库，但笔者这里没有显式链接也正常执行了，推测是自动链接了。</p></blockquote><h3 id="嵌套归约">嵌套归约</h3><p>由于CUDA从11.6开始就不允许在设备端执行<code>cudaDeviceSynchronize()</code>来同步子网格，并且CUDA 12.x开始CDP（CUDA Dynamic Parallelism）替换成了CDP2，在细节上与CDP1有所不同。</p><p>首先我们实现一个嵌套归约求和的核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">gpuRecursiveReduce</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tid = threadIdx.x;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br>    <span class="hljs-type">int</span> *odata = &amp;g_odata[blockIdx.x];<br><br>    <span class="hljs-comment">// 递归中止条件</span><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">2</span> &amp;&amp; tid == <span class="hljs-number">0</span>)<br>    {<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>] + idata[<span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">return</span>;<br>    }<br><br>    <span class="hljs-type">int</span> stride = size &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (stride &gt; <span class="hljs-number">1</span> &amp;&amp; tid &lt; stride)<br>        idata[tid] += idata[tid + stride];<br>    __syncthreads();<br><br>    <span class="hljs-comment">// 嵌套调用生成子网格</span><br>    <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>        gpuRecursiveReduce&lt;&lt;&lt;<span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride);<br>    __syncthreads();<br>}<br></code></pre></td></tr></table></figure><p>注意下面的语句。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">gpuRecursiveReduce&lt;&lt;&lt;<span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride);<br></code></pre></td></tr></table></figure><p>这里迫使该核函数在<code>cudaStreamTailLaunch</code>特殊流中执行，这是CDP2的新特性，这个流允许父网格在完成工作后才启动新网格。在大多数情况下，可以使用该流来实现与<code>cudaDeviceSynchronize()</code>相同的功能。</p><p><strong>在实际的实验过程中，笔者发现大多数情况下，这种嵌套的归约计算结果是错误的，但在小数据量的情况下是正确的，具体原因还有待分析。</strong></p><blockquote><p>详细代码参考<a href="https://github.com/Deleter-D/CUDA/blob/master/02_execution_model/06_nested_reduce.cu">nested_reduce.cu</a>。</p></blockquote><p>对该核函数进行性能测试，结果如下所示。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> size: <span class="hljs-number">524288</span><br><span class="hljs-attribute">Execution</span> Configuration: grid <span class="hljs-number">1024</span> block <span class="hljs-number">512</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">470947</span> ms     cpu_sum: <span class="hljs-number">6451596</span><br><span class="hljs-attribute">gpu</span> nested      elapsed <span class="hljs-number">83</span>.<span class="hljs-number">5106</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>CUDA官方文档对于CDP2的同步有如下描述：</p><p>任何线程的CUDA运行时操作，包括核函数启动，在网格中的所有线程中都是可见的。这意味着父网格中的调用线程可以执行同步，以控制由网格中的任意线程在网格中的任何线程创建的流上启动网格的顺序。直到网格中所有线程的所有任务都已完成，网格的执行才被视为完成。如果网格中的所有线程在所有子网格完成之前退出，则将自动触发隐式同步操作。</p><p>大概意思就是，从CDP2开始，开发者已经不需要再核函数内进行显式的同步操作了，一切同步交给流和编译器来控制。去掉显式同步后的核函数实现如下所示。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">gpuRecursiveReduceNosync</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">unsigned</span> tid = threadIdx.x;<br><br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * blockDim.x;<br>    <span class="hljs-type">int</span> *odata = &amp;g_odata[blockIdx.x];<br><br>    <span class="hljs-keyword">if</span> (size == <span class="hljs-number">2</span> &amp;&amp; tid == <span class="hljs-number">0</span>)<br>    {<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>] + idata[<span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">return</span>;<br>    }<br><br>    <span class="hljs-type">int</span> stride = size &gt;&gt; <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (stride &gt; <span class="hljs-number">1</span> &amp;&amp; tid &lt; stride)<br>    {<br>        idata[tid] += idata[tid + stride];<br>        <span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>            gpuRecursiveReduceNosync&lt;&lt;&lt;<span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride);<br>    }<br>}<br></code></pre></td></tr></table></figure><p>性能测试如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> size: <span class="hljs-number">524288</span><br><span class="hljs-attribute">Execution</span> Configuration: grid <span class="hljs-number">1024</span> block <span class="hljs-number">512</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">496094</span> ms     cpu_sum: <span class="hljs-number">6451596</span><br><span class="hljs-attribute">gpu</span> nested      elapsed <span class="hljs-number">78</span>.<span class="hljs-number">52</span> ms        gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> nestedNosyn elapsed <span class="hljs-number">69</span>.<span class="hljs-number">1308</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>可以观察到性能有一些提升。在这个版本的实现中，每个线程块产生一个子网格，并引起了大量的调用，具体过程如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/4730c47f-e3ca-44d9-ac45-31d59345574b"></p><p>为了减少其创建的子网格数量，可以将启动方式改为下图所示的方法。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/792ec296-6651-4df4-a97c-a3838098cc35"></p><p>即只令第一个线程块的第一个线程来启动子网格，每次嵌套调用时，子线程块大小就会减小到其父线程块的一半。对于之前的实现来说，每个嵌套层的核函数执行过程都会有一半的线程空闲。但在这种实现方式中，所有空闲线程都会在每次核函数启动时被移除。这样会释放更多的计算资源，使得更多的线程块活跃起来。</p><p>同时，由于子线程块的大小是父线程块的一半，为了正确的计算数据的偏移，必须将一开始父线程块的大小传递进去。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">gpuRecursiveReduce2</span><span class="hljs-params">(<span class="hljs-type">int</span> *g_idata, <span class="hljs-type">int</span> *g_odata, <span class="hljs-type">int</span> stride, <span class="hljs-type">int</span> <span class="hljs-type">const</span> dim)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> *idata = g_idata + blockIdx.x * dim;<br><br>    <span class="hljs-keyword">if</span> (stride == <span class="hljs-number">1</span> &amp;&amp; threadIdx.x == <span class="hljs-number">0</span>)<br>    {<br>        g_odata[blockIdx.x] = idata[<span class="hljs-number">0</span>] + idata[<span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">return</span>;<br>    }<br><br>    idata[threadIdx.x] += idata[threadIdx.x + stride];<br><br>    <span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span> &amp;&amp; blockIdx.x == <span class="hljs-number">0</span>)<br>        gpuRecursiveReduce2&lt;&lt;&lt;gridDim.x, stride / <span class="hljs-number">2</span>&gt;&gt;&gt;(g_idata, g_odata, stride / <span class="hljs-number">2</span>, dim);<br>}<br></code></pre></td></tr></table></figure><p>性能测试如下。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Array</span> size: <span class="hljs-number">524288</span><br><span class="hljs-attribute">Execution</span> Configuration: grid <span class="hljs-number">1024</span> block <span class="hljs-number">512</span><br><span class="hljs-attribute">cpu</span> reduce      elapsed <span class="hljs-number">0</span>.<span class="hljs-number">48291</span> ms      cpu_sum: <span class="hljs-number">6451596</span><br><span class="hljs-attribute">gpu</span> nested      elapsed <span class="hljs-number">76</span>.<span class="hljs-number">7643</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> nestedNosyn elapsed <span class="hljs-number">69</span>.<span class="hljs-number">8579</span> ms      gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> nested2     elapsed <span class="hljs-number">0</span>.<span class="hljs-number">082464</span> ms     gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">gpu</span> neighbored  elapsed <span class="hljs-number">0</span>.<span class="hljs-number">025632</span> ms     gpu_sum: <span class="hljs-number">6451596</span>        &lt;&lt;&lt;<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;<br><span class="hljs-attribute">Result</span> correct!<br></code></pre></td></tr></table></figure><p>虽然对比之前的嵌套归约提升很大，但其性能甚至不如之前实现的性能最差的相邻匹配的归约。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程——NVCC编译器</title>
    <link href="https://deleter-d.github.io/posts/50741/"/>
    <id>https://deleter-d.github.io/posts/50741/</id>
    <published>2024-02-20T07:59:25.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="使用nvcc编译">使用NVCC编译</h2><p>核函数可以使用CUDA指令集架构（PTX）撰写，也可以使用C++撰写，两种方式都需要使用<code>nvcc</code>编译器编译。<code>nvcc</code>简化了编译PTX或C++代码的过程。</p><blockquote><p>PTX（Parallel Thread Execution）是CUDA平台为基于GPU通用计算而定义的虚拟机和指令集，类似于针对GPU的汇编代码。</p><p>在编译CUDA C++程序时，nvcc会将设备代码编译为PTX代码，以适应更多的实际架构，再将PTX代码编译为cubin对象进行执行与调用。从CUDA C++编译为PTX代码的过程是与实际GPU设备无关的。</p></blockquote><h3 id="编译工作流">编译工作流</h3><h4 id="离线编译">离线编译</h4><p><code>nvcc</code>编译的源文件可以同时包含主机代码和设备代码，它会将两者自动分离。</p><ul><li>将设备代码编译成汇编形式（PTX代码）或二进制形式（cubin对象）；</li><li>修改主机代码，通过CUDA运行时函数调用替换<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>，从PTX代码或cubin对象中加载和启动编译后的核函数。</li></ul><p>修改后的主机代码要么作为C++代码输出，留给其他工具编译，要么直接作为目标代码输出，令<code>nvcc</code>在最后的编译阶段调用主机的编译器。</p><p>应用程序可以：</p><ul><li>链接到编译后的主机代码（最常见的情况）；</li><li>或忽略修改后的主机代码，并使用CUDA驱动程序API加载和执行PTX代码或cubin对象。</li></ul><h4 id="即时编译">即时编译</h4><p>即时编译大多情况是针对PTX代码的，这里不过多赘述，详见<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#just-in-time-compilation">Just-in-Time Compilation</a>。</p><p>NVRTC（CUDA C++的运行时编译库）可以在运行时将CUDA C++设备代码编译为PTX代码，是作为<code>nvcc</code>编译CUDA C++设备代码的替代方案的。</p><h3 id="二进制兼容性">二进制兼容性</h3><p>二进制代码是特定于体系结构的，可以使用编译器的<code>-code</code>选项生产cubin对象。例如使用<code>-code=sm_80</code>可以针对计算能力为8.0的设备编译生成二进制代码。</p><p>二进制代码对计算能力的小版本是向前兼容的，但小版本无法向后兼容，大版本之间也无法兼容。即为计算能力X.y的设备生成的二进制代码，只能在计算能力X.z的设备上执行，其中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.178ex" height="1.903ex" role="img" focusable="false" viewBox="0 -636 2288.6 841"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(742.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(1798.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>。</p><h3 id="ptx兼容性">PTX兼容性</h3><p>某些PTX指令只在具有更高计算能力的设备上支持，包含这些指令的代码必须使用编译器的<code>-arch</code>选项指定合适的计算能力。</p><p>为某些特定计算能力生成的PTX代码可以被编译为具有更大或相同计算能力设备的二进制代码。但从较早版本的PTX代码编译而来的二进制文件可能不会利用某些硬件新特性，可能导致性能不如使用新版PTX代码编译的二进制文件。</p><h3 id="应用程序兼容性">应用程序兼容性</h3><p>要在具有特定计算能力的设备上执行代码，应用程序必须加载与该计算能力兼容的二进制或PTX代码，如果要考虑将代码在未来的体系结构上执行，则尽量选择即时编译。</p><p>使用编译器的<code>-arch</code>和<code>-code</code>选项或<code>-gencode</code>选项来控制将哪些PTX代码嵌入到CUDA C++应用程序中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">nvcc x.cu<br>        -gencode arch=compute_50,code=sm_50<br>        -gencode arch=compute_60,code=sm_60<br>        -gencode arch=compute_70,code=\"compute_70,sm_70\"<br></code></pre></td></tr></table></figure><p>嵌入二进制代码兼容5.0和6.0的计算能力设备，PTX和二进制代码兼容7.0的计算能力设备。</p><p>主机代码会在运行时加载和执行最合适的代码，以上述编译命令为例：</p><ul><li>计算能力5.0和5.2的设备会选择5.0的二进制代码；</li><li>计算能力6.0和6.1的设备会选择6.0的二进制代码；</li><li>计算能力7.0和7.5的设备会选择7.0的二进制代码；</li><li>计算能力8.0和8.6的设备会选择编译为二进制代码的PTX代码。</li></ul><p><code>nvcc</code>编译器的<code>-arch</code>，<code>-code</code>和<code>-gencode</code>选项有一些简写方式，例如<code>-arch=sm_70</code>是<code>-arch=compute_70 -code=compute70,sm_70</code>的简写，等价于<code>-gencode arch=compute_70,code=\"compute_70,sm_70\"</code>。</p><blockquote><p>使用<code>-arch=compute_XY</code>来指定一个虚拟架构的计算能力，用<code>-code=sm_XY</code>来指定一个实际架构的计算能力。</p><ul><li>虚拟架构应该尽可能低，以适配更多计算能力的设备；</li><li>真实架构应该尽可能高，以充分发挥GPU的实际计算能力。</li></ul><p>例如<code>nvcc helloworld.cu -o helloworld -arch=compute_61</code>编译出的可执行文件只能在计算能力大于等于6.1的设备上执行。</p><p>指定实际架构计算能力时必须指定虚拟架构计算能力，并且实际架构计算能力必须不小于虚拟架构计算能力。</p><p>例如<code>nvcc helloworld.cu -o helloworld -arch=compute_61 -code=sm_60</code>将是不合法的编译命令。</p><p><code>nvcc</code>可以同时指定多个GPU版本进行编译，使得编译出来的可执行文件能够在不同计算能力的设备上执行。使用编译器选项<code>-gencode arch=compute_XY,code=sm_XY</code>来指定各个版本的计算能力。注意与<code>-gencode arch=compute_XY,code=compute_XY</code>选项的差异，随后会介绍这个差异。</p><p>例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">nvcc helloworld.cu -o helloworld_fat \<br>        -gencode arch=compute_50,code=sm_52 \<br>        -gencode arch=compute_60,code=sm_61 \<br>        -gencode arch=compute_80,code=sm_89<br></code></pre></td></tr></table></figure><p>上面的编译命令编译出的可执行文件包含3个二进制版本，称为胖二进制文件（fatbinary）。在该例子中，执行该编译命令的CUDA版本必须支持8.9的计算能力。</p><p>上面的例子中，每个<code>-gencode</code>分别指定了虚拟架构和实际架构的计算能力，这样可以针对不同的实际架构编译出不同的二进制文件，并将这些二进制文件整合进一个胖二进制文件中。</p><p>而对于选项<code>-gencode arch=compute_XY,code=compute_XY</code>，注意<code>arch</code>和<code>code</code>选项的值均为<code>compute_XY</code>即虚拟架构，且<code>arch</code>和<code>code</code>指定的<code>compute_XY</code>必须完全一致。</p><p>回看官方文档中的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">nvcc x.cu<br>        -gencode arch=compute_50,code=sm_50<br>        -gencode arch=compute_60,code=sm_60<br>        -gencode arch=compute_70,code=\"compute_70,sm_70\"<br></code></pre></td></tr></table></figure><p>前两个<code>-gencode</code>编译出了针对实际架构计算能力5.0和6.0的二进制代码，最后一个<code>-gencode</code>编译出了针对实际架构计算能力7.0的二进制代码，和针对虚拟架构计算能力7.0的PTX代码，当一个计算能力更高的设备（如8.0）来调研该胖二进制文件时，由于没有针对更高计算能力的二进制代码，故会自动选择编译好的PTX代码，采用即时编译的方式为更高计算能力的设备编译二进制代码并调用执行。</p><p>当不指定任何虚拟架构和实际架构的计算能力时，会指定为所使用的CUDA版本的默认值，具体的默认值可以在官方文档中找到。</p><p>另外，关于PTX代码，可以使用<code>nvcc</code>的<code>-ptx</code>选项，将<code>.cu</code>文件编译为一个<code>.ptx</code>文件，其中存放的就是PTX代码。</p><p>例如<code>nvcc hellowrold.cu -ptx</code>。</p><p>详细代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/00_CUDA_official_documentation/01_compute_capability.cu">compute_capability.cu</a>与<a href="https://github.com/Deleter-D/CUDA/blob/master/00_CUDA_official_documentation/01_compute_capability.ptx">compute_capability.ptx</a>。</p></blockquote><h3 id="c兼容性">C++兼容性</h3><p>编译器前端按照C++语法规则处理CUDA源文件，主机代码支持完整的C++，而设备代码仅支持C++的一个子集。</p><h3 id="位兼容性">64位兼容性</h3><p>64位版本的<code>nvcc</code>会以64位模式编译设备代码，64位模式编译的设备代码只支持64位模式编译的主机代码。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CUDA编程模型概述</title>
    <link href="https://deleter-d.github.io/posts/57516/"/>
    <id>https://deleter-d.github.io/posts/57516/</id>
    <published>2024-02-20T07:48:18.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。</p><span id="more"></span><h2 id="核函数">核函数</h2><p>CUDA的核函数（Kernel）是通过<code>__global__</code>说明符定义的，通过C++扩展语法<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>来启动。下面是一个向量加法的例子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 核函数定义</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">VecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> i = threadIdx.x;<br>    C[i] = A[i] + B[i];<br>}<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    ...<br>    <span class="hljs-comment">// 核函数调用，该核函数包含N个线程</span><br>    VecAdd&lt;&lt;&lt;<span class="hljs-number">1</span>, N&gt;&gt;&gt;(A, B, C);<br>    ...<br>}<br></code></pre></td></tr></table></figure><blockquote><p>核函数的编写是无需考虑并行性的，并行调度是由编译器和GPU自动完成的，只需要针对每个线程需要处理的逻辑编写代码即可。</p><p>核函数的返回类型必须是<code>void</code>，限定符<code>__global__</code>和返回类型的顺序可以调换，上面的核函数也可以写成如下形式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> __global__ <span class="hljs-title">VecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C)</span></span>;<br></code></pre></td></tr></table></figure><p>核函数有一些注意事项：</p><ul><li>核函数只能访问GPU内存；</li><li>核函数不能使用变长参数；</li><li>核函数不能使用静态变量；</li><li>核函数不能使用函数指针；</li><li>核函数具有异步性；</li></ul><p>具体例子参考<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/01_hello_world.cu">hello_world.cu</a>。</p><p>CUDA除了核函数还有两种函数，设备函数和主机函数。</p><ul><li>设备函数使用<code>__device__</code>限定符修饰，只能在设备上执行，只能被核函数或其他设备函数调用；</li><li>主机函数使用<code>__host__</code>限定符修饰，可以与<code>__device__</code>限定符同时使用，编译器会针对主机和设备分别编译该函数；</li></ul><p>注意：<code>__global__</code>不能与<code>__host__</code>或<code>__device__</code>同时使用。</p></blockquote><blockquote><p>除此之外，还需要掌握两个常用技巧，一个是错误处理，一个是性能分析。这两个技巧将在整个GPU算子开发和优化过程中起到重要的作用。关于错误处理，示例代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/02_error_handle.cu">error_handle.cu</a>。关于性能分析，详见<a href="#性能分析">性能分析</a>，以及代码示例<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/03_profiling.cu">profiling.cu</a>。</p></blockquote><h2 id="线程层级结构">线程层级结构</h2><p>为了方便的定位和访问线程，CUDA提供了线程索引<code>threadIdx</code>，这是一个具有三个分量的向量，可以使用一维、二维或三维的线程索引来标识线程。</p><p>线程的索引和ID对应关系如下：</p><ul><li>一维block：索引与ID相等；</li><li>大小为<code>(Dx, Dy)</code>的二维block：索引<code>(x, y)</code>对应ID为<code>(x + y * Dx)</code>；</li><li>大小为<code>(Dx, Dy, Dz)</code>的三维block：索引<code>(x, y, z)</code>对应ID为<code>(x + y * Dx + z * Dx * Dy)</code>。</li></ul><p>下面是一个矩阵加法的例子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatAdd</span><span class="hljs-params">(<span class="hljs-type">float</span> A[N][N], <span class="hljs-type">float</span> B[N][N], <span class="hljs-type">float</span> C[N][N])</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> i = threadIdx.x;<br>    <span class="hljs-type">int</span> j = threadIdx.y;<br>    C[i][j] = A[i][j] + B[i][j];<br>}<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    ...<br>    <span class="hljs-comment">// 核函数调用，该核函数包括N * N * 1个线程</span><br>    <span class="hljs-type">int</span> numBlocks = <span class="hljs-number">1</span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(N, N)</span></span>;<br>    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);<br>    ...<br>}<br></code></pre></td></tr></table></figure><blockquote><p>对于当前的GPU，每个线程块（block）最多可以容纳1024个线程。但每个核函数可以被多个形状相同的线程块执行，故总线程数为线程块数量 * 每块线程数。</p></blockquote><p>线程块由一维、二维或三维的线程块网格（grid）组织起来，网格中线程块的数量通常由被处理的数据决定，通常这个数量是超过物理处理单元数量的。</p><p>grid和block的数量可以由<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>来指定，其中的数据类型可以是<code>int</code>或<code>dim3</code>。</p><p>每个block可以由一维、二维或三维的<code>blockIdx</code>唯一标识，block的维度可以通过<code>blockDim</code>在核函数内获取。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/42de655c-5f10-41d2-9bc8-e1a40f3fd95f"></p><p>扩展一下上面的矩阵加法的例子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatAdd</span><span class="hljs-params">(<span class="hljs-type">float</span> A[N][N], <span class="hljs-type">float</span> B[N][N], <span class="hljs-type">float</span> C[N][N])</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (i &lt; N &amp;&amp; j &lt; N)<br>        C[i][j] = A[i][j] + B[i][j];<br>}<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    ...<br>    <span class="hljs-comment">// 每个block有16 * 16共256个线程</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-comment">// grid大小是由矩阵的大小决定的，来确保每个矩阵元素都有线程处理</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">numBlocks</span><span class="hljs-params">(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y)</span></span>;<br>    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);<br>    ...<br>}<br></code></pre></td></tr></table></figure><p>上面的例子是基于每个grid的线程数在每个维度上都能被每个block的线程数整除，但实际中可能不是这样的。</p><p>同一个block中的线程可以通过共享内存（shared memory）来协作，并可以通过内部函数<code>__syncthreads()</code>来同步线程以协调访存，这些后面会再提到。</p><blockquote><p>详细来说，CUDA可以组织最多三个维度的grid和block，如果不指定维度，则默认都是一维的。</p><p>有一些内建变量可以用来索引线程，这些变量只在核函数内有效，定义在<code>device_launch_parameters.h</code>头文件中。</p><p>其中，<code>blockIdx</code>和<code>threadIdx</code>是类型为<code>uint3</code>的结构体，分别都有<code>x, y, z</code>三个成员，该结构体源码长下面这样。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">__device_builtin__</span> uint3<br>{<br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x, y, z;<br>};<br></code></pre></td></tr></table></figure><p>而<code>gridDim</code>和<code>blockDim</code>是类型为<code>dim3</code>的结构体，同样有<code>x, y, z</code>三个成员，源码是下面这样。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">__device_builtin__</span> dim3<br>{<br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x, y, z;<br><span class="hljs-comment">// 还有其他部分...</span><br>};<br></code></pre></td></tr></table></figure><p>对于上述几个变量，他们有下列范围关系：</p><ul><li><code>blockIdx.x</code>范围为<code>[0, gridDim.x-1]</code>；</li><li><code>blockIdx.y</code>范围为<code>[0, gridDim.y-1]</code>；</li><li><code>blockIdx.z</code>范围为<code>[0, gridDim.z-1]</code>；</li><li><code>threadIdx.x</code>范围为<code>[0, blockDim.x-1]</code>;</li><li><code>threadIdx.y</code>范围为<code>[0, blockDim.y-1]</code>;</li><li><code>threadIdx.z</code>范围为<code>[0, blockDim.z-1]</code>;</li></ul><p>定义多维grid和block可以使用C++构造函数的形式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">dim3 <span class="hljs-title">grid_size</span><span class="hljs-params">(Gx, Gy, Gz)</span></span>;<br><span class="hljs-function">dim3 <span class="hljs-title">block_size</span><span class="hljs-params">(Bx, By, Bz)</span></span>;<br></code></pre></td></tr></table></figure><p>grid和block是有大小限制的：</p><ul><li><code>gridDim.x</code>最大值为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="6.816ex" height="2.072ex" role="img" focusable="false" viewBox="0 -833.9 3012.6 915.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(533,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1512.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2512.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>；</li><li><code>gridDim.y</code>最大值为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="6.816ex" height="2.072ex" role="img" focusable="false" viewBox="0 -833.9 3012.6 915.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(533,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1512.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2512.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>；</li><li><code>gridDim.z</code>最大值为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="6.816ex" height="2.072ex" role="img" focusable="false" viewBox="0 -833.9 3012.6 915.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(533,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1512.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2512.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>；</li><li><code>blockDim.x</code>最大值为1024；</li><li><code>blockDim.y</code>最大值为1024；</li><li><code>blockDim.z</code>最大值为64；</li></ul><p>但block有一个额外限制，总的block数最大为1024，即满足上述限制的同时要满足<code>blockDim.x * blockDim.y * blockDim.z &lt;= 1024</code>。</p><p>具体例子参考<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/04_threads_management.cu">threads_management.cu</a></p></blockquote><h3 id="线程块集群">线程块集群</h3><p>线程块集群（Thread Block Cluster）是一个可选的层级。在线程块中，线程会被协调安排在流式多处理器（streaming multiprocessor）中。类似地，一个线程块集群中的线程会被协调安排在GPU处理簇（GPU Processing Cluster, GPC）中。</p><p>与block类似，簇也有一维、二维或三维的形式。簇中的block数量是可以由用户定义的，但CUDA支持的可移植的簇中最多包含8个block。对于不能支持最大簇的GPU设备或MIG配置中，会相应减小这个最大数量。在特定体系结构下，可以用<code>cudaOccupancyMaxPotentialClusterSize</code>接口来查询簇支持的最大block数量。</p><blockquote><p>MIG是英伟达提供的多实例GPU框架，能够独立划分GPU资源，使得GPU在运行不同任务的时候不会争抢资源。</p></blockquote><p><img src="https://github.com/Deleter-D/Images/assets/56388518/48e6be32-5b22-4ec0-884d-00d767fa2893"></p><p>可以使用编译时核函数属性<code>__cluster_dims__(X, Y, Z)</code>或者使用CUDA核函数的启动API<code>cudaLanunchKernelEx</code>来启用线程块集群。若核函数使用编译时属性确定簇大小，则核函数启动时就无法改变簇大小。下面是使用编译时核函数属性使用线程块集群的例子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 编译时确定线程块集群尺寸为2 * 1 * 1</span><br>__global__ <span class="hljs-type">void</span> __cluster_dims__(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>) <span class="hljs-built_in">cluster_kernel</span>(<span class="hljs-type">float</span> *input, <span class="hljs-type">float</span>* output) {}<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">float</span> *input, *output;<br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">numBlocks</span><span class="hljs-params">(N / threadsPerBlock.x, N / threadsPerBlock.y)</span></span>;<br><br>    <span class="hljs-comment">// grid的维度不受线程块集群启动方式影响</span><br>    <span class="hljs-comment">// grid的维度必须是线程块集群尺寸的倍数</span><br>    cluster_kernel&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(input, output);<br>}<br></code></pre></td></tr></table></figure><p>线程块集群大小也可以在运行时设置，并且使用CUDA核函数的启动API<code>cudaLaunchKernelEx</code>来启动内核。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">cluster_kernel</span><span class="hljs-params">(<span class="hljs-type">float</span> *input, <span class="hljs-type">float</span>* output)</span> </span>{}<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-type">float</span> *input, *output;<br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">numBlocks</span><span class="hljs-params">(N / threadsPerBlock.x, N / threadsPerBlock.y)</span></span>;<br><br>    {<br>        cudaLaunchConfig_t config = {<span class="hljs-number">0</span>};<br>        <span class="hljs-comment">// grid的维度不受线程块集群启动方式影响</span><br>        <span class="hljs-comment">// grid的维度必须是线程块集群尺寸的倍数</span><br>        config.gridDim = numBlocks;<br>        config.blockDim = threadsPerBlock;<br><br>        cudaLaunchAttribute attribute[<span class="hljs-number">1</span>];<br>        attribute[<span class="hljs-number">0</span>].id = cudaLaunchAttributeClusterDimension;<br>        attribute[<span class="hljs-number">0</span>].val.clusterDim.x = <span class="hljs-number">2</span>; <span class="hljs-comment">// 线程块集群的X维度大小</span><br>        attribute[<span class="hljs-number">0</span>].val.clusterDim.y = <span class="hljs-number">1</span>; <span class="hljs-comment">// 线程块集群的Y维度大小</span><br>        attribute[<span class="hljs-number">0</span>].val.clusterDim.z = <span class="hljs-number">1</span>; <span class="hljs-comment">// 线程块集群的Z维度大小</span><br>        config.attrs = attribute;<br>        config.numAttrs = <span class="hljs-number">1</span>;<br><br>        <span class="hljs-built_in">cudaLaunchKernelEx</span>(&amp;config, cluster_kernel, input, output);<br>    }<br>}<br></code></pre></td></tr></table></figure><p>在计算能力9.0的GPU中，线程块集群中所有的线程块都保证在单个GPC上调度，并且允许簇中的线程块使用<code>Cluster Group</code>中的API<code>cluster.sync()</code>来执行硬件支持的同步操作。同时<code>Cluster Group</code>还提供成员函数<code>num_threads()</code>和<code>num_blocks()</code>来获取簇中的线程数和线程块数。<code>dim_threads()</code>和<code>dim_blocks()</code>获取线程和线程块的维度排列方式。</p><p>对于同一线程块集群中的线程块来说，共享内存是分布式的，可以互相访问彼此的共享内存。</p><h2 id="内存层级结构">内存层级结构</h2><p><img src="https://github.com/Deleter-D/Images/assets/56388518/c3212b1c-8279-44eb-9420-df8763211819"></p><p>CUDA线程可以从不同的内存空间中访问数据。</p><ul><li>每个线程拥有私有的本地内存（Local Memory）；</li><li>每个线程块拥有所有块内线程可见的共享内存（Shared Memory），这些块内线程与线程块有着相同的生命周期；</li><li>每个线程块集群中的线程块可以在彼此的共享内存中进行读、写和原子操作；</li><li>所有线程共享全局内存（Global Memory）。</li></ul><p>此外还有两片可以被所有线程访问的读内存空间，常量内存（Constant Memory）和纹理内存（Texture Memory）空间。全局、常量、纹理内存针对不同的内存使用进行了优化，纹理内存还为一些特定的数据格式提供不同的访存模式以及数据过滤。这三片内存在同一个程序的核函数启动期间是持久的。</p><blockquote><p>CUDA的内存管理与标准C语言的内存管理非常类似。</p><table><thead><tr class="header"><th>标准C函数</th><th>CUDA C函数</th><th>功能</th></tr></thead><tbody><tr class="odd"><td><code>malloc</code></td><td><code>cudaMalloc</code></td><td>内存分配</td></tr><tr class="even"><td><code>memcpy</code></td><td><code>cudaMemcpy</code></td><td>内存般移</td></tr><tr class="odd"><td><code>memset</code></td><td><code>cudaMemset</code></td><td>内存初始化</td></tr><tr class="even"><td><code>free</code></td><td><code>cudaFree</code></td><td>内存释放</td></tr></tbody></table><p>函数签名的对比如下。</p><table><colgroup><col style="width: 50%"><col style="width: 50%"></colgroup><thead><tr class="header"><th>标准C函数</th><th>CUDA C函数</th></tr></thead><tbody><tr class="odd"><td><code>extern void *malloc(size_t __size)</code></td><td><code>__host__ __device__ cudaError_t cudaMalloc(void **devPtr, size_t size)</code></td></tr><tr class="even"><td><code>extern void *memcpy(void *__restrict __dest, const void *__restrict __src, size_t __n)</code></td><td><code>__host__ cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind)</code></td></tr><tr class="odd"><td><code>extern void *memset(void *__s, int __c, size_t __n)</code></td><td><code>__host__ cudaError_t cudaMemset(void *devPtr, int value, size_t count)</code></td></tr><tr class="even"><td><code>extern void free(void *__ptr)</code></td><td><code>__host__ __device__ cudaError_t cudaFree(void *devPtr)</code></td></tr></tbody></table><p>上表中<code>cudaMemcpy</code>接口中的最后一个参数<code>cudaMemcpyKind</code>是一个枚举类，有五个成员。</p><ul><li><code>cudaMemcpyHostToHost</code>：主机 -&gt; 主机；</li><li><code>cudaMemcpyHostToDevice</code>：主机 -&gt; 设备；</li><li><code>cudaMemcpyDeviceToHost</code>：设备 -&gt; 主机；</li><li><code>cudaMemcpyDeviceToDevice</code>：设备 -&gt; 设备；</li><li><code>cudaMemcpyDefault</code>：默认方式，仅允许在支持统一虚拟寻址的系统中使用。</li></ul><p>详细代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/05_memory_management.cu">memory_management.cu</a>。</p></blockquote><h2 id="异构编程">异构编程</h2><p>CUDA 编程模型假设主机和设备维护自己独立的内存空间，分别称为主机内存（Host Memory）和设备内存（Device Memory），程序通过CUDA运行时来管理设备内存，包括内存申请、释放以及主机和设备之间的数据搬移。</p><p>CUDA还提供了统一内存管理，贯通了主机内存和设备内存，使得系统中所有CPU和GPU都能够通过一个单一的、连续的内存视图来管理内存。统一内存使得设备端可以超额订阅内存，且不必再显式地将数据从主机端镜像到设备端，从而简化程序的移植。</p><h2 id="异步simt编程模型">异步SIMT编程模型</h2><p>在CUDA中，线程是运算或内存操作的最低层级抽象。异构编程模型定义了CUDA线程的异步操作，为CUDA线程之间的同步定义了异步屏障（Asynchronous Barrier）行为。该模型还解释并定义了<code>cuda::memcpy_async</code>如何在GPU计算的同时从全局内存中异步搬移数据。</p><h3 id="异步操作">异步操作</h3><p>异步操作的定义是，由CUDA线程发起，并且看起来像由另一个线程异步执行的操作。在良好的程序中，一个或多个CUDA线程与异步操作同步。发起异步操作的CUDA线程不需要位于同步线程中。这样的异步线程（类似线程）始终与启动异步操作的CUDA线程相关联。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/e85f06cf-a5d4-4cb8-9d8e-3d47d4b84127"></p><p>异步操作使用同步对象来同步操作的完成，同步对象可以由用户显式管理（<code>cuda::memcpy_async</code>）或由库隐式管理（<code>cooperative_groups::memcpy_async</code>）。同步对象可以是<code>cuda::barrier</code>或<code>cuda::pipeline</code>，后续会详细介绍。这些同步对象可以在不同的线程域中使用，详见下表。</p><table><thead><tr class="header"><th>线程域</th><th>描述</th></tr></thead><tbody><tr class="odd"><td><code>cuda::thread_scope::thread_scope_thread</code></td><td>仅在发起异步操作的线程内同步。</td></tr><tr class="even"><td><code>cuda::thread_scope::thread_scope_block</code></td><td>在发起异步操作的线程所属的block内同步所有或任意线程。</td></tr><tr class="odd"><td><code>cuda::thread_scope::thread_scope_device</code></td><td>在发起异步操作的线程所属的GPU设备上同步所有或任意线程。</td></tr><tr class="even"><td><code>cuda::thread_scope::thread_scope_system</code></td><td>在发起异步操作的线程所属的整个系统中同步所有或任意线程。</td></tr></tbody></table><h2 id="计算能力">计算能力</h2><p>设备的计算能力由版本号表示，也称为“SM 版本”。 该版本号标识 GPU 硬件支持的功能，并由应用程序在运行时使用来确定当前 GPU 上可用的硬件功能和指令。计算能力包括主版本号X和次版本号Y，用X.Y表示。</p><ul><li>Hopper架构：9</li><li>Ampere架构：8</li><li>Volta架构：7<ul><li>Turing架构：7.5</li></ul></li><li>Pascal架构：6</li><li>Maxwell架构：5</li><li>Kepler架构：3</li></ul><p>若想知道自己的GPU对应的计算能力可以在英伟达官网给出的列表中查询<a href="https://developer.nvidia.com/cuda-gpus">GPU Compute Capability</a>。</p><p>支持的虚拟架构计算能力见<a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#virtual-architecture-feature-list">Virtual Architecture Feature List</a>，实际架构计算能力见<a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list">GPU Feature List</a>。</p><h2 id="性能分析">性能分析</h2><p>这里对性能分析手段只需有一个初步了解，不讨论过多细节。CUDA性能分析大致有6种方法：</p><ul><li>CPU计时</li><li>事件计时</li><li>NVVP（Nidia Visual Profiler）</li><li><code>nvprof</code></li><li>Nsight Systems（<code>nsys</code>）</li><li>Nsight Compute（<code>ncu</code>）</li></ul><h3 id="cpu计时">CPU计时</h3><p>是最简单粗暴的方式，统计精度不高，不推荐使用。</p><h3 id="事件计时">事件计时</h3><p>通过CUDA提供的事件API来统计时间，精度比CPU计时高，但只能统计到某代码段的运行时间，没有其他性能信息。</p><h3 id="nvvp和nvprof">NVVP和<code>nvprof</code></h3><p>NVVP是带有图形界面的性能分析工具，<code>nvprof</code>是针对命令行的。这两个工具是有局限性的，当文件较大的时候，性能分析的速度会很慢。</p><p>这两个工具是上一代的CUDA性能分析工具，工具定位也不是很清楚。对于计算能力7.5及以上的设备已经不支持使用<code>nvprof</code>来进行性能分析了。</p><h3 id="nsight-systems和nsight-compute">Nsight Systems和Nsight Compute</h3><p>这两个是新一代的CUDA性能分析工具，Nsight Systems是系统层面的分析工具，不仅会分析GPU的使用情况，还会给出CPU使用情况，以及CPU和GPU之间的交互情况。而Nsight Compute则用于分析核函数。</p><p>Nvidia官方推荐的使用顺序是：</p><ul><li>先使用Nsight Systems从系统层面进行分析，优化不必要的同步和数据传输等操作。</li><li>如果是计算程序，则使用Nsight Compute进行分析来优化核函数性能； 如果是图形程序，则使用Nsight Graphics进行分析，由于重点在于计算算子的开发，所以不对这一工具作过多介绍。</li><li>优化过核函数后，再使用Nsight Systems重新进行系统层面的分析，继续优化。</li></ul><p>重复以上过程，直到达到一个比较满意的性能。</p><h2 id="组织并行线程">组织并行线程</h2><p>在此之前，我们已经了解了CUDA的基本编程模型，接下来用一系列实例来加深理解。</p><h3 id="二维grid二维block">二维grid二维block</h3><p>使用二维grid和二维block可以最好的理解矩阵加法映射到CUDA线程的过程，如果将grid中的每个block平铺开，再将每个block中的线程也平铺开，那么正好每个线程就对应矩阵的一个元素。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/58d83140-598a-4aa4-a7cc-0cd35fdfb6b5"></p><p>这种情况下，可以先分别定位线程在x维度和y维度上的索引：</p><ul><li>x维度索引<code>ix = blockDim.x * blockIdx.x + threadIdx.x</code>；</li><li>y维度索引<code>iy = blockDim.y * blockIdx.y + threadIdx.y</code>；</li></ul><p>然后再得到全局索引<code>idx = iy * nx + ix</code>，当然这个的前提是矩阵为行优先存储。</p><p>详细代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/06_example_sum_matrix_2D-grid_2D-block.cu">example_sum_matrix_2D-grid_2D-block.cu</a>。</p><h3 id="一维grid一维block">一维grid一维block</h3><p>使用一维grid一维block就意味着每个线程必须处理矩阵的一列数据，如图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/454a29b9-5130-4d16-b4aa-9ed0b7004bf6"></p><p>此时，x维度上的线程索引仍然为<code>ix = blockDim.x * blockIdx.x + threadIdx.x</code>。但y维度的线程只有1个，所以需要在线程内部遍历该线程待处理列向量中的每一个元素。元素在线程内部的索引为<code>idx = iy * nx + ix</code>，其中<code>iy</code>的范围是<code>[0, ny)</code>。</p><p>详细代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/07_example_sum_matrix_1D-grid_1D-block.cu">example_sum_matrix_1D-grid_1D-block.cu</a>。</p><h3 id="二维grid一维block">二维grid一维block</h3><p>这种情况下，每个线程都只处理矩阵的一个元素，可以看作是<a href="#二维grid二维block">二维grid二维block</a>的一种特殊情况，其中block的y维度为1，映射关系如图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/65280438-b3a6-459f-979e-627144af3459"></p><p>还是从x和y两个维度来分别索引线程：</p><ul><li>x维度索引<code>ix = blockDim.x * blockIdx.x + threadIdx.x</code>；</li><li>y维度索引<code>iy = blockIdx.y</code>；</li></ul><p>然后得到线程的全局索引为<code>idx = iy * nx + ix</code>。</p><p>详细代码见<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/08_example_sum_matrix_2D-grid_1D-block.cu">example_sum_matrix_2D-grid_1D-block.cu</a>。</p><h2 id="设备管理">设备管理</h2><h3 id="运行时api查询gpu信息">运行时API查询GPU信息</h3><p>可以通过运行时API<code>cudaGetDeviceProperties()</code>来获取关于GPU的所有信息，通过给该API传入一个<code>cudaDeviceProp</code>和设备id来获取带有设备信息的结构体。结构体的成员详见<a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp">cudaDeviceProp</a>。</p><p>常用的一些属性请参考<a href="https://github.com/Deleter-D/CUDA/blob/master/01_programming_model/09_device_management.cu">device_management.cu</a>，代码中还给出了在多GPU系统中确定最优GPU的方法。</p><h3 id="使用nvidia-smi查询gpu信息">使用nvidia-smi查询GPU信息</h3><p><code>nvidia-smi</code></p><p>选项<code>-L</code>可以列出系统中安装了多少个GPU，以及每个GPU的设备ID。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">nvidia-smi -L</span><br>GPU 0: NVIDIA GeForce RTX 4070 (UUID: GPU-2792043a-40d8-faf2-cf4e-e94d68836d2f)<br></code></pre></td></tr></table></figure><p>选项<code>-q -i ${DeviceID}</code>可以获取指定设备的详细信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">nvidia-smi -q -i 0</span><br></code></pre></td></tr></table></figure><p>可以通过下列参数精简显示的信息：</p><ul><li>MEMORY</li><li>UTILIZATION</li><li>ECC</li><li>TEMPERATURE</li><li>POWER</li><li>CLOCK</li><li>COMPUTE</li><li>PIDS</li><li>PERFORMANCE</li><li>SUPPORTED_CLOCKS</li><li>PAGE_RETIREMENT</li><li>ACCOUNTING</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">nvidia-smi -q -i 0 -d MEMORY</span><br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">nvidia-smi -q -i 0 -d UTILIZATION</span><br></code></pre></td></tr></table></figure><h3 id="通过环境变量设置设备">通过环境变量设置设备</h3><p>可以通过环境变量<code>CUDA_VISIBLE_DEVICES</code>来指定设备。</p><ul><li>若<code>CUDA_VISIBLE_DEVICES = 2</code>，则设备2将在CUDA程序中以设备0的身份出现；</li><li>若<code>CUDA_VISIBLE_DEVICES = 2,3</code>，则设备2，3将在CUDA程序中以设备0，1的身份出现。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="CUDA" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"/>
    
    
    <category term="CUDA" scheme="https://deleter-d.github.io/tags/CUDA/"/>
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>打造vscode般的neovim</title>
    <link href="https://deleter-d.github.io/posts/22702/"/>
    <id>https://deleter-d.github.io/posts/22702/</id>
    <published>2024-02-02T08:56:36.000Z</published>
    <updated>2024-02-27T09:38:43.380Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>偶然在Youtube上看到一个大佬的Neovim配置教程，深入浅出，逻辑条理，加了一点自己的内容，就产生了这么一个授人以渔的教程。</p><span id="more"></span><h1 id="打造vs-code般的neovim">打造VS Code般的Neovim</h1><h2 id="一点废话">一点废话</h2><p>Neovim是什么就不过多介绍了，有兴趣可以自行Google，没兴趣那我就一句话介绍Neovim：</p><ul><li><del>一个可以变得很好看很好用的基于TUI的文本编辑器。</del></li><li><del>由于Vim拒绝了两个大补丁，作者一怒之下开的新分支。</del></li><li>Neovim是一个积极重构Vim的项目，旨在简化维护和鼓励贡献，在多个开发人员之间分配工作，在不修改核心的情况下创建高级UI，最大化可扩展性。</li></ul><p>就是单纯用vim觉得丑，所以跑路，尝试配置一个媲美VS Code体验的Neovim。教程来自于油管一个大佬，讲的很不错，不像某些教程，只告诉你怎么做，不告诉你为什么。这里附上链接，有兴趣可以自行观看。<a href="https://www.youtube.com/playlist?list=PLsz00TDipIffreIaUNk64KxTIkQaGguqn">Neovim for Newbs. FREE NEOVIM COURSE - YouTube</a></p><p>后面的内容有一个很重要的宗旨，你不是非得按照这个文档描述的步骤一步一步来做，这个文档最重要的目的是告诉你Neovim配置的方法。当你学会这个方法之后，可以完全自定义想要的内容。当然，这个时代不一定非要自己造轮子，github上有很多别人配置好的预制菜，你只需要clone下来就可以用。但本文档可以让你了解整个流程，在抄别人作业过程中遇到问题可以自己解决掉。</p><h2 id="依赖">依赖</h2><p>安装之前，你大致需要以下这些依赖工具，请确保环境中已经安装。</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mel">git, gcc, g++, <span class="hljs-keyword">python</span>, <span class="hljs-keyword">python</span>-venv, unzip<br></code></pre></td></tr></table></figure><h2 id="安装neovim">安装Neovim</h2><blockquote><p>官方仓库：<a href="https://github.com/neovim/neovim">neovim/neovim</a></p></blockquote><p>Windows系统可以直接下载zip包，解压到任何位置，然后运行<code>nvim.exe</code>。</p><p>Linux下可以下载<code>nvim.appimage</code>，然后执行<code>chmod u+x nvim.appimage &amp;&amp; ./nvim.appimage</code>。</p><p>安装好后在终端里运行<code>nvim</code>，就能得到下图。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/6ef7b27d-58e8-413c-b416-8ce95856db90"></p><h2 id="安装nerd-fonts">安装Nerd fonts</h2><p>我建议在安装完Neovim后先把字体安装好，后面用到的一些美化插件是比较依赖于<code>Nerd fonts</code>的。打开官方网站<a href="https://www.nerdfonts.com/#home">Nerd Fonts</a>，选一个喜欢的字体下载。这里推荐<code>Hack Nerd Font</code>。</p><p>Windows下只需要双击ttf文件，点击安装即可。</p><p>Linux下需要执行以下步骤。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo unzip Hack -d /usr/share/fonts/Hack<br>cd /usr/share/fonts/Hack<br>sudo mkfontscale  # 生成核心字体信息<br>sudo mkfontdir    # 生成字体文件夹<br>sudo fc-cache -fv # 刷新系统字体缓存<br></code></pre></td></tr></table></figure><h2 id="初始化配置文件">初始化配置文件</h2><p>Neovim的配置全部是基于<code>lua</code>的，所以后面创建的所以脚本均为<code>lua</code>脚本。</p><p>创建初始化配置文件<code>init.lua</code>，进行一些基础配置。</p><blockquote><p>Windows中配置文件放在<code>C:\Users\username\AppData\Local\nvim</code>下；</p><p>Linux中放在<code>~/.config/nvim</code>下</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lua">vim.cmd(<span class="hljs-string">"set expandtab"</span>)  <span class="hljs-comment">-- 使用空格代替制表符，确保在不同的编辑环境中保持一致</span><br>vim.cmd(<span class="hljs-string">"set tabstop=2"</span>)     <span class="hljs-comment">-- 设置制表符的宽度为2个空格</span><br>vim.cmd(<span class="hljs-string">"set softtabstop=2"</span>) <span class="hljs-comment">-- 设置软制表符的宽度也为2个空格，软制表符指的是按下Tab的时候插入的空格数</span><br>vim.cmd(<span class="hljs-string">"set shiftwidth=2"</span>)  <span class="hljs-comment">-- 设置每级缩进为2个空格</span><br></code></pre></td></tr></table></figure><p>然后在命令模式下执行<code>source %</code>，激活当前配置文件。</p><h2 id="插件管理器">插件管理器</h2><p>目前主流的插件管理器有两个：<code>lazy</code>和<code>packer</code>。</p><blockquote><p>官方仓库：</p><ul><li><a href="https://github.com/folke/lazy.nvim">folke/lazy.nvim</a></li><li><a href="https://github.com/wbthomason/packer.nvim">wbthomason/packer.nvim</a></li></ul></blockquote><p>两个包管理的差别不大，<del>为了贯彻好看的宗旨</del>，这里我们选择<code>lazy</code>作为包管理器。</p><p>安装<code>lazy</code>非常简单，只需要将README中Installation部分的语句复制粘贴到<code>init.lua</code>中即可。下面这些语句实现的大致功能为，为<code>lazy</code>指定一个存放数据的目录，然后检查<code>lazy</code>是否被安装，若没有则从<code>github</code>上拉取安装。</p><blockquote><p>这里注意要修改一下链接，将仓库链接从<code>https</code>协议改为<code>ssh</code>协议。如果你的网络条件支持稳定的通过<code>https</code>访问<code>github</code>，那当我这句话没说过。</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> lazypath = vim.fn.stdpath(<span class="hljs-string">"data"</span>) .. <span class="hljs-string">"/lazy/lazy.nvim"</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> vim.loop.fs_stat(lazypath) <span class="hljs-keyword">then</span><br>  vim.fn.system({<br>    <span class="hljs-string">"git"</span>,<br>    <span class="hljs-string">"clone"</span>,<br>    <span class="hljs-string">"--filter=blob:none"</span>,<br>    <span class="hljs-string">"ssh://git@github.com/folke/lazy.nvim.git"</span>, <span class="hljs-comment">-- 注意此处需要魔改一下</span><br>    <span class="hljs-string">"--branch=stable"</span>, <span class="hljs-comment">-- latest stable release</span><br>    lazypath,<br>  })<br><span class="hljs-keyword">end</span><br>vim.opt.rtp:prepend(lazypath)<br></code></pre></td></tr></table></figure><p>然后我们创建两个变量来存放插件和选项，并调用<code>setup()</code>函数来配置它。这个<code>setup()</code>函数将伴随整个插件配置过程，具体细节无需关心，毕竟我们也不写<code>lua</code>，我们只是<code>lua</code>的搬运工。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> plugins = {}<br><span class="hljs-keyword">local</span> opts = {}<br><br><span class="hljs-built_in">require</span>(<span class="hljs-string">"lazy"</span>).setup(plugins, opts)<br></code></pre></td></tr></table></figure><p>完成上面的步骤后，同样<code>source %</code>激活一下，这里可能会卡顿一会儿，因为此时后台在从<code>github</code>上拉取并安装<code>lazy</code>。</p><p>安装好后，命令模式下执行<code>: Lazy</code>就可以打开<code>lazy</code>的管理界面了。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b76255d1-a1ee-4f02-b10a-9c259b4127b6"></p><h2 id="主题">主题</h2><p>主题这里，大佬推荐<code>catppuccin</code>，确实挺好看，无脑跟！</p><blockquote><p>官方仓库：<a href="https://github.com/catppuccin/nvim">catppuccin/nvim</a></p></blockquote><p>有了<code>lazy</code>，安装这些插件及其简单，只需要将下面这行放入我们上一步中创建的<code>plugins</code>变量中。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> plugins = {<br>  { <span class="hljs-string">"catppuccin/nvim"</span>, name = <span class="hljs-string">"catppuccin"</span>, priority = <span class="hljs-number">1000</span> },<br>}<br></code></pre></td></tr></table></figure><p>此时<code>:q</code>退出Neovim，然后重新打开，你会发现<code>lazy</code>管理界面跳了出来，然后提示你正在安装。等待一会儿就可以看到，主题颜色已经变了。但还没结束，现在主题颜色变了只是因为<code>lazy</code>帮你安装完成后自动加载了该插件。如果此时你再退出重开一次，会发现主题又变回了默认状态。我们需要再添加两行代码，将默认的主题配置成<code>catppuccin</code>。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-built_in">require</span>(<span class="hljs-string">"catppuccin"</span>).setup()<br>vim.cmd.colorscheme <span class="hljs-string">"catppuccin"</span><br></code></pre></td></tr></table></figure><p>到此，<code>catppuccin</code>就配置完成了，不出意外你将得到下面这样的状态。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/27b03968-3582-458e-91a6-438a3ce64739"></p><h2 id="核心插件">核心插件</h2><h3 id="telescope">Telescope</h3><p><code>telescope</code>是一个基于列表模糊查找器，可以用来查找文件。其他更高级的功能可以参考官方仓库。</p><blockquote><p>官方仓库：<a href="https://github.com/nvim-telescope/telescope.nvim">nvim-telescope/telescope.nvim</a></p></blockquote><p>安装插件同样及其简单，在<code>plugins</code>变量中增加一项即可。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> plugins = {<br>  { <span class="hljs-string">"catppuccin/nvim"</span>, name = <span class="hljs-string">"catppuccin"</span>, priority = <span class="hljs-number">1000</span> },<br>  {<br>    <span class="hljs-string">'nvim-telescope/telescope.nvim'</span>, tag = <span class="hljs-string">'0.1.5'</span>,<br>    dependencies = { <span class="hljs-string">'nvim-lua/plenary.nvim'</span> }<br>  },<br>}<br></code></pre></td></tr></table></figure><p>退出Neovim再重新打开，你又会看到<code>lazy</code>在帮你安装插件。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/d415dabc-08d6-412c-b0b6-42c8b4ccef40"></p><p>上图是已经安装好的状态。然后在<code>init.lua</code>中对<code>telescope</code>进行一些配置。这里主要介绍两个功能，基本能够满足需要，其余的功能可以参考官方仓库自行配置。</p><h4 id="文件搜索">文件搜索</h4><p>在<code>init.lua</code>中添加如下两行。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> builtin = <span class="hljs-built_in">require</span>(<span class="hljs-string">"telescope.builtin"</span>) <span class="hljs-comment">-- 用来加载telescope内置的内容</span><br>vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'&lt;C-p&gt;'</span>, builtin.find_files, {}) <span class="hljs-comment">-- 设置快捷键，Ctrl + P为模糊搜索文件</span><br></code></pre></td></tr></table></figure><p>再重开Neovim，然后按<code>Ctrl + P</code>就可以打开<code>telescope</code>，输入文件名即可搜索文件。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/12f2dcb4-e1be-4903-9607-686929de3c0e"></p><h4 id="字符搜索">字符搜索</h4><p>同样在<code>init.lua</code>中添加语句。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">vim.g.mapleader = <span class="hljs-string">" "</span> <span class="hljs-comment">-- 设置leader键为空格</span><br><span class="hljs-comment">-- 快捷键为 &lt;leader&gt; + fg，这里f和g按顺序按就好，但是空格不要松开</span><br>vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'&lt;leader&gt;fg'</span>, builtin.live_grep, {}) <br></code></pre></td></tr></table></figure><p>配置完后<code>:source %</code>一下，按上面配置好的快捷键即可打开字符搜索。下图是一个搜索<code>lazy</code>字符串的例子。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/127233e7-4338-4b5f-9818-9d2c82e97443"></p><blockquote><p>到这一步可能会出现一个问题，搜索框可以正常打开，但是搜什么都是空白的。原因是缺少一个依赖工具<code>ripgrep</code>，只需要按官方仓库的提示安装即可。</p><p><code>ripgrep</code>官方仓库：<a href="https://github.com/BurntSushi/ripgrep">BurntSushi/ripgrep</a></p><p>安装Installation章节的提示安装即可。</p><ul><li>Windows下执行<code>winget install BurntSushi.ripgrep.MSVC</code>。</li><li>Linux下，以Ubuntu为例执行<code>sudo apt-get install ripgrep</code>。</li></ul><p>其余操作系统官方仓库中写的都很清楚，安装完成该工具，重启终端并打开Neovim就可以正常使用了。</p></blockquote><h3 id="treesitter">Treesitter</h3><p><code>treesitter</code>是一个基于语法树的语法高亮插件。</p><blockquote><p>官方仓库：<a href="https://github.com/nvim-treesitter/nvim-treesitter">nvim-treesitter/nvim-treesitter</a></p></blockquote><p>安装过程类似，还是在<code>plugins</code>中加入一行。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> plugins = {<br>  { <span class="hljs-string">"catppuccin/nvim"</span>, name = <span class="hljs-string">"catppuccin"</span>, priority = <span class="hljs-number">1000</span> },<br>  {<br>    <span class="hljs-string">'nvim-telescope/telescope.nvim'</span>, tag = <span class="hljs-string">'0.1.5'</span>,<br>    dependencies = { <span class="hljs-string">'nvim-lua/plenary.nvim'</span> }<br>  },<br>  { <span class="hljs-string">"nvim-treesitter/nvim-treesitter"</span>, build = <span class="hljs-string">":TSUpdate"</span> },<br>}<br></code></pre></td></tr></table></figure><p>重启Neovim，<code>lazy</code>会帮你安装，然后对其进行配置。</p><blockquote><p>在配置<code>treesitter</code>之前，请确保你的系统路径中有可用的C编译器，<code>gcc</code>、<code>clang</code>、<code>MSVC</code>都可以。</p><p>如果你是Windows用户，要确保开启开发者模式。打开<code>设置 -&gt; 系统 -&gt; 开发者选项 -&gt; 开发人员模式</code>。</p></blockquote><p>在<code>init.lua</code>中添加如下代码。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> <span class="hljs-built_in">config</span> = <span class="hljs-built_in">require</span>(<span class="hljs-string">"nvim-treesitter.configs"</span>)<br><span class="hljs-built_in">config</span>.setup({<br>  ensure_installed = { <span class="hljs-string">"lua"</span>, <span class="hljs-string">"c"</span>, <span class="hljs-string">"cpp"</span> }, <span class="hljs-comment">-- 确保安装lua，c和cpp相关的内容</span><br>  highlight = { enable = <span class="hljs-literal">true</span> }, <span class="hljs-comment">-- 开启高亮</span><br>  indent = { enable = <span class="hljs-literal">true</span> },    <span class="hljs-comment">-- 开启缩进</span><br>})<br></code></pre></td></tr></table></figure><p>此时<code>:source %</code>一下，<code>treesitter</code>就会开始安装语言相关的内容。安装完后会发现，当前打开的这个<code>lua</code>脚本已经拥有了语法高亮。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/4a834eb2-f842-465a-8961-27be541d7e92"></p><p>你可以用<code>:TSInstall</code>来安装新的语言支持，用<code>:TSModuleInfo</code>来查看已经支持的语言。</p><h3 id="neo-tree">Neo-tree</h3><p><code>neo-tree</code>，就如同该插件的名称一样，是一个文件<code>tree</code>。同样在<code>plugins</code>中添加。</p><blockquote><p>官方仓库：<a href="https://github.com/nvim-neo-tree/neo-tree.nvim">nvim-neo-tree/neo-tree.nvim</a></p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> plugins = {<br>  { <span class="hljs-string">"catppuccin/nvim"</span>, name = <span class="hljs-string">"catppuccin"</span>, priority = <span class="hljs-number">1000</span> },<br>  {<br>    <span class="hljs-string">'nvim-telescope/telescope.nvim'</span>, tag = <span class="hljs-string">'0.1.5'</span>,<br>    dependencies = { <span class="hljs-string">'nvim-lua/plenary.nvim'</span> }<br>  },<br>  { <span class="hljs-string">"nvim-treesitter/nvim-treesitter"</span>, build = <span class="hljs-string">":TSUpdate"</span> },<br>  {<br>    <span class="hljs-string">"nvim-neo-tree/neo-tree.nvim"</span>,<br>    branch = <span class="hljs-string">"v3.x"</span>,<br>    dependencies = {<br>      <span class="hljs-string">"nvim-lua/plenary.nvim"</span>,<br>      <span class="hljs-string">"nvim-tree/nvim-web-devicons"</span>,<br>      <span class="hljs-string">"MunifTanjim/nui.nvim"</span>,<br>    }<br>  }<br>}<br></code></pre></td></tr></table></figure><p>重启Neovim，等待<code>lazy</code>安装插件，安装完成后即可使用<code>neo-tree</code>。</p><p>输入命令<code>:Neotree filesystem reveal left</code>就可以在左侧显示文件树了。当然，为这条命令设置一个快捷键会更方便。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lua">vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'&lt;C-b&gt;'</span>, <span class="hljs-string">':Neotree filesystem reveal left&lt;CR&gt;'</span>, {})<br></code></pre></td></tr></table></figure><p>这里为了保持VS Code的习惯，设置成了<code>Ctrl + b</code>，你可以根据自己的习惯来配置。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/b938e2af-50fb-48a3-9adb-1df39d998003"></p><h2 id="模块化插件配置">模块化插件配置</h2><p>配置到这里聪明的你可能已经发现一个问题了，我们所有的配置都集中在同一个文件<code>init.lua</code>中，这显然是不合理的。所以我们接下来将之前所做过的所有配置，拆分开来，同时体验一下<code>neo-tree</code>带来的便利。</p><p>按下<code>Ctrl + b</code>打开文件树，按<code>a</code>创建文件夹及文件<code>lua/plugins.lua</code>。将我们之前的<code>plugins</code>变量丢进<code>plugins.lua</code>脚本中，然后返回该变量，脚本内容如下。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  { <span class="hljs-string">"catppuccin/nvim"</span>, name = <span class="hljs-string">"catppuccin"</span>, priority = <span class="hljs-number">1000</span> },<br>  {<br>    <span class="hljs-string">'nvim-telescope/telescope.nvim'</span>, tag = <span class="hljs-string">'0.1.5'</span>,<br>    dependencies = { <span class="hljs-string">'nvim-lua/plenary.nvim'</span> }<br>  },<br>  { <span class="hljs-string">"nvim-treesitter/nvim-treesitter"</span>, build = <span class="hljs-string">":TSUpdate"</span> },<br>  {<br>    <span class="hljs-string">"nvim-neo-tree/neo-tree.nvim"</span>,<br>    branch = <span class="hljs-string">"v3.x"</span>,<br>    dependencies = {<br>      <span class="hljs-string">"nvim-lua/plenary.nvim"</span>,<br>      <span class="hljs-string">"nvim-tree/nvim-web-devicons"</span>,<br>      <span class="hljs-string">"MunifTanjim/nui.nvim"</span>,<br>    }<br>  }<br>}<br></code></pre></td></tr></table></figure><p>然后将<code>init.lua</code>中的<code>plugins</code>变量删除，并修改下面的语句。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-built_in">require</span>(<span class="hljs-string">"lazy"</span>).setup(<span class="hljs-string">"plugins"</span>) <span class="hljs-comment">-- 原本是 require("lazy").setup(plugins, opts)</span><br></code></pre></td></tr></table></figure><p>我们创建的<code>plugins.lua</code>脚本相对<code>init.lua</code>的路径为<code>./lua/plugins.lua</code>，这里只需要写<code>"plugins"</code>即可，<code>lazy</code>会自动找到这个路径。重启Neovim确保工作正常。</p><p>但是这样的模块化依然不够，这只是将依托答辩从旱厕搬进了马桶，并没有好多少，所以我们需要对插件配置进一步拆分。</p><p>在<code>lua</code>文件夹下创建<code>plugins</code>文件夹，在<code>plugins</code>文件夹下创建我们第一个配置的插件<code>catppuccin</code>对应的脚本，命名为<code>catppuccin.lua</code>。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/9108a6d9-0b6b-4308-b71e-f9529e44ea08"></p><blockquote><p>此时左下角提示<code>Config Change Detected. Reloading...</code>，这都要归功于<code>lazy</code>插件管理器，它会实时的检测插件配置的变换，自动帮你重新加载。</p></blockquote><p>将<code>plugins.lua</code>中关于<code>catppuccin</code>的配置都转移到<code>catppuccin.lua</code>中，同样的方式进行返回。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  <span class="hljs-string">"catppuccin/nvim"</span>, <br>  name = <span class="hljs-string">"catppuccin"</span>, <br>  priority = <span class="hljs-number">1000</span><br>}<br></code></pre></td></tr></table></figure><p>同时<code>init.lua</code>中还有一些关于<code>catppuccin</code>的配置。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-built_in">require</span>(<span class="hljs-string">"catppuccin"</span>).setup()<br>vim.cmd.colorscheme <span class="hljs-string">"catppuccin"</span><br></code></pre></td></tr></table></figure><p>想要将这些配置也搬入<code>catppuccin.lua</code>脚本，就需要用到<code>lazy</code>提供的一个配置项<code>config</code>。这个<code>config</code>需要我们定义一个函数，在函数体中对插件进行配置。同时，使用<code>config</code>就相当于自动调用了<code>require("...").setup(opts)</code>。所以我们对<code>catppuccin.lua</code>进行修改。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  <span class="hljs-string">"catppuccin/nvim"</span>, <br>  name = <span class="hljs-string">"catppuccin"</span>, <br>  priority = <span class="hljs-number">1000</span>,<br>  <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    vim.cmd.colorscheme <span class="hljs-string">"catppuccin"</span><br>  <span class="hljs-keyword">end</span><br>}<br></code></pre></td></tr></table></figure><p>至此就实现了<code>catppuccin</code>插件的模块化，其他的所有插件都是同理的。我们将所有的插件都模块化，最终得到这样的文件结构。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5a03004f-6add-4b1c-b2a6-29a1ee8b077d"></p><p>现在我们的<code>init.lua</code>已经比之前简洁多了，这种模式可以更方便的管理插件，并且可以随时添加新的插件，只需要添加一个新的<code>lua</code>脚本即可。</p><blockquote><p>到这一步，我们之前用作过渡的<code>plugins.lua</code>脚本就可以删掉了，因为<code>lazy</code>会去找<code>plugins</code>文件夹下的子模块。</p></blockquote><p>但是！<code>init.lua</code>中还有一些关于Vim的基本配置，这些配置如果慢慢增多，还是会导致<code>init.lua</code>混乱不堪。所以我们将关于Vim的配置一并模块化。</p><p>在<code>lua</code>文件夹下创建一个名为<code>vim-options.lua</code>的脚本，将<code>init.lua</code>中关于Vim配置的语句全部丢进去。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/ec10b4b0-ab2e-4b45-b7d3-e9014fa2594b"></p><p>同时在<code>init.lua</code>中添加一句。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-built_in">require</span>(<span class="hljs-string">"vim-options"</span>) <span class="hljs-comment">-- 本句需要在require("lazy")之前</span><br></code></pre></td></tr></table></figure><h2 id="代码相关插件">代码相关插件</h2><h3 id="lsp">LSP</h3><p>先来说说什么是LSP，下面是wiki对于LSP的定义：</p><blockquote><p>The Language Server Protocol (LSP) is an open, JSON-RPC-based protocol for use between source code editors or integrated development environments (IDEs) and servers that provide "language intelligence tools": programming language-specific features like code completion, syntax highlighting and marking of warnings and errors, as well as refactoring routines. The goal of the protocol is to allow programming language support to be implemented and distributed independently of any given editor or IDE.</p></blockquote><p>感觉还是有点抽象，我觉得视频中的大佬解释的非常形象，这里转述一下。</p><p>将编辑器想象成客户端，LSP想象成服务器。编辑器打开一个文件的时候，会向LSP发送一个<code>DID OPEN</code>信号，告知LSP目前打开了一个文件。当文件发生任何改动的时候，会向LSP发送一个<code>DID UPDATE</code>信号，告知LSP代码被更改过。此时LSP会返回一个JSON文件，其中包含了类似下面这样的信息，告知编辑器哪里有错误、警告等等。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">{</span><br>    <span class="hljs-attr">"ERRORS"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"..."</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">"WARNINGS"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"..."</span><br><span class="hljs-punctuation">}</span><br></code></pre></td></tr></table></figure><p>所以，编写代码的过程中，能够有这样一个LSP提示错误和警告是非常必要的功能。</p><h4 id="lsp管理">LSP管理</h4><p>创建一个<code>lsp-config.lua</code>脚本来配置LSP。首先需要一个插件<code>Mason</code>，可以帮助我们很方便的安装各种语言的LSP、Linter、Formatter等。</p><blockquote><p>Mason官方仓库：<a href="https://github.com/williamboman/mason.nvim">williamboman/mason.nvim</a></p></blockquote><p>脚本中添加如下内容。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  <span class="hljs-string">"williamboman/mason.nvim"</span>,<br>  <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    <span class="hljs-built_in">require</span>(<span class="hljs-string">"mason"</span>).setup()<br>  <span class="hljs-keyword">end</span><br>}<br></code></pre></td></tr></table></figure><p>重启Neovim等待安装完成，输入<code>:Mason</code>即可打开<code>mason</code>的管理界面，在这里可以看到各种LSP、Linter、Formatter等。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/c3d90e3f-617c-4157-a6dc-16051ec65eb2"></p><h4 id="lsp配置">LSP配置</h4><p>除了<code>mason</code>我们还需要另一个工具<code>mason-lspconfig</code>来辅助配置<code>mason</code>的LSP。修改<code>lsp-config.lua</code>脚本如下。</p><blockquote><p>官方仓库：<a href="https://github.com/williamboman/mason-lspconfig.nvim">williamboman/mason-lspconfig.nvim</a></p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  {<br>    <span class="hljs-string">"williamboman/mason.nvim"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-built_in">require</span>(<span class="hljs-string">"mason"</span>).setup()<br>    <span class="hljs-keyword">end</span><br>  },<br>  {<br>    <span class="hljs-string">"williamboman/mason-lspconfig.nvim"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-built_in">require</span>(<span class="hljs-string">"mason-lspconfig"</span>).setup({<br>        ensure_installed = { <span class="hljs-string">"lua_ls"</span>, <span class="hljs-string">"clangd"</span>, <span class="hljs-string">"pyright"</span> } <span class="hljs-comment">-- 配置预安装的LSP服务</span><br>      })<br>    <span class="hljs-keyword">end</span><br>  }<br>}<br></code></pre></td></tr></table></figure><blockquote><p>各种编程语言对应的LSP服务名称可以参考官方仓库的README<a href="https://github.com/williamboman/mason-lspconfig.nvim?tab=readme-ov-file#available-lsp-servers">available-lsp-servers</a>。这里选择预装了<code>lua</code>、<code>C/C++</code>、<code>python</code>的LSP服务。</p></blockquote><p>重启Neovim等待安装，输入<code>:Mason</code>检查是否安装成果，不出意外你会得到如下所示的状态。</p><blockquote><p>这里有一个需要注意的地方，有些LSP是基于<code>node.js</code>和<code>npm</code>包管理器的，所以请确保你的环境已经安装了<code>node.js</code>。</p><p>同时，如果你使用了代理，请给<code>npm</code>也配置代理，具体方法自行Google。</p></blockquote><p><img src="https://github.com/Deleter-D/Images/assets/56388518/e9fa2622-c281-41b3-bfad-08c35fe9bcad"></p><h4 id="lsp客户端">LSP客户端</h4><p>接下来我们还需要用到一个叫做<code>nvim-lspconfig</code>的插件，使得Neovim能够和LSP进行通信</p><blockquote><p>官方仓库：<a href="https://github.com/neovim/nvim-lspconfig">neovim/nvim-lspconfig</a></p></blockquote><p>继续修改<code>lsp-config.lua</code>脚本如下。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  {<br>    <span class="hljs-string">"williamboman/mason.nvim"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-built_in">require</span>(<span class="hljs-string">"mason"</span>).setup()<br>    <span class="hljs-keyword">end</span><br>  },<br>  {<br>    <span class="hljs-string">"williamboman/mason-lspconfig.nvim"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-built_in">require</span>(<span class="hljs-string">"mason-lspconfig"</span>).setup({<br>        ensure_installed = { <span class="hljs-string">"lua_ls"</span>, <span class="hljs-string">"clangd"</span>, <span class="hljs-string">"pyright"</span> }<br>      })<br>    <span class="hljs-keyword">end</span><br>  },<br>  {<br>    <span class="hljs-string">"neovim/nvim-lspconfig"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-keyword">local</span> lspconfig = <span class="hljs-built_in">require</span>(<span class="hljs-string">"lspconfig"</span>)<br>      lspconfig.lua_ls.setup({})<br>      lspconfig.clangd.setup({})<br>      lspconfig.pyright.setup({})<br>    <span class="hljs-keyword">end</span><br>  }<br>}<br></code></pre></td></tr></table></figure><p>老样子，重启Neovim等待安装，然后输入<code>:LspInfo</code>查看当前LSP服务的状态。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/1e010c1b-ba90-4236-aab7-8012b90c4524"></p><p>可以看到检测到一个客户端，所配置的LSP服务叫做<code>lua_ls</code>。</p><p>然后配置一些快捷键，以便进行LSP相关的操作。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs lua">{<br>    <span class="hljs-string">"neovim/nvim-lspconfig"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-keyword">local</span> lspconfig = <span class="hljs-built_in">require</span>(<span class="hljs-string">"lspconfig"</span>)<br>      lspconfig.lua_ls.setup({})<br>      lspconfig.clangd.setup({})<br>      lspconfig.pyright.setup({})<br><br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'K'</span>, vim.lsp.buf.hover, {})<br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'gD'</span>, vim.lsp.buf.declaration, {})<br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'gd'</span>, vim.lsp.buf.definition, {})<br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'gi'</span>, vim.lsp.buf.implementation, {})<br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'&lt;C-k&gt;'</span>, vim.lsp.buf.signature_help, {})<br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'&lt;leader&gt;rn'</span>, vim.lsp.buf.<span class="hljs-built_in">rename</span>, {})<br>      vim.keymap.set(<span class="hljs-string">'n'</span>, <span class="hljs-string">'&lt;leader&gt;ca'</span>, vim.lsp.buf.code_action, {})<br>    <span class="hljs-keyword">end</span><br>}<br></code></pre></td></tr></table></figure><h3 id="代码格式化">代码格式化</h3><p>这里用到一个名为<code>null-ls</code>的插件，通过和特定语言的formatter配合进行操作，这里的formatter通过<code>mason</code>来安装。</p><blockquote><p>官方仓库：<a href="https://github.com/nvimtools/none-ls.nvim">nvimtools/none-ls.nvim</a></p></blockquote><p>添加<code>none-ls.lua</code>配置脚本。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br><span class="hljs-string">"nvimtools/none-ls.nvim"</span>,<br><span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br><span class="hljs-keyword">local</span> null_ls = <span class="hljs-built_in">require</span>(<span class="hljs-string">"null-ls"</span>)<br>null_ls.setup({<br>sources = {<br>null_ls.builtins.formatting.stylua,<br>null_ls.builtins.formatting.clang_format,<br>null_ls.builtins.formatting.black,<br>null_ls.builtins.formatting.isort,<br>},<br>})<br><br>vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;leader&gt;gf"</span>, vim.lsp.buf.<span class="hljs-built_in">format</span>, {})<br><span class="hljs-keyword">end</span>,<br>}<br></code></pre></td></tr></table></figure><p>这里配置了<code>lua</code>、<code>C/C++</code>和<code>Python</code>的formatter。</p><h3 id="代码自动补全">代码自动补全</h3><p>关于代码自动补全，有一系列的插件，这里推荐先捋清它们之间的关系。我们先列出可能用到的插件并附上仓库链接：</p><ol type="1"><li><code>nvim-cmp</code>（<a href="https://github.com/hrsh7th/nvim-cmp">hrsh7th/nvim-cmp</a>）；</li><li><code>LuaSnip</code>（<a href="https://github.com/L3MON4D3/LuaSnip">L3MON4D3/LuaSnip</a>）；</li><li><code>cmp.luasnip</code>（<a href="https://github.com/saadparwaiz1/cmp_luasnip">saadparwaiz1/cmp_luasnip</a>）；</li><li><code>friendly-snippets</code>（<a href="https://github.com/rafamadriz/friendly-snippets">rafamadriz/friendly-snippets</a>）；</li><li><code>cmp.nvim.lsp</code>（<a href="https://github.com/hrsh7th/cmp-nvim-lsp">hrsh7th/cmp-nvim-lsp</a>）。</li></ol><p><code>nvim-cmp</code>是一个代码补全引擎，可以根据输入来显示补全信息。<code>nvim-cmp</code>这个补全引擎只能提供代码补全的能力，它本身并没有补全的”素材“。这时就需要一些第三方插件来提高代码补全的来源，也就是“素材”（<code>Snippets</code>），并赋予这些Snippets展开的能力。</p><p><code>LuaSnip</code>是一个<code>lua</code>写的<code>Snippets</code>引擎，它属于扩展<code>Snippets</code>的工具。是为<code>nvim-cmp</code>提供服务的。</p><p><code>cmp.luasnip</code>则是<code>LuaSnip</code>的“素材”来源，它为<code>nvim-cmp</code>提供一系列可能的<code>Snippets</code>，然后<code>LuaSnip</code>会将这些<code>Snippets</code>展开。</p><p><code>friendly-snippets</code>是一个针对不同编程语言的<code>Snippets</code>集合，可以将不同语言的“素材”集中在一起，并使得<code>LuaSnip</code>可以加载。</p><p><code>cmp.nvim.lsp</code>也是一个<code>Snippets</code>来源，但可以从任何缓存中存在的LSP来获取“素材”。</p><p>解释清楚上述几个插件的关系后，就可以开始配置了。先来进行<code>nvim-cmp</code>的基本配置，初步配置文件如下所示。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  <span class="hljs-string">"hrsh7th/nvim-cmp"</span>,<br>  <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    <span class="hljs-keyword">local</span> cmp = <span class="hljs-built_in">require</span>(<span class="hljs-string">"cmp"</span>)<br>    cmp.setup({<br>      snippet = {<br>        expand = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">(args)</span></span><br>          <span class="hljs-built_in">require</span>(<span class="hljs-string">"luasnip"</span>).lsp_expand(args.body)<br>        <span class="hljs-keyword">end</span>,<br>      },<br>      window = {<br>        completion = cmp.<span class="hljs-built_in">config</span>.window.bordered(),<br>        documentation = cmp.<span class="hljs-built_in">config</span>.window.bordered(),<br>      },<br>      mapping = cmp.mapping.preset.<span class="hljs-built_in">insert</span>({<br>        <span class="hljs-comment">-- ["&lt;C-b&gt;"] = cmp.mapping.scroll_docs(-4),</span><br>        [<span class="hljs-string">"&lt;C-f&gt;"</span>] = cmp.mapping.scroll_docs(<span class="hljs-number">4</span>),<br>        [<span class="hljs-string">"&lt;C-Space&gt;"</span>] = cmp.mapping.complete(),<br>        [<span class="hljs-string">"&lt;C-e&gt;"</span>] = cmp.mapping.abort(),<br>        [<span class="hljs-string">"&lt;CR&gt;"</span>] = cmp.mapping.confirm({ <span class="hljs-built_in">select</span> = <span class="hljs-literal">true</span> }),<br>      }),<br>      sources = cmp.<span class="hljs-built_in">config</span>.sources({<br>        { name = <span class="hljs-string">"nvim_lsp"</span> },<br>        { name = <span class="hljs-string">"luasnip"</span> },<br>      }, {<br>        { name = <span class="hljs-string">"buffer"</span> },<br>      }),<br>    })<br>  <span class="hljs-keyword">end</span>,<br>}<br></code></pre></td></tr></table></figure><p>接下来配置<code>LuaSnip</code>及其<code>Snippets</code>来源：<code>cmp.luasnip</code>、<code>friendly-snippets</code>。将上面对<code>nvim-cmp</code>的配置放入一个<code>{}</code>中，然后在它的上面再创建一个新的<code>{}</code>，内容如下。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs lua">{<br>  <span class="hljs-string">"L3MON4D3/LuaSnip"</span>,<br>  dependencies = {<br>    <span class="hljs-string">"saadparwaiz1/cmp_luasnip"</span>,<br>    <span class="hljs-string">"rafamadriz/friendly-snippets"</span>,<br>  },<br>},<br></code></pre></td></tr></table></figure><p>然后需要在<code>nvim-cmp</code>的配置中添加一行。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-built_in">require</span>(<span class="hljs-string">"luasnip.loaders.from_vscode"</span>).lazy_load()<br></code></pre></td></tr></table></figure><p>重启Neovim就发现，现在已经有了一定程度的代码补全能力。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/84dee0d6-1053-4c17-ae90-a4f3e18ec6fb"></p><p>最后安装<code>cpm.nvim.lsp</code>来提高补全的质量，使得引擎能从LSP中获取<code>Snippets</code>。同样地，在上面脚本的基础上再添加一个<code>{}</code>。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">{<br>  <span class="hljs-string">"hrsh7th/cmp-nvim-lsp"</span>,<br>},<br></code></pre></td></tr></table></figure><p>同时，在<code>lsp-config.lua</code>脚本中关于<code>nvim-lspconfig</code>插件的配置中增加一项，并在所配置的每一项LSP中增加语句，内容如下。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs lua">{<br>    <span class="hljs-string">"neovim/nvim-lspconfig"</span>,<br>    <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>        <span class="hljs-keyword">local</span> capabilities = <span class="hljs-built_in">require</span>(<span class="hljs-string">"cmp_nvim_lsp"</span>).default_capabilities()<br><br>        <span class="hljs-keyword">local</span> lspconfig = <span class="hljs-built_in">require</span>(<span class="hljs-string">"lspconfig"</span>)<br>        lspconfig.lua_ls.setup({<br>            capabilities = capabilities,<br>        })<br>        lspconfig.clangd.setup({<br>            capabilities = capabilities,<br>        })<br>        lspconfig.pyright.setup({<br>            capabilities = capabilities,<br>        })<br><br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"K"</span>, vim.lsp.buf.hover, {})<br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"gD"</span>, vim.lsp.buf.declaration, {})<br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"gd"</span>, vim.lsp.buf.definition, {})<br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"gi"</span>, vim.lsp.buf.implementation, {})<br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;C-k&gt;"</span>, vim.lsp.buf.signature_help, {})<br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;leader&gt;rn"</span>, vim.lsp.buf.<span class="hljs-built_in">rename</span>, {})<br>        vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;leader&gt;ca"</span>, vim.lsp.buf.code_action, {})<br>    <span class="hljs-keyword">end</span>,<br>},<br></code></pre></td></tr></table></figure><p>再次尝试代码补全，发现补全的来源中已经多了来自LSP的内容。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/8727d832-bb7c-44dc-9c5b-e35d6e3ef1d5"></p><h3 id="debugger">Debugger</h3><p>在安装Debugger之前，我们需要介绍一个概念叫做Debug Adapter Protocol (DAP)。也许你在之前配置LSP的时候就已经在<code>Mason</code>中见过这个缩写了。DAP是微软为VS Code开发的，是为了使得编辑器和Debugger能够顺畅的交流。视频中的大佬描述的非常形象，编辑器和Debugger就像酷酷的西部牛仔一样，每个人都有自己交流的方式，而DAP站出来对Debugger说“Let's make things easier.”。DAP提供了一套通用的API，使得不同语言的不同Debugger能够使用这一套API为编辑器提供统一的格式，而编辑器要做的只是利用DAP提供的这套统一格式而已。</p><p>其实这套概念和LSP有点类似。我们需要一个服务端，也需要一个客户端。服务端我们可以借助<code>Mason</code>来安装，客户端我们这里用到的是<code>nvim-dap</code>，是一个为Neovim实现的DAP客户端。</p><blockquote><p>官方仓库：<a href="https://github.com/mfussenegger/nvim-dap">mfussenegger/nvim-dap</a></p></blockquote><p>同时我们还需要一个叫做<code>nvim-dap-ui</code>的UI插件来辅助Debugger工作。然后进行一些配置使得UI能够根据DAP自动打开或关闭。</p><blockquote><p>官方仓库：<a href="https://github.com/rcarriga/nvim-dap-ui">rcarriga/nvim-dap-ui</a></p></blockquote><p>新建一个<code>debugger.lua</code>的配置文件。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  <span class="hljs-string">"mfussenegger/nvim-dap"</span>,<br>  dependencies = {<br>    <span class="hljs-string">"rcarriga/nvim-dap-ui"</span>,<br>  },<br>  <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    <span class="hljs-keyword">local</span> dap = <span class="hljs-built_in">require</span>(<span class="hljs-string">"dap"</span>)<br>    <span class="hljs-keyword">local</span> dapui = <span class="hljs-built_in">require</span>(<span class="hljs-string">"dapui"</span>)<br>    dapui.setup()<br><br>    dap.listeners.before.attach.dapui_config = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      dapui.<span class="hljs-built_in">open</span>()<br>    <span class="hljs-keyword">end</span><br>    dap.listeners.before.launch.dapui_config = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      dapui.<span class="hljs-built_in">open</span>()<br>    <span class="hljs-keyword">end</span><br>    dap.listeners.before.event_terminated.dapui_config = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      dapui.<span class="hljs-built_in">close</span>()<br>    <span class="hljs-keyword">end</span><br>    dap.listeners.before.event_exited.dapui_config = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      dapui.<span class="hljs-built_in">close</span>()<br>    <span class="hljs-keyword">end</span><br><br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;leader&gt;b"</span>, dap.toggle_breakpoint, {})<br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;F5&gt;"</span>, dap.continue, {})<br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;F6&gt;"</span>, dap.terminate, {})<br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;F7&gt;"</span>, dap.restart, {})<br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;F9&gt;"</span>, dap.step_into, {})<br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;F10&gt;"</span>, dap.step_out, {})<br>    vim.keymap.set(<span class="hljs-string">"n"</span>, <span class="hljs-string">"&lt;F12&gt;"</span>, dap.step_over, {})<br>  <span class="hljs-keyword">end</span>,<br>}<br></code></pre></td></tr></table></figure><p>除了上面的配置，我们还需要针对你要debug的语言安装对应的DAP，并在<code>nvim-dap</code>中配置。这里以C/C++为例，使用codelldb作为DAP。首先在<code>Mason</code>中安装codelldb，然后对<code>nvim-dap</code>进行如下配置。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> install_root_dir = vim.fn.stdpath(<span class="hljs-string">"data"</span>) .. <span class="hljs-string">"/mason"</span><br><span class="hljs-keyword">local</span> extension_path = install_root_dir .. <span class="hljs-string">"/packages/codelldb/extension/"</span><br><span class="hljs-keyword">local</span> codelldb_path = extension_path .. <span class="hljs-string">"adapter/codelldb"</span><br>dap.adapters.codelldb = {<br>  <span class="hljs-built_in">type</span> = <span class="hljs-string">"server"</span>,<br>  port = <span class="hljs-string">"${port}"</span>,<br>  executable = {<br>    command = codelldb_path,<br>    args = { <span class="hljs-string">"--port"</span>, <span class="hljs-string">"${port}"</span> },<br>  },<br>}<br>dap.configurations.c = {<br>  {<br>    name = <span class="hljs-string">"Launch file"</span>,<br>    <span class="hljs-built_in">type</span> = <span class="hljs-string">"codelldb"</span>,<br>    request = <span class="hljs-string">"launch"</span>,<br>    program = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>      <span class="hljs-keyword">return</span> vim.fn.<span class="hljs-built_in">input</span>(<span class="hljs-string">"Path to executable: "</span>, vim.fn.getcwd() .. <span class="hljs-string">"/"</span>, <span class="hljs-string">"file"</span>)<br>    <span class="hljs-keyword">end</span>,<br>    cwd = <span class="hljs-string">"${workspaceFolder}"</span>,<br>  },<br>}<br>dap.configurations.cpp = dap.configurations.c<br></code></pre></td></tr></table></figure><p>用一个简单的C程序测试一下。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/343250c6-3db5-474f-870d-1d1d0565089c"></p><h2 id="美化插件">美化插件</h2><h3 id="lualine">lualine</h3><p><code>lualine</code>是一个非常美观的底部状态栏。安装它只需要在<code>plugins</code>下添加一个<code>lua</code>脚本即可。</p><blockquote><p>官方仓库：<a href="https://github.com/nvim-lualine/lualine.nvim">nvim-lualine/lualine.nvim</a></p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br>  <span class="hljs-string">'nvim-lualine/lualine.nvim'</span>,<br>  dependencies = { <span class="hljs-string">'nvim-tree/nvim-web-devicons'</span> },<br>  <span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    <span class="hljs-built_in">require</span>(<span class="hljs-string">'lualine'</span>).setup({<br>      options = {<br>        theme = <span class="hljs-string">'dracula'</span><br>      }<br>    })<br>  <span class="hljs-keyword">end</span><br>}<br></code></pre></td></tr></table></figure><p>重启Neovim，然后就得到了如下图所示的效果。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/86ec9d67-d04f-4226-8c98-31a075397739"></p><p><del>好好好，越来越像VS Code了。</del></p><h3 id="telescope-ui-select">Telescope-ui-select</h3><p>该插件是<code>telescope</code>插件的一个扩展，可以配合<code>vim.lsp.buf.code_action()</code>使用，使其以一种悬浮窗的形式显示，而不是底部命令栏。</p><blockquote><p>官方仓库：<a href="https://github.com/nvim-telescope/telescope-ui-select.nvim">nvim-telescope/telescope-ui-select.nvim</a></p></blockquote><p><img src="https://github.com/Deleter-D/Images/assets/56388518/a702981b-3793-424a-97d9-c13717634583"></p><h3 id="alpha-nvim">alpha-nvim</h3><p>该插件可以提供一个类似于VS Code的欢迎界面，配置脚本如下。</p><blockquote><p>官方仓库：<a href="https://github.com/goolord/alpha-nvim">goolord/alpha-nvim</a></p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">return</span> {<br><span class="hljs-string">"goolord/alpha-nvim"</span>,<br>dependencies = {<br><span class="hljs-string">"nvim-tree/nvim-web-devicons"</span>,<br>},<br><span class="hljs-built_in">config</span> = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br><span class="hljs-keyword">local</span> alpha = <span class="hljs-built_in">require</span>(<span class="hljs-string">"alpha"</span>)<br><span class="hljs-keyword">local</span> dashboard = <span class="hljs-built_in">require</span>(<span class="hljs-string">"alpha.themes.dashboard"</span>)<br><br>dashboard.section.header.val = {<br><span class="hljs-string">[[                               __                ]]</span>,<br><span class="hljs-string">[[  ___     ___    ___   __  __ /\_\    ___ ___    ]]</span>,<br><span class="hljs-string">[[ / _ `\  / __`\ / __`\/\ \/\ \\/\ \  / __` __`\  ]]</span>,<br><span class="hljs-string">[[/\ \/\ \/\  __//\ \_\ \ \ \_/ |\ \ \/\ \/\ \/\ \ ]]</span>,<br><span class="hljs-string">[[\ \_\ \_\ \____\ \____/\ \___/  \ \_\ \_\ \_\ \_\]]</span>,<br><span class="hljs-string">[[ \/_/\/_/\/____/\/___/  \/__/    \/_/\/_/\/_/\/_/]]</span>,<br>}<br><br>dashboard.section.buttons.val = {<br>dashboard.button(<span class="hljs-string">"e"</span>, <span class="hljs-string">"  New file"</span>, <span class="hljs-string">":ene &lt;BAR&gt; startinsert &lt;CR&gt;"</span>),<br>dashboard.button(<span class="hljs-string">"q"</span>, <span class="hljs-string">"󰅚  Quit NVIM"</span>, <span class="hljs-string">":qa&lt;CR&gt;"</span>),<br>}<br><br>alpha.setup(dashboard.opts)<br><span class="hljs-keyword">end</span>,<br>}<br></code></pre></td></tr></table></figure><p><code>header</code>和<code>buttons</code>两项配置是最具有可玩性的，官方仓库中有许多用户提供了他们自定义的配置文件。上面的最简配置文件效果如下图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/5beb0355-dae8-4dc0-aa08-b43e4fb349cc"></p><h2 id="快捷键列表">快捷键列表</h2><p>经过上面的一系列配置，我们就得到了下表中的功能。</p><h3 id="编辑器相关">编辑器相关</h3><table><thead><tr class="header"><th>快捷键</th><th>功能</th></tr></thead><tbody><tr class="odd"><td><code>&lt;C-p&gt;</code></td><td>文件模糊搜索</td></tr><tr class="even"><td><code>&lt;leader&gt;fg</code></td><td>字符串搜索</td></tr><tr class="odd"><td><code>&lt;C-b&gt;</code></td><td>打开文件树</td></tr></tbody></table><h3 id="lsp相关">LSP相关</h3><table><thead><tr class="header"><th>快捷键</th><th>功能</th></tr></thead><tbody><tr class="odd"><td><code>K</code></td><td>悬浮窗显示函数信息</td></tr><tr class="even"><td><code>gD</code></td><td>转到声明</td></tr><tr class="odd"><td><code>gd</code></td><td>转到定义</td></tr><tr class="even"><td><code>gi</code></td><td>转到实现</td></tr><tr class="odd"><td><code>&lt;C-k&gt;</code></td><td>函数签名帮助信息</td></tr><tr class="even"><td><code>&lt;leader&gt;rn</code></td><td>重命名</td></tr><tr class="odd"><td><code>&lt;leader&gt;ca</code></td><td>代码动作</td></tr><tr class="even"><td><code>&lt;leader&gt;gf</code></td><td>代码格式化</td></tr></tbody></table><h3 id="dap相关">DAP相关</h3><table><thead><tr class="header"><th>快捷键</th><th>功能</th></tr></thead><tbody><tr class="odd"><td><code>&lt;leader&gt;b</code></td><td>添加断点</td></tr><tr class="even"><td><code>&lt;F5&gt;</code></td><td>开始/继续执行</td></tr><tr class="odd"><td><code>&lt;F6&gt;</code></td><td>终止debug会话</td></tr><tr class="even"><td><code>&lt;F7&gt;</code></td><td>重新开启debug会话</td></tr><tr class="odd"><td><code>&lt;F9&gt;</code></td><td>单步执行</td></tr><tr class="even"><td><code>&lt;F10&gt;</code></td><td>单步跳出</td></tr><tr class="odd"><td><code>&lt;F12&gt;</code></td><td>逐过程执行</td></tr></tbody></table><h1 id="写在最后">写在最后</h1><p>上面讲了这么多插件，但依然希望你不要教条的按照这个教程来做，重要的是学会配置的方法，同时善用Google寻找更加优秀的插件。当然，最推荐的还是直接抄作业，在巨人的肩膀上进行自定义。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;偶然在Youtube上看到一个大佬的Neovim配置教程，深入浅出，逻辑条理，加了一点自己的内容，就产生了这么一个授人以渔的教程。&lt;/p&gt;</summary>
    
    
    
    <category term="折腾" scheme="https://deleter-d.github.io/categories/%E6%8A%98%E8%85%BE/"/>
    
    
    <category term="Neovim" scheme="https://deleter-d.github.io/tags/Neovim/"/>
    
    <category term="编辑器" scheme="https://deleter-d.github.io/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"/>
    
    <category term="VSCode" scheme="https://deleter-d.github.io/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>以张量角度考虑softmax算子</title>
    <link href="https://deleter-d.github.io/posts/27559/"/>
    <id>https://deleter-d.github.io/posts/27559/</id>
    <published>2023-12-05T08:01:50.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在之前的文章中已经介绍了Softmax算子开发的整体思路，但笔者只从向量的角度进行了说明，本篇文章就以处理张量的角度来进一步阐述。</p><span id="more"></span><h1 id="张量的内存排布">张量的内存排布</h1><p>要使Softmax算子处理张量，首先要了解张量在内存上的排布，我们用<code>numpy</code>的<code>ndarray</code>来说明。</p><p>首先利用<code>python</code>来创建一个<code>ndarray</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>data = np.random.randn(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>).astype(np.float32)<br></code></pre></td></tr></table></figure><p>然后我们写一个简单的<code>C++</code>函数（<code>tensor.cpp</code>），该函数接受一个对应数据类型的指针作为参数，功能就简单的打印输出。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><br><span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">printTensor</span><span class="hljs-params">(<span class="hljs-type">float</span> *tensor, <span class="hljs-type">int</span> *shape)</span></span>{<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; shape[<span class="hljs-number">0</span>]; i++) {<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; shape[<span class="hljs-number">1</span>]; j++) {<br>            std::cout &lt;&lt; tensor[i * shape[<span class="hljs-number">0</span>] + j] &lt;&lt; <span class="hljs-string">" "</span>;<br>        }<br>        std::cout &lt;&lt; <span class="hljs-string">"\n"</span>;<br>    }<br>}<br></code></pre></td></tr></table></figure><p>其中的<code>extern "C"</code>是必要的，否则调用时会出现<code>undefined symbol</code>问题。</p><p>然后将其编译成一个动态链接库，以供<code>python</code>调用，命令如下。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">g++ -shared -fPIC -o tensor.so tensor.cpp<br></code></pre></td></tr></table></figure><blockquote><p>注意：如果代码中使用了<code>C++</code>的标准库，则编译器要使用<code>g++</code>而不是<code>gcc</code>，否则会出现标准库符号找不到的问题，<code>clang</code>同理。</p></blockquote><p>编译好后在<code>python</code>中调用该库，数据类型的转换是利用<code>ctypes</code>来实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> ctypes <span class="hljs-keyword">import</span> CDLL, POINTER, c_float, c_int<br><br>data = np.random.randn(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>).astype(np.float32)<br>c_int_arr = c_int * <span class="hljs-built_in">len</span>(data.shape)<br><br>lib = CDLL(<span class="hljs-string">"./tensor.so"</span>) <span class="hljs-comment"># 获取动态链接库</span><br>printTensor = lib.printTensor <span class="hljs-comment"># 获取库中的函数符号</span><br>printTensor.argtypes = [ <span class="hljs-comment"># 定义函数的参数类型</span><br>    POINTER(c_float),<br>    POINTER(c_int),<br>]<br><br><span class="hljs-comment"># 函数调用</span><br>printTensor(<br>    data.ctypes.data_as(POINTER(c_float)), <span class="hljs-comment"># 将numpy的ndarray转换为C语言的float职责</span><br>    c_int_arr(data.shape[<span class="hljs-number">0</span>], data.shape[<span class="hljs-number">1</span>]), <span class="hljs-comment"># 将形状信息也传递给C++</span><br>)<br></code></pre></td></tr></table></figure><p>部分执行结果如下所示。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dns">-<span class="hljs-number">1.48456 0</span>.<span class="hljs-number">336725 1</span>.<span class="hljs-number">69846</span> -<span class="hljs-number">0.0248114</span> <span class="hljs-number">0.39322 0</span>.<span class="hljs-number">614784 0</span>.<span class="hljs-number">326595 0</span>.<span class="hljs-number">575949</span> -<span class="hljs-number">0.708058</span> -<span class="hljs-number">1.39587</span> -<span class="hljs-number">1.83477 0</span>.<span class="hljs-number">349339</span> -<span class="hljs-number">0.610898</span> -<span class="hljs-number">0.423076</span> -<span class="hljs-number">0.136989 0</span>.<span class="hljs-number">442269 0</span>.<span class="hljs-number">446412</span> -<span class="hljs-number">0.486558</span> -<span class="hljs-number">0.292987</span> <span class="hljs-number">1.29332 0</span>.<span class="hljs-number">187811 0</span>.<span class="hljs-number">331237 0</span>.<span class="hljs-number">63905</span> -<span class="hljs-number">1.46251</span> -<span class="hljs-number">0.536956</span> <span class="hljs-number">0.495119</span> -<span class="hljs-number">0.429213</span> -<span class="hljs-number">0.988436</span> -<span class="hljs-number">0.414105</span> -<span class="hljs-number">2.26553 1</span>.<span class="hljs-number">23408</span> -<span class="hljs-number">0.544561</span> <br><span class="hljs-number">0.369648</span> -<span class="hljs-number">1.12966</span> -<span class="hljs-number">0.154628 1</span>.<span class="hljs-number">09682 0</span>.<span class="hljs-number">676383 0</span>.<span class="hljs-number">444374</span> -<span class="hljs-number">0.706796</span> -<span class="hljs-number">0.873308</span> -<span class="hljs-number">1.32488</span> -<span class="hljs-number">0.537758</span> -<span class="hljs-number">1.81611</span> -<span class="hljs-number">2.06588 0</span>.<span class="hljs-number">721618 1</span>.<span class="hljs-number">02888</span> -<span class="hljs-number">0.919128</span> -<span class="hljs-number">0.765203</span> -<span class="hljs-number">0.42332 0</span>.<span class="hljs-number">0602946 1</span>.<span class="hljs-number">16713 0</span>.<span class="hljs-number">140398</span> -<span class="hljs-number">0.534829</span> -<span class="hljs-number">0.0961945</span> <span class="hljs-number">0.0153079</span> -<span class="hljs-number">0.261519</span> <span class="hljs-number">0.0927059</span> -<span class="hljs-number">0.868659</span> <span class="hljs-number">1.27008</span> -<span class="hljs-number">0.379786</span> <span class="hljs-number">0.382002</span> -<span class="hljs-number">1.76778 0</span>.<span class="hljs-number">660476 1</span>.<span class="hljs-number">06135</span><br>...<br></code></pre></td></tr></table></figure><p>以上得出结论，<code>numpy</code>中的张量在内存上就是一个<strong>一维数组</strong>，可以用指针来操作，其他框架的张量同理。</p><h1 id="算子逻辑">算子逻辑</h1><p>由于张量在内存上都是一维排布的，所以最内层维度在内存上是连续的。所以对于昇腾芯片来说，<code>Softmax</code>最适合加速的就是在张量的最后一个维度上进行计算，下面的讨论都基于最后一个维度。对于一个NHWC的张量来说，我们在最后一个维度上进行<code>Softmax</code>也是实际中最常用的情况。</p><p>算子涉及向量自然指数、向量归约求和、向量除法等运算，其中最需要关心的就是向量归约求和，因为它涉及到对齐的问题。</p><h2 id="可能的数据情况">可能的数据情况</h2><p>主要有以下几种情况：</p><h3 id="情况一数据repeat对齐">情况一：数据<code>repeat</code>对齐</h3><p>最好解决的就是<code>repeat</code>对齐的情况，不需要做尾块处理，直接利用<code>vec_cross_add()</code>归约求和即可。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/32e28548-e1d0-4781-b340-fa7631e1fba8"></p><h3 id="情况二数据部分repeat对齐部分block对齐">情况二：数据部分<code>repeat</code>对齐，部分<code>block</code>对齐</h3><p>对于部分<code>repeat</code>对齐，部分<code>block</code>对齐的情况，需要分开来处理。对于<code>repeat</code>对齐的部分同样简单处理，对于<code>block</code>对齐的部分，无法直接调用<code>vec_cross_add</code>接口进行归约求和，需要利用标量操作来累加进前面的结果中。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/9beafb91-6f29-4fbf-bc9b-5f3ba6996c4c"></p><h3 id="情况三数据部分repeat对齐部分block对齐剩余尾块block不对齐">情况三：数据部分<code>repeat</code>对齐，部分<code>block</code>对齐，剩余尾块<code>block</code>不对齐</h3><p>最后一种情况是最需要注意的情况，而且实际使用中大部分是这种情况。着重关注非<code>block</code>对齐部分的数据，这部分数据要从搬移的时候就开始做单独处理。因为GM与UB之间的数据搬移最小粒度是一个<code>block</code>，无法真正做到元素级别的搬移。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/3f33eedc-f0df-47f2-992c-acde552b4b62" style="zoom: 67%;"></p><p>对于这种情况的数据搬移，我们考虑一种简化情况，即数据长度大于一个<code>block</code>但不足两个<code>block</code>。对于这样的数据，GM与UB之间的搬移需要一个临时空间来辅助。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/dd30457f-da75-4fbc-8f4c-fab2a5dc42b6" style="zoom:50%;"></p><p>具体方式是从末尾向前取一个整<code>block</code>进行搬移，这样不会影响到后续的数据，同时使得<code>group</code>之间的访存严格隔离开来。</p><p>这样处理的时候，由于会有被重复搬移的数据，所以要注意在累加的时候不要重复累加元素。</p><h2 id="算子实现">算子实现</h2><p>为了避免张量过大，在UB上申请的空间超出限制，这里使<code>group</code>循环分批处理一个向量。即从GM搬移进UB，处理完后再搬回GM，再搬入下一批数据进行处理，直到所有数据被处理完成。</p><p>这样处理有一个好处就是，情况二和情况三的数据只会出现在最后一次迭代中。该算子的处理大体分为三个小模块，求<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.157ex" height="1.553ex" role="img" focusable="false" viewBox="0 -675.5 953.5 686.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,363) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container></span>、归约求和以及向量除法。</p><p>在写核心逻辑之前，我们需要为算子准备一系列的常量，方便后面使用。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 一个向量的repeat数量</span><br>std::<span class="hljs-type">size_t</span> total_repeat_count = vec_bytes / REPEAT_SIZE;<br><span class="hljs-comment">// 需要的核内迭代次数</span><br>std::<span class="hljs-type">size_t</span> iteration_times = total_repeat_count / MAX_REPEAT_PER_ITERATION + <span class="hljs-number">1</span>;<br><span class="hljs-comment">// 最后一次迭代处理的字节数</span><br>std::<span class="hljs-type">size_t</span> last_iter_bytes = vec_bytes - (iteration_times - <span class="hljs-number">1</span>) * MAX_BYTES_PER_ITERATION;<br><span class="hljs-comment">// 最后一次迭代数据中元素的个数</span><br>std::<span class="hljs-type">size_t</span> elem_count = last_iter_bytes / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><span class="hljs-comment">// 最后一次迭代数据中对齐block的个数</span><br>std::<span class="hljs-type">size_t</span> block_count = last_iter_bytes / BLOCK_SIZE;<br><span class="hljs-comment">// 最后一次迭代数据中对齐repeate的个数</span><br>std::<span class="hljs-type">size_t</span> repeat_count = last_iter_bytes / REPEAT_SIZE;<br><span class="hljs-comment">// 最后一次迭代数据中block对齐的元素个数</span><br>std::<span class="hljs-type">size_t</span> align_block_elem_count = block_count * BLOCK_SIZE / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><span class="hljs-comment">// 最后一次迭代数据中repeat对齐的元素个数</span><br>std::<span class="hljs-type">size_t</span> align_repeat_elem_count = repeat_count * REPEAT_SIZE / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><span class="hljs-comment">// 最后一次迭代数据中非对齐元素个数</span><br>std::<span class="hljs-type">size_t</span> tail_elem_count = elem_count - align_block_elem_count;<br><span class="hljs-comment">// 最后一次迭代数据中非对齐字节数</span><br>std::<span class="hljs-type">size_t</span> tail_bytes = tail_elem_count * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><span class="hljs-comment">// 最后一次迭代数据中，向前取整block的元素个数</span><br>std::<span class="hljs-type">size_t</span> tail_block_elem_count = BLOCK_SIZE / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><span class="hljs-comment">// 最后一次迭代数据中，向前取整block的起点索引</span><br>std::<span class="hljs-type">size_t</span> tail_memcpy_index = dim2 - tail_block_elem_count;<br></code></pre></td></tr></table></figure><p>核心逻辑如下，详细说明见注释。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; iteration_times; i++) {<br>  index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>  <span class="hljs-keyword">if</span> (i == iteration_times - <span class="hljs-number">1</span>) {<br>    tail_index = group_id * dim2 + tail_memcpy_index;<br>    <span class="hljs-comment">// 加载最后一次迭代中，block对齐的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      <span class="hljs-comment">// 加载最后一次迭代中，block非对齐的数据，向前取整block</span><br>      temp.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br>    bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec.<span class="hljs-built_in">to_view</span>(elem_count), input_vec.<span class="hljs-built_in">to_view</span>(elem_count));<br>    bisheng::<span class="hljs-built_in">vec_exp</span>(temp, temp);<br>    input_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      temp.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br>  } <span class="hljs-keyword">else</span> {<br>    <span class="hljs-comment">// 整块的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec, input_vec);<br>    input_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  }<br>}<br><br><span class="hljs-comment">// 计算向量和</span><br><span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; iteration_times; i++) {<br>  index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>  <span class="hljs-keyword">if</span> (i == iteration_times - <span class="hljs-number">1</span>) {<br>    tail_index = group_id * dim2 + tail_memcpy_index;<br>    <span class="hljs-comment">// 加载最后一次迭代中，block对齐的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      <span class="hljs-comment">// 加载最后一次迭代中，block非对齐的数据，向前取整block</span><br>      temp.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br>    <span class="hljs-keyword">if</span> (align_repeat_elem_count) {<br>      <span class="hljs-comment">// 将最后一次迭代中repeat对齐的数据求和</span><br>      bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_vec.<span class="hljs-built_in">to_view</span>(repeat_count, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), input_vec.<span class="hljs-built_in">to_view</span>(align_repeat_elem_count));<br>      <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; repeat_count; j++) {<br>        sum += sum_vec[j];<br>      }<br>    }<br>    <span class="hljs-comment">// 计算repeat不对齐，但block部分对齐的数据</span><br>    <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = align_repeat_elem_count; j &lt; align_block_elem_count; j++) {<br>      sum += input_vec[j];<br>    }<br>    <span class="hljs-comment">// 计算block不对齐的数据</span><br>    <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = tail_block_elem_count - tail_elem_count; j &lt; tail_block_elem_count; j++) {<br>      sum += temp[j];<br>    }<br>  } <span class="hljs-keyword">else</span> {<br>    <span class="hljs-comment">// 整块的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_vec.<span class="hljs-built_in">to_view</span>(MAX_REPEAT_PER_ITERATION, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), input_vec.<span class="hljs-built_in">to_view</span>(MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br>    <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>); j++) {<br>      sum += sum_vec[j];<br>    }<br>  }<br>}<br><br><span class="hljs-comment">// 利用向量和初始化分母向量</span><br>bisheng::vector&lt;<span class="hljs-type">float</span>, BLOCK_SIZE / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; temp_res;<br><span class="hljs-function">bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_BYTES_PER_ITERATION / <span class="hljs-title">sizeof</span><span class="hljs-params">(<span class="hljs-type">float</span>)</span>&gt; <span class="hljs-title">divisor</span><span class="hljs-params">(sum)</span></span>;<br><span class="hljs-function">bisheng::vector&lt;<span class="hljs-type">float</span>, BLOCK_SIZE / <span class="hljs-title">sizeof</span><span class="hljs-params">(<span class="hljs-type">float</span>)</span>&gt; <span class="hljs-title">temp_divisor</span><span class="hljs-params">(sum)</span></span>;<br><br><span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; iteration_times; i++) {<br>  index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>  <span class="hljs-keyword">if</span> (i == iteration_times - <span class="hljs-number">1</span>) {<br>    tail_index = group_id * dim2 + tail_memcpy_index;<br>    <span class="hljs-comment">// 加载最后一次迭代中，block对齐的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      <span class="hljs-comment">// 加载最后一次迭代中，block非对齐的数据，向前取整block</span><br>      temp.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br>    bisheng::<span class="hljs-built_in">vec_div</span>(res_vec.<span class="hljs-built_in">to_view</span>(elem_count), input_vec.<span class="hljs-built_in">to_view</span>(elem_count), divisor.<span class="hljs-built_in">to_view</span>(elem_count));<br>    bisheng::<span class="hljs-built_in">vec_div</span>(temp_res, temp, temp_divisor);<br>    res_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      temp_res.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br>  } <span class="hljs-keyword">else</span> {<br>    <span class="hljs-comment">// 整块的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    bisheng::<span class="hljs-built_in">vec_div</span>(res_vec, input_vec, divisor);<br>    res_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  }<br>}<br></code></pre></td></tr></table></figure><h1 id="算子优化">算子优化</h1><h2 id="算子逻辑优化">算子逻辑优化</h2><p>观察上述的核心逻辑，可以观察到几个比较明显的优化点：</p><ul><li>计算<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.157ex" height="1.553ex" role="img" focusable="false" viewBox="0 -675.5 953.5 686.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,363) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container></span>和归约求和的过程可以合并，不需要先计算<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.157ex" height="1.553ex" role="img" focusable="false" viewBox="0 -675.5 953.5 686.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,363) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container></span>后搬出，再搬入计算归约和；</li><li>最后计算除法的过程，可以用倒数乘法来代替；</li><li>可以开启<code>double buffering</code>。</li></ul><p>优化后的核心逻辑如下所示。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 计算e^x并归约求和</span><br><span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; iteration_times; i++) {<br>  index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>  <span class="hljs-comment">// 判断当前缓冲区</span><br>  <span class="hljs-keyword">auto</span> &amp;input_vec = i % <span class="hljs-number">2</span> ? input_vec_0 : input_vec_1;<br>  <span class="hljs-keyword">auto</span> &amp;sum_vec = i % <span class="hljs-number">2</span> ? sum_vec_0 : sum_vec_1;<br>  <span class="hljs-keyword">auto</span> &amp;sum_temp = i % <span class="hljs-number">2</span> ? sum_temp_0 : sum_temp_1;<br>  <span class="hljs-keyword">auto</span> &amp;sum = i % <span class="hljs-number">2</span> ? sum_0 : sum_1;<br><br>  <span class="hljs-keyword">if</span> (i == iteration_times - <span class="hljs-number">1</span>) {<br>    tail_index = group_id * dim2 + tail_memcpy_index;<br>    <span class="hljs-comment">// 加载最后一次迭代中，block对齐的数据</span><br>    <span class="hljs-keyword">if</span> (align_block_elem_count) {<br>      input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec.<span class="hljs-built_in">to_view</span>(elem_count), input_vec.<span class="hljs-built_in">to_view</span>(elem_count));<br>      <span class="hljs-comment">// 将最后一次迭代中repeat对齐的数据求和</span><br>      <span class="hljs-keyword">if</span> (align_repeat_elem_count) {<br>        bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_vec.<span class="hljs-built_in">to_view</span>(repeat_count, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), input_vec.<span class="hljs-built_in">to_view</span>());<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; repeat_count; j++) {<br>          sum += sum_vec[j];<br>        }<br>      }<br>      <span class="hljs-comment">// 计算repeat不对齐，但block部分对齐的数据</span><br>      <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = align_repeat_elem_count; j &lt; align_block_elem_count; j++) {<br>        sum += input_vec[j];<br>      }<br>      input_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_exp_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    }<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      <span class="hljs-comment">// 加载最后一次迭代中，block非对齐的数据，向前取整block</span><br>      temp.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>      bisheng::<span class="hljs-built_in">vec_exp</span>(temp, temp);<br>      <span class="hljs-comment">// 计算block不对齐的数据</span><br>      <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = tail_block_elem_count - tail_elem_count; j &lt; tail_block_elem_count; j++) {<br>        sum += temp[j];<br>      }<br>      temp.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_exp_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br><br>  } <span class="hljs-keyword">else</span> { <span class="hljs-comment">// 整块的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec, input_vec);<br>    bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_vec.<span class="hljs-built_in">to_view</span>(MAX_REPEAT_PER_ITERATION, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), input_vec.<span class="hljs-built_in">to_view</span>(MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)));<br>    bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_temp.<span class="hljs-built_in">to_view</span>(sum_vec_repeat_count, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), sum_vec.<span class="hljs-built_in">to_view</span>(MAX_REPEAT_PER_ITERATION));<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; sum_vec_repeat_count; j++) {<br>      sum += sum_temp[j];<br>    }<br>    input_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_exp_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  }<br>}<br><br><span class="hljs-comment">// 两个缓冲区的和相加</span><br>sum_0 += sum_1;<br><span class="hljs-keyword">auto</span> &amp;sum = sum_0;<br><br>bisheng::vector&lt;<span class="hljs-type">float</span>, BLOCK_SIZE / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; temp_res;<br><span class="hljs-type">float</span> divisor = <span class="hljs-number">1</span> / sum;<br><br><span class="hljs-comment">// 向量除法</span><br><span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; iteration_times; i++) {<br>  index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>  <span class="hljs-comment">// 判断当前缓冲区</span><br>  <span class="hljs-keyword">auto</span> &amp;input_vec = i % <span class="hljs-number">2</span> ? input_vec_0 : input_vec_1;<br>  <span class="hljs-keyword">auto</span> &amp;res_vec = i % <span class="hljs-number">2</span> ? res_vec_0 : res_vec_1;<br>  <span class="hljs-keyword">if</span> (i == iteration_times - <span class="hljs-number">1</span>) {<br>    tail_index = group_id * dim2 + tail_memcpy_index;<br>    <span class="hljs-comment">// 加载最后一次迭代中，block对齐的数据</span><br>    <span class="hljs-keyword">if</span> (align_block_elem_count) {<br>      input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_exp_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>      bisheng::<span class="hljs-built_in">vec_mul</span>(res_vec.<span class="hljs-built_in">to_view</span>(elem_count), input_vec.<span class="hljs-built_in">to_view</span>(elem_count), divisor);<br>      res_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), align_block_elem_count);<br>    }<br>    <span class="hljs-keyword">if</span> (tail_bytes) {<br>      <span class="hljs-comment">// 加载最后一次迭代中，block非对齐的数据，向前取整block</span><br>      temp.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_exp_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>      bisheng::<span class="hljs-built_in">vec_mul</span>(temp_res, temp, divisor);<br>      temp_res.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + tail_index).<span class="hljs-built_in">get</span>(), tail_block_elem_count);<br>    }<br>  } <span class="hljs-keyword">else</span> { <span class="hljs-comment">// 整块的数据</span><br>    input_vec.<span class="hljs-built_in">load</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_exp_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    bisheng::<span class="hljs-built_in">vec_mul</span>(res_vec, input_vec, divisor);<br>    res_vec.<span class="hljs-built_in">store</span>(sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(d_tensor + index).<span class="hljs-built_in">get</span>(), MAX_BYTES_PER_ITERATION / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  }<br>}<br></code></pre></td></tr></table></figure><h2 id="分核方案优化">分核方案优化</h2><p>由于毕昇异构算子中存在一个限制，即<code>group</code>的数量最大为65535。按照上述的分核方案，最多只能处理65535个向量，显然是不合理的。所以，当向量个数大于65535时，要令每个逻辑核处理多个向量。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 每个group处理的向量个数</span><br>std::<span class="hljs-type">size_t</span> vec_count_per_group = (vec_count + MAX_KERNEL_COUNT - <span class="hljs-number">1</span>) / MAX_KERNEL_COUNT;<br><span class="hljs-comment">// 开启的group数量</span><br>std::<span class="hljs-type">size_t</span> group_count = (vec_count + vec_count_per_group - <span class="hljs-number">1</span>) / vec_count_per_group;<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; vec_count_per_group; i++) {<br>  iteration_begin = group_index + i * dim3;<br>  <span class="hljs-keyword">if</span> (iteration_begin &gt;= element_total_count) <span class="hljs-comment">// 注意判断边界</span><br>    <span class="hljs-keyword">break</span>;<br>  bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_BYTES_PER_ITERATION / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; input_vec_0;<br>  bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_BYTES_PER_ITERATION / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; input_vec_1;<br>  <span class="hljs-function">bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_REPEAT_PER_ITERATION&gt; <span class="hljs-title">sum_vec_0</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br>  <span class="hljs-function">bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_REPEAT_PER_ITERATION&gt; <span class="hljs-title">sum_vec_1</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> sum_vec_repeat_count = MAX_REPEAT_PER_ITERATION * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>) / REPEAT_SIZE;<br>  <span class="hljs-function">bisheng::vector&lt;<span class="hljs-type">float</span>, sum_vec_repeat_count&gt; <span class="hljs-title">sum_temp_0</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br>  <span class="hljs-function">bisheng::vector&lt;<span class="hljs-type">float</span>, sum_vec_repeat_count&gt; <span class="hljs-title">sum_temp_1</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br>  bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_BYTES_PER_ITERATION / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; res_vec_0;<br>  bisheng::vector&lt;<span class="hljs-type">float</span>, MAX_BYTES_PER_ITERATION / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; res_vec_1;<br>  bisheng::vector&lt;<span class="hljs-type">float</span>, BLOCK_SIZE / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; temp;<br>  __local <span class="hljs-type">float</span> sum_0 = <span class="hljs-number">0.0f</span>;<br>  __local <span class="hljs-type">float</span> sum_1 = <span class="hljs-number">0.0f</span>;<br><br>  <span class="hljs-comment">// 计算e^x并归约求和</span><br>  <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; iteration_times; j++) {<br>    ...<br>  }<br><br>  <span class="hljs-comment">// 两个缓冲区的和相加</span><br>  sum_0 += sum_1;<br>  <span class="hljs-keyword">auto</span> &amp;sum = sum_0;<br><br>  bisheng::vector&lt;<span class="hljs-type">float</span>, BLOCK_SIZE / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)&gt; temp_res;<br>  <span class="hljs-type">float</span> divisor = <span class="hljs-number">1</span> / sum;<br><br>  <span class="hljs-comment">// 向量除法</span><br>  <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; iteration_times; j++) {<br>    ...<br>  }<br>}<br></code></pre></td></tr></table></figure><h1 id="功能测试">功能测试</h1><p>功能测试采取将算子封装到<code>MindSpore</code>框架中进行测试，具体方案如下。先将算子代码编译为动态链接库。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">clang++ -fsycl -fdevices=ascend_910 \<br>    -I <span class="hljs-variable">${ASCEND_TOOLKIT_HOME}</span>/include \<br>    -L <span class="hljs-variable">${ASCEND_TOOLKIT_HOME}</span>/lib64 -lascendcl \<br>    -shared -fPIC -o softmax.so \<br>    -mllvm -inline-threshold=9000 -mllvm -enable-explicit-vectorizer -Rpass=ascend-vec \<br>    ./softmax.cpp<br></code></pre></td></tr></table></figure><p>然后按照要求封装为<code>MindSpore</code>可调用的状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SoftmaxBS</span>(<span class="hljs-title class_ inherited__">Cell</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SoftmaxBS, self).__init__()<br>        self.bisheng_softmax = ops.Custom(<br>            <span class="hljs-string">"softmax.so:softmax_npu"</span>,<br>            out_shape=<span class="hljs-keyword">lambda</span> x: x,<br>            out_dtype=<span class="hljs-keyword">lambda</span> x: x,<br>            func_type=<span class="hljs-string">"aot"</span>,<br>        )<br>        self.bisheng_softmax.add_prim_attr(<span class="hljs-string">"primitive_target"</span>, <span class="hljs-string">"Ascend"</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">construct</span>(<span class="hljs-params">self, x0</span>):<br>        output = self.bisheng_softmax(x0)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>在结果正确性方面，采用了<code>numpy</code>中的<code>allClose()</code>函数来对比<code>MindSpore</code>算子与自定义算子的结果张量，若两者在一定精度范围内接近，则认为计算结果正确。具体判断逻辑如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">context.set_context(mode=ms.PYNATIVE_MODE, device_target=<span class="hljs-string">"Ascend"</span>)<br>softmax_bs = SoftmaxBS()<br>softmax = Softmax(axis=-<span class="hljs-number">1</span>)<br>data = ms.Tensor(np.random.randn(dim0, dim1, dim2, dim3), ms.float16)<br>output_bs = softmax_bs(data)<br>output_ms = softmax(data)<br><span class="hljs-keyword">if</span> np.allclose(output_bs.asnumpy(), output_ms.asnumpy(), rtol=<span class="hljs-number">1e-3</span>, atol=<span class="hljs-number">1e-3</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"correct!"</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"error!"</span>)<br></code></pre></td></tr></table></figure><p>经过测试，算子逻辑没有问题，精度由于使用了<code>float16</code>来计算，所以只设置到了<code>1e-3</code>。</p><h1 id="性能测试">性能测试</h1><p>性能测试采用单算子测试的方式。对于<code>MindSpore</code>中的算子，采用框架自带的<code>Profiler()</code>来分析算子性能，再通过<code>msprof.py</code>脚本工具导出算子性能数据的<code>summary</code>数据，通过读取<code>Task Duration</code>列来获取算子的执行时间。而对于自定义算子，则采用<code>msprof</code>命令行工具运行算子，同样通过<code>summary</code>数据来获取算子执行时间。</p><table><thead><tr class="header"><th>ID</th><th>Shape</th><th>数据类型</th><th>MindSpore</th><th>BiSheng</th><th>加速比</th></tr></thead><tbody><tr class="odd"><td>1</td><td>8x16x1024x1024</td><td>half</td><td>2658.672</td><td>9720.826</td><td>0.273503</td></tr><tr class="even"><td>2</td><td>16x16x1024x1024</td><td>half</td><td>5274.796</td><td>18483.56</td><td>0.285378</td></tr><tr class="odd"><td>3</td><td>16x16x1024x2048</td><td>half</td><td>10550.81</td><td>21184.74</td><td>0.498038</td></tr><tr class="even"><td>4</td><td>16x16x1024x4096</td><td>half</td><td>22255.22</td><td>26612.28</td><td>0.836276</td></tr><tr class="odd"><td>5</td><td>4x4x512x8192</td><td>half</td><td>1221.49</td><td>1350.776</td><td>0.904288</td></tr><tr class="even"><td>6</td><td>4x4x512x16384</td><td>half</td><td>2438.494</td><td>1337.628</td><td>1.822999</td></tr><tr class="odd"><td>7</td><td>4x4x512x32768</td><td>half</td><td>4869.044</td><td>2412.854</td><td>2.01796</td></tr><tr class="even"><td>8</td><td>4x4x512x65535</td><td>half</td><td>6671.878</td><td>6200.692</td><td>1.075989</td></tr><tr class="odd"><td>9</td><td>4x4x512x131072</td><td>half</td><td>19467.07</td><td>8748.974</td><td>2.225069</td></tr><tr class="even"><td>10</td><td>4x4x512x8193</td><td>half</td><td>4984.124</td><td>1564.236</td><td>3.186299</td></tr><tr class="odd"><td>11</td><td>4x4x512x16385</td><td>half</td><td>1354.314</td><td>1555.814</td><td>0.870486</td></tr><tr class="even"><td>12</td><td>4x4x512x32769</td><td>half</td><td>4288.27</td><td>2667.928</td><td>1.607341</td></tr><tr class="odd"><td>13</td><td>4x4x512x65536</td><td>half</td><td>9732.024</td><td>4516.888</td><td>2.154586</td></tr><tr class="even"><td>14</td><td>4x4x512x131073</td><td>half</td><td>79671.69</td><td>9390.606</td><td>8.484191</td></tr></tbody></table><p>经过一系列的性能测试，发现在小数据量的情况下，性能始终无法与TBE算子相比。推测可能的原因是，TBE算子针对某些静态形状有优化，但本算子针对的是动态形状场景，所以性能较差。但当数据量变大，充分发挥设备并行能力的情况下，性能有所好转。在其最擅长的形状上，加速比可以达到2左右，在用例14这种情况下，加速比甚至达到了8以上。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在之前的文章中已经介绍了Softmax算子开发的整体思路，但笔者只从向量的角度进行了说明，本篇文章就以处理张量的角度来进一步阐述。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="异构编程" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>csv文件对于不同形状张量的存储与解析</title>
    <link href="https://deleter-d.github.io/posts/18632/"/>
    <id>https://deleter-d.github.io/posts/18632/</id>
    <published>2023-11-22T12:58:58.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>关于同一个csv文件存储和解析不同形状张量的问题，看似简单，暗坑很多。</p><span id="more"></span><h1 id="csv文件对于不同形状张量的存储与解析">csv文件对于不同形状张量的存储与解析</h1><h2 id="起因">起因</h2><p>最近写项目测试的时候，发小有一个小的需求，需要将不同形状的张量存入同一个文件中，同时需要记录其形状信息，从而方便算子的测试。但由于<code>numpy</code>中的<code>savetxt</code>等方法都要求张量形状一致，所以没办法直接使用。</p><p>一开始想的比较简单，使用<code>csv</code>文件来存储，分四列数据，前三列记录三个维度的形状信息，最后一列将整个张量存储下来。但实际开始写之后才发现，其中有一些问题处理起来比较麻烦，特此记录一下。</p><h2 id="初步尝试">初步尝试</h2><p>生成数据的代码比较简单，使用<code>numpy</code>随机生成一个张量，不仅张量中的数据是随机的，张量本身的形状也是在一定范围内随机生成的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateData3D</span>(<span class="hljs-params">shape_limit, dtype</span>):<br>    dim0 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>)<br>    dim1 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>    dim2 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">2</span>] + <span class="hljs-number">1</span>)<br>    data = randn(dim0, dim1, dim2).astype(dtype)<br>    <span class="hljs-keyword">return</span> (dim0, dim1, dim2, data)<br></code></pre></td></tr></table></figure><p>这个函数返回一个元组，前三个元素记录形状，最后一个元素是张量本身。然后写一个简单的批量数据生成代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateDataset</span>(<span class="hljs-params">filepath, count, shape_limit, dtype</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        writer = csv.writer(file, delimiter=<span class="hljs-string">","</span>)<br>        writer.writerow([<span class="hljs-string">"dim0"</span>, <span class="hljs-string">"dim1"</span>, <span class="hljs-string">"dim2"</span>, <span class="hljs-string">"data"</span>])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> trange(count):<br>            data = generateData3D(shape_limit, dtype)<br>            writer.writerow(data)<br></code></pre></td></tr></table></figure><h2 id="问题出现">问题出现</h2><p>看起来没有任何问题，调用它来生成文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">generateDataset(<span class="hljs-string">"test.csv"</span>, <span class="hljs-number">10</span>, (<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">320</span>), <span class="hljs-string">"float32"</span>)<br></code></pre></td></tr></table></figure><p>这里的意思是生成10个张量，每个张量的形状最大为<code>(8, 8, 320)</code>，每一个维度都是0到该数之间的一个随机整数，数据类型是<code>float32</code>。我们来看看生成的<code>csv</code>文件的内容，这里只取有问题的一部分展示。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs subunit">5,3,110,"[[[<span class="hljs-string">-8</span>.6134362e<span class="hljs-string">-01</span>  3.6351961e<span class="hljs-string">-01</span> <span class="hljs-string">-1</span>.4064503e<span class="hljs-string">-01</span> ... <span class="hljs-string">-8</span>.0155706e<span class="hljs-string">-01</span><br>    7.4856186e<span class="hljs-string">-01</span>  3.2745436e<span class="hljs-string">-01</span>]<br>  [<span class="hljs-string">-1</span>.4208823e<span class="hljs-string">+00</span>  4.2760447e<span class="hljs-string">-01</span> <span class="hljs-string">-7</span>.0980674e<span class="hljs-string">-01</span> ...  3.3898675e<span class="hljs-string">-01</span><br>    1.9081663e<span class="hljs-string">-01</span>  1.2164949e<span class="hljs-string">-01</span>]<br>  [ 2.0867598e<span class="hljs-string">+00</span> <span class="hljs-string">-2</span>.5110641e<span class="hljs-string">-01</span> <span class="hljs-string">-7</span>.9451543e<span class="hljs-string">-01</span> ... <span class="hljs-string">-9</span>.6020055e<span class="hljs-string">-01</span><br>    9.4596267e<span class="hljs-string">-01</span>  1.8399478e<span class="hljs-string">-01</span>]]<br><br> [[<span class="hljs-string">-7</span>.6276101e<span class="hljs-string">-02</span>  1.0084456e<span class="hljs-string">+00</span> <span class="hljs-string">-5</span>.4734468e<span class="hljs-string">-01</span> ...  7.9609489e<span class="hljs-string">-01</span><br>   <span class="hljs-string">-2</span>.9747225e<span class="hljs-string">-02</span>  3.6186981e<span class="hljs-string">-01</span>]<br>  [ 1.6717568e<span class="hljs-string">-01</span> <span class="hljs-string">-2</span>.7845892e<span class="hljs-string">-01</span> <span class="hljs-string">-6</span>.9172156e<span class="hljs-string">-01</span> ... <span class="hljs-string">-7</span>.8677136e<span class="hljs-string">-01</span><br>    4.0880820e<span class="hljs-string">-01</span>  1.1563424e<span class="hljs-string">-01</span>]<br>  [ 1.2279550e<span class="hljs-string">+00</span>  2.7903655e<span class="hljs-string">+00</span>  3.3148596e<span class="hljs-string">-01</span> ... <span class="hljs-string">-1</span>.0443866e<span class="hljs-string">+00</span><br>   <span class="hljs-string">-1</span>.7026719e<span class="hljs-string">-01</span> <span class="hljs-string">-7</span>.7582508e<span class="hljs-string">-01</span>]]<br></code></pre></td></tr></table></figure><p>会发现生成的<code>csv</code>文件中出现了省略号，这是<code>numpy</code>在输出张量的时候为了美观做的处理，但当他被解析为字符串后，数据信息就丢失了。这一点比较好处理，只需要令<code>numpy</code>完整输出整个张量即可，我们修改<code>generateDataset</code>函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateDataset</span>(<span class="hljs-params">filepath, count, shape_limit, dtype</span>):<br>    np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># 注意添加这一句</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        writer = csv.writer(file, delimiter=<span class="hljs-string">","</span>)<br>        writer.writerow([<span class="hljs-string">"dim0"</span>, <span class="hljs-string">"dim1"</span>, <span class="hljs-string">"dim2"</span>, <span class="hljs-string">"data"</span>])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> trange(count):<br>            data = generateData3D(shape_limit, dtype)<br>            writer.writerow(data)<br></code></pre></td></tr></table></figure><p>上述问题就得到了解决。</p><h2 id="文件解析">文件解析</h2><p>到此我以为这个需求已经实现了，只需要再写一个解析<code>csv</code>文件的函数就好了，于是我写了如下函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">loadFromFile</span>(<span class="hljs-params">filepath, shape_limit, dtype</span>):<br>    data = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"r"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        reader = csv.reader(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-built_in">next</span>(reader)<br>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:<br>            data.append(row)<br>    <span class="hljs-keyword">return</span> data<br></code></pre></td></tr></table></figure><p>我们调用它来读取刚才生产的文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data = loadFromFile(<span class="hljs-string">"test.csv"</span>, (<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">320</span>), <span class="hljs-string">"float32"</span>)<br><span class="hljs-built_in">print</span>(data[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><p>这里只输出第一条记录，下面展示一部分。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs subunit">['4', '3', '216', '[[[ 3.38217378e<span class="hljs-string">-01</span>  8.90219882e<span class="hljs-string">-02</span>  2.17747045e<span class="hljs-string">+00</span>  1.05902016e<span class="hljs-string">+00</span>\n   <span class="hljs-string">-1</span>.54809088e<span class="hljs-string">-01</span> <span class="hljs-string">-1</span>.73685062e<span class="hljs-string">+00</span>  2.45146394e<span class="hljs-string">-01</span> <span class="hljs-string">-8</span>.57644677e<span class="hljs-string">-01</span>\n    2.61454940e<span class="hljs-string">+00</span> <span class="hljs-string">-5</span>.65550804e<span class="hljs-string">-01</span> <span class="hljs-string">-6</span>.17945969e<span class="hljs-string">-01</span> <span class="hljs-string">-2</span>.49281359e<span class="hljs-string">+00</span>\n   <span class="hljs-string">-1</span>.82697034e<span class="hljs-string">+00</span> <span class="hljs-string">-2</span>.62623811e<span class="hljs-string">+00</span>  6.89034387e<span class="hljs-string">-02</span>  1.78881836e<span class="hljs-string">+00</span>\n   <span class="hljs-string">-9</span>.63348448e<span class="hljs-string">-02</span> <span class="hljs-string">-2</span>.35723400e<span class="hljs-string">+00</span>  9.03523326e<span class="hljs-string">-01</span> <span class="hljs-string">-1</span>.08545446e<span class="hljs-string">+00</span>\n ......<br></code></pre></td></tr></table></figure><p>这里发现输出的张量中有一些换行符，这是由于<code>numpy</code>格式化输出张量带来的后果，一开始我并没有觉得这是个问题，以<code>numpy</code>的强大能力，应该可以就这样将这个张量解析出来。</p><h2 id="问题又出现">问题又出现</h2><p>这里使用<code>type</code>函数查看从文件中读出来的张量的真实类型，即<code>type(data[0][3])</code>，发现是<code>&lt;class 'str'&gt;</code>，然后我做了如下尝试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">np.fromstring(data[<span class="hljs-number">0</span>][<span class="hljs-number">3</span>], dtype=np.float32)<br></code></pre></td></tr></table></figure><p>但是报如下错误。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">ValueError: <span class="hljs-keyword">string</span> size must be <span class="hljs-keyword">a</span> multiple <span class="hljs-keyword">of</span> <span class="hljs-keyword">element</span> size<br></code></pre></td></tr></table></figure><p>经过一通查询，原来<code>np.fromstring</code>是根据<code>dtype</code>来解析字符串的，它要求字符串的大小必须是元素个数的整数倍。但在我们存文件的时候会发现，有些数字是科学计数法存入的，有些数是普通的浮点数形式。对于字符串来说，每个数字映射后的字符串长度显然不一定是<code>float32</code>类型的4字节，所以解析的时候肯定会出问题。（PS. 又一个因为<code>numpy</code>格式化输出带来的问题。）</p><p>到此遇到的两个问题都是因为<code>numpy</code>的格式化输出引起的，所以我就尝试令<code>numpy</code>不要格式化输出，但在搜索了很多资料后我放弃了这个想法。（可能是我粗心没找到解决方案。）</p><p>后来换了一种思路来解决这个问题，我尝试先将这个读取出来的字符串解析成<code>python</code>的<code>list</code>，然后再用这个<code>list</code>来初始化一个<code>numpy</code>张量，从而供其他地方使用，于是进行了如下尝试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">ast.literal_eval(data[<span class="hljs-number">0</span>][<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure><p>但执行会报如下错误。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs subunit">    [[[ 3.38217378e<span class="hljs-string">-01</span>  8.90219882e<span class="hljs-string">-02</span>  2.17747045e<span class="hljs-string">+00</span>  1.05902016e<span class="hljs-string">+00</span><br>                        ^<br>SyntaxError: invalid syntax<br></code></pre></td></tr></table></figure><p>查询了很多资料，都没有说明这个问题是什么引起的。但在查询资料的过程中发现，别人在调用这个函数的时候，字符串都是以逗号隔开的一系列数字。这里由于<code>numpy</code>的格式化输出，是用空格隔开的，中间还有很多换行符。（again！）</p><p>于是我尝试令<code>numpy</code>输出的数据以逗号隔开，找了很多<code>numpy</code>中的写文件函数，均由于各种限制无法实现我的需求。所以在存文件的时候尝试将<code>numpy</code>数组先转换为字符串后，在写入文件。因为<code>numpy</code>的<code>array2string</code>函数是支持指定元素分隔符的，故我们改进<code>generateData3D</code>函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateData3D</span>(<span class="hljs-params">shape_limit, dtype</span>):<br>    dim0 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>)<br>    dim1 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>    dim2 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">2</span>] + <span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 注意下面这句的修改</span><br>    data = np.array2string(randn(dim0, dim1, dim2).astype(dtype), separator=<span class="hljs-string">","</span>)<br>    <span class="hljs-keyword">return</span> (dim0, dim1, dim2, data)<br></code></pre></td></tr></table></figure><p>重新生成文件后，再次尝试将该字符串解析为<code>list</code>，这次成功解析了！</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dns">[[[<span class="hljs-number">0</span>.<span class="hljs-number">0282006636</span>, -<span class="hljs-number">0.705630183</span>, <span class="hljs-number">0.205503568</span>, <span class="hljs-number">0.10408926</span>, -<span class="hljs-number">0.130971402</span>, -<span class="hljs-number">0</span>.<span class="hljs-number">0346300565</span>, <span class="hljs-number">1.86623621</span>, <span class="hljs-number">1.35530257</span>, -<span class="hljs-number">0.83048594</span>, <span class="hljs-number">1.27699852</span>, -<span class="hljs-number">0</span>.<span class="hljs-number">725055277</span>, -<span class="hljs-number">0</span>.<span class="hljs-number">514897704</span>, <span class="hljs-number">0.423814148</span>, <span class="hljs-number">1.65991676</span>, -<span class="hljs-number">0</span>.<span class="hljs-number">527909875</span>, -<span class="hljs-number">0.678127706</span>, -<span class="hljs-number">0</span>.<span class="hljs-number">269491076</span>, -<span class="hljs-number">1.05497122</span>, <span class="hljs-number">0</span>.<span class="hljs-number">670092762</span>, <span class="hljs-number">1.45376074</span>, <span class="hljs-number">1.53001487</span>, -<span class="hljs-number">0.844848216</span>, <span class="hljs-number">0</span>.<span class="hljs-number">337865025</span>, -<span class="hljs-number">0.144725695</span>, -<span class="hljs-number">0.4941248</span>, <span class="hljs-number">0.819156349</span> ......<br></code></pre></td></tr></table></figure><p>我们再进一步尝试将该<code>list</code>转为<code>numpy</code>张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">np.array(ast.literal_eval(data[<span class="hljs-number">0</span>][<span class="hljs-number">3</span>])).astype(np.float32)<br></code></pre></td></tr></table></figure><p>打印该数组。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dns">[[[ <span class="hljs-number">0.02820066</span> -<span class="hljs-number">0.7056302</span>   <span class="hljs-number">0.20550357</span> ...  <span class="hljs-number">0.01451482</span> -<span class="hljs-number">2.1041124</span><br>    <span class="hljs-number">1.8852443</span> ]]<br> [[-<span class="hljs-number">0.05282624</span>  <span class="hljs-number">0.5842251</span>   <span class="hljs-number">0.70602226</span> ... -<span class="hljs-number">0.14502124</span>  <span class="hljs-number">2.547757</span><br>    <span class="hljs-number">0.28345433</span>]]<br> [[-<span class="hljs-number">0.01983055</span> -<span class="hljs-number">0.5919099</span>  -<span class="hljs-number">0.9039266</span>  ... -<span class="hljs-number">1.7636172</span>  -<span class="hljs-number">1.9037529</span><br>   -<span class="hljs-number">1.0482264</span> ]]<br></code></pre></td></tr></table></figure><p>发现已经变成了<code>numpy</code>张量的格式化输出，再查看其类型和形状进一步确认有没有问题。</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs actionscript">&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">'numpy.ndarray'</span>&gt;<br>(<span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">264</span>)<br></code></pre></td></tr></table></figure><p>类型与生成的数据中记录下来的一致，问题应该是解决了。</p><h2 id="进一步优化">进一步优化</h2><p>写到这里，回头看看可以发现，记录下来的形状信息其实并没有用到。因为在将字符串解析为<code>list</code>的时候，形状的信息自然的保留了下来。所以我们将存储形状信息的代码去掉，让这个<code>csv</code>文件只存储张量本身。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateData3D</span>(<span class="hljs-params">shape_limit, dtype</span>):<br>    dim0 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>)<br>    dim1 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>    dim2 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">2</span>] + <span class="hljs-number">1</span>)<br>    data = np.array2string(randn(dim0, dim1, dim2).astype(dtype), separator=<span class="hljs-string">","</span>)<br>    <span class="hljs-keyword">return</span> (data,) <span class="hljs-comment"># 注意这里返回的依然是一个元组</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateDataset</span>(<span class="hljs-params">filepath, count, shape_limit, dtype</span>):<br>    np.set_printoptions(threshold=np.inf)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        writer = csv.writer(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-comment"># 这里就直接写入数据了，没有写表头</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> trange(count):<br>            data = generateData3D(shape_limit, dtype)<br>            writer.writerow(data)<br></code></pre></td></tr></table></figure><p>在读取数据的时候做一些相应处理即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">loadFromFile</span>(<span class="hljs-params">filepath, shape_limit, dtype</span>):<br>    data = []<br>    csv.field_size_limit(sys.maxsize)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"r"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        reader = csv.reader(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:<br>            data.append(row)<br>    result = []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data:<br>        result.append(np.array(ast.literal_eval(item[<span class="hljs-number">0</span>]), dtype=dtype))<br>    <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><p>这样读取出来的数据就是一个<code>list</code>，其中的每个元素都是一个<code>numpy.ndarray</code>。最后再写一个生成算子真值的函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateGolden</span>(<span class="hljs-params">output_file, input_file, dtype</span>):<br>    np.set_printoptions(threshold=np.inf)<br>    <span class="hljs-built_in">input</span> = tqdm(loadFromFile(input_file, dtype))<br>    softmax = Softmax()<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(output_file, <span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        writer = csv.writer(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>:<br>            <span class="hljs-comment"># 获取到的张量转换为mindspore的张量进行运算</span><br>            golden = softmax(ms.Tensor(item, dtype=ms.float32))<br>            <span class="hljs-comment"># 转回numpy张量</span><br>            golden = golden.asnumpy()<br>            <span class="hljs-comment"># numpy数组转字符串</span><br>            golden = np.array2string(golden.astype(dtype), separator=<span class="hljs-string">","</span>)<br>            writer.writerow((golden,))<br></code></pre></td></tr></table></figure><p>其中加了一些<code>tqdm</code>的内容，输出信息丰富一些。</p><h2 id="完整代码">完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> csv<br><span class="hljs-keyword">import</span> ast<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> trange, tqdm<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> numpy.random <span class="hljs-keyword">import</span> randint, randn<br><span class="hljs-keyword">import</span> mindspore <span class="hljs-keyword">as</span> ms<br><span class="hljs-keyword">from</span> mindspore.nn <span class="hljs-keyword">import</span> Softmax<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateData3D</span>(<span class="hljs-params">shape_limit, dtype</span>):<br>    dim0 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>)<br>    dim1 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>    dim2 = randint(<span class="hljs-number">1</span>, shape_limit[<span class="hljs-number">2</span>] + <span class="hljs-number">1</span>)<br>    data = np.array2string(randn(dim0, dim1, dim2).astype(dtype), separator=<span class="hljs-string">","</span>)<br>    <span class="hljs-keyword">return</span> (data,)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateDataset</span>(<span class="hljs-params">filepath, count, shape_limit, dtype</span>):<br>    np.set_printoptions(threshold=np.inf)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        writer = csv.writer(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> trange(count):<br>            data = generateData3D(shape_limit, dtype)<br>            writer.writerow(data)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loadFromFile</span>(<span class="hljs-params">filepath, dtype</span>):<br>    data = []<br>    csv.field_size_limit(sys.maxsize)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"r"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        reader = csv.reader(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:<br>            data.append(row)<br>    result = []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data:<br>        result.append(np.array(ast.literal_eval(item[<span class="hljs-number">0</span>]), dtype=dtype))<br>    <span class="hljs-keyword">return</span> result<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateGolden</span>(<span class="hljs-params">output_file, input_file, dtype</span>):<br>    np.set_printoptions(threshold=np.inf)<br>    <span class="hljs-built_in">input</span> = tqdm(loadFromFile(input_file, dtype))<br>    softmax = Softmax()<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(output_file, <span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> file:<br>        writer = csv.writer(file, delimiter=<span class="hljs-string">","</span>)<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>:<br>            <span class="hljs-comment"># 获取到的张量转换为mindspore的张量进行运算</span><br>            golden = softmax(ms.Tensor(item, dtype=ms.float32))<br>            <span class="hljs-comment"># 转回numpy张量</span><br>            golden = golden.asnumpy()<br>            <span class="hljs-comment"># numpy数组转字符串</span><br>            golden = np.array2string(golden.astype(dtype), separator=<span class="hljs-string">","</span>)<br>            writer.writerow((golden,))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">"data generation."</span>)<br><br>    parser.add_argument(<br>        <span class="hljs-string">"--input-filename"</span>,<br>        <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>,<br>        default=<span class="hljs-string">"input_data.csv"</span>,<br>        <span class="hljs-built_in">help</span>=<span class="hljs-string">"set the filename of input data."</span>,<br>    )<br>    parser.add_argument(<br>        <span class="hljs-string">"--shape-limit"</span>,<br>        nargs=<span class="hljs-string">"+"</span>,<br>        <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>,<br>        default=(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">320</span>),<br>        <span class="hljs-built_in">help</span>=<span class="hljs-string">"the largest amount of each dimension."</span>,<br>    )<br>    parser.add_argument(<br>        <span class="hljs-string">"--data-amount"</span>,<br>        <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>,<br>        default=<span class="hljs-number">100</span>,<br>        <span class="hljs-built_in">help</span>=<span class="hljs-string">"the amount of input data."</span>,<br>    )<br>    parser.add_argument(<br>        <span class="hljs-string">"--dtype"</span>,<br>        <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>,<br>        default=<span class="hljs-string">"float32"</span>,<br>        <span class="hljs-built_in">help</span>=<span class="hljs-string">"the data type of input data."</span>,<br>    )<br>    parser.add_argument(<br>        <span class="hljs-string">"--golden-filename"</span>,<br>        <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>,<br>        default=<span class="hljs-string">"golden_data.csv"</span>,<br>        <span class="hljs-built_in">help</span>=<span class="hljs-string">"set the filename of golden data."</span>,<br>    )<br><br>    args = parser.parse_args()<br>    input_filename = args.input_filename<br>    golden_filename = args.golden_filename<br>    data_amount = args.data_amount<br>    dtype = args.dtype<br>    shape_limit = <span class="hljs-built_in">tuple</span>(args.shape_limit)<br><br>    ms.set_context(device_target=<span class="hljs-string">"Ascend"</span>, device_id=<span class="hljs-number">4</span>)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"input filename: <span class="hljs-subst">{input_filename}</span>"</span>)<br>    <span class="hljs-built_in">print</span>(<br>        <span class="hljs-string">f"\twill generating <span class="hljs-subst">{data_amount}</span> <span class="hljs-subst">{dtype}</span> input data with random shape less than <span class="hljs-subst">{shape_limit}</span>"</span><br>    )<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"generating..."</span>)<br>    generateDataset(<br>        input_filename,<br>        data_amount,<br>        shape_limit,<br>        dtype,<br>    )<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"golden filename: <span class="hljs-subst">{golden_filename}</span>"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"generating..."</span>)<br>    generateGolden(golden_filename, input_filename, dtype)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"all done."</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;关于同一个csv文件存储和解析不同形状张量的问题，看似简单，暗坑很多。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="python" scheme="https://deleter-d.github.io/tags/python/"/>
    
    <category term="numpy" scheme="https://deleter-d.github.io/tags/numpy/"/>
    
    <category term="csv" scheme="https://deleter-d.github.io/tags/csv/"/>
    
  </entry>
  
  <entry>
    <title>AscendC算子开发及单算子调用</title>
    <link href="https://deleter-d.github.io/posts/19902/"/>
    <id>https://deleter-d.github.io/posts/19902/</id>
    <published>2023-10-16T03:42:58.000Z</published>
    <updated>2024-02-27T09:37:44.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>摘要记录一下Ascend C的学习过程，整体来说Ascend C的核心部分还是比较易用的，唯一的小缺点就是学习初期不得不被一些无关算子核心逻辑的工程文件所干扰。</p><span id="more"></span><h1 id="ascend-c算子开发">Ascend C算子开发</h1><p>笔者在阅读Ascend C官方文档的过程中发现，对于初学者来说，尤其是第一次接触异构编程思想的初学者，有很大一部分内容是无需开发者关注的，例如算子工程的相关的<code>CmakeLists.txt</code>，以及单算子调用的一些通用工具类等文件。同时，在环境配置的过程中，也发现了一些需要注意的地方，特此记录备忘。</p><h2 id="环境准备">环境准备</h2><p>笔者的硬件及系统环境如下：</p><ul><li>操作系统：openEuler release 20.03 (LTS-SP3)</li><li>设备：Ascend 910B</li></ul><p>开发环境需要准备三个<code>run</code>包，分别是驱动、固件和<code>cann-toolkit</code>开发套件，笔者这里使用当前的最新版CANN包，版本号为<code>7.0.RC1.alpha003</code>。并在官网下载好对应的驱动和固件的<code>run</code>包。</p><h3 id="安装流程">安装流程</h3><p>上述准备的三个包，按照驱动 -&gt; 固件 -&gt; CANN包的顺序来安装。</p><p>首先安装驱动，执行如下命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">/path/to/Ascend-hdk-910-npu-driver_23.0.rc2_linux-aarch64.run --full --install-for-all<br></code></pre></td></tr></table></figure><blockquote><p>注意：笔者使用root用户进行安装，以<code>full</code>模式执行<code>run</code>包，并加上<code>install-for-all</code>选项来为所有用户安装。</p></blockquote><p>接下来安装固件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">/path/to/Ascend-hdk-910-npu-firmware_6.4.12.1.241.run --full<br></code></pre></td></tr></table></figure><p>驱动和固件都安装完成后，最好重启一次系统：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">reboot<br></code></pre></td></tr></table></figure><p>重启完成后，安装CANN包：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">path/to/Ascend-cann-toolkit_7.0.RC1.alpha003_linux-aarch64.run --full --install-for-all<br></code></pre></td></tr></table></figure><p>安装完成后，开发环境就准备好了。</p><h3 id="安装过程中可能的问题">安装过程中可能的问题</h3><p>笔者在安装过程中，遇到了一个问题，很蠢，但值得注意。</p><p>问题的表现是，在按照上述的流程安装好开发环境之后，除<code>root</code>用户外的其他普通用户使用<code>msopgen</code>工具生成算子工程时，出现了权限不足的问题。但因为加上了<code>install-for-all</code>选项，所以不应该是CANN包的权限问题。然后又查看<code>msopgen</code>的代码发现，该工具将python解释器指定为了<code>root</code>用户下的<code>conda</code>环境中的解释器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/root/miniconda3/bin/python3</span><br><span class="hljs-comment"># coding=utf-8</span><br><span class="hljs-string">"""</span><br><span class="hljs-string">Function:</span><br><span class="hljs-string">This file mainly involves main function of op generation module.</span><br><span class="hljs-string">Copyright Information:</span><br><span class="hljs-string">Huawei Technologies Co., Ltd. All Rights Reserved © 2020</span><br><span class="hljs-string">"""</span><br></code></pre></td></tr></table></figure><p>原来是<code>root</code>用户下的<code>conda</code>配置为了默认激活<code>base</code>环境，笔者安装时没有注意这一点，导致在CANN包安装的过程中，选择到了<code>conda</code>环境下的python解释器，这样一来，其他用户肯定是没有权限的。在关闭<code>base</code>环境重新安装CANN包后，问题解决。</p><h2 id="算子开发流程">算子开发流程</h2><p>至此，环境准备好后，开始正式的算子开发步骤。</p><h3 id="算子工程配置文件">算子工程配置文件</h3><p>CANN包中提供了一个自动生成算子工程的工具<code>msopgen</code>，该工具可以通过一个<code>json</code>配置文件来生成完整的算子工程，具体的编写方式请参考<a href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/70RC1alpha003/operatordevelopment/ascendcopdevg/atlas_ascendc_10_0023.html">官方文档</a>。</p><p>这里以<code>sinh</code>算子为例，该算子是一元操作，所以只需要一个输入，且输出形状与输入形状一致。根据该特征来编写<code>json</code>文件，为了贴合Ascend C官方建议的编程范式，将文件命名为<code>sinh_custom.json</code>。为了简洁，这里我们只实现一种数据类型的操作。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">{</span><br>        <span class="hljs-attr">"op"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"SinhCustom"</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"language"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"cpp"</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"input_desc"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">{</span><br>                <span class="hljs-attr">"name"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"x"</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">"param_type"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"required"</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">"format"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">"ND"</span><br>                <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">"type"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">"fp16"</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">}</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"output_desc"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">{</span><br>                <span class="hljs-attr">"name"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"y"</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">"param_type"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"required"</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">"format"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">"ND"</span><br>                <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">"type"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">"fp16"</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">}</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">}</span><br><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure><h3 id="生成算子工程">生成算子工程</h3><p>创建一个文件夹用作算子工程目录，使用<code>msopgen</code>工具执行如下命令来生成算子工程。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mkdir</span> /path/to/SinhCustom<br>/path/to/msopgen gen -i /path/to/sinh_custom.json -c ai_core-Ascend910B -lan cpp -out /path/to/SinhCustom<br></code></pre></td></tr></table></figure><p>命令行会输出类似如下的信息：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh">2023-10-07 14:58:42 (942445) - [INFO] Start to generate AI Core operator files.<br>2023-10-07 14:58:42 (942445) - [INFO] Start to parse the ir template:/path/to/SinhCustom/sinh_custom.json<br>2023-10-07 14:58:42 (942445) - [INFO] Start to parse the op: SinhCustom<br>2023-10-07 14:58:42 (942445) - [INFO] Start to parse the input_desc: x<br>2023-10-07 14:58:42 (942445) - [INFO] Start to parse the output_desc: y<br>2023-10-07 14:58:42 (942445) - [WARNING] The <span class="hljs-string">"attr"</span> value is invalid or no <span class="hljs-string">"attr"</span> exists <span class="hljs-keyword">in</span> the map.<br>2023-10-07 14:58:42 (942445) - [INFO] Start to check the <span class="hljs-built_in">type</span> and format between the inputs/outputs <span class="hljs-keyword">in</span> IR template.<br>2023-10-07 14:58:42 (942445) - [INFO] Start to generate a new project.<br>2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/cmake/config.cmake generated successfully.<br>2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/op_host/sinh_custom_tiling.h generated successfully.<br>2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/op_host/sinh_custom.cpp generated successfully.<br>2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/op_kernel/sinh_custom.cpp generated successfully.<br>2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/framework/tf_plugin/tensorflow_sinh_custom_plugin.cc generated successfully.<br>2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/framework/tf_plugin/CMakeLists.txt generated successfully.<br>2023-10-07 14:58:42 (942445) - [INFO] Generation completed.<br></code></pre></td></tr></table></figure><p>此时会发现指定的输出目录只已经生成了一系列的算子工程文件。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh">SinhCustom<br>├── build.sh<br>├── cmake<br>├── CMakeLists.txt<br>├── CMakePresets.json <span class="hljs-comment"># 这个配置项需要修改</span><br>├── framework<br>├── op_host<br>│   ├── CMakeLists.txt<br>│   ├── sinh_custom.cpp <span class="hljs-comment"># 算子host侧核心逻辑</span><br>│   └── sinh_custom_tiling.h <span class="hljs-comment"># 算子tiling结构体定义</span><br>├── op_kernel<br>│   ├── CMakeLists.txt<br>│   └── sinh_custom.cpp <span class="hljs-comment"># 算子kernel侧核心逻辑</span><br>├── scripts<br>└── sinh_custom.json <span class="hljs-comment"># 笔者此处将工程配置文件和算子工程目录放在了一起</span><br></code></pre></td></tr></table></figure><p>我们只需要专注于上述带有注释的几个文件即可。</p><p>此处先修改与算子核心逻辑无关的配置项<code>CMakePresets.json</code>，官方文档中也描述的非常清楚，只需要将<code>ASCEND_CANN_PACKAGE_PATH</code>配置项修改为实际的CANN包安装路径即可。在<code>root</code>用户下安装的默认路径为<code>/usr/local/Ascend/ascend-toolkit/latest</code>。</p><p>以上将所有无关算子逻辑的内容修改完毕，接下来就可以专注于算子开发了。</p><h3 id="算子逻辑开发">算子逻辑开发</h3><p>官方文档中推荐先实现<code>kernel</code>侧的逻辑，但笔者有一些不同的看法。我推荐先实现算子<code>tiling</code>结构体的定义与具体策略，这样做的好处是，可以提前将<code>tiling</code>策略所需的变量确定下来，并且借助于CANN包只提供的一系列宏，这一过程并不需要很大的工作量。在实现<code>kernel</code>侧逻辑的过程中，这些变量将有助于思考数据在逻辑核上如何具体分配和执行，当然这只是笔者的观点，可以根据自己的编程习惯来作调整。</p><h4 id="tiling结构体定义及策略实现"><code>tiling</code>结构体定义及策略实现</h4><p>首先确定<code>tiling</code>过程中所需的变量，参考官方样例，需要定义整块、尾块的个数及其中的元素个数，还需要定义最小对齐单位。<code>op_host/sinh_custom_tiling.h</code>代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> SINH_CUSTOM_TILING_H <span class="hljs-comment">// 头文件保护记得加上，自动生成的文件中不包含</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SINH_CUSTOM_TILING_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"register/tilingdata_base.h"</span></span><br><br><span class="hljs-keyword">namespace</span> optiling<br>{<br>  <span class="hljs-built_in">BEGIN_TILING_DATA_DEF</span>(TilingData)<br>  <span class="hljs-built_in">TILING_DATA_FIELD_DEF</span>(<span class="hljs-type">uint32_t</span>, formerNum);    <span class="hljs-comment">// 整块个数</span><br>  <span class="hljs-built_in">TILING_DATA_FIELD_DEF</span>(<span class="hljs-type">uint32_t</span>, tailNum);      <span class="hljs-comment">// 尾块个数</span><br>  <span class="hljs-built_in">TILING_DATA_FIELD_DEF</span>(<span class="hljs-type">uint32_t</span>, formerLength); <span class="hljs-comment">// 整块内元素个数</span><br>  <span class="hljs-built_in">TILING_DATA_FIELD_DEF</span>(<span class="hljs-type">uint32_t</span>, tailLength);   <span class="hljs-comment">// 尾块内元素个数</span><br>  <span class="hljs-built_in">TILING_DATA_FIELD_DEF</span>(<span class="hljs-type">uint32_t</span>, alignNum);     <span class="hljs-comment">// 最小对齐单位，元素个数</span><br>  END_TILING_DATA_DEF;<br><br>  <span class="hljs-built_in">REGISTER_TILING_DATA_CLASS</span>(SinhCustom, TilingData)<br>}<br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>然后在<code>op_host/sinh_custom.cpp</code>中实现具体的<code>tiling</code>策略，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">namespace</span> optiling<br>{<br>    <span class="hljs-keyword">constexpr</span> <span class="hljs-type">uint32_t</span> BLOCK_DIM = <span class="hljs-number">24</span>;                        <span class="hljs-comment">// 划分核心数量</span><br>    <span class="hljs-keyword">constexpr</span> <span class="hljs-type">uint32_t</span> SIZE_OF_HALF = <span class="hljs-number">2</span>;                      <span class="hljs-comment">// 数据类型的字节数</span><br>    <span class="hljs-keyword">constexpr</span> <span class="hljs-type">uint32_t</span> BLOCK_SIZE = <span class="hljs-number">32</span>;                       <span class="hljs-comment">// 昇腾设备上的数据block为32字节</span><br>    <span class="hljs-keyword">constexpr</span> <span class="hljs-type">uint32_t</span> ALIGN_NUM = BLOCK_SIZE / SIZE_OF_HALF; <span class="hljs-comment">// 最小对齐单位</span><br>    <span class="hljs-function"><span class="hljs-type">static</span> ge::graphStatus <span class="hljs-title">TilingFunc</span><span class="hljs-params">(gert::TilingContext *context)</span></span><br><span class="hljs-function">    </span>{<br><br>        TilingData tiling;<br>        <span class="hljs-type">uint32_t</span> totalLength = context-&gt;<span class="hljs-built_in">GetInputTensor</span>(<span class="hljs-number">0</span>)-&gt;<span class="hljs-built_in">GetShapeSize</span>();<br>        context-&gt;<span class="hljs-built_in">SetBlockDim</span>(BLOCK_DIM);<br><br>        <span class="hljs-comment">// 使输入向上对齐</span><br>        <span class="hljs-type">uint32_t</span> totalLengthAligned = ((totalLength + ALIGN_NUM - <span class="hljs-number">1</span>) / ALIGN_NUM) * ALIGN_NUM;<br>        <span class="hljs-comment">// 计算整块和尾块个数</span><br>        <span class="hljs-type">uint32_t</span> formerNum = (totalLengthAligned / ALIGN_NUM) % BLOCK_DIM;<br>        <span class="hljs-type">uint32_t</span> tailNum = BLOCK_DIM - formerNum;<br>        <span class="hljs-comment">// 计算整块和尾块的元素个数</span><br>        <span class="hljs-type">uint32_t</span> formerLength = ((totalLengthAligned / BLOCK_DIM + ALIGN_NUM - <span class="hljs-number">1</span>) / ALIGN_NUM) * ALIGN_NUM;<br>        <span class="hljs-type">uint32_t</span> tailLength = (totalLengthAligned / BLOCK_DIM / ALIGN_NUM) * ALIGN_NUM;<br><br>        <span class="hljs-comment">// 设置tiling参数</span><br>        tiling.<span class="hljs-built_in">set_formerNum</span>(formerNum);<br>        tiling.<span class="hljs-built_in">set_tailNum</span>(tailNum);<br>        tiling.<span class="hljs-built_in">set_formerLength</span>(formerLength);<br>        tiling.<span class="hljs-built_in">set_tailLength</span>(tailLength);<br>        tiling.<span class="hljs-built_in">set_alignNum</span>(ALIGN_NUM);<br><br>        <span class="hljs-comment">// 以下为固定写法，不用纠结</span><br>        tiling.<span class="hljs-built_in">SaveToBuffer</span>(context-&gt;<span class="hljs-built_in">GetRawTilingData</span>()-&gt;<span class="hljs-built_in">GetData</span>(), context-&gt;<span class="hljs-built_in">GetRawTilingData</span>()-&gt;<span class="hljs-built_in">GetCapacity</span>());<br>        context-&gt;<span class="hljs-built_in">GetRawTilingData</span>()-&gt;<span class="hljs-built_in">SetDataSize</span>(tiling.<span class="hljs-built_in">GetDataSize</span>());<br>        context-&gt;<span class="hljs-built_in">SetTilingKey</span>(<span class="hljs-number">1</span>);<br>        <span class="hljs-type">size_t</span> *currentWorkspace = context-&gt;<span class="hljs-built_in">GetWorkspaceSizes</span>(<span class="hljs-number">1</span>);<br>        currentWorkspace[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-keyword">return</span> ge::GRAPH_SUCCESS;<br>    }<br>}<br></code></pre></td></tr></table></figure><h4 id="kernel侧实现"><code>kernel</code>侧实现</h4><p>有了上述实现的<code>tiling</code>策略，我们就可以根据数据划分的逻辑来确定<code>kernel</code>侧的具体实现。根据官方推荐的矢量编程范式，我们可以先将算子类的框架写出来，再慢慢填充内容。在<code>op_kernel/sinh_custom.cpp</code>中写出算子类框架。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> AscendC; <span class="hljs-comment">// 记得开启AscendC命名空间</span><br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int32_t</span> BUFFER_NUM = <span class="hljs-number">2</span>; <span class="hljs-comment">// TQue的缓冲数量，此处开启双Buffer</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">KernelSinh</span><br>{<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-title">KernelSinh</span><span class="hljs-params">()</span> </span>{} <span class="hljs-comment">// 类构造函数，无须任何代码</span><br>    <span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">Init</span><span class="hljs-params">(GM_ADDR x, GM_ADDR y,   <span class="hljs-comment">// 初始化函数的参数为输入、输出</span></span></span><br><span class="hljs-params"><span class="hljs-function">                                <span class="hljs-type">uint32_t</span> formerNum, <span class="hljs-type">uint32_t</span> tailNum, <span class="hljs-comment">// 以及上面定义的一系列tiling参数</span></span></span><br><span class="hljs-params"><span class="hljs-function">                                <span class="hljs-type">uint32_t</span> formerLength, <span class="hljs-type">uint32_t</span> tailLength,</span></span><br><span class="hljs-params"><span class="hljs-function">                                <span class="hljs-type">uint32_t</span> alignNum)</span> </span>{ <span class="hljs-comment">/* TODO */</span> }<br>    <span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">Process</span><span class="hljs-params">()</span> </span>{ <span class="hljs-comment">/* TODO */</span> }<br><br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">CopyIn</span><span class="hljs-params">()</span> </span>{ <span class="hljs-comment">/* TODO */</span> }<br>    <span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">Compute</span><span class="hljs-params">()</span> </span>{ <span class="hljs-comment">/* TODO */</span> }<br>    <span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">CopyOut</span><span class="hljs-params">()</span> </span>{ <span class="hljs-comment">/* TODO */</span> }<br><br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">/* TODO */</span><br>};<br></code></pre></td></tr></table></figure><p>第一步应该做的是分析算子类的私有数据成员，首先一定需要的是用来管理内存的<code>Tpipe</code>，同时需要输入输出分别对应的<code>TQue</code>和<code>GlobalTensor</code>，同时每个逻辑核还 需要直到当前处理的数据个数，所以需要一个变量<code>tileLength</code>来确定分片大小。</p><p>再来分析算子，公式如下所示。 <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="24.009ex" height="4.885ex" role="img" focusable="false" viewBox="0 -1451.2 10612.1 2159.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D432" d="M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z"></path></g></g><g data-mml-node="mo" transform="translate(884.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(1940.6,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1228,0)"></path></g><g data-mml-node="mo" transform="translate(3724.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4113.6,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mo" transform="translate(4720.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5387.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6443.1,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1200.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2200.7,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(778,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g></g></g></g><g data-mml-node="mn" transform="translate(1445.5,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(778,0)"></path></g><rect width="3929" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span> 可以观察到，我们需要计算两个中间结果，分别是<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.213ex" height="1.556ex" role="img" focusable="false" viewBox="0 -677 978.2 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="3.458ex" height="1.779ex" role="img" focusable="false" viewBox="0 -775.2 1528.3 786.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(778,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g></g></g></g></g></svg></mjx-container></span>，所以需要相应的数据结构来存放这两个中间结果，Ascend C提供的<code>TBuf</code>可以很好的承担这一责任。</p><p>至此我们就将算子类需要的私有数据成员确定了下来。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp">TPipe pipe;                                      <span class="hljs-comment">// 用于操作队列</span><br>TBuf&lt;QuePosition::VECCALC&gt; tempBuf;              <span class="hljs-comment">// 存放中间结果</span><br>TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX;   <span class="hljs-comment">// 输入队列</span><br>TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY; <span class="hljs-comment">// 输出队列</span><br>GlobalTensor&lt;DTYPE_X&gt; xGm;                       <span class="hljs-comment">// 输入数据对应的GM内存空间</span><br>GlobalTensor&lt;DTYPE_Y&gt; yGm;                       <span class="hljs-comment">// 输出数据对应的GM内存空间</span><br><span class="hljs-type">uint32_t</span> tileLength;                             <span class="hljs-comment">// 每个逻辑核需要知道分片数据个数</span><br></code></pre></td></tr></table></figure><p>接下来要做的是完善算子类的初始化函数<code>Init()</code>，在该函数中我们需要为<code>GlobalTensor</code>分配内存，并初始化相应的<code>TQue</code>，同时需要针对某些变量做合法性判断。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">Init</span><span class="hljs-params">(GM_ADDR x, GM_ADDR y,</span></span><br><span class="hljs-params"><span class="hljs-function">                            <span class="hljs-type">uint32_t</span> formerNum, <span class="hljs-type">uint32_t</span> tailNum,</span></span><br><span class="hljs-params"><span class="hljs-function">                            <span class="hljs-type">uint32_t</span> formerLength, <span class="hljs-type">uint32_t</span> tailLength,</span></span><br><span class="hljs-params"><span class="hljs-function">                            <span class="hljs-type">uint32_t</span> alignNum)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">GetBlockIdx</span>() &lt; formerNum)<br>    {<br>        <span class="hljs-comment">// 处理整块逻辑</span><br>        <span class="hljs-keyword">this</span>-&gt;tileLength = formerLength;<br>        xGm.<span class="hljs-built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X *)x + formerLength * <span class="hljs-built_in">GetBlockIdx</span>(), formerLength);<br>        yGm.<span class="hljs-built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y *)y + formerLength * <span class="hljs-built_in">GetBlockIdx</span>(), formerLength);<br>    }<br>    <span class="hljs-keyword">else</span><br>    {<br>        <span class="hljs-comment">// 处理尾块逻辑</span><br>        <span class="hljs-keyword">this</span>-&gt;tileLength = tailLength;<br>        xGm.<span class="hljs-built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X *)x + formerLength * formerNum + tailLength * (<span class="hljs-built_in">GetBlockIdx</span>() - formerNum), tailLength);<br>        yGm.<span class="hljs-built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y *)y + formerLength * formerNum + tailLength * (<span class="hljs-built_in">GetBlockIdx</span>() - formerNum), tailLength);<br>    }<br><br>    <span class="hljs-built_in">ASSERT</span>(alignNum != <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-string">"align num can not be zero!"</span>);<br>    pipe.<span class="hljs-built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, (((<span class="hljs-keyword">this</span>-&gt;tileLength + alignNum - <span class="hljs-number">1</span>) / alignNum) * alignNum) * <span class="hljs-built_in">sizeof</span>(half));<br>    pipe.<span class="hljs-built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, (((<span class="hljs-keyword">this</span>-&gt;tileLength + alignNum - <span class="hljs-number">1</span>) / alignNum) * alignNum) * <span class="hljs-built_in">sizeof</span>(half));<br>}<br></code></pre></td></tr></table></figure><p>再然后就是算子最核心的部分——计算逻辑，分别实现矢量编程范式的三步骤。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">CopyIn</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.<span class="hljs-built_in">AllocTensor</span>&lt;DTYPE_X&gt;();<br>    <span class="hljs-built_in">DataCopy</span>(xLocal, xGm, <span class="hljs-keyword">this</span>-&gt;tileLength); <span class="hljs-comment">// GM -&gt; LM</span><br>    inQueueX.<span class="hljs-built_in">EnQue</span>&lt;DTYPE_X&gt;(xLocal);<br>}<br><span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">Compute</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.<span class="hljs-built_in">DeQue</span>&lt;DTYPE_X&gt;();<br>    LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="hljs-built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();<br>    pipe.<span class="hljs-built_in">InitBuffer</span>(tempBuf, <span class="hljs-keyword">this</span>-&gt;tileLength * <span class="hljs-built_in">sizeof</span>(DTYPE_X));<br>    LocalTensor&lt;DTYPE_X&gt; tempLocal = tempBuf.<span class="hljs-built_in">Get</span>&lt;DTYPE_X&gt;(<span class="hljs-keyword">this</span>-&gt;tileLength);<br>    <span class="hljs-comment">// 计算exp(x)</span><br>    <span class="hljs-built_in">Exp</span>(yLocal, xLocal, <span class="hljs-keyword">this</span>-&gt;tileLength);<br>    <span class="hljs-comment">// 计算-x</span><br>    <span class="hljs-function">half <span class="hljs-title">nagOne</span><span class="hljs-params">(<span class="hljs-number">-1.0</span>)</span></span>;<br>    <span class="hljs-built_in">Muls</span>(tempLocal, xLocal, nagOne, <span class="hljs-keyword">this</span>-&gt;tileLength);<br>    <span class="hljs-comment">// 计算exp(-x)</span><br>    <span class="hljs-built_in">Exp</span>(tempLocal, tempLocal, <span class="hljs-keyword">this</span>-&gt;tileLength);<br>    <span class="hljs-comment">// 计算exp(x)-exp(-x)</span><br>    <span class="hljs-built_in">Sub</span>(yLocal, yLocal, tempLocal, <span class="hljs-keyword">this</span>-&gt;tileLength);<br>    <span class="hljs-comment">// 计算最终结果</span><br>    <span class="hljs-function">half <span class="hljs-title">denominator</span><span class="hljs-params">(<span class="hljs-number">0.5</span>)</span></span>;<br>    <span class="hljs-built_in">Muls</span>(yLocal, yLocal, denominator, <span class="hljs-keyword">this</span>-&gt;tileLength);<br>    outQueueY.<span class="hljs-built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);<br>    inQueueX.<span class="hljs-built_in">FreeTensor</span>(xLocal);<br>}<br><span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">CopyOut</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="hljs-built_in">DeQue</span>&lt;DTYPE_Y&gt;();<br>    <span class="hljs-built_in">DataCopy</span>(yGm, yLocal, <span class="hljs-keyword">this</span>-&gt;tileLength); <span class="hljs-comment">// LM -&gt; GM</span><br>    outQueueY.<span class="hljs-built_in">FreeTensor</span>(yLocal);<br>}<br></code></pre></td></tr></table></figure><p>实现的具体细节与接口可以参考官方文档。</p><p>最后再将<code>Process()</code>函数补全，并完善核函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">Process</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-built_in">CopyIn</span>();<br>    <span class="hljs-built_in">Compute</span>();<br>    <span class="hljs-built_in">CopyOut</span>();<br>}<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function">__global__ __aicore__ <span class="hljs-type">void</span></span><br><span class="hljs-function"><span class="hljs-title">sinh_custom</span><span class="hljs-params">(GM_ADDR x, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling)</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-built_in">GET_TILING_DATA</span>(tiling_data, tiling);<br>    KernelSinh op;<br>    op.<span class="hljs-built_in">Init</span>(x, y,<br>            tiling_data.formerNum, tiling_data.tailNum,<br>            tiling_data.formerLength, tiling_data.tailLength,<br>            tiling_data.alignNum);<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">TILING_KEY_IS</span>(<span class="hljs-number">1</span>))<br>    {<br>        op.<span class="hljs-built_in">Process</span>();<br>    }<br>}<br></code></pre></td></tr></table></figure><p>至此就完成了<code>kernel</code>侧的实现。</p><h4 id="host侧实现"><code>host</code>侧实现</h4><p>我们回到<code>op_host/sinh_custom.cpp</code>，关于类型推导函数，这个算子输入输出的形状一致。<code>msopgen</code>生成的算子工程中，默认即为输入输出形状一致，所以无须改动。如果在写其他复杂算子的时候，需要仔细分析数据形状的变化。关于算子原型注册，也无须改动。</p><p>现在就完成了整个算子的逻辑，可以执行<code>build.sh</code>来验证有没有编译时错误，若没有错误则可以进行运行时验证。</p><h1 id="核函数调用">核函数调用</h1><p>笔者直接将官方的核函数调用样例拿来做了一些修改，需要修改的地方如下。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">kernel_invocation<br>├── cmake<br>├── CMakeLists.txt<br>├── data_utils.h<br>├── input<br>├── main.cpp <span class="hljs-comment"># 需要修改</span><br>├── output<br>├── run.sh <span class="hljs-comment"># 需要修改</span><br>├── add_custom.cpp <span class="hljs-comment"># 替换为自己的算子实现</span><br>├── add_custom.py <span class="hljs-comment"># 需要修改</span><br>└── verify_result.py <span class="hljs-comment"># 添加的代码，用于验证结果</span><br></code></pre></td></tr></table></figure><p>将官方样例中的<code>add_custom.cpp</code>替换为自己实现的<code>kernel</code>侧算子，笔者这里的名称为<code>sinh_custom.cpp</code>。同时为了CPU侧调试，需要添加一个核函数的包装函数，代码如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> __CCE_KT_TEST__</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">sinh_custom_do</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> blockDim, <span class="hljs-type">void</span> *l2ctrl, <span class="hljs-type">void</span> *stream, <span class="hljs-type">uint8_t</span> *x, <span class="hljs-type">uint8_t</span> *y)</span></span><br><span class="hljs-function"></span>{<br>    sinh_custom&lt;&lt;&lt;blockDim, l2ctrl, stream&gt;&gt;&gt;(x, y);<br>}<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><blockquote><p>注意：为了快速验证逻辑，在核函数验证过程中未使用动态<code>tiling</code>，所以没有之前提到的那些<code>tiling</code>参数。</p></blockquote><p>然后是<code>sinh_custom.py</code>，官方样例中是<code>add_custom.py</code>，这里修改文件名称，因为后面的<code>run.sh</code>中是通过算子文件名来调用这一python脚本的。</p><p>由于本算子只需要一个输入向量，所以只生成一个<code>input</code>数据，然后修改<code>golden</code>数据的生成方式，调用<code>numpy</code>中与算子功能相同的函数来计算，注意数据类型，代码如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen_golden_data_simple</span>():<br>    np.random.seed(<span class="hljs-number">42</span>)<br>    input_x = np.random.randn(<span class="hljs-number">8</span>, <span class="hljs-number">2048</span>).astype(np.float16)<br>    golden = np.sinh(input_x).astype(np.float16)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'-----------------------<span class="hljs-subst">{input_x[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]}</span>'</span>)<br>    input_x.tofile(<span class="hljs-string">"./input/input_x.bin"</span>)<br>    golden.tofile(<span class="hljs-string">"./output/golden.bin"</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<br>    gen_golden_data_simple()<br></code></pre></td></tr></table></figure><p><code>main.cpp</code>中要调整相应的内存申请等操作，只需要一个<code>input</code>，CPU侧调试和NPU侧调试的代码都需要修改，具体如下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"data_utils.h"</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> __CCE_KT_TEST__</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"acl/acl.h"</span></span><br><span class="hljs-function"><span class="hljs-keyword">extern</span> <span class="hljs-type">void</span> <span class="hljs-title">sinh_custom_do</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> coreDim, <span class="hljs-type">void</span> *l2ctrl, <span class="hljs-type">void</span> *stream, <span class="hljs-type">uint8_t</span> *x, <span class="hljs-type">uint8_t</span> *y)</span></span>;<br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"tikicpulib.h"</span></span><br><span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function">__global__ __aicore__ <span class="hljs-type">void</span> <span class="hljs-title">sinh_custom</span><span class="hljs-params">(GM_ADDR x, GM_ADDR y)</span></span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br><span class="hljs-function"><span class="hljs-type">int32_t</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int32_t</span> argc, <span class="hljs-type">char</span> *argv[])</span></span><br><span class="hljs-function"></span>{<br>  <span class="hljs-type">size_t</span> inputByteSize = <span class="hljs-number">8</span> * <span class="hljs-number">2048</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">uint16_t</span>);<br>  <span class="hljs-type">size_t</span> outputByteSize = <span class="hljs-number">8</span> * <span class="hljs-number">2048</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">uint16_t</span>);<br>  <span class="hljs-type">uint32_t</span> blockDim = <span class="hljs-number">8</span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> __CCE_KT_TEST__</span><br>  <span class="hljs-type">uint8_t</span> *x = (<span class="hljs-type">uint8_t</span> *)AscendC::<span class="hljs-built_in">GmAlloc</span>(inputByteSize);<br>  <span class="hljs-type">uint8_t</span> *y = (<span class="hljs-type">uint8_t</span> *)AscendC::<span class="hljs-built_in">GmAlloc</span>(outputByteSize);<br><br>  <span class="hljs-built_in">ReadFile</span>(<span class="hljs-string">"./input/input_x.bin"</span>, inputByteSize, x, inputByteSize);<br><br>  AscendC::<span class="hljs-built_in">SetKernelMode</span>(KernelMode::AIV_MODE);<br>  <span class="hljs-built_in">ICPU_RUN_KF</span>(sinh_custom, blockDim, x, y);<br><br>  <span class="hljs-built_in">WriteFile</span>(<span class="hljs-string">"./output/output_y.bin"</span>, y, outputByteSize);<br><br>  AscendC::<span class="hljs-built_in">GmFree</span>((<span class="hljs-type">void</span> *)x);<br>  AscendC::<span class="hljs-built_in">GmFree</span>((<span class="hljs-type">void</span> *)y);<br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclInit</span>(<span class="hljs-literal">nullptr</span>));<br>  aclrtContext context;<br>  <span class="hljs-type">int32_t</span> deviceId = <span class="hljs-number">0</span>;<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtSetDevice</span>(deviceId));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtCreateContext</span>(&amp;context, deviceId));<br>  aclrtStream stream = <span class="hljs-literal">nullptr</span>;<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtCreateStream</span>(&amp;stream));<br><br>  <span class="hljs-type">uint8_t</span> *xHost, *yHost;<br>  <span class="hljs-type">uint8_t</span> *xDevice, *yDevice;<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtMallocHost</span>((<span class="hljs-type">void</span> **)(&amp;xHost), inputByteSize));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtMallocHost</span>((<span class="hljs-type">void</span> **)(&amp;yHost), outputByteSize));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtMalloc</span>((<span class="hljs-type">void</span> **)&amp;xDevice, inputByteSize, ACL_MEM_MALLOC_HUGE_FIRST));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtMalloc</span>((<span class="hljs-type">void</span> **)&amp;yDevice, outputByteSize, ACL_MEM_MALLOC_HUGE_FIRST));<br><br>  <span class="hljs-built_in">ReadFile</span>(<span class="hljs-string">"./input/input_x.bin"</span>, inputByteSize, xHost, inputByteSize);<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtMemcpy</span>(xDevice, inputByteSize, xHost, inputByteSize, ACL_MEMCPY_HOST_TO_DEVICE));<br><br>  <span class="hljs-built_in">sinh_custom_do</span>(blockDim, <span class="hljs-literal">nullptr</span>, stream, xDevice, yDevice);<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtSynchronizeStream</span>(stream));<br><br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtMemcpy</span>(yHost, outputByteSize, yDevice, outputByteSize, ACL_MEMCPY_DEVICE_TO_HOST));<br>  <span class="hljs-built_in">WriteFile</span>(<span class="hljs-string">"./output/output_y.bin"</span>, yHost, outputByteSize);<br><br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtFree</span>(xDevice));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtFree</span>(yDevice));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtFreeHost</span>(xHost));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtFreeHost</span>(yHost));<br><br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtDestroyStream</span>(stream));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtDestroyContext</span>(context));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclrtResetDevice</span>(deviceId));<br>  <span class="hljs-built_in">CHECK_ACL</span>(<span class="hljs-built_in">aclFinalize</span>());<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>}<br></code></pre></td></tr></table></figure><p>原样例中的验证方式是求md5和，但由于核函数中调用了<code>Exp</code>、<code>Muls</code>等API，所以精度可能会有损失，不适合用md5sum的方式来验证。这里就需要引入新的文件<code>verify_result.py</code>，这里使用了<code>numpy.isclose</code>函数来进行验证，这也是官方单算子API调用的结果验证方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_compare</span>(<span class="hljs-params">file1, file2,file3</span>):<br>    input1 = np.fromfile(file1, dtype=np.float16)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"input1: "</span>, input1)<br>    golden = np.fromfile(file2, dtype=np.float16)<br>    output = np.fromfile(file3, dtype=np.float16)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"output: "</span>, output)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"-------------golden is :"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"golden: "</span>, golden)<br><br>    different_element_results = np.isclose(<br>        output, golden,<br>        rtol=<span class="hljs-number">5e-2</span>,<br>        atol=<span class="hljs-number">1e-3</span>,<br>        equal_nan=<span class="hljs-literal">True</span>)<br>    different_element_indexes = np.where(<br>        different_element_results != np.array((<span class="hljs-literal">True</span>,)))[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">if</span> different_element_indexes.size == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"result correct!"</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"result error!"</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> different_element_indexes.size == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    intput_file1 = sys.argv[<span class="hljs-number">1</span>]<br>    golden_file = sys.argv[<span class="hljs-number">2</span>]<br>    output_file = sys.argv[<span class="hljs-number">3</span>]<br>    cmp_result = data_compare(intput_file1, golden_file, output_file)<br><br>    <span class="hljs-keyword">if</span> (cmp_result == <span class="hljs-number">0</span>):<br>        sys.exit(<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">else</span>:<br>        sys.exit(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>最后是修改<code>run.sh</code>脚本，需要修改的只有最后验证结果的部分。原样例的验证方式是md5sum。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">"md5sum: "</span>;<span class="hljs-built_in">md5sum</span> output/*.bin<br></code></pre></td></tr></table></figure><p>修改为调用脚本判断。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">"result verification: "</span><br>python3 verify_result.py ./input/input_x.bin ./output/golden.bin ./output/output_y.bin<br></code></pre></td></tr></table></figure><h1 id="单算子api调用">单算子API调用</h1><p>单算子调用是通过自动生成的两段式API来执行的，为了快速验证，同样是将官方样例中的单算子API调用样例拿来做了一些修改。需要修改的几处关键代码如下。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sh">aclnn_online_model<br>├── build<br>├── inc<br>├── README.md<br>├── run<br>│   └── out<br>│       ├── execute_sinh_op<br>│       ├── result_files<br>│       └── test_data<br>│           ├── config<br>│           └── data<br>│               ├── generate_data.py <span class="hljs-comment"># 生成测试数据脚本，需要修改</span><br>├── run.sh <span class="hljs-comment"># 需要修改</span><br>├── scripts<br>│   └── verify_result.py <span class="hljs-comment"># 调整验证方式，例如相对和绝对误差参数等</span><br>└── src<br>    ├── CMakeLists.txt <span class="hljs-comment"># 需要修改</span><br>    ├── common.cpp<br>    ├── main.cpp <span class="hljs-comment"># 需要修改</span><br>    ├── operator_desc.cpp<br>    └── op_runner.cpp <span class="hljs-comment"># 需要修改</span><br></code></pre></td></tr></table></figure><p>具体细节如下。</p><p><code>generate_data.py</code>中，按照算子来修改测试数据生成方式。本算子需要<code>half</code>类型的测试数据，故代码改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.random.randn(<span class="hljs-number">8</span>, <span class="hljs-number">2048</span>).astype(np.float16)<br><br>a.tofile(<span class="hljs-string">'input_0.bin'</span>)<br></code></pre></td></tr></table></figure><p><code>verify_result.py</code>中，根据实际读取的输入和输出，利用<code>np.isclose</code>来进行比较，该函数详细用法参考<code>numpy</code>官方文档。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_compare</span>(<span class="hljs-params">file1, file2</span>):<br>    input1 = np.fromfile(file1, dtype=np.float16)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"input1: "</span>, input1)<br>    golden = np.sinh(input1).astype(np.float16)<br>    output = np.fromfile(file2, dtype=np.float16)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"output: "</span>, output)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"-------------golden is :"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"golden: "</span>, golden)<br><br>    different_element_results = np.isclose(<br>        output, golden,<br>        rtol=<span class="hljs-number">5e-2</span>,<br>        atol=<span class="hljs-number">1e-3</span>,<br>        equal_nan=<span class="hljs-literal">True</span>)<br>    different_element_indexes = np.where(<br>        different_element_results != np.array((<span class="hljs-literal">True</span>,)))[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> different_element_indexes.size == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    intput_file1 = sys.argv[<span class="hljs-number">1</span>]<br>    output_file = sys.argv[<span class="hljs-number">2</span>]<br>    cmp_result = data_compare(intput_file1, output_file)<br><br>    <span class="hljs-keyword">if</span> (cmp_result == <span class="hljs-number">0</span>):<br>        sys.exit(<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">else</span>:<br>        sys.exit(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p><code>main.cpp</code>中，需要将<code>CreateOpDesc()</code>函数根据具体的输入输出来做修改。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">OperatorDesc <span class="hljs-title">CreateOpDesc</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    std::vector&lt;<span class="hljs-type">int64_t</span>&gt; shape{<span class="hljs-number">8</span>, <span class="hljs-number">2048</span>};<br>    aclDataType dataType = ACL_FLOAT16;<br>    aclFormat format = ACL_FORMAT_ND;<br>    OperatorDesc opDesc;<br>    opDesc.<span class="hljs-built_in">AddInputTensorDesc</span>(dataType, shape.<span class="hljs-built_in">size</span>(), shape.<span class="hljs-built_in">data</span>(), format);<br>    opDesc.<span class="hljs-built_in">AddOutputTensorDesc</span>(dataType, shape.<span class="hljs-built_in">size</span>(), shape.<span class="hljs-built_in">data</span>(), format);<br>    <span class="hljs-keyword">return</span> opDesc;<br>}<br></code></pre></td></tr></table></figure><p><code>op_runner.cpp</code>中将两段式API修改为自己算子的API，请善用<code>Ctrl + F</code>搜索关键代码进行修改，具体的API名称可以查看算子目录下的<code>build_out/autogen</code>目录。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp">...<br><span class="hljs-keyword">auto</span> ret = <span class="hljs-built_in">aclnnSinhCustomGetWorkspaceSize</span>(inputTensor_[<span class="hljs-number">0</span>], outputTensor_[<span class="hljs-number">0</span>], &amp;workspaceSize, &amp;handle);<br>...<br><span class="hljs-built_in">INFO_LOG</span>(<span class="hljs-string">"Execute aclnnSinhCustomGetWorkspaceSize success, workspace size %lu"</span>, workspaceSize);<br>...<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">aclnnSinhCustom</span>(workspace, workspaceSize, handle, stream) != ACL_SUCCESS)<br>{<br>    ...<br>}<br><span class="hljs-built_in">INFO_LOG</span>(<span class="hljs-string">"Execute aclnnSinhCustom success"</span>);<br>...<br></code></pre></td></tr></table></figure><p>接着修改<code>src/CMakeLists.txt</code>。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(AUTO_GEN_PATH <span class="hljs-string">"../SinhCustom/build_out/autogen"</span>) <span class="hljs-comment"># 16行</span><br><br><span class="hljs-comment"># 50行以后，修改可执行文件的名称</span><br><span class="hljs-keyword">add_executable</span>(execute_sinh_op<br>    <span class="hljs-variable">${AUTO_GEN_PATH}</span>/aclnn_sinh_custom.cpp<br>    operator_desc.cpp<br>    op_runner.cpp<br>    main.cpp<br>    op_runner.cpp<br>    common.cpp<br>)<br><br><span class="hljs-keyword">target_link_libraries</span>(execute_sinh_op<br>    ascendcl<br>    acl_op_compiler<br>    nnopbase<br>    stdc++<br>)<br><br><span class="hljs-keyword">install</span>(TARGETS execute_sinh_op DESTINATION <span class="hljs-variable">${CMAKE_RUNTIME_OUTPUT_DIRECTORY}</span>)<br></code></pre></td></tr></table></figure><p>最后修改<code>run.sh</code>脚本中关于路径的部分。修改完成后，就可以执行<code>run.sh</code>脚本进行单算子API调用了。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">INFO: acl executable run success!<br>input1:  [ 0.468  -0.2585 -3.066  ...  0.9136 -1.117  -1.368 ]<br>output:  [  0.485   -0.2615 -10.71   ...   1.047   -1.365   -1.837 ]<br>-------------golden is :<br>golden:  [  0.4854  -0.2615 -10.71   ...   1.046   -1.364   -1.837 ]<br>INFO: compare golden data success!<br></code></pre></td></tr></table></figure><p>出现上述提示证明算子通过验证。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;摘要记录一下Ascend C的学习过程，整体来说Ascend C的核心部分还是比较易用的，唯一的小缺点就是学习初期不得不被一些无关算子核心逻辑的工程文件所干扰。&lt;/p&gt;</summary>
    
    
    
    <category term="高性能计算" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"/>
    
    <category term="AscendC" scheme="https://deleter-d.github.io/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/AscendC/"/>
    
    
    <category term="异构计算" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
    <category term="AscendC" scheme="https://deleter-d.github.io/tags/AscendC/"/>
    
  </entry>
  
  <entry>
    <title>毕昇编译器异构算子分核方案再探</title>
    <link href="https://deleter-d.github.io/posts/63148/"/>
    <id>https://deleter-d.github.io/posts/63148/</id>
    <published>2023-10-16T03:37:08.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>摘要根据<code>vec_cross_add</code>接口的正确用法重新实现了前面的动态分核方案，效果进一步提升。</p><span id="more"></span><h1 id="基于vec_cross_add接口重新实现softmax方案五">基于<code>vec_cross_add</code>接口重新实现Softmax（方案五）</h1><h2 id="方案实现">方案实现</h2><p>分核方案沿用方案三，经过修改，使用<code>vec_cross_add()</code>接口的Softmax算子实现如下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">using</span> <span class="hljs-type">data_t</span> = <span class="hljs-type">float</span>;<br><br><span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">ascend_softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; input)</span> </span>{<br>  std::<span class="hljs-type">size_t</span> input_sz = input.<span class="hljs-built_in">size</span>();<br>  std::<span class="hljs-type">size_t</span> byte_count = input_sz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br><br>  <span class="hljs-comment">// call the host operator if input isn't enough a full block</span><br>  <span class="hljs-keyword">if</span> (byte_count &lt; <span class="hljs-number">32</span>) {<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">softmax</span>(input);<br>  }<br><br>  <span class="hljs-comment">// number of elements per group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> elem_per_group = <span class="hljs-number">640</span>;<br>  <span class="hljs-comment">// number of repeats per group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> repeat_per_group = elem_per_group * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>) / <span class="hljs-number">256</span>;<br>  <span class="hljs-comment">// number of elements in tail block</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> tail_elem_count = input_sz % elem_per_group;<br>  <span class="hljs-comment">// number of groups</span><br>  <span class="hljs-comment">// if tail block is exist, apply for one more group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_num = (tail_elem_count &gt; <span class="hljs-number">0</span>)<br>                                    ? ((input_sz / elem_per_group) + <span class="hljs-number">1</span>)<br>                                    : (input_sz / elem_per_group);<br><br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-comment">// GM memory allocation</span><br>  <span class="hljs-keyword">auto</span> dev_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * elem_per_group, Q);<br>  <span class="hljs-keyword">auto</span> sum_res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)), Q);<br><br>  <span class="hljs-comment">// Host memory allocation</span><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">sum_res</span><span class="hljs-params">(group_num * (<span class="hljs-number">32</span> / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">data_t</span>)), <span class="hljs-number">0.0f</span>)</span></span>;<br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(input_sz, <span class="hljs-number">0.0f</span>)</span></span>;<br><br>  <span class="hljs-comment">// host -&gt; GM</span><br>  Q.<span class="hljs-built_in">memcpy</span>(dev_buf, input.<span class="hljs-built_in">data</span>(), byte_count);<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Summary</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; input_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, repeat_per_group&gt; sum_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    <span class="hljs-comment">// GM -&gt; UB</span><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(), <br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-comment">// if tail block has element and this is the last group</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec_v, input_vec_v);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tail_elem_count; ++i)<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += input_vec_v[i];<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// full block data</span><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec, input_vec);<br>      bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_vec.<span class="hljs-built_in">data</span>(), input_vec);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; repeat_per_group; ++i) {<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += sum_vec[i];<br>      }<br>    }<br><br>    <span class="hljs-comment">// UB -&gt; GM</span><br>    input_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  <span class="hljs-comment">// GM -&gt; Host</span><br>  Q.<span class="hljs-built_in">memcpy</span>(sum_res.<span class="hljs-built_in">data</span>(), sum_res_buf, group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-type">data_t</span> sum;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sum_res.<span class="hljs-built_in">size</span>(); i += <span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))<br>    sum += sum_res[i];<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Softmax</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// UB memory of exponent result</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; exp_res_vec;<br>    <span class="hljs-comment">// UB memory of divisor</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; <span class="hljs-built_in">divisor_vec</span>(sum);<br>    <span class="hljs-comment">// UB memory of final result</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; res_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    <span class="hljs-comment">// GM -&gt; UB</span><br>    exp_res_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-comment">// if tail block has element and this is the last group</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// full block data</span><br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec, exp_res_vec, divisor_vec);<br>    }<br><br>    <span class="hljs-comment">// UB -&gt; GM</span><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  <span class="hljs-comment">// GM -&gt; host</span><br>  Q.<span class="hljs-built_in">memcpy</span>(res.<span class="hljs-built_in">data</span>(), dev_buf, byte_count);<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  sycl::<span class="hljs-built_in">free</span>(dev_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(sum_res_buf, Q);<br><br>  <span class="hljs-keyword">return</span> res;<br>}<br></code></pre></td></tr></table></figure><h2 id="功能测试">功能测试</h2><p>功能测试全部验证正确。</p><h2 id="性能测试">性能测试</h2><p>与之前效果最好的方案三对比。</p><table><thead><tr class="header"><th style="text-align: left;">测试用例</th><th style="text-align: left;">640</th><th style="text-align: left;">6400</th><th style="text-align: left;">64000</th><th style="text-align: left;">640000</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">方案三加速比</td><td style="text-align: left;">0.224613</td><td style="text-align: left;">1.512394</td><td style="text-align: left;">13.30433</td><td style="text-align: left;">88.70575</td></tr><tr class="even"><td style="text-align: left;">方案五加速比</td><td style="text-align: left;">0.225836</td><td style="text-align: left;">1.330532</td><td style="text-align: left;">12.58051</td><td style="text-align: left;">101.0137</td></tr></tbody></table><p>可以看到在向量长度比较大的情况下，接口的优势还是远大于<code>for</code>循环求和的。</p><h1 id="毕昇编译器异构算子分核方案再探方案六">毕昇编译器异构算子分核方案再探（方案六）</h1><p>之前的Softmax算子实现中提到，采用动态分核方案，令每个核尽可能多的处理数据，并充分利用所以物理核带来的效果，甚至不如大量处理适量数据的逻辑核带来的效果好。当时是由于对<code>vec_cross_add()</code>求和接口产生了误解，所以转用<code>for</code>循环在逻辑核内部进行求和。</p><p>回顾一下上次的两种分核方式和性能表现。</p><ul><li>方案三：每个核处理640个数据，无论输入向量多长，都拆分为640个元素的小向量，再单独处理尾块；</li><li>方案四：根据输入向量的长度和物理核心数量，动态确定逻辑核的数量，保证每个物理核都在工作，再单独处理尾块。</li></ul><p>方案四详见<a href="https://deleter-d.github.io/posts/15984/#动态方案">基于毕昇编译器的Softmax异构算子 - 亦初 (deleter-d.github.io)</a>。</p><p>当时的性能表现是：</p><table><thead><tr class="header"><th style="text-align: left;">测试用例</th><th style="text-align: left;">640</th><th style="text-align: left;">6400</th><th style="text-align: left;">64000</th><th style="text-align: left;">640000</th><th>698880</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">方案三加速比</td><td style="text-align: left;">0.237432</td><td style="text-align: left;">1.478988</td><td style="text-align: left;">13.19605</td><td style="text-align: left;">87.72573</td><td>96.29706</td></tr><tr class="even"><td style="text-align: left;">方案四加速比</td><td style="text-align: left;">0.234373</td><td style="text-align: left;">1.436941</td><td style="text-align: left;">12.35908</td><td style="text-align: left;">80.59147</td><td>67.26953</td></tr></tbody></table><p>但转念一想，得到这个结果的前提是求和均使用了核内<code>for</code>循环，所以动态分核策略中，输入向量长度比较长的情况下，每个逻辑核分到的向量长度就会远大于方案一的策略。可想而知，效率其实是被<code>for</code>循环拖慢的。</p><p>所以，利用<code>vec_cross_add()</code>接口再次实现动态分核方案。</p><h2 id="方案实现-1">方案实现</h2><p>代码与之前的大同小异，只在求和的地方做了修改，改用<code>vec_cross_add()</code>接口。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">ascend_softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; input)</span> </span>{<br>  std::<span class="hljs-type">size_t</span> input_sz = input.<span class="hljs-built_in">size</span>();<br>  std::<span class="hljs-type">size_t</span> byte_count = input_sz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br><br>  <span class="hljs-comment">// call the host operator if input isn't enough a full block</span><br>  <span class="hljs-keyword">if</span> (byte_count &lt; <span class="hljs-number">32</span>) {<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">softmax</span>(input);<br>  }<br><br>  <span class="hljs-comment">// number of elements per group</span><br>  std::<span class="hljs-type">size_t</span> elem_per_group = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * UB_MAX_BYTES)<br>    elem_per_group = UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">51200</span>)<br>    elem_per_group = <span class="hljs-number">51200</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">25600</span>)<br>    elem_per_group = <span class="hljs-number">25600</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">12800</span>)<br>    elem_per_group = <span class="hljs-number">12800</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">5120</span>)<br>    elem_per_group = <span class="hljs-number">5120</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">2560</span>)<br>    elem_per_group = <span class="hljs-number">2560</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span><br>    elem_per_group = <span class="hljs-number">1280</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-comment">// number of repeat per group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> repeat_per_group = elem_per_group * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>) / <span class="hljs-number">256</span>;<br>  <span class="hljs-comment">// number of elements in tail block</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> tail_elem_count = input_sz % elem_per_group;<br>  <span class="hljs-comment">// number of groups</span><br>  <span class="hljs-comment">// if tail block is exist, apply for one more group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_num = (tail_elem_count &gt; <span class="hljs-number">0</span>)<br>                                    ? ((input_sz / elem_per_group) + <span class="hljs-number">1</span>)<br>                                    : (input_sz / elem_per_group);<br><br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-comment">// GM memory allocation</span><br>  <span class="hljs-keyword">auto</span> dev_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * elem_per_group, Q);<br>  <span class="hljs-keyword">auto</span> sum_res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)), Q);<br><br>  <span class="hljs-comment">// Host memory allocation</span><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">sum_res</span><span class="hljs-params">(group_num * (<span class="hljs-number">32</span> / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">data_t</span>)), <span class="hljs-number">0.0f</span>)</span></span>;<br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(input_sz, <span class="hljs-number">0.0f</span>)</span></span>;<br><br>  <span class="hljs-comment">// host -&gt; GM</span><br>  Q.<span class="hljs-built_in">memcpy</span>(dev_buf, input.<span class="hljs-built_in">data</span>(), byte_count);<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Summary</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; input_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-number">256</span>&gt; sum_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    <span class="hljs-comment">// GM -&gt; UB</span><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-comment">// if tail block has element and this is the last group</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec_v, input_vec_v);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tail_elem_count; ++i)<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += input_vec_v[i];<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// full block data</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">sum_vec_v</span>(sum_vec.<span class="hljs-built_in">data</span>(), repeat_per_group * <span class="hljs-number">8</span>);<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec_v, input_vec_v);<br>      bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_vec_v, input_vec_v);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; repeat_per_group * <span class="hljs-number">8</span>; i += <span class="hljs-number">8</span>) {<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += sum_vec_v[i];<br>      }<br>    }<br><br>    <span class="hljs-comment">// UB -&gt; GM</span><br>    input_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  <span class="hljs-comment">// GM -&gt; Host</span><br>  Q.<span class="hljs-built_in">memcpy</span>(sum_res.<span class="hljs-built_in">data</span>(), sum_res_buf, group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-type">data_t</span> sum;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sum_res.<span class="hljs-built_in">size</span>(); i += <span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))<br>    sum += sum_res[i];<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Softmax</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// UB memory of exponent result</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; exp_res_vec;<br>    <span class="hljs-comment">// UB memory of divisor</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; <span class="hljs-built_in">divisor_vec</span>(sum);<br>    <span class="hljs-comment">// UB memory of final result</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; res_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    <span class="hljs-comment">// GM -&gt; UB</span><br>    exp_res_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-comment">// if tail block has element and this is the last group</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// full block data</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    }<br><br>    <span class="hljs-comment">// UB -&gt; GM</span><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  <span class="hljs-comment">// GM -&gt; host</span><br>  Q.<span class="hljs-built_in">memcpy</span>(res.<span class="hljs-built_in">data</span>(), dev_buf, byte_count);<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  sycl::<span class="hljs-built_in">free</span>(dev_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(sum_res_buf, Q);<br><br>  <span class="hljs-keyword">return</span> res;<br>}<br></code></pre></td></tr></table></figure><h2 id="功能测试-1">功能测试</h2><p>功能测试全部正确。</p><h2 id="性能测试-1">性能测试</h2><p>把几个方案放在一起对比，其中：</p><ul><li>方案三和方案五：每个核心固定640个元素；</li><li>方案四和方案六：动态分核。</li></ul><table><thead><tr class="header"><th style="text-align: left;">测试用例</th><th style="text-align: left;">640</th><th style="text-align: left;">6400</th><th style="text-align: left;">64000</th><th style="text-align: left;">640000</th><th>698880</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">方案三加速比</td><td style="text-align: left;">0.237432</td><td style="text-align: left;">1.478988</td><td style="text-align: left;">13.19605</td><td style="text-align: left;">87.72573</td><td>96.29706</td></tr><tr class="even"><td style="text-align: left;">方案四加速比</td><td style="text-align: left;">0.234373</td><td style="text-align: left;">1.436941</td><td style="text-align: left;">12.35908</td><td style="text-align: left;">80.59147</td><td>67.26953</td></tr><tr class="odd"><td style="text-align: left;">方案五加速比</td><td style="text-align: left;">0.225836</td><td style="text-align: left;">1.330532</td><td style="text-align: left;">12.58051</td><td style="text-align: left;">101.0137</td><td>94.52815</td></tr><tr class="even"><td style="text-align: left;">方案六加速比</td><td style="text-align: left;">0.205704</td><td style="text-align: left;">1.29488</td><td style="text-align: left;">12.22252</td><td style="text-align: left;">120.7111</td><td>123.515</td></tr></tbody></table><p>在输入向量较小的情况下，由于动态分核方案可能出现某些物理核不干活儿的情况，但在大向量的情况下，这种策略是占绝对优势的。加速比的一些波动是可接受的。同时由于使用了接口进行求和，大大减小了<code>for</code>循环的压力，整体效率进一步提升了。</p><p>目前还能够想到的优化手段可能就不是靠编译器能够自动完成的了，进一步的优化可能需要借助手动同步等手段追求极致性能了。</p><h1 id="与mindspore对比">与mindspore对比</h1><p>所用的mindspore版本为2.1.0，加速卡为昇腾910，测试代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> mindspore <span class="hljs-keyword">as</span> ms<br><span class="hljs-keyword">import</span> mindspore.ops <span class="hljs-keyword">as</span> ops<br><span class="hljs-keyword">import</span> time<br><br>INPUT = <span class="hljs-number">640</span><br><span class="hljs-built_in">input</span> = ms.Tensor(np.random.random(INPUT), ms.float32)<br><br>start = time.perf_counter_ns()<br><br>ops.softmax(<span class="hljs-built_in">input</span>)<br><br>end = time.perf_counter_ns()<br>runTime = end-start<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f'Total time: <span class="hljs-subst">{runTime}</span>'</span>)<br></code></pre></td></tr></table></figure><p>针对不同的测试用例只需修改<code>INPUT</code>即可，与上面效果最好的方案六做对比，各测试用例的加速比如下。</p><table><thead><tr class="header"><th style="text-align: left;">测试用例</th><th style="text-align: left;">640</th><th style="text-align: left;">6400</th><th style="text-align: left;">64000</th><th style="text-align: left;">640000</th><th>698880</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">加速比</td><td style="text-align: left;">1.636923067</td><td style="text-align: left;">1.72635719</td><td style="text-align: left;">1.672068458</td><td style="text-align: left;">1.71248809</td><td>1.636225576</td></tr></tbody></table><p>加速比基本在1.7左右，虽然python解释器需要一定时间来解析，但通过一些手段测试后，这个时间的影响可以忽略。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;摘要根据&lt;code&gt;vec_cross_add&lt;/code&gt;接口的正确用法重新实现了前面的动态分核方案，效果进一步提升。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="机器学习" scheme="https://deleter-d.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="异构编程" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"/>
    
    <category term="深度学习" scheme="https://deleter-d.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>关于vec_cross_add接口的详细测试</title>
    <link href="https://deleter-d.github.io/posts/1040/"/>
    <id>https://deleter-d.github.io/posts/1040/</id>
    <published>2023-08-17T12:14:52.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>先说结论，问题出在我粗心了，磕头道歉！！本接口没有计算逻辑性问题，为上篇中不严谨的言论道歉。但在特定情况下，会有不符合预期的返回值。</p><span id="more"></span><h1 id="关于vec_cross_add接口的详细测试">关于<code>vec_cross_add</code>接口的详细测试</h1><p>之前在写Softmax算子的时候，碰到了该接口结果不稳定的情况，所以进行一次详细测试，看看问题出在哪里。</p><h2 id="测试方案">测试方案</h2><p>先用标准C++实现一个求和算子，用作计算标准。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">using</span> <span class="hljs-type">data_t</span> = <span class="hljs-type">float</span>;<br><br><span class="hljs-function"><span class="hljs-type">data_t</span> <span class="hljs-title">summary</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; input)</span> </span>{<br>  <span class="hljs-type">data_t</span> sum = <span class="hljs-number">0.0</span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> item : input) {<br>    sum += item;<br>  }<br>  <span class="hljs-keyword">return</span> sum;<br>}<br></code></pre></td></tr></table></figure><p>测试数据从<code>(-1,1)</code>的均匀分布中采样，为了方便复习，设置随机种子。结果的相对误差在2%以内均认为结果正确。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INPUT 64</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>{<br>  std::vector&lt;<span class="hljs-type">data_t</span>&gt; input;<br><br>  <span class="hljs-function">std::mt19937 <span class="hljs-title">gen</span><span class="hljs-params">(<span class="hljs-number">1234</span>)</span></span>;<br>  <span class="hljs-function">std::uniform_real_distribution&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">urdis</span><span class="hljs-params">(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span></span>;<br>  <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; INPUT; i++)<br>    input.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">urdis</span>(gen));<br><br>  <span class="hljs-type">data_t</span> sum = <span class="hljs-built_in">summary</span>(input);<br>  <span class="hljs-type">data_t</span> ascend_sum = <span class="hljs-built_in">ascend_summary</span>(input);<br>  std::cout.<span class="hljs-built_in">precision</span>(<span class="hljs-number">12</span>);<br>  std::cout &lt;&lt; std::<span class="hljs-built_in">setw</span>(<span class="hljs-number">12</span>) &lt;&lt; <span class="hljs-string">"host sum: "</span> &lt;&lt; std::<span class="hljs-built_in">setw</span>(<span class="hljs-number">12</span>) &lt;&lt; sum &lt;&lt; std::endl;<br>  std::cout &lt;&lt; std::<span class="hljs-built_in">setw</span>(<span class="hljs-number">12</span>) &lt;&lt; <span class="hljs-string">"ascend sum: "</span> &lt;&lt; std::<span class="hljs-built_in">setw</span>(<span class="hljs-number">12</span>) &lt;&lt; ascend_sum &lt;&lt; std::endl;<br>  <span class="hljs-keyword">if</span> ((std::<span class="hljs-built_in">fabs</span>(sum - ascend_sum) / sum) &lt; <span class="hljs-number">0.02</span>)<br>    std::cout &lt;&lt; <span class="hljs-string">"Result correct."</span> &lt;&lt; std::endl;<br>  <span class="hljs-keyword">else</span><br>    std::cout &lt;&lt; <span class="hljs-string">"Result error."</span> &lt;&lt; std::endl;<br><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>}<br></code></pre></td></tr></table></figure><h2 id="用例设计">用例设计</h2><p>为了尽可能全面测试该接口，同时排除不必要的影响，可以设置一下几种测试用例，均以<code>float</code>数据为例。</p><ol type="1"><li>输入向量长度为64，字节数为256B，1个repeat，用1个group处理。</li><li>输入向量长度为128，字节数为512B，2个repeat，用1个group处理。</li><li>输入向量长度为128，字节数为512B，2个repeat，用2个group处理。</li></ol><p>这样设计用例可以分析出，到底是接口本身有问题，还是访存过程中出现了问题。用例1可以判断接口本身计算单个repeat的结果的正确性，用例2可以判断计算多个repeat时结果的正确性，用例3可以判断分核对repeat计算的影响。</p><h2 id="算子实现">算子实现</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> GROUP_NUM 1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ELEM_PER_GROUP 64</span><br><br><span class="hljs-function"><span class="hljs-type">data_t</span> <span class="hljs-title">ascend_summary</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; &amp;input)</span> </span>{<br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-keyword">auto</span> input_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(INPUT, Q);<br>  <span class="hljs-comment">// 结果buf申请的长度，可以将每个核访问的block严格分离</span><br>  <span class="hljs-comment">// 避免了由于block踩踏发生的问题</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> res_vec_num = GROUP_NUM * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  <span class="hljs-keyword">auto</span> res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(res_vec_num, Q);<br><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> repeat_num = ELEM_PER_GROUP * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>) / <span class="hljs-number">256</span>;<br><br>  <span class="hljs-comment">// Host -&gt; GM</span><br>  Q.<span class="hljs-built_in">memcpy</span>(input_buf, input.<span class="hljs-built_in">data</span>(), INPUT * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Sum</span>&gt;(GROUP_NUM, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, ELEM_PER_GROUP&gt; input_vec;<br>    <span class="hljs-comment">// 和向量的长度取决于本group内处理的repeat数量</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, repeat_num&gt; res_vec;<br><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(input_buf + group_id * ELEM_PER_GROUP).<span class="hljs-built_in">get</span>(),<br>        ELEM_PER_GROUP);<br><br>    bisheng::<span class="hljs-built_in">vec_cross_add</span>(res_vec.<span class="hljs-built_in">data</span>(), input_vec);<br><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(res_buf + group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)))<br>            .<span class="hljs-built_in">get</span>(),<br>        repeat_num);<br>  });<br><br>  <span class="hljs-comment">// Host端的结果数组也避免了block踩踏</span><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">sum_host_vec</span><span class="hljs-params">(res_vec_num, <span class="hljs-number">0.0f</span>)</span></span>;<br>  Q.<span class="hljs-built_in">memcpy</span>(sum_host_vec.<span class="hljs-built_in">data</span>(), res_buf, res_vec_num * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-type">data_t</span> sum;<br>  <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; res_vec_num; i++)<br>    <span class="hljs-comment">// 只累加有意义的数据</span><br>    <span class="hljs-keyword">if</span> (i % (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)) &lt; repeat_num)<br>      sum += sum_host_vec[i];<br><br>  <span class="hljs-keyword">return</span> sum;<br>}<br></code></pre></td></tr></table></figure><p>针对不同的测试用例，只需要更改两个<code>#define</code>宏定义的数据即可。</p><h2 id="测试结果">测试结果</h2><h3 id="用例一">用例一</h3><p><img src="https://github.com/Deleter-D/Images/assets/56388518/a1c99f22-c4bf-41c8-b2a4-c0c9c025fab9" style="zoom: 50%;"></p><p>宏修改为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INPUT 64</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GROUP_NUM 1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ELEM_PER_GROUP 64</span><br></code></pre></td></tr></table></figure><p>结果没有任何问题。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache">  <span class="hljs-attribute">host</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">76275920868</span><br><span class="hljs-attribute">ascend</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">76275908947</span><br><span class="hljs-attribute">Result</span> correct.<br></code></pre></td></tr></table></figure><h3 id="用例二">用例二</h3><p><img src="https://github.com/Deleter-D/Images/assets/56388518/070147b9-4cdf-4ebc-aeb7-e04920a2155a" style="zoom:50%;"></p><p>宏修改为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INPUT 128</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GROUP_NUM 1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ELEM_PER_GROUP 128</span><br></code></pre></td></tr></table></figure><p>结果也没有任何问题。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache">  <span class="hljs-attribute">host</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505186081</span><br><span class="hljs-attribute">ascend</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505162239</span><br><span class="hljs-attribute">Result</span> correct.<br></code></pre></td></tr></table></figure><p>之前问题就出在类似用例二的情况。当一个group处理多个repeat时，结果向量中会存在多个有意义的值，需要在累加时将这些有意义的值全部都加起来，之前问题就出在，没妥善处理单个核处理多repeat的情况，导致有一部分有意义的数没有累加上去，最终导致结果出错。</p><h3 id="用例三">用例三</h3><p><img src="https://github.com/Deleter-D/Images/assets/56388518/4faaa240-9221-4358-8771-d4a85f3dcb13" style="zoom:50%;"></p><p>宏修改为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INPUT 128</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GROUP_NUM 2</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ELEM_PER_GROUP 64</span><br></code></pre></td></tr></table></figure><p>结果自然也没有问题。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache">  <span class="hljs-attribute">host</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505186081</span><br><span class="hljs-attribute">ascend</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505162239</span><br><span class="hljs-attribute">Result</span> correct.<br></code></pre></td></tr></table></figure><h1 id="特定不符合预期的情况">特定不符合预期的情况</h1><h2 id="情况描述">情况描述</h2><p>在此之前，我认为这个接口确实没问题了，但在偶然的情况下，还是测试出了不符合预期返回结果的情况。</p><p>在使用<code>vec_cross_add()</code>时，我们应该定义两个向量，一个作为输入向量，另一个作为结果向量。正常情况下，结果向量的长度应该为输入向量的repeat数量。例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">bisheng::vector&lt;<span class="hljs-type">float</span>, 128&gt; src; <span class="hljs-comment">// src为128个float，也就是2个repeat</span><br>bisheng::vector&lt;<span class="hljs-type">float</span>, 2&gt; dst; <span class="hljs-comment">// 结果向量长度应该为2</span><br>bisheng::<span class="hljs-built_in">vec_cross_add</span>(src.<span class="hljs-built_in">data</span>(), dst); <span class="hljs-comment">// 正常的调用方式</span><br></code></pre></td></tr></table></figure><p>这种方式确实没有问题，结果返回也正常，将结果数组中的元素都相加后，确实是输入向量元素的和。</p><p>但当我们用变长向量<code>bisheng::vector_view</code>时，返回结果就不像预期这样了。</p><p>下面实现了一个利用变长向量操作数据的算子。大部分代码与上面的一致，只需关注有注释的部分。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">data_t</span> <span class="hljs-title">ascend_summary_view</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; &amp;input)</span> </span>{<br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-keyword">auto</span> input_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(INPUT, Q);<br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> res_vec_num = GROUP_NUM * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  <span class="hljs-keyword">auto</span> res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(res_vec_num, Q);<br><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> repeat_num = ELEM_PER_GROUP * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>) / <span class="hljs-number">256</span>;<br><br>  Q.<span class="hljs-built_in">memcpy</span>(input_buf, input.<span class="hljs-built_in">data</span>(), INPUT * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br><br>  <span class="hljs-function">sycl::stream <span class="hljs-title">out</span><span class="hljs-params">(<span class="hljs-number">512</span> * GROUP_NUM, <span class="hljs-number">512</span>, Q.get_device())</span></span>;<br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">SumView</span>&gt;(GROUP_NUM, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    <span class="hljs-comment">// 申请较大的向量</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, <span class="hljs-number">30000</span>&gt; input_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, <span class="hljs-number">30000</span>&gt; res_vec;<br><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(input_buf + group_id * ELEM_PER_GROUP).<span class="hljs-built_in">get</span>(),<br>        ELEM_PER_GROUP);<br><br>    <span class="hljs-comment">// 使用变长向量来操作正确范围内的数据</span><br>    bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), ELEM_PER_GROUP);<br>    bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), repeat_num);<br><br>    bisheng::<span class="hljs-built_in">vec_cross_add</span>(res_vec_v, input_vec_v);<br><br>    <span class="hljs-comment">// 输出变长结果向量前20个元素</span><br>    out &lt;&lt; <span class="hljs-string">"group "</span> &lt;&lt; group_id &lt;&lt; <span class="hljs-string">"\n"</span>;<br>    <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">20</span>; ++i)<br>      out &lt;&lt; res_vec_v[i] &lt;&lt; <span class="hljs-string">" "</span>;<br>    out &lt;&lt; <span class="hljs-string">"\n"</span>;<br><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(res_buf + group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)))<br>            .<span class="hljs-built_in">get</span>(),<br>        repeat_num);<br>  });<br><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">sum_host_vec</span><span class="hljs-params">(res_vec_num, <span class="hljs-number">0.0f</span>)</span></span>;<br>  Q.<span class="hljs-built_in">memcpy</span>(sum_host_vec.<span class="hljs-built_in">data</span>(), res_buf, res_vec_num * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-type">data_t</span> sum;<br>  <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; res_vec_num; i++)<br>    <span class="hljs-keyword">if</span> (i % (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)) &lt; repeat_num)<br>      sum += sum_host_vec[i];<br><br>  <span class="hljs-keyword">return</span> sum;<br>}<br></code></pre></td></tr></table></figure><p>为了更清楚的看到其中发生了什么，故定义一个<code>sycl::stream</code>来输出Kernel中的信息。</p><p>理论上，即使是变长向量，返回的结果向量长度也应该是输入向量的repeat数，在这里用上面的用例二进行说明。</p><p>此时的宏为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> INPUT 128</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GROUP_NUM 1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ELEM_PER_GROUP 128</span><br></code></pre></td></tr></table></figure><p>先来看计算结果的输出：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache">  <span class="hljs-attribute">host</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505186081</span><br><span class="hljs-attribute">ascend</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">76275908947</span><br><span class="hljs-attribute">Result</span> error.<br></code></pre></td></tr></table></figure><p>计算错误，这成功复现了另一种错误的情况。这个错误表面上看起来，和上面使用定长向量测试时描述的错误原因一样，原因没有将所以有意义的数据累加进去，最终导致了结果不正确。</p><p>先想一个问题，我们在Kernel中输出了结果向量的前20个元素，理论上讲，输出应该类似于下面这种形式：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>.<span class="hljs-number">7628</span> -<span class="hljs-number">0</span>.<span class="hljs-number">2677</span> ......<br></code></pre></td></tr></table></figure><p>前两个元素应该就是两个repeat的和，后面的元素应该都是未初始化的无意义的数据。</p><p><strong>但问题的关键来了，来看一看Kernel中输出的结果向量的前20个元素。</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>.<span class="hljs-number">7628</span> <span class="hljs-number">0</span>.<span class="hljs-number">0000000013091844320297241211</span> -<span class="hljs-number">0</span>.<span class="hljs-number">0000000027893838882446289062</span> <span class="hljs-number">0</span>.<span class="hljs-number">0000000034829735755920410156</span> <span class="hljs-number">0</span>.<span class="hljs-number">000000041852550506591796875</span> -<span class="hljs-number">0</span>.<span class="hljs-number">000000004057476043701171875</span> -<span class="hljs-number">0</span>.<span class="hljs-number">0000004261577606201171875</span> <span class="hljs-number">0</span>.<span class="hljs-number">0000000014236330986022949219</span> -<span class="hljs-number">0</span>.<span class="hljs-number">2677</span> -<span class="hljs-number">0</span>.<span class="hljs-number">000000044695949554443359375</span> -<span class="hljs-number">0</span>.<span class="hljs-number">000000012639684677124023437</span> <span class="hljs-number">0</span>.<span class="hljs-number">00000000012021332979202270508</span> -<span class="hljs-number">0</span>.<span class="hljs-number">000000060646677017211914062</span> -<span class="hljs-number">0</span>.<span class="hljs-number">0000000027346568107604980469</span> -<span class="hljs-number">0</span>.<span class="hljs-number">000000011391909122467041016</span> -<span class="hljs-number">0</span>.<span class="hljs-number">000000012336615324020385742</span> <span class="hljs-number">0</span>.<span class="hljs-number">00000018131090164184570312</span><br></code></pre></td></tr></table></figure><p>这样看不够直观，我们将每个元素都换个行再输出，得到如下。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs diff">1.7628<br>0.0000000013091844320297241211<br><span class="hljs-deletion">-0.0000000027893838882446289062</span><br>0.0000000034829735755920410156<br>0.000000041852550506591796875<br><span class="hljs-deletion">-0.000000004057476043701171875</span><br><span class="hljs-deletion">-0.0000004261577606201171875</span><br>0.0000000014236330986022949219<br><span class="hljs-deletion">-0.2677</span><br><span class="hljs-deletion">-0.000000044695949554443359375</span><br><span class="hljs-deletion">-0.000000012639684677124023437</span><br>0.00000000012021332979202270508<br><span class="hljs-deletion">-0.000000060646677017211914062</span><br><span class="hljs-deletion">-0.0000000027346568107604980469</span><br><span class="hljs-deletion">-0.000000011391909122467041016</span><br><span class="hljs-deletion">-0.000000012336615324020385742</span><br>0.00000018131090164184570312<br></code></pre></td></tr></table></figure><p>观察到的结果是有些惊喜的，<code>vec_cross_add</code>并没有按照预期的形式返回结果。这些很小的数都是未初始化的无意义数据，真正有意义的数据被放在的位置0和8上。</p><p>而为什么是这两个位置，一种可能的解释是，该接口在运算的过程中，是按照block来计算的，一个repeat是8个block，所以理论上会有8个求和结果，然后这个接口将8个block的和再累加起来，放到结果向量的第一个位置。按照正常来讲，最终返回结果之前，应该将所有repeat的求和结果做一个紧凑排布，就会得到像定长向量那样正常的结果向量。可能在实现变长向量重载的时候没有做这个紧凑？我乱猜的（狗头保命）。</p><h2 id="解决方案">解决方案</h2><p>所以只要注意这一点，在使用变长向量的时候，将正确位置的元素累加即可得到正确的结果。</p><p>正确的代码实现如下，这里只展示核心部分。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">SumViewFixed</span>&gt;(GROUP_NUM, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, <span class="hljs-number">30000</span>&gt; input_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, <span class="hljs-number">30000</span>&gt; res_vec;<br><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(input_buf + group_id * ELEM_PER_GROUP).<span class="hljs-built_in">get</span>(),<br>        ELEM_PER_GROUP);<br><br>    bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), ELEM_PER_GROUP);<br>    <span class="hljs-comment">// 使用变长向量的时候就要考虑到正确数据的存放位置</span><br>    bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), repeat_num * <span class="hljs-number">8</span>);<br><br>    bisheng::<span class="hljs-built_in">vec_cross_add</span>(res_vec_v, input_vec_v);<br><br>    <span class="hljs-comment">// 结果就直接用标量操作写回GM</span><br>    <span class="hljs-keyword">for</span> (std::<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; repeat_num * <span class="hljs-number">8</span>; i += <span class="hljs-number">8</span>)<br>      res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += res_vec_v[i];<br>  });<br></code></pre></td></tr></table></figure><h2 id="测试结果-1">测试结果</h2><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache">  <span class="hljs-attribute">host</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505186081</span><br><span class="hljs-attribute">ascend</span> sum: <span class="hljs-number">1</span>.<span class="hljs-number">49505162239</span><br><span class="hljs-attribute">Result</span> correct.<br></code></pre></td></tr></table></figure><p>这是一个比较隐蔽的问题，在使用该接口的时候还是要多加注意。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;先说结论，问题出在我粗心了，磕头道歉！！本接口没有计算逻辑性问题，为上篇中不严谨的言论道歉。但在特定情况下，会有不符合预期的返回值。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="机器学习" scheme="https://deleter-d.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="异构编程" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"/>
    
    <category term="深度学习" scheme="https://deleter-d.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>基于毕昇编译器的softmax异构算子</title>
    <link href="https://deleter-d.github.io/posts/15984/"/>
    <id>https://deleter-d.github.io/posts/15984/</id>
    <published>2023-07-31T08:10:00.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>使用毕昇编译器异构开发Softmax算子，坑太多太多了。。。。</p><span id="more"></span><h1 id="分析算子">分析算子</h1><p>Softmax是非常常见的激活函数，此处不过多赘述。观察其公式： <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.27ex;" xmlns="http://www.w3.org/2000/svg" width="21.425ex" height="5.327ex" role="img" focusable="false" viewBox="0 -1351.5 9469.8 2354.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(556,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1056,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1362,0)"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1751,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(3084,0)"></path></g><g data-mml-node="mo" transform="translate(3612,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4001,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(4573,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5239.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6295.6,0)"><g data-mml-node="msup" transform="translate(994.8,676)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msup" transform="translate(1549.6,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></g><rect width="2934.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span> 首先应该注意到的是分母中的求和，因为向量内元素求和本身就是一个不太适合于向量化的操作，初步分析可知，此处的求和可能是性能的瓶颈。而分子除以分母的运算可以在得到分母（即向量元素之和）的情况下，自然而然的向量化运算。</p><h1 id="初步方案方案一">初步方案（方案一）</h1><ul><li>向量化方案：因为向量除法是可以自然而然向量化的操作，故暂时先将分母的求和操作放在Host端进行。</li><li>分核方案：本算子是在昇腾910B上进行开发的，由于数据对其以及访存粒度的限制，暂时令一个核处理640个元素。</li></ul><p><img src="https://github.com/Deleter-D/Images/assets/56388518/8acb8eb7-a02d-4699-9601-49df2dbe3ab2" style="zoom: 50%;"></p><h2 id="初步方案实现">初步方案实现</h2><p>先用标准C++实现一个Softmax算子，作为功能验证和性能对比的基准。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">using</span> <span class="hljs-type">data_t</span> = <span class="hljs-type">float</span>;<br><br><span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; input)</span> </span>{<br>  <span class="hljs-type">data_t</span> sum = <span class="hljs-number">0.0</span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> x : input) {<br>    sum += <span class="hljs-built_in">expf</span>(x);<br>  }<br>  std::vector&lt;<span class="hljs-type">data_t</span>&gt; res;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> x : input) {<br>    res.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">expf</span>(x) / sum);<br>  }<br>  <span class="hljs-keyword">return</span> res;<br>}<br></code></pre></td></tr></table></figure><p>接下来开始实现异构算子的逻辑。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">ascend_softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; input)</span> </span>{<br>  <span class="hljs-comment">// 首先拿到输入向量的大小</span><br>  std::<span class="hljs-type">size_t</span> input_sz = input.<span class="hljs-built_in">size</span>();<br>  <span class="hljs-comment">// 计算出总的数据量，单位是字节</span><br>  std::<span class="hljs-type">size_t</span> byte_count = input_sz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br><br>  <span class="hljs-comment">// 如果输入向量的大小不足一个block，则直接调用Host算子逻辑</span><br>  <span class="hljs-keyword">if</span> (byte_count &lt; <span class="hljs-number">32</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">softmax</span>(input);<br><br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-comment">// 申请GM上的内存，分别存储输入和结果</span><br>  <span class="hljs-keyword">auto</span> input_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(input_sz, Q);<br>  <span class="hljs-keyword">auto</span> res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(input_sz, Q);<br><br>  <span class="hljs-comment">// host -&gt; GM 的内存搬移</span><br>  Q.<span class="hljs-built_in">memcpy</span>(input_buf, input.<span class="hljs-built_in">data</span>(), byte_count);<br><br>  <span class="hljs-comment">// 指定每个核处理的元素个数</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> elem_per_group = <span class="hljs-number">640</span>;<br>  <span class="hljs-comment">// 计算尾块中的元素个数</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> tail_elem_count = input_sz % elem_per_group;<br>  <span class="hljs-comment">// 逻辑核的数量，若尾块中存在元素，则多开一个逻辑核</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_num = (tail_elem_count &gt; <span class="hljs-number">0</span>)<br>                                    ? ((input_sz / elem_per_group) + <span class="hljs-number">1</span>)<br>                                    : (input_sz / elem_per_group);<br><br>  <span class="hljs-comment">// 求和计算暂时由Host完成</span><br>  <span class="hljs-type">data_t</span> sum = <span class="hljs-number">0.0</span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> x : input) {<br>    sum += <span class="hljs-built_in">expf</span>(x);<br>  }<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Softmax</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// UB内存申请，分别为输入向量、指数计算结果向量、分母向量、结果向量</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; input_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; exp_res_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; <span class="hljs-built_in">divisor_vec</span>(sum);<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, elem_per_group&gt; res_vec;<br>    <span class="hljs-comment">// 获取group id</span><br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    <span class="hljs-comment">// GM -&gt; UB 的内存搬移</span><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(input_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(), elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-comment">// 本分支处理存在尾块，且当前是最后一个处理尾块的group</span><br>      <span class="hljs-comment">// 由于尾块大概率是非整block，故采用毕昇变长向量对数据进行操作</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(exp_res_vec_v, input_vec_v);<br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// 本分支处理整block的情况</span><br>      <span class="hljs-comment">// 由于指定了每个核处理的元素个数，故此处一定是整block的</span><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(exp_res_vec, input_vec);<br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec, exp_res_vec, divisor_vec);<br>    }<br><br>    <span class="hljs-comment">// UB -&gt; GM 内存搬移</span><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(res_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(input_sz, <span class="hljs-number">0.0f</span>)</span></span>;<br>  <span class="hljs-comment">// GM -&gt; host 内存搬移</span><br>  Q.<span class="hljs-built_in">memcpy</span>(res.<span class="hljs-built_in">data</span>(), res_buf, byte_count);<br>  Q.<span class="hljs-built_in">wait</span>();<br>  <span class="hljs-comment">// 释放资源</span><br>  sycl::<span class="hljs-built_in">free</span>(input_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(res_buf, Q);<br><br>  <span class="hljs-keyword">return</span> res;<br>}<br></code></pre></td></tr></table></figure><h2 id="功能验证">功能验证</h2><p>由于之前实现了Host端的逻辑，所以可以用Host端的计算结果来验证异构算子的正确性，测试代码如下。输入向量的数据是从(-1, 1)均的匀分布中取的随机数。</p><p>由于设备端会有一定的精度损失，故在测试过程中留有一定的宽容度，相对精度损失在2%以内均认为计算正确。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>{<br>  std::vector&lt;<span class="hljs-type">data_t</span>&gt; vec;<br><br>  std::random_device rd;<br>  <span class="hljs-function">std::mt19937 <span class="hljs-title">gen</span><span class="hljs-params">(rd())</span></span>;<br>  <span class="hljs-function">std::uniform_real_distribution&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">urdis</span><span class="hljs-params">(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span></span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; INPUT_COUNT; i++) {<br>    vec.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">urdis</span>(gen));<br>  }<br><br>  std::vector&lt;<span class="hljs-type">data_t</span>&gt; host_res = <span class="hljs-built_in">softmax</span>(vec);<br>  std::vector&lt;<span class="hljs-type">data_t</span>&gt; ascend_res = <span class="hljs-built_in">ascend_softmax</span>(vec);<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; host_res.<span class="hljs-built_in">size</span>(); ++i) {<br>    <span class="hljs-keyword">if</span> (std::<span class="hljs-built_in">fabs</span>(host_res[i] - ascend_res[i]) / host_res[i] &gt; <span class="hljs-number">0.02</span>) {<br>      std::cout &lt;&lt; <span class="hljs-string">"Calculation error."</span> &lt;&lt; std::endl;<br>      <span class="hljs-keyword">return</span> EXIT_FAILURE;<br>    }<br>  }<br>  std::cout &lt;&lt; <span class="hljs-string">"Result correct."</span> &lt;&lt; std::endl;<br><br>  <span class="hljs-keyword">return</span> EXIT_SUCCESS;<br>}<br></code></pre></td></tr></table></figure><h2 id="性能测试">性能测试</h2><p>性能测试使用不同长度的输入向量进行，长度分别为640、6400、64000、640000，数据类型为float。Host端的时间统计使用<code>&lt;time.h&gt;</code>中的结构体，设备端的时间统计利用毕昇C++提供的<code>profiling</code>系列接口统计。仅统计算子计算逻辑部分的时间，并执行5次取平均值后计算加速比。之后的性能测试均为该策略，后面不再赘述。</p><p>性能测试结果如下。</p><table><thead><tr class="header"><th>测试用例</th><th>640</th><th>6400</th><th>64000</th><th>640000</th></tr></thead><tbody><tr class="odd"><td>加速比</td><td>0.18163</td><td>1.103832</td><td>2.968345</td><td>3.784732</td></tr></tbody></table><p>可以看到在向量长度达到6400之后才勉强与Host端计算逻辑持平，虽然在长向量的情况下有速度上的提升，但远不是令人满意的效果。</p><h1 id="求和方式优化方案二">求和方式优化（方案二）</h1><p>在初步方案中，求和的过程是由Host端完成的，故接下来将求和也尽量的向量化。对于求和无法做到元素级别的并行，故只能将长向量拆分为多个短向量，这些短向量之间的求和操作是并行的，但单个短向量内部的求和，只能是串行的。</p><p>由于求和的每一项也需要经过指数运算，故可以把指数运算与求和放在同一个核函数内进行，计算完成后将指数运算结果向量存储下来，则后面做向量除法时就不必再运算一遍了。</p><p>总体的异构方案如图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/50df7b9b-35fb-4b9c-8229-df21215ec566" style="zoom: 67%;"></p><h2 id="方案实现">方案实现</h2><p>实现代码如下，只需关注有注释的部分，没有注释的部分与上一方案中的代码相同。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">ascend_softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">float</span>&gt; input)</span> </span>{<br>  std::<span class="hljs-type">size_t</span> input_sz = input.<span class="hljs-built_in">size</span>();<br>  std::<span class="hljs-type">size_t</span> byte_count = input_sz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><br>  <span class="hljs-keyword">if</span> (byte_count &lt; <span class="hljs-number">32</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">softmax</span>(input);<br><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> elem_per_group = <span class="hljs-number">640</span>;<br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> tail_elem_count = input_sz % elem_per_group;<br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_num = (tail_elem_count &gt; <span class="hljs-number">0</span>)<br>                                    ? ((input_sz / elem_per_group) + <span class="hljs-number">1</span>)<br>                                    : (input_sz / elem_per_group);<br>  <span class="hljs-comment">// 此处计算出每个group所处理的repeat个数，方便vec_cross_add()接口调用</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> repeat_per_group = (elem_per_group * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)) / <span class="hljs-number">256</span>;<br><br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-keyword">auto</span> input_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(group_num * elem_per_group, Q);<br>  <span class="hljs-comment">// 这里在GM上多申请两块内存，用于存放指数运算结果和求和结果</span><br>  <span class="hljs-keyword">auto</span> exp_res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(group_num * elem_per_group, Q);<br>  <span class="hljs-keyword">auto</span> sum_res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(group_num * repeat_per_group, Q);<br>  <span class="hljs-keyword">auto</span> res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(group_num * elem_per_group, Q);<br><br>  <span class="hljs-comment">// 由于vec_cross_add是按repeat为单位进行求和的，故申请的向量即为group数量乘以每个group的repeat数量</span><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">sum_res</span><span class="hljs-params">((group_num * repeat_per_group), <span class="hljs-number">0.0f</span>)</span></span>;<br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(input_sz, <span class="hljs-number">0.0f</span>)</span></span>;<br><br>  Q.<span class="hljs-built_in">memcpy</span>(input_buf, input.<span class="hljs-built_in">data</span>(), byte_count);<br><br>  <span class="hljs-comment">// 第一个核函数进行求和与指数运算的操作</span><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Summary</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; input_vec;<br>    bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; exp_res_vec;<br>    bisheng::vector&lt;<span class="hljs-type">float</span>, repeat_per_group&gt; sum_res_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(input_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-comment">// 同样的处理尾块中存在运算，且为最后一个group的情况</span><br>      bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(exp_res_vec_v, input_vec_v);<br>      <span class="hljs-comment">// 由于尾块中的元素大概率不是整repeat，所以采用标量运算的的方式</span><br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tail_elem_count; ++i)<br>        sum_res_vec[<span class="hljs-number">0</span>] += exp_res_vec_v[i];<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; repeat_per_group; ++i)<br>        sum_res_vec[i] = <span class="hljs-number">0.0f</span>;<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// 整block情况</span><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(exp_res_vec, input_vec);<br>      <span class="hljs-comment">// 这里不仅确定是整block，也能确定是整repeat，故直接调用接口</span><br>      bisheng::<span class="hljs-built_in">vec_cross_add</span>(sum_res_vec.<span class="hljs-built_in">data</span>(), exp_res_vec);<br>    }<br><br>    <span class="hljs-comment">// UB -&gt; GM 内存搬移，将指数运算结果与求和结果均保存下来</span><br>    exp_res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(exp_res_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>    sum_res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(sum_res_buf + group_id * repeat_per_group).<span class="hljs-built_in">get</span>(),<br>        repeat_per_group);<br>  });<br><br>  Q.<span class="hljs-built_in">memcpy</span>(sum_res.<span class="hljs-built_in">data</span>(), sum_res_buf, group_num * repeat_per_group * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-comment">// 由于vec_cross_add求和后的结果是多个短向量的和</span><br>  <span class="hljs-comment">// 依然是一个向量，故须在Host端进一步计算为标量</span><br>  <span class="hljs-type">float</span> sum;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> x : sum_res)<br>    sum += x;<br>  <br>  <span class="hljs-comment">// 第二个核函数进行向量除法的运算</span><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Softmax</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// 只需将上个核函数计算到的指数运算结果向量搬移进来即可</span><br>    bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; exp_res_vec;<br>    bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; <span class="hljs-built_in">divisor_vec</span>(sum);<br>    bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; res_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    exp_res_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(exp_res_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-comment">// 此处分支大同小异，不再赘述</span><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    } <span class="hljs-keyword">else</span> {<br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec, exp_res_vec, divisor_vec);<br>    }<br><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(res_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  Q.<span class="hljs-built_in">memcpy</span>(res.<span class="hljs-built_in">data</span>(), res_buf, byte_count);<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  sycl::<span class="hljs-built_in">free</span>(input_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(exp_res_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(sum_res_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(res_buf, Q);<br><br>  <span class="hljs-keyword">return</span> res;<br>}<br></code></pre></td></tr></table></figure><h2 id="功能验证-1">功能验证</h2><p>功能验证与上述方式相同，但在验证过程中出现了较为严重的问题。</p><p>在代码执行过程中，出现了计算结果时对时错的情况，在之前的项目开发过程中其实是踩过这样的坑的，所以出现这种情况时也没有特别慌张。这里分享一下定位问题的心路历程，总结一下设备端代码Debug的思路。</p><p>由于对毕昇C++和毕昇编译器这套逻辑了解不够充分，所以可能Debug的方式很笨，但只要能De出来Bug，那就是好方法。</p><ul><li>首先可以确定的是，计算向量除法的部分一定没有问题，这是方案一里面验证过的。</li><li>其次是要确定访存过程中是否存在问题，是不是访问到了一些不该访问的地方。确定访存无误后再进行下一步。</li><li>将每一步的计算结果输出，具体查看到底哪一步计算出现了错误。</li></ul><p>首先分析访存的问题，可以先将输入向量的长度和数据类型确定下来，然后带入这个向量长度计算每一次访存的范围。当然你也可以写个脚本来帮你完成这一步，但我懒，我选择草稿纸。一波计算后发现，访存并没有什么问题，每一步操作访问的范围也都是它们应该访问的，并没有访问的未定义数据。那么基本可以确定，这个Bug不是我自己的原因，那就看看每一步的计算结果。</p><p>因为第二个核函数已经经过了方案一的验证，所以没有过多纠结，分析第一个核函数。第一个核函数进行了两种运算，指数运算和求和运算。但指数运算也在方案一里验证过了，是没有问题的，所以直接就将问题定位在了求和过程中。使用同一个输入向量，分别输出Host算子中的和与<code>vec_cross_add()</code>计算的和。当然这里输出的和均为标量，<code>vec_cross_add()</code>返回的结果已经在Host端相加计算为了标量。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Host sum: 7550.05</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Ascend sum: 7090.52</span><br>[<span class="hljs-symbol">Error</span>]: <span class="hljs-link">Calculation error.</span><br></code></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Host sum: 7549.67</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Ascend sum: 7549.66</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Result correct.</span><br></code></pre></td></tr></table></figure><p>果然！是求和出现了问题，而且是时对时错的。然后有对这个问题进行了更详细的测试，主要是测试了两种情况，也即第一个核函数中的两个分支。</p><p>由于尾块是采用<code>for</code>循环计算的，理论上不会出现错误，但为了严谨还是进行了一些测试。将向量长度锁定在320，迫使它只执行尾块的逻辑，结果如下。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Host sum: 387.095</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Ascend sum: 387.095</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Result correct.</span><br></code></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Host sum: 356.134</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Ascend sum: 356.134</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Result correct.</span><br></code></pre></td></tr></table></figure><p>无论执行多少次，结果都是正确的。<del>那现在基本可以确定是<code>vec_cross_add()</code>接口出现了问题。所以我们对代码进行修改，将<code>vec_cross_add()</code>接口用<code>for</code>循环代替。</del></p><blockquote><p>此处的结论不正确，<code>vec_cross_add()</code>接口本身没有任何问题，详细测试及Softmax的重新实现详见<a href="https://deleter-d.github.io/posts/1040/">关于vec_cross_add接口的详细测试 - 亦初 (deleter-d.github.io)</a></p></blockquote><p>由于使用标量运算，故每个group求和的结果不再是向量，而是标量。所以存放求和结果的内存空间大小需要做一定的调整，这里申请大小为<code>group_num * (32 / sizeof(data_t))</code>的空间。其实理论上，每个group求和的结果只需要一个<code>data_t</code>数据类型的大小即可，但为了按照block为粒度严格分离group的访存空间，所以申请了与<code>group_num</code>个block大小相同的内存空间来存放。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> sum_res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)), Q);<br></code></pre></td></tr></table></figure><p>具体求和过程则改为如下方式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      <span class="hljs-function">bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">input_vec_v</span><span class="hljs-params">(input_vec.data(), tail_elem_count)</span></span>;<br>      <span class="hljs-function">bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">exp_res_vec_v</span><span class="hljs-params">(exp_res_vec.data(), tail_elem_count)</span></span>;<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(exp_res_vec_v, input_vec_v);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tail_elem_count; ++i)<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += exp_res_vec_v[i];<br>    } <span class="hljs-keyword">else</span> {<br>      bisheng::<span class="hljs-built_in">vec_exp</span>(exp_res_vec, input_vec);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; elem_per_group; ++i) {<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += exp_res_vec[i];<br>      }<br>    }<br></code></pre></td></tr></table></figure><p>进一步测试后，时对时错的问题解决了，到这里就可以说功能验证正确了，可喜可贺！</p><h2 id="性能测试-1">性能测试</h2><p>性能测试结果如下。</p><table><thead><tr class="header"><th>测试用例</th><th>640</th><th>6400</th><th>64000</th><th>640000</th></tr></thead><tbody><tr class="odd"><td>加速比</td><td>0.237432</td><td>1.478988</td><td>13.19605</td><td>87.72573</td></tr></tbody></table><p>对比方案一可以观察到，对求和进行向量化的意义是非常大的，尤其是向量长度变得越来越长后，这种优化的提升尤为明显。现在的加速比可以说是令人比较满意的了。</p><h1 id="空间上的优化方案三">空间上的优化（方案三）</h1><p>通过观察方案二中的数据流动，我们可以发现，在空间利用上有些浪费的地方。先来看一下方案二的数据流动方式。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/4aa99b79-7b82-4ee9-9b04-a944b0d3187c" style="zoom: 50%;"></p><blockquote><p>注：图中只描述了GM与UB之间的数据流，其中还发生了GM与Host之间的数据搬移。例如求和结果将会搬回Host，计算为标量后，利用该标量对分母向量进行初始化。</p></blockquote><p>观察上述数据流可以发现，在使用<code>exp_res_buf</code>存储指数运算结果的时候，输入<code>input_buf</code>已经失去了作用，且后面也不会再使用其中的数据。同理，在使用<code>res_buf</code>存储最终结果的时候，<code>exp_res_buf</code>也不再使用了，因为指数运算结果此时已经读入了UB中。所以，<code>input_buf</code>、<code>exp_res_buf</code>和<code>res_buf</code>三者是可以合一的。</p><p>继续对UB中的内存使用进行分析。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/e8638370-1802-4f21-ac61-b8229ee80851" style="zoom:50%;"></p><p>初步的理论分析可知，Kernel 1中的<code>input</code>和<code>exp_res_vec</code>可以合一，Kernel 2中的<code>exp_res_vec</code>与<code>res_vec</code>可以合一。我们在此过程中使用了<code>vec_exp(dst, src)</code>和<code>vec_div(dst, src0, src1)</code>接口，这两个接口分别为一元运算和二元运算。</p><p>在毕昇C++中，对于基于<code>bisheng::vector</code>类型的通用一元运算函数接口，<code>dst</code>和<code>src</code>可以是同一个<code>bisheng::vector</code>对象，即原址计算。故Kernel 1中的<code>input</code>和<code>exp_res_vec</code>可以合一。而对于二元运算，目标数据和源数据在不同的repeat迭代之间不允许出现地址重叠，虽然有部分接口例外，但我们所使用的<code>vec_div</code>接口并不在这些例外中，故无法将Kernel 2中的<code>exp_res_vec</code>与<code>res_vec</code>合一。</p><p>经过上述一系列空间优化，最终的数据流如图所示。</p><p><img src="https://github.com/Deleter-D/Images/assets/56388518/ac3a81be-bd23-4c3c-8c98-7135a0f3e78e" style="zoom:50%;"></p><h2 id="方案实现-1">方案实现</h2><p>代码与方案二几乎一致，只是改变了内存搬移的源地址与目的地址，这里就不再放代码了。</p><h2 id="功能验证-2">功能验证</h2><p>经过测试，功能验证正确。</p><h2 id="性能测试-2">性能测试</h2><p>性能测试结果如下。</p><table><thead><tr class="header"><th>测试用例</th><th>640</th><th>6400</th><th>64000</th><th>640000</th></tr></thead><tbody><tr class="odd"><td>加速比</td><td>0.224613</td><td>1.512394</td><td>13.30433</td><td>88.70575</td></tr></tbody></table><p>可以观察到，与方案二相比，时间上几乎没有区别。但由于优化了空间利用率，所以使得设备端可以承载更大长度的向量，优化的意义是比较大的。</p><h1 id="分核方案的优化方案四">分核方案的优化（方案四）</h1><blockquote><p>下面所有的讨论均已float类型的数据为例。</p></blockquote><p>分核方案的核心思想就是，尽可能利用所有物理核心，并在此基础上令每个核心处理尽可能多的数据。而我们上面采用的方案是临时将每个核处理的元素数量固定为640，这显然不是最优的方案。</p><p>首先是尽可能利用所有的物理核心，昇腾910拥有32个物理核心，所以我们要想办法让32个核心都在工作状态，尽量避免一核干活儿，多核围观的滑稽场景。</p><p>首先分析一个问题，逻辑核的数量如何确定？假设输入向量长度为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="3.086ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 1364 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>，每个逻辑核处理的运算个数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>，在不考虑有尾块的情况下，可以得到逻辑核数量的公式为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="21.624ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 9558 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6371.6,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(6669.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(7135.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7957.8,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mi" transform="translate(8958,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>。<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>由用户指定，不是我们可以控制的，故我们只能在<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="3.086ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 1364 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="11.398ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 5038 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>上做文章。为了更好的理解，我们变形一下公式<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="21.624ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 9558 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1641.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2697.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(3174.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3625.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(4110.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4682.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(5185.6,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(5685.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6285.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6857.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7957.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(8958,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>。这样就可以比较直观的看出，我们需要在<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="11.398ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 5038 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>之间做一个权衡。</p><p>这个权衡只有两种思考方式：</p><ul><li>一种是确定<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="11.398ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 5038 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>，根据<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="11.398ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 5038 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>计算得到<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>。说人话就是把逻辑核的数量定死，然后根据用户给的向量长度计算每个核要处理的元素个数。</li><li>另一种是确定<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>，即把每个逻辑核要处理的元素数量定死，然后根据用户给的向量长度计算逻辑核数量。</li></ul><h2 id="情况一">情况一</h2><p>先来考虑第一种情况，即将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="11.398ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 5038 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>定死。假设我们就定为与物理核数相同的数量，即32。考虑一个问题，假设输入向量长度非常长，那么拆分成32份后依然非常长，长到<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="8.114ex" height="1.652ex" role="img" focusable="false" viewBox="0 -694 3586.4 730"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1586.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(2586.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>个元素的大小超出了UB的承载范围，那么此时算子就会崩溃。</p><p>这时候有人就要说了（假装有人要说）：那不能把逻辑核数量写大一点吗？</p><p>好！听你的，我们将逻辑核数量定为320，理想状态下，每个物理核将处理10个逻辑核。此时再考虑一种情况，用户给的输入向量非常短，短到没办法分为320份，此时<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="8.114ex" height="1.652ex" role="img" focusable="false" viewBox="0 -694 3586.4 730"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1586.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(2586.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>为0。意味着你的每个逻辑核中，要么是处理尾块，要么根本就没有元素，但320个逻辑核依然会开启。这显然是不够合理的。</p><h2 id="情况二">情况二</h2><p>再来考虑将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>定死的情况，即将每个逻辑核要处理的元素个数定死，其实就是我们上面方案的使用的策略，这里我们暂时考虑<code>n</code>为640的情况。同样考虑一些比较极端的例子，假设输入向量非常长，此时<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="7.209ex" height="1.652ex" role="img" focusable="false" viewBox="0 -694 3186.4 730"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1586.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mi" transform="translate(2586.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>即<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.081ex;" xmlns="http://www.w3.org/2000/svg" width="9.245ex" height="1.652ex" role="img" focusable="false" viewBox="0 -694 4086.4 730"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1586.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mn" transform="translate(2586.4,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>会非常大，即逻辑核的数量会非常多。虽然这样能够充分利用所以物理核，但每个逻辑核的承载能力远不止640个元素，这样就浪费了单个逻辑核的能力，把资源都消耗在调度逻辑核上了。</p><p>这时候又有人要说了（依然假装有人说）：那不能把逻辑核处理的元素个数写大一点吗？</p><p>好！还是听你的，我们将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>定为UB能够承载的上限<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="4.477ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 1979 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>。这种情况下，我们甚至不用考虑输入向量长度非常短的情况，只考虑向量长度小于<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.506ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 4201.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2201.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(3201.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>的情况，即向量长度小于31个物理核同时工作时可以处理的最大元素个数。此时至少会有1个物理核心在看戏，若向量长度进一步缩短，那看戏的物理核只会越来越多。这显然也是不够合理的。</p><h2 id="动态方案">动态方案</h2><p>分析完两种情况，可以得出一个结论，单纯的确定<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>与<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="11.398ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 5038 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>中的任何一个都是不合适的。</p><p>那我们应该怎么确定呢？动态确定！</p><p>首先确定一个问题，我们这个算子，每个group处理多少数据是UB的上限。经过测试，每个group最多可以处理87360字节的数据，即<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="21.87ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9666.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(500,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(1000,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mo" transform="translate(2722.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mtext" transform="translate(3722.4,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z" transform="translate(672,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1116,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1560,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(2060,0)"></path></g><g data-mml-node="mo" transform="translate(6088.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6477.4,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(6997.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(7526.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(7887.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(8416.4,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(8916.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(9277.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>个元素。这个上限并不是所有算子都一样的，因为每个算子在UB上申请内存的情况不同，所以要具体问题具体分析。</p><p>我们继续上面那个公式<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="21.624ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 9558 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1641.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2697.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(3174.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3625.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(4110.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4682.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(5185.6,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(5685.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6285.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6857.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7957.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(8958,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>，这里为了通用性，我们换成处理的字节数<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>，而不是元素个数。进而<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="25.6ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 11315 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(877.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1933.6,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2362.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2852.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3213.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(3679.6,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(4370.8,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mtext" transform="translate(5371,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z" transform="translate(672,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1116,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1560,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(2060,0)"></path></g><g data-mml-node="mo" transform="translate(7737,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8126,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(8646,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(9175,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(9536,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(10065,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(10565,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(10926,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>，那么公式变为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="73.227ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 32366.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6082.6,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(6380.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6846.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7668.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(8669,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z" transform="translate(672,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1116,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1560,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(2060,0)"></path></g><g data-mml-node="mo" transform="translate(11035,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(11424,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(11944,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(12473,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(12834,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(13363,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(13863,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(14224,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(14890.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(15946.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(16423.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(16874.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(17359.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17931.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(18434.6,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(18934.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(19534.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(20106.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(21206.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mo" transform="translate(22207,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(22596,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(23025,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(23515,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(23876,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(24342,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(25033.2,0)"><path data-c="F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path></g><g data-mml-node="mtext" transform="translate(26033.4,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z" transform="translate(672,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1116,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1560,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(2060,0)"></path></g><g data-mml-node="mo" transform="translate(28399.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(28788.4,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(29308.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(29837.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(30198.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(30727.4,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(31227.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(31588.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(31977.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>。</p><ul><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="23.314ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10305 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为1280，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，此时算子可能无法充分利用所有物理核。</li><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="23.314ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10305 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为2560，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，这意味着算子将充分利用所有物理核。</li><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="23.314ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10305 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为5120，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，也会充分利用所有物理核。</li><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="24.446ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10805 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为12800，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，也会充分利用所有物理核。</li><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="24.446ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10805 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为25600，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，同样充分利用所有物理核。</li><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="24.446ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10805 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为51200，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，同样充分利用所有物理核。</li><li>当<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="24.446ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 10805 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(846,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1207,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1736,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2034,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2534,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2963,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3453,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3814,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4280,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(5026.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6082.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7304.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8305,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(500,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(1000,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g></g></g></svg></mjx-container></span>时，将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.011ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 2215 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(919,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1280,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1746,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container></span>定为87360，则<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="16.678ex" height="1.971ex" role="img" focusable="false" viewBox="0 -666 7371.6 871"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1413,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1985,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2488,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2988,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3588,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4160,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5315.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(6371.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，同样充分利用所有物理核。</li></ul><p>采取这种策略，虽然在输入向量总字节数小/于<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 4222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>时可能会出现某些物理核不工作的情况，但考虑到实际情况下，输入向量都是比较长的向量，这种偶尔的空闲是可接受的。</p><p>这里只是展示一种思路，条件分支中的阈值是可以根据实际情况进行调整的，并不是只能按照2560、5120等阈值进行分割。</p><h2 id="方案实现-2">方案实现</h2><p>同样还是注意带注释的地方，其余地方与之前相同。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">ascend_softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">data_t</span>&gt; input)</span> </span>{<br>  std::<span class="hljs-type">size_t</span> input_sz = input.<span class="hljs-built_in">size</span>();<br>  std::<span class="hljs-type">size_t</span> byte_count = input_sz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br><br>  <span class="hljs-keyword">if</span> (byte_count &lt; <span class="hljs-number">32</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">softmax</span>(input);<br><br>  <span class="hljs-comment">// 这里依照上面介绍的策略确定每个逻辑核所处理的元素个数</span><br>  std::<span class="hljs-type">size_t</span> elem_per_group = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * UB_MAX_BYTES)<br>    elem_per_group = UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">51200</span>)<br>    elem_per_group = <span class="hljs-number">51200</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">25600</span>)<br>    elem_per_group = <span class="hljs-number">25600</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">12800</span>)<br>    elem_per_group = <span class="hljs-number">12800</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">5120</span>)<br>    elem_per_group = <span class="hljs-number">5120</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (byte_count &gt;= PHYSICAL_CORES * <span class="hljs-number">2560</span>)<br>    elem_per_group = <span class="hljs-number">2560</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br>  <span class="hljs-keyword">else</span><br>    elem_per_group = <span class="hljs-number">1280</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>);<br><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> tail_elem_count = input_sz % elem_per_group;<br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_num = (tail_elem_count &gt; <span class="hljs-number">0</span>)<br>                                    ? ((input_sz / elem_per_group) + <span class="hljs-number">1</span>)<br>                                    : (input_sz / elem_per_group);<br><br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-keyword">auto</span> dev_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * elem_per_group, Q);<br>  <span class="hljs-keyword">auto</span> sum_res_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">data_t</span>&gt;(group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)), Q);<br><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">sum_res</span><span class="hljs-params">(group_num * (<span class="hljs-number">32</span> / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">data_t</span>)), <span class="hljs-number">0.0f</span>)</span></span>;<br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(input_sz, <span class="hljs-number">0.0f</span>)</span></span>;<br><br>  Q.<span class="hljs-built_in">memcpy</span>(dev_buf, input.<span class="hljs-built_in">data</span>(), byte_count);<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Summary</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// 此处直接申请最大空间，因为定义毕昇向量时指定大小必须用常量表达式，大小需要在编译时确定</span><br>    <span class="hljs-comment">// 由于前面采用了动态策略，所以不能直接使用elem_per_group来定义毕昇向量</span><br>    <span class="hljs-comment">// 只需要在使用时控制访存范围即可，第二个核函数同理，不再赘述</span><br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; input_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    input_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec_v, input_vec_v);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tail_elem_count; ++i)<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += input_vec_v[i];<br>    } <span class="hljs-keyword">else</span> {<br>      <span class="hljs-comment">// 由于毕昇向量定义了最大长度，故即使是整block的情况，也需要用变长向量来控制访存范围</span><br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec_v, input_vec_v);<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; elem_per_group; ++i) {<br>        sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))] += input_vec_v[i];<br>      }<br>    }<br><br>    input_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  Q.<span class="hljs-built_in">memcpy</span>(sum_res.<span class="hljs-built_in">data</span>(), sum_res_buf, group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-type">data_t</span> sum;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sum_res.<span class="hljs-built_in">size</span>(); i += <span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>))<br>    sum += sum_res[i];<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Softmax</span>&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; exp_res_vec;<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; <span class="hljs-built_in">divisor_vec</span>(sum);<br>    bisheng::vector&lt;<span class="hljs-type">data_t</span>, UB_MAX_BYTES / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">data_t</span>)&gt; res_vec;<br>    std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>    exp_res_vec.<span class="hljs-built_in">load</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br><br>    <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), tail_elem_count);<br><br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    } <span class="hljs-keyword">else</span> {<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::vector_view&lt;<span class="hljs-type">data_t</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(), elem_per_group);<br>      bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>    }<br><br>    res_vec.<span class="hljs-built_in">store</span>(<br>        sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">data_t</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>        elem_per_group);<br>  });<br><br>  Q.<span class="hljs-built_in">memcpy</span>(res.<span class="hljs-built_in">data</span>(), dev_buf, byte_count);<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  sycl::<span class="hljs-built_in">free</span>(dev_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(sum_res_buf, Q);<br><br>  <span class="hljs-keyword">return</span> res;<br>}<br></code></pre></td></tr></table></figure><h2 id="功能测试">功能测试</h2><p>功能测试验证正确。</p><h2 id="性能测试-3">性能测试</h2><p>性能测试结果如下。</p><table><thead><tr class="header"><th>测试用例</th><th>640</th><th>6400</th><th>64000</th><th>640000</th></tr></thead><tbody><tr class="odd"><td>加速比</td><td>0.234373</td><td>1.436941</td><td>12.35908</td><td>80.59147</td></tr></tbody></table><p>分析了许多，本想着动态分核结果会有惊喜。嘿！您猜怎么着？还真是大惊喜！</p><p>在动态分核的策略下，当向量长度总字节数不少于<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 4222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>时，总能保证32个物理核都在工作，而且不至于令逻辑核数量过多，但神奇的事情来了，这种策略成功实现了负优化！！</p><p>本方案的性能测试结果看起来还不错，但我们继续增大向量长度，使得总字节数到达划分策略的阈值附近。以<code>float</code>类型的数据为例，令向量长度为698880，此时总字节数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="35.321ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 15612 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(2000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2500,0)"></path></g><g data-mml-node="mo" transform="translate(3222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(4222.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(5000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6056,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(1000,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(1500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(2000,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(2500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(3000,0)"></path></g><g data-mml-node="mo" transform="translate(9833.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(10889.6,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(500,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(1000,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mo" transform="translate(13611.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(14612,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>。此时这种策略将分配32个逻辑核，完美贴合物理核数量，每个核心处理87360字节的数据，完美贴合UB承载的上限。惊喜的事情来了，请看加速比</p><table><thead><tr class="header"><th>测试用例</th><th>698880</th></tr></thead><tbody><tr class="odd"><td>方案三加速比</td><td>96.29706</td></tr><tr class="even"><td>方案四加速比</td><td>67.26953</td></tr></tbody></table><p>什么鬼情况？！？！</p><p>我们分别观察一下它们的分核情况。</p><p>方案三如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Host time cost: 93873327 ns</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Group num: 1875 Elements per group: 640</span><br>[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Ascend time cost: 728001 ns</span><br></code></pre></td></tr></table></figure><p>方案四如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Host time cost: 94127478 ns</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Group num: 55 Elements per group: 21840</span><br>[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Ascend time cost: 785999 ns</span><br></code></pre></td></tr></table></figure><p>可以发现两者都充分利用了所有物理核，但方案四的策略使得加速比下降了，反观方案三的1875个逻辑核取得了完胜。但转念一想，是不是让每个逻辑核承载到UB的上限有点过分，那么再来测试一下正常压力下的表现。</p><p>还是以<code>float</code>类型数据为例，向量长度为102400，此时总字节数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="34.19ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 15112 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2500,0)"></path></g><g data-mml-node="mo" transform="translate(3222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(4222.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(5000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6056,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(1000,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2500,0)"></path></g><g data-mml-node="mo" transform="translate(9333.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(10389.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2000,0)"></path></g><g data-mml-node="mo" transform="translate(13111.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(14112,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>，此时将分配32个逻辑核，每个核处理12800字节的数据，远不到UB承载的上限。</p><p>方案三分核情况如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Host time cost: 7872144 ns</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Group num: 160 Elements per group: 640</span><br>[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Ascend time cost: 375999 ns</span><br></code></pre></td></tr></table></figure><p>方案四分核情况如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Host time cost: 7813204 ns</span><br>[<span class="hljs-symbol">Debug</span>]: <span class="hljs-link">Group num: 32 Elements per group: 3200</span><br>[<span class="hljs-symbol">PERMORMANCE</span>]: <span class="hljs-link">Ascend time cost: 400999 ns</span><br></code></pre></td></tr></table></figure><p>加速比如下：</p><table><thead><tr class="header"><th>测试用例</th><th>102400</th></tr></thead><tbody><tr class="odd"><td>方案三加速比</td><td>20.73252</td></tr><tr class="even"><td>方案四加速比</td><td>19.4274</td></tr></tbody></table><p>依然是有略微的下降，这也排除了UB压力过大的问题。</p><h1 id="结论">结论</h1><p>经过一系列分析，目前能够得出的结论是，尽可能多的逻辑核数量的收益要大于单逻辑核内处理尽可能多的数据。</p><p>异构分核的坑还是太多了，踩都踩不完，过程中有很多反直觉的情况，必须靠实验来佐证。</p><h1 id="完整代码">完整代码</h1><p>最后贴上目前效果最好（方案三）的完整代码，其中包括一些自定义的Debug信息，不用太纠结。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cmath&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iomanip&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;random&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;time.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bisheng/bisheng.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sycl/sycl.hpp&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> DEBUG</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> DEBUG_HEAD <span class="hljs-string">"\033[34m[Debug]: \033[0m"</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ERROR_HEAD <span class="hljs-string">"\033[31m[Error]: \033[0m"</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PERFORMANCE</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PERFORMANCE_HEAD <span class="hljs-string">"\033[36m[PERMORMANCE]: \033[0m"</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> INPUT_COUNT 102400</span><br><br><span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">float</span>&gt; input)</span> </span>{<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"The host operator is called.\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> PERFORMANCE</span><br>  <span class="hljs-keyword">struct</span> <span class="hljs-title class_">timespec</span> time;<br>  <span class="hljs-built_in">clock_gettime</span>(CLOCK_REALTIME, &amp;time);<br>  <span class="hljs-keyword">auto</span> start_time = time.tv_sec * <span class="hljs-number">1000000000</span> + time.tv_nsec;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0</span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> x : input) {<br>    sum += <span class="hljs-built_in">expf</span>(x);<br>  }<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Host sum: "</span> &lt;&lt; sum &lt;&lt; <span class="hljs-string">"\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  std::vector&lt;<span class="hljs-type">float</span>&gt; res;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> x : input) {<br>    res.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">expf</span>(x) / sum);<br>  }<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> PERFORMANCE</span><br>  <span class="hljs-built_in">clock_gettime</span>(CLOCK_REALTIME, &amp;time);<br>  <span class="hljs-keyword">auto</span> end_time = time.tv_sec * <span class="hljs-number">1000000000</span> + time.tv_nsec;<br>  std::cout &lt;&lt; PERFORMANCE_HEAD &lt;&lt; <span class="hljs-string">"Host time cost: "</span> &lt;&lt; end_time - start_time<br>            &lt;&lt; <span class="hljs-string">" ns"</span> &lt;&lt; std::endl;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-keyword">return</span> res;<br>}<br><br><span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">ascend_softmax</span><span class="hljs-params">(std::vector&lt;<span class="hljs-type">float</span>&gt; input)</span> </span>{<br>  std::<span class="hljs-type">size_t</span> input_sz = input.<span class="hljs-built_in">size</span>();<br>  std::<span class="hljs-type">size_t</span> byte_count = input_sz * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><br>  <span class="hljs-comment">// call the host operator if input isn't enough a full block</span><br>  <span class="hljs-keyword">if</span> (byte_count &lt; <span class="hljs-number">32</span>) {<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>    std::cout &lt;&lt; DEBUG_HEAD<br>              &lt;&lt; <span class="hljs-string">"The input vector is not enough for a full block.\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">softmax</span>(input);<br>  }<br><br>  <span class="hljs-comment">// ascend code start</span><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"The ascend operator is called.\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-comment">// number of elements per group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> elem_per_group = <span class="hljs-number">640</span>;<br>  <span class="hljs-comment">// number of elements in tail block</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> tail_elem_count = input_sz % elem_per_group;<br>  <span class="hljs-comment">// number of groups</span><br>  <span class="hljs-comment">// if tail block is exist, apply for one more group</span><br>  <span class="hljs-type">const</span> std::<span class="hljs-type">size_t</span> group_num = (tail_elem_count &gt; <span class="hljs-number">0</span>)<br>                                    ? ((input_sz / elem_per_group) + <span class="hljs-number">1</span>)<br>                                    : (input_sz / elem_per_group);<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Group num: "</span> &lt;&lt; group_num<br>            &lt;&lt; <span class="hljs-string">" Elements per group: "</span> &lt;&lt; elem_per_group &lt;&lt; <span class="hljs-string">"\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{}, <span class="hljs-literal">nullptr</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                {sycl::property::queue::enable_profiling()})</span></span>;<br><br>  <span class="hljs-comment">// GM memory allocation</span><br>  <span class="hljs-keyword">auto</span> dev_buf = sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(group_num * elem_per_group, Q);<br>  <span class="hljs-keyword">auto</span> sum_res_buf =<br>      sycl::<span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)), Q);<br><br>  <span class="hljs-comment">// Host memory allocation</span><br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">sum_res</span><span class="hljs-params">(group_num * (<span class="hljs-number">32</span> / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>)), <span class="hljs-number">0.0f</span>)</span></span>;<br>  <span class="hljs-function">std::vector&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(input_sz, <span class="hljs-number">0.0f</span>)</span></span>;<br><br>  <span class="hljs-comment">// host -&gt; GM</span><br>  Q.<span class="hljs-built_in">memcpy</span>(dev_buf, input.<span class="hljs-built_in">data</span>(), byte_count);<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Kernel function started.\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  sycl::event e0 =<br>      Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> Summary&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>        bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; input_vec;<br>        std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>        <span class="hljs-comment">// GM -&gt; UB</span><br>        input_vec.<span class="hljs-built_in">load</span>(<br>            sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>            elem_per_group);<br><br>        <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>          <span class="hljs-comment">// if tail block has element and this is the last group</span><br>          bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">input_vec_v</span>(input_vec.<span class="hljs-built_in">data</span>(),<br>                                                  tail_elem_count);<br><br>          bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec_v, input_vec_v);<br>          <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; tail_elem_count; ++i)<br>            sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>))] += input_vec_v[i];<br>        } <span class="hljs-keyword">else</span> {<br>          <span class="hljs-comment">// full block data</span><br>          bisheng::<span class="hljs-built_in">vec_exp</span>(input_vec, input_vec);<br>          <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; elem_per_group; ++i) {<br>            sum_res_buf[group_id * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>))] += input_vec[i];<br>          }<br>        }<br><br>        <span class="hljs-comment">// UB -&gt; GM</span><br>        input_vec.<span class="hljs-built_in">store</span>(<br>            sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>            elem_per_group);<br>      });<br><br>  <span class="hljs-comment">// GM -&gt; Host</span><br>  Q.<span class="hljs-built_in">memcpy</span>(sum_res.<span class="hljs-built_in">data</span>(), sum_res_buf,<br>           group_num * (<span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>)) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-type">float</span> sum;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sum_res.<span class="hljs-built_in">size</span>(); i += <span class="hljs-number">32</span> / <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>))<br>    sum += sum_res[i];<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Ascend sum: "</span> &lt;&lt; sum &lt;&lt; <span class="hljs-string">"\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  sycl::event e1 =<br>      Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> Softmax&gt;(group_num, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>        <span class="hljs-comment">// UB memory of exponent result</span><br>        bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; exp_res_vec;<br>        <span class="hljs-comment">// UB memory of divisor</span><br>        bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; <span class="hljs-built_in">divisor_vec</span>(sum);<br>        <span class="hljs-comment">// UB memory of final result</span><br>        bisheng::vector&lt;<span class="hljs-type">float</span>, elem_per_group&gt; res_vec;<br>        std::<span class="hljs-type">size_t</span> group_id = group.<span class="hljs-built_in">get_group_id</span>();<br><br>        <span class="hljs-comment">// GM -&gt; UB</span><br>        exp_res_vec.<span class="hljs-built_in">load</span>(<br>            sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>            elem_per_group);<br><br>        <span class="hljs-keyword">if</span> (tail_elem_count &gt; <span class="hljs-number">0</span> &amp;&amp; group_id == group_num - <span class="hljs-number">1</span>) {<br>          <span class="hljs-comment">// if tail block has element and this is the last group</span><br>          bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">exp_res_vec_v</span>(exp_res_vec.<span class="hljs-built_in">data</span>(),<br>                                                    tail_elem_count);<br>          bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">divisor_vec_v</span>(divisor_vec.<span class="hljs-built_in">data</span>(),<br>                                                    tail_elem_count);<br>          bisheng::vector_view&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-built_in">res_vec_v</span>(res_vec.<span class="hljs-built_in">data</span>(),<br>                                                tail_elem_count);<br><br>          bisheng::<span class="hljs-built_in">vec_div</span>(res_vec_v, exp_res_vec_v, divisor_vec_v);<br>        } <span class="hljs-keyword">else</span> {<br>          <span class="hljs-comment">// full block data</span><br>          bisheng::<span class="hljs-built_in">vec_div</span>(res_vec, exp_res_vec, divisor_vec);<br>        }<br><br>        <span class="hljs-comment">// UB -&gt; GM</span><br>        res_vec.<span class="hljs-built_in">store</span>(<br>            sycl::<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(dev_buf + group_id * elem_per_group).<span class="hljs-built_in">get</span>(),<br>            elem_per_group);<br>      });<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Kernel function finished.\n"</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-comment">// GM -&gt; host</span><br>  Q.<span class="hljs-built_in">memcpy</span>(res.<span class="hljs-built_in">data</span>(), dev_buf, byte_count);<br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  sycl::<span class="hljs-built_in">free</span>(dev_buf, Q);<br>  sycl::<span class="hljs-built_in">free</span>(sum_res_buf, Q);<br><br>  <span class="hljs-comment">// ascend code end</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> PERFORMANCE</span><br>  <span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> e0_start_time =<br>      e0.<span class="hljs-built_in">get_profiling_info</span>&lt;sycl::info::event_profiling::command_start&gt;();<br>  <span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> e0_end_time =<br>      e0.<span class="hljs-built_in">get_profiling_info</span>&lt;sycl::info::event_profiling::command_end&gt;();<br>  <span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> e1_start_time =<br>      e1.<span class="hljs-built_in">get_profiling_info</span>&lt;sycl::info::event_profiling::command_start&gt;();<br>  <span class="hljs-type">const</span> <span class="hljs-type">uint64_t</span> e1_end_time =<br>      e1.<span class="hljs-built_in">get_profiling_info</span>&lt;sycl::info::event_profiling::command_end&gt;();<br>  std::cout &lt;&lt; PERFORMANCE_HEAD &lt;&lt; <span class="hljs-string">"Ascend time cost: "</span><br>            &lt;&lt; (e0_end_time - e0_start_time) + (e1_end_time - e1_start_time)<br>            &lt;&lt; <span class="hljs-string">" ns"</span> &lt;&lt; std::endl;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-keyword">return</span> res;<br>}<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>{<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG</span><br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Compile succeed"</span> &lt;&lt; std::endl;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  std::vector&lt;<span class="hljs-type">float</span>&gt; vec;<br><br>  std::random_device rd;<br>  <span class="hljs-function">std::mt19937 <span class="hljs-title">gen</span><span class="hljs-params">(rd())</span></span>;<br>  <span class="hljs-function">std::uniform_real_distribution&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">urdis</span><span class="hljs-params">(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span></span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; INPUT_COUNT; i++) {<br>    vec.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">urdis</span>(gen));<br>  }<br><br>  std::vector&lt;<span class="hljs-type">float</span>&gt; host_res = <span class="hljs-built_in">softmax</span>(vec);<br>  std::vector&lt;<span class="hljs-type">float</span>&gt; ascend_res = <span class="hljs-built_in">ascend_softmax</span>(vec);<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; host_res.<span class="hljs-built_in">size</span>(); ++i) {<br>    <span class="hljs-keyword">if</span> (std::<span class="hljs-built_in">fabs</span>(host_res[i] - ascend_res[i]) / host_res[i] &gt; <span class="hljs-number">0.02</span>) {<br>      std::cout &lt;&lt; ERROR_HEAD &lt;&lt; <span class="hljs-string">"Calculation error."</span> &lt;&lt; std::endl;<br>      <span class="hljs-keyword">return</span> EXIT_FAILURE;<br>    }<br>  }<br>  std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; <span class="hljs-string">"Result correct."</span> &lt;&lt; std::endl;<br><br>  <span class="hljs-keyword">return</span> EXIT_SUCCESS;<br>}<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;使用毕昇编译器异构开发Softmax算子，坑太多太多了。。。。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="机器学习" scheme="https://deleter-d.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="异构编程" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"/>
    
    <category term="深度学习" scheme="https://deleter-d.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>毕昇异构算子数据搬移注意事项</title>
    <link href="https://deleter-d.github.io/posts/58921/"/>
    <id>https://deleter-d.github.io/posts/58921/</id>
    <published>2023-05-30T10:40:38.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>毕昇异构算子在搬移数据的时候，有一个比较隐蔽的问题，开发过程中一定要多加分析，避免出现类似的问题。</p><span id="more"></span><h1 id="数据搬移注意事项">数据搬移注意事项</h1><h2 id="示例">示例</h2><p>在调用向量搬移接口<code>load</code>和<code>store</code>的时候，可能会遇到搬移出来的数据不符合预期的情况，用以下一个例子进行说明。</p><p>引入头文件，并定义两个常量作为矩阵的行和列数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sycl/sycl.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bisheng/bisheng.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bisheng/vector.hpp&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> sycl;<br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> bisheng;<br><br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> M = <span class="hljs-number">8</span>;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> N = <span class="hljs-number">16</span>;<br></code></pre></td></tr></table></figure><p>定义毕昇异构算子，以实现以下功能。</p><p><img src="https://user-images.githubusercontent.com/56388518/241941779-144af025-1b17-4a63-8533-d194aa485c28.png" style="zoom:67%;"></p><p>代码实现如下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">func</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br><span class="hljs-function">queue <span class="hljs-title">Q</span><span class="hljs-params">(ascend_selector{})</span></span>;<br><br>    <span class="hljs-comment">// host数据</span><br>    <span class="hljs-type">float</span> *input_ptr = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[M * N];<br>    <span class="hljs-type">float</span> *output_ptr = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[M];<br><br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M; i++)<br>    {<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; N; j++)<br>        {<br>            input_ptr[i * N + j] = j;<br>        }<br>    }<br><br>    <span class="hljs-comment">// GM的buffer</span><br>    <span class="hljs-keyword">auto</span> *input_buf = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(M * N, Q);<br>    <span class="hljs-keyword">auto</span> *output_buf = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(M, Q);<br><br>    <span class="hljs-comment">// 从host端拷贝到GM</span><br>    Q.<span class="hljs-built_in">memcpy</span>(input_buf, input_ptr, M * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><br>    Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(M, [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>        <span class="hljs-keyword">auto</span> group_id = group.<span class="hljs-built_in">get_id</span>();<br>        <span class="hljs-comment">// UB上的向量</span><br>        vector&lt;<span class="hljs-type">float</span>, N&gt; vec;<br>        vector&lt;<span class="hljs-type">float</span>, <span class="hljs-number">1</span>&gt; res;<br>        <span class="hljs-comment">// 从GM加载到UB上</span><br>        vec.<span class="hljs-built_in">load</span>(<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(input_buf + group_id * N));<br>        <span class="hljs-comment">// 取正确的数放入结果向量中</span><br>        res[<span class="hljs-number">0</span>] = vec[group_id];<br>        <span class="hljs-comment">// 从UB存储到GM上</span><br>        res.<span class="hljs-built_in">store</span>(<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(output_buf + group_id));<br>    });<br><br>    Q.<span class="hljs-built_in">wait</span>();<br><br>    Q.<span class="hljs-built_in">memcpy</span>(output_ptr, output_buf, M * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    Q.<span class="hljs-built_in">memcpy</span>(temp_ptr, temp_buf, M * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    Q.<span class="hljs-built_in">wait</span>();<br><br>    std::cout &lt;&lt; <span class="hljs-string">"output data is:"</span> &lt;&lt; std::endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M; i++)<br>    {<br>        std::cout &lt;&lt; output_ptr[i] &lt;&lt; <span class="hljs-string">" "</span>;<br>    }<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-built_in">free</span>(input_buf, Q);<br>    <span class="hljs-built_in">free</span>(output_buf, Q);<br>}<br></code></pre></td></tr></table></figure><h2 id="隐蔽的问题">隐蔽的问题</h2><p>上面的代码按照逻辑来看，似乎不存在问题，但其中有一个很隐蔽的致命问题。让我们回看核函数的代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(M, [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-keyword">auto</span> group_id = group.<span class="hljs-built_in">get_id</span>();<br>    <span class="hljs-comment">// UB上的向量</span><br>    vector&lt;<span class="hljs-type">float</span>, N&gt; vec;<br>    vector&lt;<span class="hljs-type">float</span>, <span class="hljs-number">1</span>&gt; res;<br>    <span class="hljs-comment">// 从GM加载到UB上</span><br>    vec.<span class="hljs-built_in">load</span>(<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(input_buf + group_id * N));<br>    <span class="hljs-comment">// 取正确的数放入结果向量中</span><br>    res[<span class="hljs-number">0</span>] = vec[group_id];<br>    <span class="hljs-comment">// 从UB存储到GM上</span><br>    res.<span class="hljs-built_in">store</span>(<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(output_buf + group_id));<br>});<br></code></pre></td></tr></table></figure><p>不管是向量的声明，调用<code>load()</code>接口加载数据，还是根据<code>group_id</code>取得正确的数据都没有任何问题。这个隐蔽的问题隐藏在调用<code>store</code>接口的时候。</p><p>依照目前的写法，我们所期望的数据在内存中的搬移流程如下图所示。将Host端的数据搬移至Global Memory后，利用向量搬移接口<code>load()</code>搬移至Unified Buffer，每个Group读取一行数据，然后根据<code>group_id</code>取得正确的数据存入一个单元素向量中，再将该结果向量利用<code>store()</code>搬移至Global Memory中。</p><p><img src="https://user-images.githubusercontent.com/56388518/241942739-bec8a56c-0055-4646-90f7-34f718fdc7fb.png"></p><p>我们可以执行一下这段代码，输出的结果可能是这样的。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">6</span> <span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><p>还可能是这样的。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">2</span>.<span class="hljs-number">8026</span>e-<span class="hljs-number">45</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>还可能是。。。。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span> <span class="hljs-number">1</span> <span class="hljs-number">1</span> -<span class="hljs-number">1</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">2</span>.<span class="hljs-number">8026</span>e-<span class="hljs-number">45</span> <span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span> <span class="hljs-number">1</span> <span class="hljs-number">1</span> <span class="hljs-number">3</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">2</span>.<span class="hljs-number">8026</span>e-<span class="hljs-number">45</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span>.<span class="hljs-number">8026</span>e-<span class="hljs-number">45</span><br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>.<span class="hljs-number">91908</span>e-<span class="hljs-number">42</span> <span class="hljs-number">2</span>.<span class="hljs-number">8026</span>e-<span class="hljs-number">45</span> <span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><h2 id="产生的原因">产生的原因</h2><p>这样的结果显然不符合预期。不幸的是，实际的搬移过程并不是我们想象的这样，致命的错误发生再从Unified Buffer搬移至Global Memory的过程中。</p><p>我们可以看一下<code>load()</code>和<code>store()</code>接口的源码是如何定义的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">load</span><span class="hljs-params">(sycl::global_ptr&lt;T&gt; addr, <span class="hljs-type">size_t</span> n = N)</span> </span>{<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">DMI_COPY_BLOCKS</span>(<span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">data</span>(), &amp;addr[<span class="hljs-number">0</span>], n);<br>}<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">store</span><span class="hljs-params">(sycl::global_ptr&lt;T&gt; addr, <span class="hljs-type">size_t</span> n = N)</span> </span>{<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">DMI_COPY_BLOCKS</span>(&amp;addr[<span class="hljs-number">0</span>], <span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">data</span>(), n);<br>}<br></code></pre></td></tr></table></figure><p>可以观察到它们调用了一个名为<code>DMI_COPY_BLOCKS()</code>的接口，所以<code>load()</code>和<code>store()</code>接口显然是以块粒度搬移数据的，而根据毕昇C++的文档可以得知，一个block的大小为32B。但我们所<code>store()</code>的数据根本不够一个block，这就会导致在<code>store()</code>的过程中，实际上是搬移了一整个block的数据。<strong>除了第一个位置拥有我们取出来的数据之外，其他位置均为未定义的数据。</strong></p><p>所以实际上的搬移情况是如下图所示的。</p><p><img src="https://user-images.githubusercontent.com/56388518/241942831-78c54918-5e6e-4832-8a41-edd0ef2e62a7.png" style="zoom: 50%;"></p><p>同时，Device端的Group之间都是异步的，甚至Group内部的一些操作都是异步的，这就导致<code>output_buf</code>有可能会被多个Group同时写入。显而易见地，这种情况会导致最终得到的<code>output_buf</code>中存在不正确的数据，如果你运气足够好，那还是有可能得到正确结果的。但计算机是科学，不是玄学。</p><h2 id="解决方案">解决方案</h2><p>既然<code>load()</code>和<code>store()</code>的搬移都是块粒度的，那我们索性就避免让不同的group访问到同一个block。将上面的代码稍加修改，如下所示。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">correct</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-function">queue <span class="hljs-title">Q</span><span class="hljs-params">(ascend_selector{})</span></span>;<br><br>    <span class="hljs-type">float</span> *input_ptr = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[M * N];<br>    <span class="hljs-comment">// 保证结果所在的block不重叠</span><br>    <span class="hljs-type">float</span> *output_ptr = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[M * <span class="hljs-number">8</span>];<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M; i++)<br>    {<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; N; j++)<br>        {<br>            input_ptr[i * N + j] = j;<br>        }<br>    }<br><br>    <span class="hljs-keyword">auto</span> *input_buf = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(M * N, Q);<br>    <span class="hljs-comment">// 相应的buffer也要申请更大的空间</span><br>    <span class="hljs-keyword">auto</span> *output_buf = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">float</span>&gt;(M * <span class="hljs-number">8</span>, Q);<br><br>    Q.<span class="hljs-built_in">memcpy</span>(input_buf, input_ptr, M * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><br>    Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(M, [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>        <span class="hljs-keyword">auto</span> group_id = group.<span class="hljs-built_in">get_id</span>();<br><br>        vector&lt;<span class="hljs-type">float</span>, N&gt; vec;<br>        vector&lt;<span class="hljs-type">float</span>, <span class="hljs-number">1</span>&gt; res;<br><br>        vec.<span class="hljs-built_in">load</span>(<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(input_buf + group_id * N));<br>        <br>        res[<span class="hljs-number">0</span>] = vec[group_id];<br><br>        <span class="hljs-comment">// 从UB存储到GM上是，要注意位置的计算</span><br>        res.<span class="hljs-built_in">store</span>(<span class="hljs-built_in">global_ptr</span>&lt;<span class="hljs-type">float</span>&gt;(output_buf + group_id * <span class="hljs-number">8</span>));<br>    });<br><br>    Q.<span class="hljs-built_in">wait</span>();<br><br>    Q.<span class="hljs-built_in">memcpy</span>(output_ptr, output_buf, M * <span class="hljs-number">8</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    Q.<span class="hljs-built_in">wait</span>();<br><br>    std::cout &lt;&lt; <span class="hljs-string">"output data is:"</span> &lt;&lt; std::endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M; i++)<br>    {<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">8</span>; j++)<br>        {<br>            std::cout &lt;&lt; output_ptr[i * <span class="hljs-number">8</span> + j] &lt;&lt; <span class="hljs-string">" "</span>;<br>        }<br>        std::cout &lt;&lt; std::endl;<br>    }<br><br>    <span class="hljs-built_in">free</span>(input_buf, Q);<br>    <span class="hljs-built_in">free</span>(output_buf, Q);<br>}<br></code></pre></td></tr></table></figure><p>关键的修改在于，我们将<code>output_buf</code>直接申请成了一个大矩阵，上图说话。</p><p><img src="https://user-images.githubusercontent.com/56388518/241942963-b49523b2-48a2-4f25-b5b6-b12076ac715a.png" style="zoom: 50%;"></p><p>这种方法直接避免了block的交叠，即使Group再异步，也不会产生写冲突。虽然Global Memory中的所有红色部分都是未定义的无效数据，但所带来的性能损耗几乎可以忽略不记。</p><h2 id="需要注意该问题的情况">需要注意该问题的情况</h2><p>一定要仔细分析自己的算子逻辑，在将Unified Buffer中的数据搬移至Global Memory的过程中，理清搬移的数据大小，分析是否存在block交叠的可能性。尤其要注意输入数据很小的情况下，会不会引起该问题。如果这种情况下无法处理这个问题，可以尝试将输入数据极小的情况做单独的处理，不使用昇腾加速卡进行加速，当然也可以分析更好的解决方案。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;毕昇异构算子在搬移数据的时候，有一个比较隐蔽的问题，开发过程中一定要多加分析，避免出现类似的问题。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="ITK" scheme="https://deleter-d.github.io/tags/ITK/"/>
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>毕昇编译器版本升级注意事项</title>
    <link href="https://deleter-d.github.io/posts/29203/"/>
    <id>https://deleter-d.github.io/posts/29203/</id>
    <published>2023-05-30T10:32:24.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>毕昇编译器版本升级之后，有一些需要注意和改动的地方。</p><span id="more"></span><h1 id="编译器版本升级注意事项">编译器版本升级注意事项</h1><h2 id="版本信息">版本信息</h2><h3 id="升级前">升级前</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">BiShengCPP-B030 Only For PengCheng clang version <span class="hljs-number">14.0</span>.<span class="hljs-number">0</span> (<span class="hljs-number">2</span>b53695e1bb8)<br>Target: aarch64-unknown-linux-gnu<br>Thread model: posix<br>InstalledDir: <span class="hljs-regexp">/home/</span>bisheng_tester2<span class="hljs-regexp">/Ascend/</span>ascend-toolkit<span class="hljs-regexp">/latest/</span>aarch64-linux<span class="hljs-regexp">/bisheng_cpp/</span>bin<br></code></pre></td></tr></table></figure><h3 id="升级后">升级后</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">BiShengCPP B107 Only For PengCheng clang version <span class="hljs-number">15.0</span>.<span class="hljs-number">5</span> (clang-<span class="hljs-number">3</span>fb32fbe51cb flang-<span class="hljs-number">3</span>fb32fbe51cb)<br>Target: aarch64-unknown-linux-gnu<br>Thread model: posix<br>InstalledDir: <span class="hljs-regexp">/home/</span>bisheng_tester2<span class="hljs-regexp">/Ascend/</span>ascend-toolkit<span class="hljs-regexp">/latest/</span>aarch64-linux<span class="hljs-regexp">/bisheng_cpp/</span>bin<br></code></pre></td></tr></table></figure><h2 id="代码改动">代码改动</h2><h3 id="配置文件改动">配置文件改动</h3><p>顶层<code>CMakeLists.txt</code>中的<code>-lsycl</code>不再需要。即231行改回原版的状态，如下。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">"${CMAKE_CXX_FLAGS} ${ITK_REQUIRED_CXX_FLAGS}"</span>)<br></code></pre></td></tr></table></figure><p>包含算子的<code>CMakeLists.txt</code>中的编译参数有变化。由原来的：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">"${CMAKE_CXX_FLAGS} -fsycl -fsycl-targets=ascend_910-cce"</span>)<br></code></pre></td></tr></table></figure><p>改为：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">"${CMAKE_CXX_FLAGS} -fsycl -fdevices=ascend_910"</span>)<br></code></pre></td></tr></table></figure><h3 id="接口改动">接口改动</h3><p>获取group的id时，接口从<code>group.get_id()</code>变为<code>group.get_group_id()</code>。</p><p>目前只知道这一个接口变动，后续如果发现有重要的变动会在此更新。</p><h3 id="类型支持问题">类型支持问题</h3><p>如果在编译过程中并未出现错误，那么类型支持问题可以忽略不看。</p><p>升级后的编译器由暂不支持<code>long double</code>数据类型，故需要将涉及到的<code>long double</code>类型的<strong>全局变量</strong>注释掉。</p><hr><p>所有改动可以参考<a href="https://gitee.com/yichu12138/itk/commit/f21ba71ab931d977395d66644a0e90a49cb3f5e1">本次commit</a>的内容。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;毕昇编译器版本升级之后，有一些需要注意和改动的地方。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>毕昇异构算子开发全流程</title>
    <link href="https://deleter-d.github.io/posts/35929/"/>
    <id>https://deleter-d.github.io/posts/35929/</id>
    <published>2023-05-20T08:19:06.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>毕昇异构算子开发的整体工作流，供项目成员参考。</p><span id="more"></span><h1 id="毕昇异构算子开发全流程">毕昇异构算子开发全流程</h1><h2 id="前期准备">前期准备</h2><h3 id="源码准备">源码准备</h3><p>先将<a href="https://gitee.com/wangzhenbang2023/itk">源码仓库</a>fork到自己的仓库中，并将自己的仓库克隆到本地，这里的本地指服务器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone https://gitee.com/xxx/itk.git # xxx替换成自己的gitee用户名<br></code></pre></td></tr></table></figure><p>克隆好之后，在与源码同级的文件夹中创建两个文件夹，用来存放编译构建和安装生成的文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir ITK-build<br>mkdir ITK-install<br></code></pre></td></tr></table></figure><p>截止目前文件结构应如下所示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">.<br>|--itk<br>|--ITK-build<br>|--ITK-install<br></code></pre></td></tr></table></figure><h3 id="git准备">git准备</h3><p>进入源码文件夹，并新建一个分支。以我的算子为例，创建一个名为<code>vnl_matrix_update</code>的分支。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd itk<br>git branch vnl_matrix_update<br></code></pre></td></tr></table></figure><p>创建好后切换到该分支上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git checkout vnl_matrix_update<br></code></pre></td></tr></table></figure><p>可以看到成果切换分支的提示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">Switched to branch 'vnl_matrix_update'<br></code></pre></td></tr></table></figure><p>然后提交分支。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">git add . # 将所有修改添加至暂存区<br>git commit -m 'create branch' # 将暂存区的所有内容提交至本地仓库<br></code></pre></td></tr></table></figure><blockquote><p>如果在执行<code>commit</code>时出现如下提示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">*** Please tell me who you are.<br><br>Run<br><br>git config --global user.email "you@example.com"<br>git config --global user.name "Your Name"<br><br>to set your account's default identity.<br>Omit --global to set the identity only in this repository.<br><br>fatal: empty ident name (for &lt;bisheng_tester2@csobluex.(none)&gt;) not allowed<br></code></pre></td></tr></table></figure><p>则根据提示对git进行配置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">git config --global user.email "you@example.com" # 邮箱替换为自己的<br>git config --global user.name "Your Name" # 用户名也替换为自己的<br></code></pre></td></tr></table></figure></blockquote><p>然后推送到远程仓库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git push origin vnl_matrix_update # 将vnl_matrix_update分支推送到远程仓库origin<br></code></pre></td></tr></table></figure><p>执行<code>push</code>后按照提示输入Gitee的用户名和密码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">Username for 'https://gitee.com': xxx # xxx替换成自己的gitee用户名<br>Password for 'https://yichu12138@gitee.com': # 输入密码<br>Total 0 (delta 0), reused 0 (delta 0)<br>remote: Powered by GITEE.COM [GNK-6.4]<br>remote: Create a pull request for 'vnl_matrix_update' on Gitee by visiting:<br>remote:     https://gitee.com/yichu12138/itk/pull/new/yichu12138:vnl_matrix_update...yichu12138:master<br>To https://gitee.com/yichu12138/itk.git<br> * [new branch]      vnl_matrix_update -&gt; vnl_matrix_update<br></code></pre></td></tr></table></figure><p>看到上述提示后，则表明分支已经成果提交到了自己的远程仓库中。</p><p><img src="https://user-images.githubusercontent.com/56388518/239676841-8e8efb74-5c73-4321-98b9-f9b85f89d08b.png" style="zoom:67%;"></p><h2 id="首次编译构建">首次编译构建</h2><p>按照之前的文档<a href="https://deleter-d.github.io/posts/51688/">ITK线上环境编译与VSCode远程环境接入</a>，将未改动过的源码编译构建并安装。</p><p><strong>不建议先修改代码再编译构建！！！</strong>可能会遇到问题。</p><h2 id="通用修改项">通用修改项</h2><p>接下来先修改大家都需要进行修改的地方，这些修改主要是为了让ITK适配毕昇编译器。</p><h3 id="顶层cmakelists.txt">顶层<code>CMakeLists.txt</code></h3><p>第46行修改前：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">if</span>(<span class="hljs-keyword">NOT</span> CMAKE_CXX_STANDARD)<br>  <span class="hljs-keyword">set</span>(CMAKE_CXX_STANDARD <span class="hljs-number">11</span>) <span class="hljs-comment"># Supported values are ``11``, ``14``, and ``17``.</span><br><span class="hljs-keyword">endif</span>()<br></code></pre></td></tr></table></figure><p>修改后：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">if</span>(<span class="hljs-keyword">NOT</span> CMAKE_CXX_STANDARD)<br>  <span class="hljs-keyword">set</span>(CMAKE_CXX_STANDARD <span class="hljs-number">17</span>) <span class="hljs-comment"># 修改C++标准为17，源码为11</span><br><span class="hljs-keyword">endif</span>()<br></code></pre></td></tr></table></figure><p>第231行修改前：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">"${CMAKE_CXX_FLAGS} ${ITK_REQUIRED_CXX_FLAGS}"</span>)<br></code></pre></td></tr></table></figure><p>修改后：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">"${CMAKE_CXX_FLAGS} ${ITK_REQUIRED_CXX_FLAGS} -lsycl"</span>)<br></code></pre></td></tr></table></figure><h2 id="其他修改项">其他修改项</h2><p>其余的修改项要根据自己的算子来做相应的调整。</p><h3 id="cmakelists.txt"><code>CMakeLists.txt</code></h3><p>找到与算子同级的<code>CMakeLists.txt</code>，即管理所修改算子的<code>CMakeLists.txt</code>。</p><p>以<code>vnl_matrix</code>算子为例，<code>vnl_matrix.h</code>的路径为<code>Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_matrix.h</code>，则管理它的<code>CMakeLists.txt</code>路径为<code>Modules/ThirdParty/VNL/src/vxl/core/vnl/CMakeLists.txt</code>。</p><p>当然也不能完全靠路径来判断，在找到的<code>CMakeLists.txt</code>中应该能找到算子的名称之类的信息，来确定这个<code>CMakeLists.txt</code>到底是不是管理该算子。</p><p>例如<code>vnl_matrix</code>对应的<code>CMakeLists.txt</code>中就包含如下信息，从而可以确定。</p><p><img src="https://user-images.githubusercontent.com/56388518/239676899-584636f7-a1c2-4015-a8ab-487c30460f89.png" style="zoom:67%;"></p><p>找到对应的<code>CMakeLists.txt</code>后，在末尾添加一行代码。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">"${CMAKE_CXX_FLAGS} -fsycl -fsycl-targets=ascend_910-cce"</span>)<br></code></pre></td></tr></table></figure><h3 id="算子修改">算子修改</h3><p>找到要修改的算子，并找到算子的实现。</p><p>我要修改的<code>update()</code>算子位于<code>Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_matrix.h:421</code>，相应的实现位于<code>Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_matrix.hxx:634</code>。</p><p>现在<code>vnl_matrix.hxx</code>中引入以下两个头文件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sycl/sycl.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bisheng/bisheng.hpp&gt;</span></span><br></code></pre></td></tr></table></figure><p>然后对算子代码进行修改。修改前如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>vnl_matrix&lt;T&gt;&amp; vnl_matrix&lt;T&gt;::<span class="hljs-built_in">update</span> (vnl_matrix&lt;T&gt; <span class="hljs-type">const</span>&amp; m,<br>                                      <span class="hljs-type">unsigned</span> top, <span class="hljs-type">unsigned</span> left)<br>{<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> bottom = top + m.num_rows;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> right = left + m.num_cols;<br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> NDEBUG</span><br>  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;num_rows &lt; bottom || <span class="hljs-keyword">this</span>-&gt;num_cols &lt; right)<br>    <span class="hljs-built_in">vnl_error_matrix_dimension</span> (<span class="hljs-string">"update"</span>,<br>                                bottom, right, m.num_rows, m.num_cols);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = top; i &lt; bottom; i++)<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> j = left; j &lt; right; j++)<br>      <span class="hljs-keyword">this</span>-&gt;data[i][j] = m.data[i-top][j-left];<br>  <span class="hljs-keyword">return</span> *<span class="hljs-keyword">this</span>;<br>}<br></code></pre></td></tr></table></figure><p>目前的代码暂未考虑模板类型和数据对齐的问题，只是为了展示整个工作流程。修改后如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>vnl_matrix&lt;T&gt;&amp; vnl_matrix&lt;T&gt;::<span class="hljs-built_in">update</span> (vnl_matrix&lt;T&gt; <span class="hljs-type">const</span>&amp; m,<br>                                      <span class="hljs-type">unsigned</span> top, <span class="hljs-type">unsigned</span> left)<br>{<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> bottom = top + m.num_rows;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> right = left + m.num_cols;<br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> NDEBUG</span><br>  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;num_rows &lt; bottom || <span class="hljs-keyword">this</span>-&gt;num_cols &lt; right)<br>    <span class="hljs-built_in">vnl_error_matrix_dimension</span> (<span class="hljs-string">"update"</span>,<br>                                bottom, right, m.num_rows, m.num_cols);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>  <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>  thisM = <span class="hljs-keyword">this</span>-&gt;num_rows;<br>  <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>  thisN = <span class="hljs-keyword">this</span>-&gt;num_cols;<br>  <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>  mM = m.num_rows;<br>  <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>  mN = m.num_cols;<br>  <span class="hljs-function">sycl::queue <span class="hljs-title">Q</span><span class="hljs-params">(sycl::ascend_selector{})</span></span>;<br><br>  <span class="hljs-keyword">auto</span> * devThis = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">int</span>&gt;(thisM * thisN, Q);<br>  <span class="hljs-keyword">auto</span> * devM = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">int</span>&gt;(mM * mN, Q);<br><br>  Q.<span class="hljs-built_in">memcpy</span>(devThis, *<span class="hljs-keyword">this</span>-&gt;data, thisM * thisN * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>  Q.<span class="hljs-built_in">memcpy</span>(devM, *m.data, mM * mN * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br>  Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(mM, [=](sycl::group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    __local <span class="hljs-type">int</span> UBA[mN];<br>    <span class="hljs-type">size_t</span>      groupId = group.<span class="hljs-built_in">get_id</span>();<br>    sycl::dmi::<span class="hljs-built_in">memcpy_blocks</span>(UBA, &amp;devM[groupId * mN], mN * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>) / <span class="hljs-number">32</span>);<br>    sycl::dmi::<span class="hljs-built_in">memcpy_blocks</span>(&amp;devThis[top * thisN + groupId * thisN + left], UBA, mN * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>) / <span class="hljs-number">32</span>);<br>  });<br><br>  Q.<span class="hljs-built_in">memcpy</span>(*<span class="hljs-keyword">this</span>-&gt;data, devThis, thisM * thisN * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br>  Q.<span class="hljs-built_in">wait</span>();<br><br>  <span class="hljs-keyword">return</span> *<span class="hljs-keyword">this</span>;<br>}<br></code></pre></td></tr></table></figure><p>具体的业务逻辑要根据自己算子的功能来编写。</p><h2 id="修改后编译构建">修改后编译构建</h2><p>算子修改完成后，进入<code>ITK-build</code>文件夹。由于刚才修改了<code>CMakeLists.txt</code>，故需执行一次<code>cmake</code>来刷新<code>Makefile</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">cmake ../itk/<br></code></pre></td></tr></table></figure><p>然后使用<code>make</code>编译构建并安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">make -j24 &amp;&amp; make install<br></code></pre></td></tr></table></figure><p>安装好后就可以测试了，测试通过就可以认为完成了代码的修改工作。</p><h2 id="提交成果">提交成果</h2><p>最后将修改后的成果提交至仓库中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">git add .<br>git commit -m 'operator vnl_matrix::update() heterogeneous code'<br></code></pre></td></tr></table></figure><p>执行<code>commit</code>后会提示本次提交的代码与上次提交代码之间的差异。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[vnl_matrix_update a158479] operator vnl_matrix::update() heterogeneous code<br> 3 files changed, 33 insertions(+), 5 deletions(-)<br></code></pre></td></tr></table></figure><p>最后推送到远程仓库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git push origin vnl_matrix_update<br></code></pre></td></tr></table></figure><p>出现推送成果的提示即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">Counting objects: 23, done.<br>Delta compression using up to 192 threads.<br>Compressing objects: 100% (12/12), done.<br>Writing objects: 100% (12/12), 1.45 KiB | 0 bytes/s, done.<br>Total 12 (delta 10), reused 0 (delta 0)<br>remote: Powered by GITEE.COM [GNK-6.4]<br>To https://gitee.com/yichu12138/itk.git<br>   2fb588c..a158479  vnl_matrix_update -&gt; vnl_matrix_update<br></code></pre></td></tr></table></figure><h2 id="发起pull-request">发起Pull Request</h2><p>登录Gitee到自己的仓库中，点击<code>+ Pull Request</code>发起PR。</p><p><img src="https://user-images.githubusercontent.com/56388518/239676929-3be47f60-d736-44bb-908c-ddcaaa4166ed.png"></p><p><img src="https://user-images.githubusercontent.com/56388518/239676936-fe57444b-e514-4c14-b75b-8ba951fd6a54.png"></p><p>输入标题即可提交，当然最好在说明中简略说明本次PR的目的和所修改的代码。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;毕昇异构算子开发的整体工作流，供项目成员参考。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="ITK" scheme="https://deleter-d.github.io/tags/ITK/"/>
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="git" scheme="https://deleter-d.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>毕昇编译器异构算子开发基本思想</title>
    <link href="https://deleter-d.github.io/posts/11914/"/>
    <id>https://deleter-d.github.io/posts/11914/</id>
    <published>2023-04-18T06:01:13.000Z</published>
    <updated>2023-12-05T08:55:08.153Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>基于毕昇编译器的异构编程基本思想，如果理解CUDA编程的话，可以类比理解。</p><span id="more"></span><h1 id="毕昇c异构开发基本思想">毕昇C++异构开发基本思想</h1><h2 id="队列">队列</h2><p>首先定义任务队列，任务队列用来管理device上的可执行任务。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">queue <span class="hljs-title">Q</span><span class="hljs-params">(ascend_selector{})</span></span>;<br></code></pre></td></tr></table></figure><p><code>queue</code>来自命名空间<code>sycl</code>，需要引入头文件<code>#include &lt;sycl/sycl.hpp&gt;</code>。</p><h2 id="host数据">Host数据</h2><p>想要将host上的数据搬移到device，一个核心思想就是找到host端的数据指针。如果待迁移算子中的数据封装度较高，大体上可以分为两种情况：</p><ul><li>指针传递式的封装。</li><li>数据结构式的封装。</li></ul><p>如果只是指针传递式的封装，即封装过程仅仅是将数据指针一层一层传递过来，则是比较简单的情况，只需取得该指针即可。</p><p>如果是数据结构式的封装，即封装过程中使得子类无法读取到数据的指针，则是较为复杂的情况，迁移的工作量可能会比较大。但依然没有脱离最核心的思想——找到host端的数据指针。</p><p>这里举一个简单的例子，在host端定义两个数组。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> M = <span class="hljs-number">32</span>;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> N = <span class="hljs-number">16</span>;<br><br><span class="hljs-comment">// 模拟M*M的矩阵</span><br><span class="hljs-keyword">auto</span>* ptrDataA = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[M * M];<br><span class="hljs-comment">// 模拟N*N的矩阵</span><br><span class="hljs-keyword">auto</span> *ptrDataB = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[N * N];<br></code></pre></td></tr></table></figure><p><code>ptrDataA</code>与<code>ptrDataB</code>是host端的数据指针。</p><h2 id="device数据">Device数据</h2><p>为了将host端的数据搬移到device端，需要先在device端申请内存，申请的大小根据实际情况决定。这里需要将两个矩阵都搬移至device上，故申请如下大小的内容。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> *devA = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">int</span>&gt;(M * M, Q);<br><span class="hljs-keyword">auto</span> *devB = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">int</span>&gt;(N * N, Q);<br></code></pre></td></tr></table></figure><p><code>devA</code>和<code>devB</code>分别为device端的数据指针，这两片空间处于Global Memory中，但此时仅仅是申请了内存，这两片设备内存中并不存在任何数据。接下来就需要将host端的数据正式拷贝到device端。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">memcpy</span>(devA, ptrDataA, M * M * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>Q.<span class="hljs-built_in">memcpy</span>(devB, ptrDataB, N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br></code></pre></td></tr></table></figure><p><code>memcpy()</code>接口定义如下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">memcpy</span><span class="hljs-params">(<span class="hljs-type">void</span> *Dst, <span class="hljs-type">const</span> <span class="hljs-type">void</span> *Src, <span class="hljs-type">size_t</span> Size)</span></span>;<br></code></pre></td></tr></table></figure><ul><li><code>Dst</code>为目标地址。</li><li><code>Src</code>为源地址。</li><li><code>Size</code>为待搬移数据的大小。</li></ul><h2 id="提交任务">提交任务</h2><p>截止目前，数据已经在device端准备完毕，接下来就可以进行任务的提交。任务以核函数的形式，作为参数传递给<code>launch()</code>接口。</p><p>首先来看一下<code>launch()</code>的定义。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> KernelName = detail::auto_name, <span class="hljs-keyword">typename</span> KernelType&gt;<br>event <span class="hljs-built_in">launch</span>(<span class="hljs-type">size_t</span> NumWorkGroups, _KERNELFUNCPARAM(KernelFunc) _CODELOCPARAM(&amp;CodeLoc)) <br></code></pre></td></tr></table></figure><p>接口定义虽然比较复杂，还涉及到一些宏，但我们只需要关注两个参数：</p><ul><li><code>NumWorkGroups</code>为work-group的数量。</li><li><code>KernelFunc</code>为核函数。</li></ul><p>核函数以lambda表达式的方式进行定义。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> KernelFunc = [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// TODO</span><br>};<br></code></pre></td></tr></table></figure><p>接下来进行任务的提交。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(N, KernelFunc);<br></code></pre></td></tr></table></figure><p>该行代码指定了<code>N</code>个<code>work-group</code>，并传入一个核函数<code>KernelFunc</code>作为device端执行的实际操作。</p><p>当然也可以直接将任务提交与核函数定义的代码合并，省去单独定义<code>KernelFunc</code>的步骤。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(N, [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    <span class="hljs-comment">// TODO</span><br>});<br></code></pre></td></tr></table></figure><blockquote><p>C++中的lambda表达式定义方式如下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> func = [capture] (params) <span class="hljs-keyword">mutable</span> <span class="hljs-built_in">throw</span>() -&gt; <span class="hljs-keyword">return</span>-type { func_body };<br></code></pre></td></tr></table></figure><p><code>[capture]</code>：用来捕获一定范围的变量。</p><ul><li><code>[ ]</code>不捕获任何变量；</li><li><code>[&amp;]</code>引用捕获，捕获外部作用域所有变量，在函数体内当作引用使用；</li><li><code>[=]</code>值捕获，捕获外部作用域所有变量，在函数体内创建一个拷贝使用；</li><li><code>[=, &amp;a]</code>值捕获外部作用域所有变量，按引用捕获a变量；</li><li><code>[a]</code>值捕获外部作用域所有变量，按引用捕获a变量；</li><li><code>[this]</code>捕获当前类中的this指针。</li></ul><p><code>(params)</code>：参数列表。</p><p><code>mutable</code>：当使用值捕获时，加上<code>mutable</code>关键字就可以对捕获到的值进行修改。</p><p><code>throw()</code>：用于函数体抛出异常</p><p><code>return-type</code>：用来显式指定返回类型，当不需要返回值或返回类型明确的情况下，可以将<code>-&gt;</code>与<code>return-type</code>一同省略</p><p><code>{ func_body }</code>：函数体。</p></blockquote><p>这里以矩阵的<code>update</code>操作为例，该操作给定两个矩阵<code>A</code>和<code>B</code>，以及两个参数<code>left</code>和<code>top</code>，将矩阵<code>A</code>从<code>(left, top)</code>元素开始的与矩阵<code>B</code>大小相同的子矩阵替换为矩阵<code>B</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(N, [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>    __local <span class="hljs-type">int</span> UBBuf[N];<br>    <span class="hljs-type">size_t</span> groupId = group.<span class="hljs-built_in">get_id</span>();<br>    dmi::<span class="hljs-built_in">memcpy_blocks</span>(UBBuf, &amp;devB[groupId * N], N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>) / <span class="hljs-number">32</span>);<br>    dmi::<span class="hljs-built_in">memcpy_blocks</span>(&amp;devA[top * M + groupId * M + left], UBBuf, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>) / <span class="hljs-number">32</span>);<br>});<br></code></pre></td></tr></table></figure><p>我们来一行一行解析上面的代码。</p><p>首先看第一行<code>__local int UBBuf[N]</code>，该语句利用空间制导符<code>__local</code>在Unified Buffer中申请了一片大小为<code>N</code>的内存空间。</p><p>第二行<code>size_t groupId = group.get_id()</code>利用<code>get_id()</code>接口获取到了当前的work-group的id。</p><p>第三行<code>dmi::memcpy_blocks(UBBuf, &amp;devB[groupId * N], N * sizeof(int) / 32)</code>，利用命名空间<code>dmi</code>下的<code>memcpy_blocks()</code>接口进行连续数据的拷贝，将之前定义的Global Memory中<code>devB</code>的数据并行的拷贝至Unified Buffer中的<code>UBBuf</code>中。可以观察到拷贝的源地址是利用<code>groupId</code>计算得来的，这一点后面会详细解释。</p><p>第四行<code>dmi::memcpy_blocks(&amp;devA[top * M + groupId * M + left], UBBuf, N * sizeof(int) / 32)</code>，同样是利用连续数据拷贝的接口，将Unified Buffer中的<code>UBBuf</code>中的数据，拷贝到Global Memory中<code>devA</code>的正确位置，从而实现<code>update</code>操作。拷贝的目的地址同样是利用<code>groupId</code>与参数<code>left</code>和<code>top</code>计算得来。</p><h3 id="work-group的理解">work-group的理解</h3><p>以上面提到的矩阵<code>update()</code>操作为例。</p><p><img src="https://user-images.githubusercontent.com/56388518/232685578-f50902ed-afc2-4cbf-a322-9139b44626b2.png" style="zoom: 67%;"></p><p>当<code>groupId == 0</code>时，<code>&amp;devA[top * M + groupId * M + left]</code>计算的结果为<code>&amp;devA[top * M + left]</code>，即图中<code>groupId=0</code>箭头所指的那一行数据。而<code>groupId == 1</code>时，同理，计算结果为<code>&amp;devA[top * M + M + left]</code>，即比<code>groupId == 0</code>时多向前指了一行数据，也即图中<code>groupId=1</code>箭头所指的数据。</p><p>理解work-group最重要的一点就是，要意识到所有group都是并行的，是同时执行的。</p><h2 id="取回数据">取回数据</h2><p>通过核函数使device执行完任务后，最后一步就是要将运算结果从device上取回host，也即从Global Memory中搬移回Host Memory中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">memcpy</span>(ptrDataA, devA, M * M * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br></code></pre></td></tr></table></figure><p>最后可以利用<code>wait()</code>接口对device端的任务进行同步。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">Q.<span class="hljs-built_in">wait</span>();<br></code></pre></td></tr></table></figure><h1 id="完整示例">完整示例</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vnl/vnl_matrix.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sycl/sycl.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bisheng/bisheng.hpp&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> sycl;<br><br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> M = <span class="hljs-number">32</span>;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> N = <span class="hljs-number">16</span>;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> left = <span class="hljs-number">4</span>;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> top = <span class="hljs-number">7</span>;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> <span class="hljs-type">const</span> *argv[])</span></span><br><span class="hljs-function"></span>{<br>    <span class="hljs-function">queue <span class="hljs-title">Q</span><span class="hljs-params">(ascend_selector{})</span></span>;<br><br>    <span class="hljs-comment">// host端数据指针</span><br>    <span class="hljs-keyword">auto</span> *ptrDataA = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[M * M];<br>    <span class="hljs-keyword">auto</span> *ptrDataB = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[N * N];<br><br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M * M; i++)<br>    {<br>        ptrDataA[i] = <span class="hljs-number">1</span>;<br>    }<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N; i++)<br>    {<br>        ptrDataB[i] = <span class="hljs-number">2</span>;<br>    }<br>    <br>    <span class="hljs-comment">// 申请device端内存</span><br>    <span class="hljs-keyword">auto</span> *devA = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">int</span>&gt;(M * M, Q);<br>    <span class="hljs-keyword">auto</span> *devB = <span class="hljs-built_in">malloc_device</span>&lt;<span class="hljs-type">int</span>&gt;(N * N, Q);<br><br>    <span class="hljs-comment">// 将host端的数据拷贝至device端，此时数据在Global Memory中</span><br>    Q.<span class="hljs-built_in">memcpy</span>(devA, ptrDataA, M * M * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    Q.<span class="hljs-built_in">memcpy</span>(devB, ptrDataB, N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br>    <span class="hljs-comment">// 提交任务</span><br>    <span class="hljs-comment">// &lt;class Test&gt;是为该任务命名，Test可以根据实际情况修改为合适的名称</span><br>    Q.<span class="hljs-built_in">launch</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>&gt;(N, [=](group&lt;<span class="hljs-number">1</span>&gt; group) {<br>        <span class="hljs-comment">// 申请Unified Buffer内存</span><br>        __local <span class="hljs-type">int</span> UBA[N];<br>        <span class="hljs-comment">// 获取group id</span><br>        <span class="hljs-type">size_t</span> groupId=group.<span class="hljs-built_in">get_id</span>();<br>        <span class="hljs-comment">// 将矩阵B的数据并行地拷贝进Unified Buffer</span><br>        dmi::<span class="hljs-built_in">memcpy_blocks</span>(UBA, &amp;devB[groupId * N], N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>) / <span class="hljs-number">32</span>);<br>        <span class="hljs-comment">// 将Unified Buffer中的数据并行的拷贝进矩阵A的正确位置</span><br>        dmi::<span class="hljs-built_in">memcpy_blocks</span>(&amp;devA[top * M + groupId * M + left], UBA, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>) / <span class="hljs-number">32</span>);<br>    });<br><br>    <span class="hljs-comment">// 将结果从Global Memory中取回Host Memory</span><br>    Q.<span class="hljs-built_in">memcpy</span>(ptrDataA, devA, M * M * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br>    <span class="hljs-comment">// 任务同步</span><br>    Q.<span class="hljs-built_in">wait</span>();<br><br>    <span class="hljs-comment">// 输出矩阵A，检查update操作是否正确</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M * M; i++)<br>    {<br>        <span class="hljs-keyword">if</span> (i % M == <span class="hljs-number">0</span>)<br>            std::cout &lt;&lt; std::endl;<br>        std::cout &lt;&lt; ptrDataA[i] &lt;&lt; <span class="hljs-string">" "</span>;<br>    }<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>}<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;基于毕昇编译器的异构编程基本思想，如果理解CUDA编程的话，可以类比理解。&lt;/p&gt;</summary>
    
    
    
    <category term="项目" scheme="https://deleter-d.github.io/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="毕昇编译器" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="异构编程" scheme="https://deleter-d.github.io/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"/>
    
    <category term="毕昇C++" scheme="https://deleter-d.github.io/tags/%E6%AF%95%E6%98%87C/"/>
    
  </entry>
  
</feed>

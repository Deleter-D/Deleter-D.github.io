{"pages":[{"title":"","text":"🎈🎈微笑墙🎈🎈 彭小苒 唐艺昕 唐艺昕 李一桐 gakki gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://removeif.github.io/images/avatar.jpg 网站名称：辣椒の酱 网站地址：https://removeif.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"计算机是一个神奇的领域，从传统算法的诞生，到人工智能的兴起，再到如今大模型的落地，无一不体现着人类的智慧。 罗翔老师在一段采访中提到一个观点： 很多“高傲”的观点跟老百姓的基本的内心常识相抵触的时候，在技术主义在逻辑论证上是没有问题的，但其实是抵触人内心的良知的。这种思想变化的发生是基于人生的经历。人要接受自己的有限性，人承认自己是有限的，于是承认你的逻辑是有限的，承认你的理性是有限的，承认你的阅读是有限的，承认你整个人就是在一种偏见之中。人这一生就是走出偏见。 ——罗翔 人类的确是有限的，至少在当今人类还是碳基生命的情况下，是有限的。 我们承认我们是有限的，但依然有人向着无限进步在冲锋。在自己的领域里不断学习、不断进步，才能在处理问题的时候逻辑缜密、充满自信。我享受解决问题的过程，更享受问题解决后的正反馈。我也享受与人交流技术问题，使用各自的技术观点进行交锋，如同两个屠龙的优雅剑士， 不争对错、不争高低，只求在互相展示自身高超剑技的过程中终结恶龙。但我最享受的，是在一个团队中沟通交流解决问题，团队中每一分子各司其职，每个人都在团队中贡献自己的价值，最终解决难题的过程。如同《三体》中的“秦一号”计算机，每个人在其中负责自己的逻辑单元，但组合在一起却有了比肩神明的能力。也许有一天我们的“物理学”也会不存在了，但希望我们能保持一份勇气，敢于打破所谓的“不存在”，享受提高技术与认知的过程。 祝大家在各自的领域中，像一个勇士一样，拿起武器，向着限制人类的高墙发起冲锋，至死方休！","link":"/about/index.html"},{"title":"","text":"说一切你所念，讲一切你所想","link":"/message/index.html"},{"title":"","text":"&lt;div class=&quot;music-player&quot;&gt; &lt;div class=&quot;d-title&quot;&gt; &lt;i class=&quot;fa fa-music&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;听听音乐 &lt;/div&gt; &lt;br/&gt; &lt;/div&gt; &lt;div id=&quot;musicarea&quot;&gt; &lt;div class=&quot;music&quot;&gt;&lt;/div&gt; &lt;p id=&quot;p_message&quot;&gt;&lt;span id=&quot;music_story_message&quot; class=&quot;span_animation&quot;&gt;&lt;/span&gt;&lt;/p&gt; &lt;br/&gt; &lt;ul id=&quot;musiclist&quot;&gt;&lt;/ul&gt; &lt;br/&gt; &lt;div id=&quot;desc&quot;&gt;&lt;/div&gt; &lt;/div&gt; 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &lt;div class=&quot;d-title&quot;&gt; &lt;i class=&quot;fa fa-video-camera&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;看看视频 &lt;/div&gt; &lt;br/&gt; &lt;p class=&quot;hits&quot;&gt;-&gt;点击以下条目开始播放视频,向下滑动查看更多&lt;-&lt;/p&gt; &lt;div id=&quot;video-list&quot;&gt;&lt;/div&gt; &lt;br/&gt; &lt;div id=&quot;dplayer&quot;&gt;&lt;br/&gt;&lt;/div&gt;","link":"/media/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放！","link":"/music/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: 'd0194124d91614aeed82', clientSecret: '13620eee98e6f3c9023f67b62c72998e959bd6b6', id: '114514', repo: 'Deleter-D.github.io', owner: 'Deleter-D', admin: \"Deleter-D\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"},{"title":"算法练习——回溯","text":"力扣，回溯算法相关练习。 77. 组合（中等）","link":"/unpublished/%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0%E2%80%94%E2%80%94%E5%9B%9E%E6%BA%AF.html"}],"posts":[{"title":"2D-to-3D方法的基线论文阅读笔记-ICCV2017","text":"文章题目为：A simple yet effective baseline for 3d human pose estimation。是一个简单的神经网络结构，文章提出了很多改进方向，故该系统作为一个baseline为以后的研究提供参考，而不是完整的3D姿态估计系统。 大纲 引言 绝大多数现存的人类描绘都是二维的，这些表示在向其他人传达事实、想法和感受方面发挥了重要作用，而这种传递信息的方式之所以成为可能，是因为人类能够在存在深度歧义的情况下理解复杂的空间安排。本文将关注这个空间推理问题的一个特定实例：从单个图像中估计三维人体姿态。 正式地说，给定人类的图像（即二维表示），三维姿态估计是生成与所描绘人物的空间位置匹配的三维图形的任务。为了从图像转换为三维姿态，算法必须对许多因素保持不变，包括背景场景、照明、服装形状和纹理、肤色和图像瑕疵等。早期的方法通过轮廓、形状上下文、SIFT（Scale Invariant Feature Transform，尺度不变特征变换）描述符或边缘方向直方图等特征实现了这种不变性。 尽管需要大量数据的深度学习系统目前在二维姿态估计（这也需要这些不变量）等任务上优于基于人类工程特征的方法，但由于缺乏户外图像的3D真实姿态数据，因此直接从彩色图像推断3D姿态是具有挑战性的任务。 最近，一些系统探索了利用端到端深度架构从图像中直接推断3D姿态的可能性，而其他系统则认为，通过对合成数据进行训练，可以从彩色图像中实现3d推理。本文探讨了将3D姿态估计解耦到获得良好训练的2D姿态估计中的能力，以及利用2D关节检测进行3D姿态估计，重点是后者。 本文对这一问题的主要贡献是设计和分析了一种神经网络，它的性能略好于当时的SOTA（当微调检测结果或使用真实值时，效果会更优），并且速度快（大小为64的小批量前向传播需要大约3ms，允许在批处理模式下处理多达300fps的数据），同时易于理解和再现。这种精度和性能飞跃的主要原因是一组简单的想法，例如估计相机坐标系中的3D关节、添加残差连接和使用批量归一化。由于网络简单，这些想法可以与其他不成功的想法（例如估计关节角度）一起快速测试。 先前工作 图像深度 从纯粹的二维刺激中感知深度是一个经典问题。透视线索在计算机视觉中被用来推断任意场景中的长度、面积和距离比。除了透视信息，经典的计算机视觉系统还尝试使用阴影或纹理等其他线索，从单个图像中恢复深度。现代系统通常从监督学习的角度来处理这个问题，让系统推断出哪些图像特征对深度估计最具辨别力。 自顶向下的3D推理 最早的深度估计算法之一采取利用场景中物体的已知三维结构的方式。已经表明，人类在感知抽象为一组稀疏点投影的人体运动时也会使用这种自顶向下的信息。从最小表示（如稀疏的2D投影）中推理3D人体姿态的想法，抽象出其他可能更丰富的图像线索，启发了本工作中解决的基于2D关节的3D姿势估计问题。 2D-to-3D关节映射 Lee和Chen的工作发现，给定骨骼长度，从2d投影推断3d关节的问题归结为一个二叉决策树，其中每个分裂对应于相对于父关节的两种可能状态。这种二叉树可以根据联合约束进行修剪，尽管它很少产生单一的解。Jiang使用了一个大型姿态数据库，基于最近邻查询来解决歧义。Gupta等人（在搜索过程中引入了时间约束）以及Chen和Ramanan最近重新审视了利用最近邻来细化姿态推断结果的想法。从数据集编译关于3D人体姿态知识的另一种方法是通过创建适合于将人体姿态表示为稀疏组合的完备基，将姿态提升到再生核希尔伯特空间（RHKS）[18]，或者通过从极端人体姿态的专门数据集创建新的先验。 基于深度网络的2D到3D关节映射 Pavlakos等人介绍了一种基于堆叠沙漏结构的深度卷积神经网络，该网络不是回归2D关节概率热图，而是映射到3D空间中的概率分布。Moreno Noguer研究从2D到3D空间预测成对距离矩阵（distance matrix，DM）。距离矩阵在旋转、平移和反射之前是不变的；因此，多维缩放与人类姿态的先验互补，以排除不可能的预测。 Moreno Noguer的DM回归方法以及Pavlakos等人的体积方法背后的一个主要动机是，从2D检测中预测3D关键点本质上是困难的。例如，Pavlakos等人提出了一个基线，其中使用了直接的3D关节表示，其结果比使用体积回归的精确得多。 2D-to-3D角姿态 另一个算法分支，用于从图像中推断3D姿势，该图像根据角度（有时是身体形状）来估计身体构造，而不是直接估计关节的3D位置。这些方法的主要优点是，由于人类关节的运动受限，问题的维数较低，并且所得到的估计被迫具有类似人类的结构。此外，使用这种表示法，约束人体结构（如骨骼长度或关节角度范围）相当简单。 本文试验了这种方法；然而实验表明，关节和2D点之间的高度非线性映射使得学习和推理更加困难，计算成本也更高。因此，本文选择直接估计3D关节。 解决方案方法论 本文的目标是在给定二维输入的情况下估计三维空间中的身体关节位置。 形式上，输入是一系列2D关键点，输出是一系列3D空间中的点，目标是学习一个函数，使其在个姿态的数据集上最小化预测误差： 其中，可以通过两种途径获得 已知摄像机参数下的真实2D关节位置 2D关节检测器 本文专注于是深度神经网络的系统，并努力找到一种简单、可扩展和高效的架构，能够很好地完成这项任务。 本文方法——网络设计 图1. 模型架构 图1展示了本文架构的基本构建块的示意图。本文的方法基于简单、深层、多层神经网络，具有批量归一化、Dropout和校正线性单元（RELU）以及残差连接。未描述的是两个额外的线性层：一个直接应用于输入，将其维度增加到1024，另一个应用于最终预测之前，生成大小为的输出。本文的大多数实验中，使用了2个残差块，这意味着总共有6个线性层，该模型包含400~500万个可训练参数。 该架构得益于深度神经网络优化方面的多项相对较新的改进，这些改进主要出现在非常深的卷积神经网络环境下，这些贡献也可以用于提升本文的2D到3D姿态估计任务的泛化性。 2D/3D位置 本文的第一个设计选择是使用2D点作为输入，3D点作为输出，而最近的工作使用原始图像或2D概率分布作为输入，3D概率、3D运动参数或基础姿态系数和相机参数估计作为输出。虽然2D检测携带的信息较少，但它们的低维度使其非常有吸引力。 线性ReLU层 大多数3D人体姿态估计的深度学习方法都基于卷积神经网络，卷积神经网络学习可应用于整个图像或2D关节位置热图的平移不变滤波器。然而，由于我们以低维点作为输入和输出，可以使用更简单、计算成本更低的线性层。ReLU是在深度神经网络中添加非线性的标准选择。 残差连接 残差连接是一种促进非常深卷积神经网络训练的技术，可以提高泛化性能并减少训练时间。在文本的案例中，残差连接帮助减少了大约10%的误差。 批量归一化和Dropout 尽管具有上述三个组件的简单网络利用真实2D位置上训练时，在2D到3D姿态估计上获得了良好的性能。但作者发现，当利用2D检测器的输出训练时，或当利用2D真实位置训练并在有噪声的2D观测上测试时，其性能不佳。批次归一化和Dropout在这两种情况下改善了本文系统的性能，同时导致训练和测试时间略有增加。 最大范数约束 作者对每个层的权重应用了约束，使其最大范数小于等于1。结合批量归一化，我们发现当训练和测试示例之间的分布不同时，可以稳定训练并提高泛化能力。 数据预处理 本文通过减去平均值并除以标准差，将标准归一化应用于2D输入和3D输出。由于我们不对3D预测的全局位置进行预测，因此将3D姿势在髋关节周围归零（与之前的工作和Human3.6M的标准协议一致）。 相机坐标 在作者看来，期望算法推断任意坐标空间中的3D关节位置是不现实的，因为这样的空间的任何平移或旋转都不会导致输入数据的改变。全局坐标系的一个自然选择是相机坐标系，因为这使得不同相机之间的2D-to-3D问题相似，隐含地允许每个相机有更多的训练数据，并防止过拟合到特定的全局坐标系。 2D检测 本文使用Newell等人在MPII数据集上预训练的最先进的堆叠沙漏网络获得2D检测。 与之前的工作类似，本文使用Human3.6M提供的边界框来估计图像中的人物中心。将计算出的中心周围的440×440像素的正方形裁剪到检测器（然后通过堆叠的沙漏将其大小调整为256×256）。这些检测与真实2D位置之间的平均误差为15像素，略高于Moreno Noguer在同一数据集上使用CPM的结果（10像素）。 与CPM相比，堆叠沙漏网络更合适，因为它在MPII数据集上有着稍微更好的结果，它的评估速度大约快10倍。 作者还对Human3.6M数据集（最初在MPII上预训练）上的堆叠沙漏模型进行了微调，在目标数据集上获得了更精确的2D关节检测，并进一步减少了3D姿态估计误差。 作者使用了堆叠沙漏的所有默认参数，但由于GPU的内存限制，迷你批量大小从6减小到3。并将学习率设置为，并训练40000次迭代。 训练细节 作者使用Adam对网络进行了200个epoch的训练，初始学习率为0.001，指数衰减，使用大小为64的小批量。初始化时使用Kaiming初始化设置线性层的权重。作者使用Tensorflow实现了代码，在Titan Xp GPU上，前向与反向传播大约需要5ms，前向传播大约需要2ms。这意味着，加上最先进的实时2D检测器，该的网络可以成为实时运行的全像素到3D系统的一部分。 Kaiming初始化，由我国计算机视觉领域专家何恺明提出。 Kaiming均匀分布的初始化采用，bound由下式计算： 其中用来衡量这一层中负数的比例，负数越多，ReLU层会将越多的输入抹平为0，就是用来衡量这种抹平对方差的影响。 实验评估 数据集和协议 在Human3.6M上，遵循标准方案，使用受试者1、5、6、7和8进行训练，使用受测者9和11进行评估。得到了根关节（中心髋关节）对齐后，所有关节和相机的真实值和预测值之间的平均误差（毫米）。通常，训练和测试在每个动作中独立进行，称其为协议1。然而，在本文的一些基线中，预测已经通过刚性变换与真实值进一步一致，此后处理称为协议2。 在HumanEva中，对所有受试者和每个动作分别进行训练和测试，并且始终在刚性变换后计算误差。 定量结果 2D-to-3D回归的上界 本文的方法基于来自2D关节位置的直接回归，自然地取决于2D姿态检测器的输出质量，并且在使用真实2D关节位置时获得最佳性能。 本文在不同水平的高斯噪声下测试了一个最初用真实2D关节位置训练的系统，结果见表1。 表1. 不同高斯噪声下的测试结果 其中，GT表示真实关节位置；CPM表示级联金字塔网络；SH表示堆叠沙漏结构。表1的上半部分展示了利用2D真实关节位置进行训练和测试时，加入不同等级的高斯噪声情况下的结果；下半部分展示了利用2D真实关节位置进行训练，利用2D检测器的输出进行测试的结果。 虽然每一帧都是独立评估的，而且不使用时间信息，但该网络产生的预测非常平滑。 对检测器噪声的鲁棒性 为了分析方法的鲁棒性，本文试验了用（有噪声的）2D检测器检测的图像来测试系统，系统始终使用真实2D关节位置进行训练。结果见表1的下半部分。 在这种情况下，本文的工作也优于先前的工作，并证明本文的网络在利用真实2D位置进行训练，并在2D检测器的输出上进行测试时可以获得相当好的表现。 利用2D检测器进行训练 在这里，本文最接近的竞争对手是Pavlakos等人的体积预测方法，该方法使用堆叠沙漏结构，在Human3.6M上进行端到端训练，并对所有动作使用单一模型。 即使在使用开箱即用的堆叠沙漏检测时，本文的方法也比这一结果高出4.4 mm，并且当在Human3.6M上微调2D检测器时，将差距提高了一倍多，达到9.0 mm。详细结果见表2。 表2. Human3.6m的协议1的结果 其中，SA表示模型针对每个动作都进行了训练；MA表示使用单个模型对所有动作进行训练；SH表示用堆叠沙漏检测器对系统进行了训练和测试；FT表示2D检测器是微调过的；GT表示使用了真实2D关节位置。 本文的方法在协议2（与真实位置刚性对齐）下的结果见表3。虽然本文的方法比以前的开箱即用检测稍差，但当经过微调后，该方法获得了最好的成绩。 表3. Human3.6m的协议2的结果 其中，14j（17j）表示该身体模型考虑了14（17）个关节；*表示该结果并非取自原论文。 在HumanEva数据集上的结果见表4。 表4. HumanEva上的结果 消融和超参数分析 以未微调的MA模型为基础，表5中给出了消融实验的结果。去掉Dropout或批量归一化会导致误差增加3~8mm；残差连接大约带来8mm的增益。如果不将数据预处理到相机坐标中，则会导致100mm以上的误差。 表5. 消融实验 最后，作者分析了网络对深度和宽度的敏感性。使用单个残差块会导致6mm的损失，使用2个残差块时性能饱和。将线性层减少到512维会导致更差的性能（本文中采取的维度为1024），而具有2048维的层要慢得多，而且似乎不会提高精度。 定性结果 图2给出了Human3.6m的一些定性结果，图3给出了MPII测试集中一些户外场景图像的定性结果。 图2. Human3.6m定性结果 图3. MPII定性结果 在MPII上的结果揭示了本文方法的一些局限性；例如，该系统无法从失败的检测器输出中恢复，并且很难处理与Human3.6M中的任何示例不相似的姿势（例如，人倒立）。 最后，户外场景下大多数人的图像都不是全身的，而是在一定程度上被裁剪出来的。本文的全身姿势训练系统目前无法处理此类情况。 讨论 观察表2可以看出，在所有动作中，使用SH检测进行训练时，相较于使用真实2D关节位置，误差普遍增加。 然而，拍照、打电话、坐着和坐下的动作却有了特别大的增长。我们假设这是由于这些动作中的严重自遮挡——例如，在一些电话序列中，我们永远看不到演员的一只手。类似地，在坐着和坐下时，腿通常与相机视点对齐，这会导致透视上的大幅缩短。 进一步改进 一个改进方向是，堆叠沙漏结构最终产生大小为64×64的关节检测热图，因此更大的输出分辨率可能会带来更细粒度的检测，从而使本文的系统更接近在使用2D真实关节位置训练时的性能。 另一个方向是，使用2D堆叠沙漏热图中的多个样本来估计期望的梯度——即强化学习中常用的策略梯度——从而端到端地训练网络。另一个想法是使用3D mocap数据库和“假”相机参数来模拟2D检测器的输出，以进行数据增强，可遵循Shrivastava等人的对抗方法。 尝试结合地估计场景中每个人的深度是一条有趣的研究路径，因为这将允许本文的系统对多人进行3D姿态估计。最后，本文的架构很简单，对网络设计的进一步研究可能会在2D-to-3D系统上产生更好的结果。","link":"/posts/5750/"},{"title":"AscendC算子开发及单算子调用","text":"摘要记录一下Ascend C的学习过程，整体来说Ascend C的核心部分还是比较易用的，唯一的小缺点就是学习初期不得不被一些无关算子核心逻辑的工程文件所干扰。 Ascend C算子开发 笔者在阅读Ascend C官方文档的过程中发现，对于初学者来说，尤其是第一次接触异构编程思想的初学者，有很大一部分内容是无需开发者关注的，例如算子工程的相关的CmakeLists.txt，以及单算子调用的一些通用工具类等文件。同时，在环境配置的过程中，也发现了一些需要注意的地方，特此记录备忘。 环境准备 笔者的硬件及系统环境如下： 操作系统：openEuler release 20.03 (LTS-SP3) 设备：Ascend 910B 开发环境需要准备三个run包，分别是驱动、固件和cann-toolkit开发套件，笔者这里使用当前的最新版CANN包，版本号为7.0.RC1.alpha003。并在官网下载好对应的驱动和固件的run包。 安装流程 上述准备的三个包，按照驱动 -&gt; 固件 -&gt; CANN包的顺序来安装。 首先安装驱动，执行如下命令： 1/path/to/Ascend-hdk-910-npu-driver_23.0.rc2_linux-aarch64.run --full --install-for-all 注意：笔者使用root用户进行安装，以full模式执行run包，并加上install-for-all选项来为所有用户安装。 接下来安装固件： 1/path/to/Ascend-hdk-910-npu-firmware_6.4.12.1.241.run --full 驱动和固件都安装完成后，最好重启一次系统： 1reboot 重启完成后，安装CANN包： 1path/to/Ascend-cann-toolkit_7.0.RC1.alpha003_linux-aarch64.run --full --install-for-all 安装完成后，开发环境就准备好了。 安装过程中可能的问题 笔者在安装过程中，遇到了一个问题，很蠢，但值得注意。 问题的表现是，在按照上述的流程安装好开发环境之后，除root用户外的其他普通用户使用msopgen工具生成算子工程时，出现了权限不足的问题。但因为加上了install-for-all选项，所以不应该是CANN包的权限问题。然后又查看msopgen的代码发现，该工具将python解释器指定为了root用户下的conda环境中的解释器。 12345678#!/root/miniconda3/bin/python3# coding=utf-8\"\"\"Function:This file mainly involves main function of op generation module.Copyright Information:Huawei Technologies Co., Ltd. All Rights Reserved © 2020\"\"\" 原来是root用户下的conda配置为了默认激活base环境，笔者安装时没有注意这一点，导致在CANN包安装的过程中，选择到了conda环境下的python解释器，这样一来，其他用户肯定是没有权限的。在关闭base环境重新安装CANN包后，问题解决。 算子开发流程 至此，环境准备好后，开始正式的算子开发步骤。 算子工程配置文件 CANN包中提供了一个自动生成算子工程的工具msopgen，该工具可以通过一个json配置文件来生成完整的算子工程，具体的编写方式请参考官方文档。 这里以sinh算子为例，该算子是一元操作，所以只需要一个输入，且输出形状与输入形状一致。根据该特征来编写json文件，为了贴合Ascend C官方建议的编程范式，将文件命名为sinh_custom.json。为了简洁，这里我们只实现一种数据类型的操作。 123456789101112131415161718192021222324252627282930[ { \"op\": \"SinhCustom\", \"language\": \"cpp\", \"input_desc\": [ { \"name\": \"x\", \"param_type\": \"required\", \"format\": [ \"ND\" ], \"type\": [ \"fp16\" ] } ], \"output_desc\": [ { \"name\": \"y\", \"param_type\": \"required\", \"format\": [ \"ND\" ], \"type\": [ \"fp16\" ] } ] }] 生成算子工程 创建一个文件夹用作算子工程目录，使用msopgen工具执行如下命令来生成算子工程。 12mkdir /path/to/SinhCustom/path/to/msopgen gen -i /path/to/sinh_custom.json -c ai_core-Ascend910B -lan cpp -out /path/to/SinhCustom 命令行会输出类似如下的信息： 1234567891011121314152023-10-07 14:58:42 (942445) - [INFO] Start to generate AI Core operator files.2023-10-07 14:58:42 (942445) - [INFO] Start to parse the ir template:/path/to/SinhCustom/sinh_custom.json2023-10-07 14:58:42 (942445) - [INFO] Start to parse the op: SinhCustom2023-10-07 14:58:42 (942445) - [INFO] Start to parse the input_desc: x2023-10-07 14:58:42 (942445) - [INFO] Start to parse the output_desc: y2023-10-07 14:58:42 (942445) - [WARNING] The \"attr\" value is invalid or no \"attr\" exists in the map.2023-10-07 14:58:42 (942445) - [INFO] Start to check the type and format between the inputs/outputs in IR template.2023-10-07 14:58:42 (942445) - [INFO] Start to generate a new project.2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/cmake/config.cmake generated successfully.2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/op_host/sinh_custom_tiling.h generated successfully.2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/op_host/sinh_custom.cpp generated successfully.2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/op_kernel/sinh_custom.cpp generated successfully.2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/framework/tf_plugin/tensorflow_sinh_custom_plugin.cc generated successfully.2023-10-07 14:58:42 (942445) - [INFO] File /path/to/SinhCustom/framework/tf_plugin/CMakeLists.txt generated successfully.2023-10-07 14:58:42 (942445) - [INFO] Generation completed. 此时会发现指定的输出目录只已经生成了一系列的算子工程文件。 123456789101112131415SinhCustom├── build.sh├── cmake├── CMakeLists.txt├── CMakePresets.json # 这个配置项需要修改├── framework├── op_host│ ├── CMakeLists.txt│ ├── sinh_custom.cpp # 算子host侧核心逻辑│ └── sinh_custom_tiling.h # 算子tiling结构体定义├── op_kernel│ ├── CMakeLists.txt│ └── sinh_custom.cpp # 算子kernel侧核心逻辑├── scripts└── sinh_custom.json # 笔者此处将工程配置文件和算子工程目录放在了一起 我们只需要专注于上述带有注释的几个文件即可。 此处先修改与算子核心逻辑无关的配置项CMakePresets.json，官方文档中也描述的非常清楚，只需要将ASCEND_CANN_PACKAGE_PATH配置项修改为实际的CANN包安装路径即可。在root用户下安装的默认路径为/usr/local/Ascend/ascend-toolkit/latest。 以上将所有无关算子逻辑的内容修改完毕，接下来就可以专注于算子开发了。 算子逻辑开发 官方文档中推荐先实现kernel侧的逻辑，但笔者有一些不同的看法。我推荐先实现算子tiling结构体的定义与具体策略，这样做的好处是，可以提前将tiling策略所需的变量确定下来，并且借助于CANN包只提供的一系列宏，这一过程并不需要很大的工作量。在实现kernel侧逻辑的过程中，这些变量将有助于思考数据在逻辑核上如何具体分配和执行，当然这只是笔者的观点，可以根据自己的编程习惯来作调整。 tiling结构体定义及策略实现 首先确定tiling过程中所需的变量，参考官方样例，需要定义整块、尾块的个数及其中的元素个数，还需要定义最小对齐单位。op_host/sinh_custom_tiling.h代码如下： 123456789101112131415161718#ifndef SINH_CUSTOM_TILING_H // 头文件保护记得加上，自动生成的文件中不包含#define SINH_CUSTOM_TILING_H#include \"register/tilingdata_base.h\"namespace optiling{ BEGIN_TILING_DATA_DEF(TilingData) TILING_DATA_FIELD_DEF(uint32_t, formerNum); // 整块个数 TILING_DATA_FIELD_DEF(uint32_t, tailNum); // 尾块个数 TILING_DATA_FIELD_DEF(uint32_t, formerLength); // 整块内元素个数 TILING_DATA_FIELD_DEF(uint32_t, tailLength); // 尾块内元素个数 TILING_DATA_FIELD_DEF(uint32_t, alignNum); // 最小对齐单位，元素个数 END_TILING_DATA_DEF; REGISTER_TILING_DATA_CLASS(SinhCustom, TilingData)}#endif 然后在op_host/sinh_custom.cpp中实现具体的tiling策略，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839namespace optiling{ constexpr uint32_t BLOCK_DIM = 24; // 划分核心数量 constexpr uint32_t SIZE_OF_HALF = 2; // 数据类型的字节数 constexpr uint32_t BLOCK_SIZE = 32; // 昇腾设备上的数据block为32字节 constexpr uint32_t ALIGN_NUM = BLOCK_SIZE / SIZE_OF_HALF; // 最小对齐单位 static ge::graphStatus TilingFunc(gert::TilingContext *context) { TilingData tiling; uint32_t totalLength = context-&gt;GetInputTensor(0)-&gt;GetShapeSize(); context-&gt;SetBlockDim(BLOCK_DIM); // 使输入向上对齐 uint32_t totalLengthAligned = ((totalLength + ALIGN_NUM - 1) / ALIGN_NUM) * ALIGN_NUM; // 计算整块和尾块个数 uint32_t formerNum = (totalLengthAligned / ALIGN_NUM) % BLOCK_DIM; uint32_t tailNum = BLOCK_DIM - formerNum; // 计算整块和尾块的元素个数 uint32_t formerLength = ((totalLengthAligned / BLOCK_DIM + ALIGN_NUM - 1) / ALIGN_NUM) * ALIGN_NUM; uint32_t tailLength = (totalLengthAligned / BLOCK_DIM / ALIGN_NUM) * ALIGN_NUM; // 设置tiling参数 tiling.set_formerNum(formerNum); tiling.set_tailNum(tailNum); tiling.set_formerLength(formerLength); tiling.set_tailLength(tailLength); tiling.set_alignNum(ALIGN_NUM); // 以下为固定写法，不用纠结 tiling.SaveToBuffer(context-&gt;GetRawTilingData()-&gt;GetData(), context-&gt;GetRawTilingData()-&gt;GetCapacity()); context-&gt;GetRawTilingData()-&gt;SetDataSize(tiling.GetDataSize()); context-&gt;SetTilingKey(1); size_t *currentWorkspace = context-&gt;GetWorkspaceSizes(1); currentWorkspace[0] = 0; return ge::GRAPH_SUCCESS; }} kernel侧实现 有了上述实现的tiling策略，我们就可以根据数据划分的逻辑来确定kernel侧的具体实现。根据官方推荐的矢量编程范式，我们可以先将算子类的框架写出来，再慢慢填充内容。在op_kernel/sinh_custom.cpp中写出算子类框架。 123456789101112131415161718192021using namespace AscendC; // 记得开启AscendC命名空间constexpr int32_t BUFFER_NUM = 2; // TQue的缓冲数量，此处开启双Bufferclass KernelSinh{public: __aicore__ inline KernelSinh() {} // 类构造函数，无须任何代码 __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, // 初始化函数的参数为输入、输出 uint32_t formerNum, uint32_t tailNum, // 以及上面定义的一系列tiling参数 uint32_t formerLength, uint32_t tailLength, uint32_t alignNum) { /* TODO */ } __aicore__ inline void Process() { /* TODO */ }private: __aicore__ inline void CopyIn() { /* TODO */ } __aicore__ inline void Compute() { /* TODO */ } __aicore__ inline void CopyOut() { /* TODO */ }private: /* TODO */}; 第一步应该做的是分析算子类的私有数据成员，首先一定需要的是用来管理内存的Tpipe，同时需要输入输出分别对应的TQue和GlobalTensor，同时每个逻辑核还 需要直到当前处理的数据个数，所以需要一个变量tileLength来确定分片大小。 再来分析算子，公式如下所示。 可以观察到，我们需要计算两个中间结果，分别是和，所以需要相应的数据结构来存放这两个中间结果，Ascend C提供的TBuf可以很好的承担这一责任。 至此我们就将算子类需要的私有数据成员确定了下来。 1234567TPipe pipe; // 用于操作队列TBuf&lt;QuePosition::VECCALC&gt; tempBuf; // 存放中间结果TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX; // 输入队列TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY; // 输出队列GlobalTensor&lt;DTYPE_X&gt; xGm; // 输入数据对应的GM内存空间GlobalTensor&lt;DTYPE_Y&gt; yGm; // 输出数据对应的GM内存空间uint32_t tileLength; // 每个逻辑核需要知道分片数据个数 接下来要做的是完善算子类的初始化函数Init()，在该函数中我们需要为GlobalTensor分配内存，并初始化相应的TQue，同时需要针对某些变量做合法性判断。 123456789101112131415161718192021222324__aicore__ inline void Init(GM_ADDR x, GM_ADDR y, uint32_t formerNum, uint32_t tailNum, uint32_t formerLength, uint32_t tailLength, uint32_t alignNum){ if (GetBlockIdx() &lt; formerNum) { // 处理整块逻辑 this-&gt;tileLength = formerLength; xGm.SetGlobalBuffer((__gm__ DTYPE_X *)x + formerLength * GetBlockIdx(), formerLength); yGm.SetGlobalBuffer((__gm__ DTYPE_Y *)y + formerLength * GetBlockIdx(), formerLength); } else { // 处理尾块逻辑 this-&gt;tileLength = tailLength; xGm.SetGlobalBuffer((__gm__ DTYPE_X *)x + formerLength * formerNum + tailLength * (GetBlockIdx() - formerNum), tailLength); yGm.SetGlobalBuffer((__gm__ DTYPE_Y *)y + formerLength * formerNum + tailLength * (GetBlockIdx() - formerNum), tailLength); } ASSERT(alignNum != 0 &amp;&amp; \"align num can not be zero!\"); pipe.InitBuffer(inQueueX, BUFFER_NUM, (((this-&gt;tileLength + alignNum - 1) / alignNum) * alignNum) * sizeof(half)); pipe.InitBuffer(outQueueY, BUFFER_NUM, (((this-&gt;tileLength + alignNum - 1) / alignNum) * alignNum) * sizeof(half));} 再然后就是算子最核心的部分——计算逻辑，分别实现矢量编程范式的三步骤。 123456789101112131415161718192021222324252627282930313233__aicore__ inline void CopyIn(){ LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.AllocTensor&lt;DTYPE_X&gt;(); DataCopy(xLocal, xGm, this-&gt;tileLength); // GM -&gt; LM inQueueX.EnQue&lt;DTYPE_X&gt;(xLocal);}__aicore__ inline void Compute(){ LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.DeQue&lt;DTYPE_X&gt;(); LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.AllocTensor&lt;DTYPE_Y&gt;(); pipe.InitBuffer(tempBuf, this-&gt;tileLength * sizeof(DTYPE_X)); LocalTensor&lt;DTYPE_X&gt; tempLocal = tempBuf.Get&lt;DTYPE_X&gt;(this-&gt;tileLength); // 计算exp(x) Exp(yLocal, xLocal, this-&gt;tileLength); // 计算-x half nagOne(-1.0); Muls(tempLocal, xLocal, nagOne, this-&gt;tileLength); // 计算exp(-x) Exp(tempLocal, tempLocal, this-&gt;tileLength); // 计算exp(x)-exp(-x) Sub(yLocal, yLocal, tempLocal, this-&gt;tileLength); // 计算最终结果 half denominator(0.5); Muls(yLocal, yLocal, denominator, this-&gt;tileLength); outQueueY.EnQue&lt;DTYPE_Y&gt;(yLocal); inQueueX.FreeTensor(xLocal);}__aicore__ inline void CopyOut(){ LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.DeQue&lt;DTYPE_Y&gt;(); DataCopy(yGm, yLocal, this-&gt;tileLength); // LM -&gt; GM outQueueY.FreeTensor(yLocal);} 实现的具体细节与接口可以参考官方文档。 最后再将Process()函数补全，并完善核函数。 123456__aicore__ inline void Process(){ CopyIn(); Compute(); CopyOut();} 1234567891011121314extern \"C\" __global__ __aicore__ voidsinh_custom(GM_ADDR x, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling){ GET_TILING_DATA(tiling_data, tiling); KernelSinh op; op.Init(x, y, tiling_data.formerNum, tiling_data.tailNum, tiling_data.formerLength, tiling_data.tailLength, tiling_data.alignNum); if (TILING_KEY_IS(1)) { op.Process(); }} 至此就完成了kernel侧的实现。 host侧实现 我们回到op_host/sinh_custom.cpp，关于类型推导函数，这个算子输入输出的形状一致。msopgen生成的算子工程中，默认即为输入输出形状一致，所以无须改动。如果在写其他复杂算子的时候，需要仔细分析数据形状的变化。关于算子原型注册，也无须改动。 现在就完成了整个算子的逻辑，可以执行build.sh来验证有没有编译时错误，若没有错误则可以进行运行时验证。 核函数调用 笔者直接将官方的核函数调用样例拿来做了一些修改，需要修改的地方如下。 1234567891011kernel_invocation├── cmake├── CMakeLists.txt├── data_utils.h├── input├── main.cpp # 需要修改├── output├── run.sh # 需要修改├── add_custom.cpp # 替换为自己的算子实现├── add_custom.py # 需要修改└── verify_result.py # 添加的代码，用于验证结果 将官方样例中的add_custom.cpp替换为自己实现的kernel侧算子，笔者这里的名称为sinh_custom.cpp。同时为了CPU侧调试，需要添加一个核函数的包装函数，代码如下。 123456#ifndef __CCE_KT_TEST__void sinh_custom_do(uint32_t blockDim, void *l2ctrl, void *stream, uint8_t *x, uint8_t *y){ sinh_custom&lt;&lt;&lt;blockDim, l2ctrl, stream&gt;&gt;&gt;(x, y);}#endif 注意：为了快速验证逻辑，在核函数验证过程中未使用动态tiling，所以没有之前提到的那些tiling参数。 然后是sinh_custom.py，官方样例中是add_custom.py，这里修改文件名称，因为后面的run.sh中是通过算子文件名来调用这一python脚本的。 由于本算子只需要一个输入向量，所以只生成一个input数据，然后修改golden数据的生成方式，调用numpy中与算子功能相同的函数来计算，注意数据类型，代码如下。 1234567891011121314import numpy as npdef gen_golden_data_simple(): np.random.seed(42) input_x = np.random.randn(8, 2048).astype(np.float16) golden = np.sinh(input_x).astype(np.float16) print(f'-----------------------{input_x[0][0]}') input_x.tofile(\"./input/input_x.bin\") golden.tofile(\"./output/golden.bin\")if __name__ == \"__main__\": gen_golden_data_simple() main.cpp中要调整相应的内存申请等操作，只需要一个input，CPU侧调试和NPU侧调试的代码都需要修改，具体如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;stdio.h&gt;#include \"data_utils.h\"#ifndef __CCE_KT_TEST__#include \"acl/acl.h\"extern void sinh_custom_do(uint32_t coreDim, void *l2ctrl, void *stream, uint8_t *x, uint8_t *y);#else#include \"tikicpulib.h\"extern \"C\" __global__ __aicore__ void sinh_custom(GM_ADDR x, GM_ADDR y);#endifint32_t main(int32_t argc, char *argv[]){ size_t inputByteSize = 8 * 2048 * sizeof(uint16_t); size_t outputByteSize = 8 * 2048 * sizeof(uint16_t); uint32_t blockDim = 8;#ifdef __CCE_KT_TEST__ uint8_t *x = (uint8_t *)AscendC::GmAlloc(inputByteSize); uint8_t *y = (uint8_t *)AscendC::GmAlloc(outputByteSize); ReadFile(\"./input/input_x.bin\", inputByteSize, x, inputByteSize); AscendC::SetKernelMode(KernelMode::AIV_MODE); ICPU_RUN_KF(sinh_custom, blockDim, x, y); WriteFile(\"./output/output_y.bin\", y, outputByteSize); AscendC::GmFree((void *)x); AscendC::GmFree((void *)y);#else CHECK_ACL(aclInit(nullptr)); aclrtContext context; int32_t deviceId = 0; CHECK_ACL(aclrtSetDevice(deviceId)); CHECK_ACL(aclrtCreateContext(&amp;context, deviceId)); aclrtStream stream = nullptr; CHECK_ACL(aclrtCreateStream(&amp;stream)); uint8_t *xHost, *yHost; uint8_t *xDevice, *yDevice; CHECK_ACL(aclrtMallocHost((void **)(&amp;xHost), inputByteSize)); CHECK_ACL(aclrtMallocHost((void **)(&amp;yHost), outputByteSize)); CHECK_ACL(aclrtMalloc((void **)&amp;xDevice, inputByteSize, ACL_MEM_MALLOC_HUGE_FIRST)); CHECK_ACL(aclrtMalloc((void **)&amp;yDevice, outputByteSize, ACL_MEM_MALLOC_HUGE_FIRST)); ReadFile(\"./input/input_x.bin\", inputByteSize, xHost, inputByteSize); CHECK_ACL(aclrtMemcpy(xDevice, inputByteSize, xHost, inputByteSize, ACL_MEMCPY_HOST_TO_DEVICE)); sinh_custom_do(blockDim, nullptr, stream, xDevice, yDevice); CHECK_ACL(aclrtSynchronizeStream(stream)); CHECK_ACL(aclrtMemcpy(yHost, outputByteSize, yDevice, outputByteSize, ACL_MEMCPY_DEVICE_TO_HOST)); WriteFile(\"./output/output_y.bin\", yHost, outputByteSize); CHECK_ACL(aclrtFree(xDevice)); CHECK_ACL(aclrtFree(yDevice)); CHECK_ACL(aclrtFreeHost(xHost)); CHECK_ACL(aclrtFreeHost(yHost)); CHECK_ACL(aclrtDestroyStream(stream)); CHECK_ACL(aclrtDestroyContext(context)); CHECK_ACL(aclrtResetDevice(deviceId)); CHECK_ACL(aclFinalize());#endif return 0;} 原样例中的验证方式是求md5和，但由于核函数中调用了Exp、Muls等API，所以精度可能会有损失，不适合用md5sum的方式来验证。这里就需要引入新的文件verify_result.py，这里使用了numpy.isclose函数来进行验证，这也是官方单算子API调用的结果验证方式。 1234567891011121314151617181920212223242526272829303132333435363738import sysimport mathimport numpy as npdef data_compare(file1, file2,file3): input1 = np.fromfile(file1, dtype=np.float16) print(\"input1: \", input1) golden = np.fromfile(file2, dtype=np.float16) output = np.fromfile(file3, dtype=np.float16) print(\"output: \", output) print(\"-------------golden is :\") print(\"golden: \", golden) different_element_results = np.isclose( output, golden, rtol=5e-2, atol=1e-3, equal_nan=True) different_element_indexes = np.where( different_element_results != np.array((True,)))[0] if different_element_indexes.size == 0: print(\"result correct!\") else: print(\"result error!\") return 0 if different_element_indexes.size == 0 else 1if __name__ == '__main__': intput_file1 = sys.argv[1] golden_file = sys.argv[2] output_file = sys.argv[3] cmp_result = data_compare(intput_file1, golden_file, output_file) if (cmp_result == 0): sys.exit(0) else: sys.exit(1) 最后是修改run.sh脚本，需要修改的只有最后验证结果的部分。原样例的验证方式是md5sum。 1echo \"md5sum: \";md5sum output/*.bin 修改为调用脚本判断。 12echo \"result verification: \"python3 verify_result.py ./input/input_x.bin ./output/golden.bin ./output/output_y.bin 单算子API调用 单算子调用是通过自动生成的两段式API来执行的，为了快速验证，同样是将官方样例中的单算子API调用样例拿来做了一些修改。需要修改的几处关键代码如下。 123456789101112131415161718192021aclnn_online_model├── build├── inc├── README.md├── run│ └── out│ ├── execute_sinh_op│ ├── result_files│ └── test_data│ ├── config│ └── data│ ├── generate_data.py # 生成测试数据脚本，需要修改├── run.sh # 需要修改├── scripts│ └── verify_result.py # 调整验证方式，例如相对和绝对误差参数等└── src ├── CMakeLists.txt # 需要修改 ├── common.cpp ├── main.cpp # 需要修改 ├── operator_desc.cpp └── op_runner.cpp # 需要修改 具体细节如下。 generate_data.py中，按照算子来修改测试数据生成方式。本算子需要half类型的测试数据，故代码改为： 12345import numpy as npa = np.random.randn(8, 2048).astype(np.float16)a.tofile('input_0.bin') verify_result.py中，根据实际读取的输入和输出，利用np.isclose来进行比较，该函数详细用法参考numpy官方文档。 123456789101112131415161718192021222324252627282930313233import sysimport mathimport numpy as npdef data_compare(file1, file2): input1 = np.fromfile(file1, dtype=np.float16) print(\"input1: \", input1) golden = np.sinh(input1).astype(np.float16) output = np.fromfile(file2, dtype=np.float16) print(\"output: \", output) print(\"-------------golden is :\") print(\"golden: \", golden) different_element_results = np.isclose( output, golden, rtol=5e-2, atol=1e-3, equal_nan=True) different_element_indexes = np.where( different_element_results != np.array((True,)))[0] return 0 if different_element_indexes.size == 0 else 1if __name__ == '__main__': intput_file1 = sys.argv[1] output_file = sys.argv[2] cmp_result = data_compare(intput_file1, output_file) if (cmp_result == 0): sys.exit(0) else: sys.exit(1) main.cpp中，需要将CreateOpDesc()函数根据具体的输入输出来做修改。 12345678910OperatorDesc CreateOpDesc(){ std::vector&lt;int64_t&gt; shape{8, 2048}; aclDataType dataType = ACL_FLOAT16; aclFormat format = ACL_FORMAT_ND; OperatorDesc opDesc; opDesc.AddInputTensorDesc(dataType, shape.size(), shape.data(), format); opDesc.AddOutputTensorDesc(dataType, shape.size(), shape.data(), format); return opDesc;} op_runner.cpp中将两段式API修改为自己算子的API，请善用Ctrl + F搜索关键代码进行修改，具体的API名称可以查看算子目录下的build_out/autogen目录。 1234567891011...auto ret = aclnnSinhCustomGetWorkspaceSize(inputTensor_[0], outputTensor_[0], &amp;workspaceSize, &amp;handle);...INFO_LOG(\"Execute aclnnSinhCustomGetWorkspaceSize success, workspace size %lu\", workspaceSize);...if (aclnnSinhCustom(workspace, workspaceSize, handle, stream) != ACL_SUCCESS){ ...}INFO_LOG(\"Execute aclnnSinhCustom success\");... 接着修改src/CMakeLists.txt。 1234567891011121314151617181920set(AUTO_GEN_PATH \"../SinhCustom/build_out/autogen\") # 16行# 50行以后，修改可执行文件的名称add_executable(execute_sinh_op ${AUTO_GEN_PATH}/aclnn_sinh_custom.cpp operator_desc.cpp op_runner.cpp main.cpp op_runner.cpp common.cpp)target_link_libraries(execute_sinh_op ascendcl acl_op_compiler nnopbase stdc++)install(TARGETS execute_sinh_op DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}) 最后修改run.sh脚本中关于路径的部分。修改完成后，就可以执行run.sh脚本进行单算子API调用了。 123456INFO: acl executable run success!input1: [ 0.468 -0.2585 -3.066 ... 0.9136 -1.117 -1.368 ]output: [ 0.485 -0.2615 -10.71 ... 1.047 -1.365 -1.837 ]-------------golden is :golden: [ 0.4854 -0.2615 -10.71 ... 1.046 -1.364 -1.837 ]INFO: compare golden data success! 出现上述提示证明算子通过验证。","link":"/posts/19902/"},{"title":"CUDA编程——NVCC编译器","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 使用NVCC编译 核函数可以使用CUDA指令集架构（PTX）撰写，也可以使用C++撰写，两种方式都需要使用nvcc编译器编译。nvcc简化了编译PTX或C++代码的过程。 PTX（Parallel Thread Execution）是CUDA平台为基于GPU通用计算而定义的虚拟机和指令集，类似于针对GPU的汇编代码。 在编译CUDA C++程序时，nvcc会将设备代码编译为PTX代码，以适应更多的实际架构，再将PTX代码编译为cubin对象进行执行与调用。从CUDA C++编译为PTX代码的过程是与实际GPU设备无关的。 编译工作流 离线编译 nvcc编译的源文件可以同时包含主机代码和设备代码，它会将两者自动分离。 将设备代码编译成汇编形式（PTX代码）或二进制形式（cubin对象）； 修改主机代码，通过CUDA运行时函数调用替换&lt;&lt;&lt;...&gt;&gt;&gt;，从PTX代码或cubin对象中加载和启动编译后的核函数。 修改后的主机代码要么作为C++代码输出，留给其他工具编译，要么直接作为目标代码输出，令nvcc在最后的编译阶段调用主机的编译器。 应用程序可以： 链接到编译后的主机代码（最常见的情况）； 或忽略修改后的主机代码，并使用CUDA驱动程序API加载和执行PTX代码或cubin对象。 即时编译 即时编译大多情况是针对PTX代码的，这里不过多赘述，详见Just-in-Time Compilation。 NVRTC（CUDA C++的运行时编译库）可以在运行时将CUDA C++设备代码编译为PTX代码，是作为nvcc编译CUDA C++设备代码的替代方案的。 二进制兼容性 二进制代码是特定于体系结构的，可以使用编译器的-code选项生产cubin对象。例如使用-code=sm_80可以针对计算能力为8.0的设备编译生成二进制代码。 二进制代码对计算能力的小版本是向前兼容的，但小版本无法向后兼容，大版本之间也无法兼容。即为计算能力X.y的设备生成的二进制代码，只能在计算能力X.z的设备上执行，其中。 PTX兼容性 某些PTX指令只在具有更高计算能力的设备上支持，包含这些指令的代码必须使用编译器的-arch选项指定合适的计算能力。 为某些特定计算能力生成的PTX代码可以被编译为具有更大或相同计算能力设备的二进制代码。但从较早版本的PTX代码编译而来的二进制文件可能不会利用某些硬件新特性，可能导致性能不如使用新版PTX代码编译的二进制文件。 应用程序兼容性 要在具有特定计算能力的设备上执行代码，应用程序必须加载与该计算能力兼容的二进制或PTX代码，如果要考虑将代码在未来的体系结构上执行，则尽量选择即时编译。 使用编译器的-arch和-code选项或-gencode选项来控制将哪些PTX代码嵌入到CUDA C++应用程序中。 1234nvcc x.cu -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=\\\"compute_70,sm_70\\\" 嵌入二进制代码兼容5.0和6.0的计算能力设备，PTX和二进制代码兼容7.0的计算能力设备。 主机代码会在运行时加载和执行最合适的代码，以上述编译命令为例： 计算能力5.0和5.2的设备会选择5.0的二进制代码； 计算能力6.0和6.1的设备会选择6.0的二进制代码； 计算能力7.0和7.5的设备会选择7.0的二进制代码； 计算能力8.0和8.6的设备会选择编译为二进制代码的PTX代码。 nvcc编译器的-arch，-code和-gencode选项有一些简写方式，例如-arch=sm_70是-arch=compute_70 -code=compute70,sm_70的简写，等价于-gencode arch=compute_70,code=\\\"compute_70,sm_70\\\"。 使用-arch=compute_XY来指定一个虚拟架构的计算能力，用-code=sm_XY来指定一个实际架构的计算能力。 虚拟架构应该尽可能低，以适配更多计算能力的设备； 真实架构应该尽可能高，以充分发挥GPU的实际计算能力。 例如nvcc helloworld.cu -o helloworld -arch=compute_61编译出的可执行文件只能在计算能力大于等于6.1的设备上执行。 指定实际架构计算能力时必须指定虚拟架构计算能力，并且实际架构计算能力必须不小于虚拟架构计算能力。 例如nvcc helloworld.cu -o helloworld -arch=compute_61 -code=sm_60将是不合法的编译命令。 nvcc可以同时指定多个GPU版本进行编译，使得编译出来的可执行文件能够在不同计算能力的设备上执行。使用编译器选项-gencode arch=compute_XY,code=sm_XY来指定各个版本的计算能力。注意与-gencode arch=compute_XY,code=compute_XY选项的差异，随后会介绍这个差异。 例如 1234nvcc helloworld.cu -o helloworld_fat \\ -gencode arch=compute_50,code=sm_52 \\ -gencode arch=compute_60,code=sm_61 \\ -gencode arch=compute_80,code=sm_89 上面的编译命令编译出的可执行文件包含3个二进制版本，称为胖二进制文件（fatbinary）。在该例子中，执行该编译命令的CUDA版本必须支持8.9的计算能力。 上面的例子中，每个-gencode分别指定了虚拟架构和实际架构的计算能力，这样可以针对不同的实际架构编译出不同的二进制文件，并将这些二进制文件整合进一个胖二进制文件中。 而对于选项-gencode arch=compute_XY,code=compute_XY，注意arch和code选项的值均为compute_XY即虚拟架构，且arch和code指定的compute_XY必须完全一致。 回看官方文档中的例子： 1234nvcc x.cu -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=\\\"compute_70,sm_70\\\" 前两个-gencode编译出了针对实际架构计算能力5.0和6.0的二进制代码，最后一个-gencode编译出了针对实际架构计算能力7.0的二进制代码，和针对虚拟架构计算能力7.0的PTX代码，当一个计算能力更高的设备（如8.0）来调研该胖二进制文件时，由于没有针对更高计算能力的二进制代码，故会自动选择编译好的PTX代码，采用即时编译的方式为更高计算能力的设备编译二进制代码并调用执行。 当不指定任何虚拟架构和实际架构的计算能力时，会指定为所使用的CUDA版本的默认值，具体的默认值可以在官方文档中找到。 另外，关于PTX代码，可以使用nvcc的-ptx选项，将.cu文件编译为一个.ptx文件，其中存放的就是PTX代码。 例如nvcc hellowrold.cu -ptx。 详细代码见compute_capability.cu与compute_capability.ptx。 C++兼容性 编译器前端按照C++语法规则处理CUDA源文件，主机代码支持完整的C++，而设备代码仅支持C++的一个子集。 64位兼容性 64位版本的nvcc会以64位模式编译设备代码，64位模式编译的设备代码只支持64位模式编译的主机代码。","link":"/posts/50741/"},{"title":"CUDA编程——GPU加速库和OpenACC","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 CUDA库概述 CUDA支持的库及其作用域如下表所示。 库名 作用域 官方文档 NVIDIA CUDA Math Library 数学运算 https://docs.nvidia.com/cuda/cuda-math-api/index.html NVIDIA cuBLAS 线性代数 https://docs.nvidia.com/cuda/cublas/index.html NVIDIA cuSPARSE 稀疏线性代数 https://docs.nvidia.com/cuda/cusparse/index.html NVIDIA CUSP 稀疏线性代数和图形计算 https://cusplibrary.github.io/index.html NVIDIA cuFFT 快速傅里叶变换 https://docs.nvidia.com/cuda/cufft/index.html NVIDIA cuRAND 随机数生成 https://docs.nvidia.com/cuda/curand/index.html NVIDIA NPP 图像和信号处理 https://docs.nvidia.com/cuda/npp/index.html MAGMA 新一代线性代数 https://icl.utk.edu/magma/ IMSL Fortran Numerical Library 数学与统计学 https://www.imsl.com/products/imsl-fortran-libraries AccelerEyes ArrayFire 数学，信号和图像处理，统计学 https://arrayfire.com/ Thrust 并行算法和数据结构 https://docs.nvidia.com/cuda/thrust/index.html Geometry Performance Primitives 计算几何 https://developer.nvidia.com/geometric-performance-primitives-gpp Paralution 稀疏迭代方法 https://www.paralution.com/ AmgX 核心求解 https://github.com/NVIDIA/AMGX CUDA的库有一些通用的工作流： 在库操作中创建一个特定的库句柄来管理上下文信息； 为库函数的输入输出分配设备内存； 如果输入格式不是函数库支持的格式则需要进行转换； 将输入以支持的格式填入预先分配的设备内存中； 配置要执行的库运算； 执行一个将计算部分交付给GPU的库函数调用； 取回设备内存中的计算结果（结果可能是库设定的格式）； 如有必要，将取回的数据转换成应用程序的原始格式； 释放CUDA资源； 继续完成应用程序的其他工作。 cuSPARSE库 较新版本的cuSPARSE将API分为了两大类： Legacy：这部分接口是为了兼容旧版本所保留的，在未来的版本也不会改进； Generic：这部分是cuSPARSE的标准接口。 下面的讨论都基于Generic系列接口。 Generic系列接口大体分为几类： 稀疏向量与稠密向量之间的操作（Axpby、Gather、Scatter、求和、点积）； 稀疏向量与稠密矩阵之间的操作（乘积）； 稀疏矩阵与稠密向量之间的操作（乘积、三角线性方程求解、三对角、五对角线性方程求解）； 稀疏矩阵与稠密矩阵之间的操作（乘积、三角线性方程求解、三对角、五对角线性方程求解）； 稀疏矩阵与稀疏矩阵之间的操作（求和、乘积）； 稠密矩阵与稠密矩阵之间的操作，输出一个稀疏矩阵（乘积）； 稀疏矩阵预处理（不完全Cholesky分解、不完全LU分解）； 不同稀疏矩阵存储格式的相互转换。 cuSPARSE数据存储格式 cuSPARSE的索引有两种，从零开始和从一开始的，这是为了兼容C/C++和Fortran。 向量存储格式 稠密向量不过多介绍，与C/C++的数组存储方式是一致的。 稀疏向量是借助两个数组表示的： 值数组values：存储向量中的非零值； 索引数组indices：存储向量中非零值在等价稠密向量中的索引。 官方文档中的图片很好的解释了这种存储方式。 矩阵存储格式 稠密矩阵 稠密矩阵有行优先和列优先两种组织方式，通过几个参数来表示： 矩阵行数rows； 矩阵列数columns； 主维度leading_dimension：主维度在行优先模式下必须大于等于列数，在列优先模式下必须大于等于行数； 值数组指针：该数组的长度在行优先模式下为rows * leading_dimension，在列优先模式下为columns * leading_dimension。 下图是一个的稠密矩阵在两种模式下的内存布局。 这里比较特殊的一个参数就是主维度leading_dimension，这个参数的存在是为了更好的表示子矩阵。下图是官方文档中的示例。 我们推广这个示例，将一个rows * columns的矩阵以行优先存储，并令其leading_dimension为columns。此时取它的一个m * n的子矩阵，起始元素指针为sub，想要得到其(i, j)位置的元素，只需要利用如下计算公式： 1sub_ij = sub + j * leading_dimension + i; 列优先存储同理。 稀疏矩阵 坐标存储Coordinate (COO) COO是一种利用非零元素及其坐标来存储稀疏矩阵的方式，主要有如下参数表示： 矩阵行数rows； 矩阵列数columns； 非零元素个数nnz； 行索引数组指针row_indices：其长度为nnz，存放了非零元素在等价稠密矩阵中的行索引； 列索引数组指针column_indices：其长度为nnz，存放了非零元素在等价稠密矩阵中的列索引； 值数组指针values：其长度为nnz，存放了矩阵的非零元素，按照等价稠密矩阵行优先的顺序排列。 COO的每一项由一个&lt;row, column&gt;的二元组表示，COO默认是按照行的顺序排序的。 若想计算COO格式下的元素在等价稠密矩阵中的位置，可以通过如下公式： 12345// 行优先rows_indices[i] * leading_dimension + column_indices[i];// 列优先column_indices[i] * leading_dimension + row_indices[i]; 压缩稀疏行Compressed Sparse Row (CSR) CSR和COO非常类似，只是将行索引数组进行了压缩，用一个行偏移数组来代替了。 行偏移数组row_offsets：其长度为rows + 1，存储了每一行起始元素在列索引数组和值索引数组中的位置； 其余参数与COO一致。 若想计算CSR格式下的元素在等价稠密矩阵中的位置，可以通过如下公式： 12345// 行优先row * leading_dimension + column_indices[row_offsets[row] + k]// 列优先column_indices[row_offsets[row] + k] * leading_dimension + row 其中，row表示稠密矩阵的第几行，k的范围是k = 0; k &lt; row_offsets[row + 1] - row_offsets[row]。 此外还有CSC、SELL、BSR、BLOCKED-ELL等稀疏矩阵的存储方式，详细参考官方文档的介绍。 具体示例 我们来实现一个比较常见的操作，也就是SpMV函数。接下来的内容重点在于cuSPARSE库一些通用操作。 首先需要创建一个句柄。 12cusparseHandle_t handle;ERROR_CHECK_CUSPARSE(cusparseCreate(&amp;handle)); 由于我们的数据大部分是在主机端准备的，所以生成的数据自然而然地是以稠密的形式存储的。所以需要进行稠密矩阵到稀疏矩阵的转换。这一部分的工作可能有一些复杂，总体步骤包含： 创建cuSPARSE的稠密和稀疏矩阵； 判断是否需要额外的buffer； 分析非零元素个数； 准备特定稀疏矩阵格式所需要的空间； 执行转换。 12345678910111213141516171819202122232425262728293031// 创建稠密矩阵cusparseDnMatDescr_t dn_mat;ERROR_CHECK_CUSPARSE(cusparseCreateDnMat(&amp;dn_mat, rows, columns, ld, d_A, CUDA_R_32F, CUSPARSE_ORDER_ROW));// 创建稀疏矩阵cusparseSpMatDescr_t sp_mat;ERROR_CHECK_CUSPARSE(cusparseCreateCsr(&amp;sp_mat, rows, columns, 0, d_row_offsets_A, NULL, NULL, CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I, CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F));// 若有必要，为转换工作申请额外的buffersize_t buffer_size = 0;void *d_buffer = NULL;ERROR_CHECK_CUSPARSE(cusparseDenseToSparse_bufferSize(handle, dn_mat, sp_mat, CUSPARSE_DENSETOSPARSE_ALG_DEFAULT, &amp;buffer_size)); // 该函数返回所需的buffer大小ERROR_CHECK(cudaMalloc(&amp;d_buffer, buffer_size));// 分析矩阵中的非零元素个数ERROR_CHECK_CUSPARSE(cusparseDenseToSparse_analysis(handle, dn_mat, sp_mat, CUSPARSE_DENSETOSPARSE_ALG_DEFAULT, d_buffer));// 获取非零元素个数int64_t rows_tmp, cols_tmp, nnz;ERROR_CHECK_CUSPARSE(cusparseSpMatGetSize(sp_mat, &amp;rows_tmp, &amp;cols_tmp, &amp;nnz));// 申请CSR中的列索引数组和值数组int *d_column_indices_A;float *d_values_A;ERROR_CHECK(cudaMalloc((void **)&amp;d_column_indices_A, nnz * sizeof(int)));ERROR_CHECK(cudaMalloc((void **)&amp;d_values_A, nnz * sizeof(float)));// 为稀疏矩阵设置各个数组指针ERROR_CHECK_CUSPARSE(cusparseCsrSetPointers(sp_mat, d_row_offsets_A, d_column_indices_A, d_values_A));// 执行稠密矩阵到稀疏矩阵的转换ERROR_CHECK_CUSPARSE(cusparseDenseToSparse_convert(handle, dn_mat, sp_mat, CUSPARSE_DENSETOSPARSE_ALG_DEFAULT, d_buffer)); 准备好矩阵后，接着准备参与运算的两个稠密向量。 123cusparseDnVecDescr_t dn_vec_X, dn_vec_Y;ERROR_CHECK_CUSPARSE(cusparseCreateDnVec(&amp;dn_vec_X, columns, d_X, CUDA_R_32F));ERROR_CHECK_CUSPARSE(cusparseCreateDnVec(&amp;dn_vec_Y, rows, d_Y, CUDA_R_32F)); 最后就是执行计算，但在执行真正的计算之前，依然需要判断是否需要额外的buffer。 12345678910// 若有必要，为SpMV计算申请额外的bufferfloat alpha = 3.0f;float beta = 4.0f;size_t spmv_buffer_size;void *d_spmv_buffer;ERROR_CHECK_CUSPARSE(cusparseSpMV_bufferSize(handle, CUSPARSE_OPERATION_NON_TRANSPOSE, &amp;alpha, sp_mat, dn_vec_X, &amp;beta, dn_vec_Y, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, &amp;spmv_buffer_size));ERROR_CHECK(cudaMalloc(&amp;d_spmv_buffer, spmv_buffer_size));// 执行SpMV计算ERROR_CHECK_CUSPARSE(cusparseSpMV(handle, CUSPARSE_OPERATION_NON_TRANSPOSE, &amp;alpha, sp_mat, dn_vec_X, &amp;beta, dn_vec_Y, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, d_spmv_buffer)); 注意，无论是计算之前，还是前面提到的稠密转稀疏之前，它们判断是否需要额外buffer的操作，全部交给库来自行判断，不需要人为干预。程序员需要做的只是写一个像上面一样较为通用的代码，使其能够在需要buffer的时候申请得到即可。 示例完整代码参考cusparse.cu。关于其他API就不过多阐述了，用到的时候查官方文档即可。 cuBLAS库 cuBLAS库与cuSPARSE库最大的不同在于，cuBLAS库并不支持多种稀疏矩阵类型，它更擅长处理稠密矩阵和稠密向量的运算。 当前的cuBLAS库将接口分为了四类： cuBLAS API（CUDA 6.0开始）； cuBLASXt API（CUDA 6.0开始）； cuBLASLt API（CUDA 10.1开始）； cuBLASDx API（未包含在CUDA Toolkit中）。 上面四套API的主要区别在于： cuBLAS API需要将数据搬移到设备上进行运算； cuBLASXt API可以将数据放在主机或参与运算的任何设备上，库会承担运算和数据分发的责任； cuBLASLt API是一套专注于通用矩阵乘（GEMM）的灵活的轻量级API，该API可以通过参数来灵活指定矩阵数据布局、输入类型、计算类型以及算法的实现。用户指定了一组预期的GEMM操作后，这组操作可以根据不同的输入来复用； cuBLASDx API则是一个设备端API扩展，可以在核函数中执行BLAS计算。通过融合数值运算，可以减少延迟并进一步提高性能。目前该组API还在preview阶段。 同时，cuBLAS API存在新旧两套API，后面的所有讨论都基于定义在cublas_v2.h头文件中的新版API，旧版API定义在cublas.h中。具体的区别这里不过多讨论，有兴趣可以查看官方文档New and Legacy cuBLAS API。 cuBLAS数据存储格式 cuBLAS有两套数据排布方式，一套为了兼容Fortran从1开始的索引，另一套是兼容C从0开始的索引。可以通过以下两个宏来计算全局索引。 12#define IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))#define IDX2C(i,j,ld) (((j)*(ld))+(i)) 要记住最核心的一点，cuBLAS是以列主序的形式存储矩阵的。 具体示例 在熟悉了cuSPARSE的使用之后，你会发现cuBLAS要简洁很多，因为少了很多配置稀疏矩阵的过程，下面以通用矩阵乘法为例说明。 同样地，首先创建句柄。 12cublasHandle_t handle;ERROR_CHECK_CUBLAS(cublasCreate(&amp;handle)); 然后就可以直接进行计算了，如果需要的话，可以使用cublasSetStream()来绑定一个流。 1ERROR_CHECK_CUBLAS(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, &amp;alpha, d_A, lda, d_B, ldb, &amp;beta, d_C, ldc)); 详细代码参考cublas.cu。 cuFFT库 cuFFT库由两部分组成： cuFFT：提供GPU上的高性能快速傅里叶变换操作，它需要提前将数据搬移到设备端； cuFFTW：为FFTW的用户提供快速移植到GPU的能力，为了这种快速移植能力，cuFFTW支持主机端的数据传入，它将自动为用户处理如cudaMalloc、cudaMemcpy等操作。 下面的内容重点介绍cuFFT。cuFFT提供一种简单易用的配置机制称为plan，它使用内部构建的block来优化给定配置和特定GPU硬件之间的转化。一旦创建了一个plan，库将自动保存多次执行该plan所需的所有状态，无需重新配置。不同类型的FFT需要不同的线程配置和GPU资源，plan接口提供了这样一种简单的配置重用方式。 cuFFT支持多种类型的变换，如复数-复数变换（C2C）、复数-实数变换（C2R）、实数-复数变换（R2C）。由于变换的不同，需要的输入输出数据布局也就不同。 cuFFT数据存储格式 在cuFFT中，数据布局严格取决于配置和变换的类型。一般地，C2C变换情况下，输入输出数据应为cufftComplex或cufftDoubleComplex，具体取决于计算精度。而C2R变换，只需要非冗余的复数元素组成的向量作为输入，输出则是由cufftReal或cufftDouble元素组成的向量。对于R2C变换，需要一个实数向量作为输入，输出一个非冗余复数元素组成的向量。 在C2R和R2C变换中，输入输出的大小是不同的。对于非就地变换，创建一个大小合适的输出数组即可。但对于就地变换，程序员应当使用填充的数据布局，这种布局与FFTW兼容。无论是就地C2R还是R2C变换，输出的起始地址都与输入的起始地址一致，所有应当填充R2C中的输入或C2R中的输出数据。 以一维变换为例，期望的输入输出大小以及类型如下表所示。 FFT类型 输入数据大小（类型） 输出数据大小（类型） C2C （cufftComplex） （cufftComplex） C2R （cufftComplex） （cufftReal） R2C （cufftReal） （cufftComplex） 对于多维的情况，参考官方文档multidimensional-transforms。 具体示例 关于傅里叶变换算法本身这里不过多展开，下面用一个比较基本的一维复数-复数FFT来说明。 首先依旧是创建句柄，这里之所以将句柄命名为plan是因为，后续创建cuFFT的plan时，是基于这个句柄的。 12cufftHandle plan;ERROR_CHECK_CUFFT(cufftCreate(&amp;plan)); 创建plan，这个plan可以复用。如果需要的话，可以使用cufftSetStream()来绑定一个流。 1ERROR_CHECK_CUFFT(cufftPlan1d(&amp;plan, fft_size, CUFFT_C2C, batch_size)); 执行变换操作，这里进行了一次正向变换，归一化后又进行了逆向变换。 123456// 执行正向变换ERROR_CHECK_CUFFT(cufftExecC2C(plan, d_data, d_data, CUFFT_FORWARD));// 归一化scaling_kernel&lt;&lt;&lt;1, 128&gt;&gt;&gt;(d_data, element_count, 1.f / fft_size);// 执行逆向变换ERROR_CHECK_CUFFT(cufftExecC2C(plan, d_data, d_data, CUFFT_INVERSE)); 详细代码参考cufft.cu。 cuRAND库 介绍cuRAND库之前要引入两个与随机数生成相关的概念： PRNG：伪随机数生成器； QRNG：拟随机数生成器。 PRNG和QRNG的最大区别就在于，生成每一个随机数的事件是否为独立事件。PRNG每次采样均为独立统计事件，这意味着每次采样，所得到某个数的概率是相同的。而QRNG每次采样并不是独立事件，它会尽可能的均匀填充输出类型的范围。一个更具体的例子是，假设第一个生成的随机数是2的概率为，下一个生成的随机数同样是2的概率为。在PRNG中不会因为上一次取得的数是2就变小，它与是完全相等的，但在QRNG中，会由于的成立而变小。 cuRAND库与其他库最大的不同就是，它提供了主机端和设备端两套API。 主机端API定义在头文件curand.h中。但要注意的是，主机端API允许两种生成方式：主机生成和设备生成。若生成时传入的数据指针是主机内存指针，则生成过程由CPU在主机端完成，结果也存储在主机内存中。若生成时传入的数据指针是设备内存指针，则生成过程由设备端完成，结果存储在设备的全局内存中。 设备端API定义在头文件curand_kernel.h中，可以在核函数中直接生成随机数并使用，而不需要将生成结果存入全局内存后再读取。 cuRAND库的RNG有9种，分别有5种PRNG和4种QRNG： PRNG： CURAND_RNG_PSEUDO_XORWOW：使用XORWOW算法实现的，XORWOW算法是伪随机数生成器xor-shift系列的成员； CURAND_RNG_PSEUDO_MRG32K3A：组合多重递归伪随机数生成器系列的成员； CURAND_RNG_PSEUDO_MTGP32：Mersenne Twister伪随机数生成器系列的成员，具有为GPU定制的参数； CURAND_RNG_PSEUDO_MT19937：Mersenne Twister伪随机数生成器系列的成员，参数与CPU版本相同，但顺序不同，仅支持主机API，并且只能在架构sm_35或更高版本上使用； CURAND_RNG_PSEUDO_PHILOX4_32_10：Philox系列的成员，三大基于非加密计数器的随机数生成器之一。 QRNG： CURAND_RNG_QUASI_SOBOL32：32位序列的Sobol生成器； CURAND_RNG_QUASI_SCRAMBLED_SOBOL32：添加扰乱的32位序列的Sobol生成器； CURAND_RNG_QUASI_SOBOL64：64位序列的Sobol生成器； CURAND_RNG_QUASI_SCRAMBLED_SOBOL64：添加扰乱的64位序列的Sobol生成器。 cuRAND中的QRNG都是基于Sobol算法的，它以方向向量作为种子，上述的四种变体每种都能产生高达20000维的序列。 具体示例 主机端API 主机端API调用流程如下： 创建生成器并指定RNG类型； 设置偏移量（offset）、排序方式（ordering）、种子（seed）； 从指定分布中执行生成任务； 若在设备端生成，根据需要确定是否将生成结果拷贝回主机端； 具体示例如下，首先创建生成器。 12ERROR_CHECK_CURAND(curandCreateGeneratorHost(&amp;gen, CURAND_RNG_PSEUDO_XORWOW)); // 主机端生成ERROR_CHECK_CURAND(curandCreateGenerator(&amp;gen, CURAND_RNG_PSEUDO_XORWOW)); // 设备端生成 设置offset、ordering、seed。 123456// 设置偏移量ERROR_CHECK_CURAND(curandSetGeneratorOffset(gen, 0ULL));// 设置排序方式ERROR_CHECK_CURAND(curandSetGeneratorOrdering(gen, CURAND_ORDERING_PSEUDO_BEST));// 设置种子ERROR_CHECK_CURAND(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL)); 从指定分布中执行生成任务。 12// 以正态分布为例，此外还有均匀分布、对数正态分布和泊松分布ERROR_CHECK_CURAND(curandGenerateNormal(gen, data, n, mean, stddev)); 设备端API 设备端API调用主要有以下几个步骤： 根据RNG算法创建状态； 初始化状态； 生成随机值； 每个支持的RNG算法都有对应的状态。 1curandStateXORWOW_t rand_state; 根据不同的RNG算法调用不同的curand_init重载。 1234unsigned long long seed = threadIdx.x;unsigned long long subsequence = 1ULL;unsigned long long offset = 0ULL;curand_init(seed, subsequence, offset, &amp;rand_state); 值得注意的是，由于线程的高度并发，所以应当避免在不同线程中使用相同的种子，也应当避免使用当前时间戳作为种子。 这里的subsequence会使得curand_init()返回的序列是调用了(2^67 * subsequence + offset)次curand()的结果。 最后生成随机值。 1float x = curand_normal(&amp;rand_state); 详细代码参考curand.cu。 OpenACC 基本概念 OpenACC是一个基于编译器指令的API，它的工作方式和OpenMP非常类似，都是使用#pragma开头的编译器指令作为指导。OpenACC的并行粒度分为gang、worker、vector，这些概念可以和CUDA一一对应。 OpenACC CUDA gang block worker warp（未显式指出） vector thread 一个gang可以包含一个或多个执行线程，每个gang内部都包含一个或多个worker。每个worker都有一个向量宽度，由一个或多个同时执行相同指令的向量元素构成，简单理解就是一个worker可以包含一个或多个vector。每个vector都是一个单一的执行流，类似于CUDA线程。 OpenACC的目标是建立一个单线程的主机程序，该主机程序将核函数下放至多处理单元（PU），每个PU一次只运行一个gang，但可以同时执行多个独立的worker。在OpenACC中，gang并行使用多个PU，每个gang中的多线程并行即为worker并行。每个worker中的并行以及一个跨向量操作的并行称为vector并行。这里的PU有点类似于NVIDIA GPU中的SM。 并行模式 根据任务是否通过gang、worker、vector并行执行，OpenACC将执行分为几种模式。 假设一个OpenACC程序的并行计算区域创建了个gang，每个gang包含个worker，每个worker的向量宽度为V。此时总共有个执行线程来处理这个并行区域。 gang冗余模式 开始执行并行区域时，gang以冗余模式执行，可以在并行执行前对gang的状态进行初始化。在该模式下，每个gang中只有一个活跃的worker和一个活跃的vector元素，其他worker和vector元素是闲置的，因此只有个活跃执行线程。用CUDA伪核函数来表示如下。 1234__global__ void kernel() { if (threadIdx.x == 0) foo();} gang分裂模式 在OpenACC并行区域的某些地方，程序可能通过gang转换为并行执行，这种情况下程序以gang分裂模式执行。该模式下每个gang中仍然只有一个活跃的worker和一个活跃的vector元素，因此同样只有个活跃执行线程。但每个活跃的vector执行不同的并行区域，故计算任务被分散到各个gang中。以向量加法为例，CUDA伪核函数表达如下。 1234567__global__ void kernel(int* v1, int* v2, int* out, int N) { if (threadIdx.x == 0) { for (int i = blockIdx.x; i &lt; N; i += gridDim.x) { out[i] = v1[i] + v2[i]; } }} 每个gang只有一个活跃worker时，程序处于单一worker模式，当worker中只有一个活跃vector时，程序处于单一vector模式。所以gang冗余模式和gang分裂模式也可以被称作单一worker模式和单一vector模式。 worker分裂模式 在该模式下，并行区域的工作被划分到多个gang的多个worker中，可以提供路并行。CUDA伪核函数表达如下。 123456789__global__ void kernel(int* v1, int* v2, int* out, int N) { if (threadIdx.x % warpSize == 0) { int warpId = threadIdx.x / warpSize; int warpsPerBlock = blockDim.x / warpSize; for (int i = blockIdx.x * warpsPerBlock + warpId; i &lt; N; i += gridDim.x * warpsPerBlock) { out[i] = v1[i] + v2[i]; } }} vector分裂模式 该模式将工作在gang、worker、vector通道上进行划分，提供路并行。该模式最接近CUDA核函数的行为模式，CUDA伪核函数表达如下。 1234__global__ void kernel(int* v1, int* v2, int* out, int N) { if (threadIdx.x &lt; N) out[i] = v1[i] + v2[i];} 基本用法 前面提到了OpenACC的工作方式与OpenMP的极为相似，在源代码中加入#pragma acc即可指导编译器对源代码进行翻译，使其能够在GPU上并行执行。 计算指令 核函数指令 #pragma acc kernels会自动分析代码块中的可并行循环。 1234567#pragma acc kernels{ for (int i = 0; i &lt; N; i++) { C[i] = A[i] + B[i]; }} 核函数指令可以有条件子句来修饰，当条件为false时，代码块不会在设备上执行。 1234567#pragma acc kernels if(N &gt; 128){ for (int i = 0; i &lt; N; i++) { C[i] = A[i] + B[i]; }} 默认情况下，核函数指令结束时会有一个隐式同步，但可以通过添加async子句来使执行不被阻塞。 async子句接受一个可选的整型参数，若传入ID则可以使用指令来等待。 1234567891011#pragma acc kernels async(3){ for (int i = 0; i &lt; N; i++) { C[i] = A[i] + B[i]; }}#pragma acc wait(3) // 或通过运行时API来等待 acc_async_wait(3)// 或者使用空等待指令，等待所以异步任务完成#pragma acc wait // 或通过运行时API来等待 acc_async_wait_all 也可以将async子句和wait子句结合起来，实现链式异步工作。 12345678910111213#pragma acc kernels async(0){ ...}#pragma acc kernels wait(0) async(1){ ...}#pragma acc kernels wait(1) async(2){ ...}#pragma acc wait(2) 而检查异步任务在没有阻塞的情况下是否完成只能通过运行时API来完成。 1acc_async_test(int); // 已结束返回非零值，否则返回零 目前想要编译OpenACC的代码，推荐使用PGI编译器。PGI被英伟达收购之后，编译器就纳入了NVIDIA HPC SDK中了。需要安装HPC SDK后使用pgcc命令来编译代码。详细代码参考openacc_kernels.c。 并行指令 上面提到的核函数指令是一个强大的工具，编译器会自动分析代码并选择一个合适的并行策略，在这个过程中，程序员对程序的控制是较少的。但并行指令#pragma acc parallel则可以提供更多的控制选项。 并行指令同样支持核函数指令的一些子句，如if、async、wait。此外可以使用num_gangs(int)来设置gang数量，num_workers(int)设置worker数量，vector_length(int)设置每个worker的向量宽度。 1234#pragma acc parallel num_gangs(32) num_workers(32) vector_length(64){ ...} 并行指令还支持reduction子句，格式为#pragma acc parallel reduction(op:var1, var2, ...)，支持的op有+、*、max、min、&amp;、|、^、&amp;&amp;、||。 1234567#pragma acc parallel reduction(+ : result){ for (int i = 0; i &lt; N; i++) { result += A[i]; }} 并行指令还支持private和firstprivate子句。private会为每个gang创建一个private型复制变量，只有该gang可以使用该变量的拷贝，因此该值的改变对其他gang或主机程序是不可见的。firstprivate功能和private相同，只是会将每个gang中的private型变量的值初始化为主机上该变量当前的值。 123456789#pragma acc parallel private(a){ ...}#pragma acc parallel firstprivate(a){ ...} 详细代码参考openacc_parallel.c。 循环指令 并行指令需要程序员为编译器明确标注并行性，并行区域总是以gang冗余模式开始的，执行并行模式之间的转换需要对编译器有明确的指示，这种指示可以通过循环指令#pragma acc loop来完成。 12345678910111213#pragma acc parallel{#pragma acc loop for (int i = 0; i &lt; N; i++) { C[i] = A[i] + B[i]; }#pragma acc loop for (int i = 0; i &lt; N; i++) { D[i] = C[i] * A[i]; }} 上面的代码并没有为循环指令添加子句，所以编译器可以自由使用它认为的最优循环调度。也可以通过gang、worker或vector子句来显式控制每一级的并行性。 12345678910#pragma acc parallel{ int a = 1;#pragma acc loop gang for (int i = 0; i &lt; N; i++) { vec2[i] = a; }} 上述代码中，并行区域以gang冗余模式开始，遇到带有gang子句的循环指令后，转换为了gang分裂模式。 考虑下列代码。 1234567891011121314151617#pragma acc parallel{#pragma acc loop for (int i = 0; i &lt; N; i++) { ... }}#pragma acc kernels{#pragma acc loop for (int i = 0; i &lt; N; i++) { ... }} 可以简写为下列形式。 1234567891011#pragma acc parallel loopfor (int i = 0; i &lt; N; i++){ ...}#pragma acc kernels loopfor (int i = 0; i &lt; N; i++){ ...} 详细代码参考openacc_parallel.c。 循环指令loop不仅可以和并行指令paralle结合，还可以与核函数指令kernels结合，但某些循环指令的子句在并行指令和核函数指令下会有所不同。 子句 并行指令下的行为 核函数指令下的行为 collapse(int) 指明循环指令适用于多重嵌套循环 与并行指令下相同 gang(int) 指明循环应通过gang划分到并行区域，gang数量由并行指令决定 说明循环应通过gang进行划分，gang有选择的使用整型参数 worker(int) 指明循环应通过每个gang中的worker划分到并行区域，将每个gang由单一worker模式转换到worker分裂模式 说明循环应通过每个gang中的worker划分到并行区域，worker有选择的使用整型参数 vector(int) 指明循环应通过vector通道进行分配，是一个worker由单一vector模式转换到vector分裂模式 说明循环应通过vector通道进行分配，vector有选择的使用整型参数 seq 为了按序执行，使用seq对循环进行标记 与并行指令下相同 auto 指明编译器应为相关的循环选择gang、worker或vector并行 与并行指令下相同 tile(int, ...) 指明编译器应将嵌套循环中的每个循环拆分为两个循环：外层的tile循环和内层的element循环。内层循环次数为tile_size，外层循环次数取决于串行代码。若附加到多个紧密的嵌套循环中，tile可以使用多个tile_size，并自动将所有外部循环放在内部循环之外 与并行指令下相同 device_type(type) type是一个逗号分隔的列表，分隔不同设备类型的子句。所有子句都遵循device_type的设定，只有当循环在指定设备类型上执行时，才可能有指令结束，或在下一个type的设备上执行的情况。 与并行指令下相同 independent 该子句声称被标记的循环为并行的且编译器分析高于一切 与并行指令下相同 数据指令 #pragma acc data可以在主机和设备之间进行显式的数据传输。 12345678910111213141516#pragma acc data copyin(A[0 : N], B[0 : N]) copyout(C[0 : N], D[0 : N]){#pragma acc parallel {#pragma acc loop for (int i = 0; i &lt; N; i++) { C[i] = A[i] + B[i]; }#pragma acc loop for (int i = 0; i &lt; N; i++) { D[i] = C[i] * A[i]; } }} 上面的代码告知编译器，只有A和B应该被拷贝到设备，只有C和D应该被拷贝回主机。同时指明了数组的范围，某些情况下，编译器能够推断要复制的数组大小，可以将代码简化为下面的样子。 1#pragma acc data copyin(A, B) copyout(C, D) 除了上述指定代码块的方法，还可以使用enter data指令和exit data指令来标记在任意节点传入和传出设备的数组。enter data指明的数据会持续保留在设备端，直到遇到将其传回的exit data指令。这两个指令可以与async和wait子句结合发挥最大作用。 注意，单纯的data指令不支持async和wait子句。 1234567891011121314151617181920 init(vec1); init(vec2);#pragma acc enter data copyin(vec1[0 : N], vec2[0 : N]) async(0) process(vec3);#pragma acc kernels wait(0) async(1) { for (int i = 0; i &lt; N; i++) { vec1[i] = do_something(vec2[i]); } }#pragma acc exit data copyout(vec1[0 : N]) wait(1) async(2) process(vec4);#pragma acc wait(2) 考虑如下代码。 1234567#pragma acc data copyin(A[0 : N], B[0 : N]) copyout(C[0 : N], D[0 : N]){#pragma acc parallel { ... }} 可以简写为下列形式。 1234#pragma acc parallel copyin(A[0 : N], B[0 : N]) copyout(C[0 : N], D[0 : N]){ ...} 详细代码参考openacc_data.c。 数据指令支持的子句见下表。 子句 行为 data支持 enter data支持 exit data支持 if(cond) 若cond为true则执行数据搬移 Y Y Y copy(var1, ...) 在进入数据区域时将变量拷贝至设备端，离开数据区域时拷贝回主机端 Y N N copyin(var1, ...) 指明变量只能被拷贝至设备端 Y Y N copyout(var1, ...) 指明变量只能被拷贝回主机端 Y N Y create(var1, ...) 指明列出的变量需要在设备端分配内存，但变量值不必传入或传出设备 Y Y N present(var1, ...) 指明列出的变量已经在设备端了，不必再次传入。运行时，编译器会发现并使用这些已经存在于设备端的数据 Y N N present_or_copy(var1,...) 若列出的变量已经在设备端了，则功能与present一致；若不在设备端，则功能与copy一致 Y N N present_or_copyin(var1, ...) 若列出的变量已经在设备端了，则功能与present一致；若不在设备端，则功能与copyin一致 Y Y N present_or_copyout(var1, ...) 若列出的变量已经在设备端了，则功能与present一致；若不在设备端，则功能与copyout一致 Y N N present_or_create(var1, ...) 若列出的变量已经在设备端了，则功能与present一致；若不在设备端，则功能与create一致 Y Y N deviceptr(var1, ...) 指明列出的变量是设备内存指针，不必再为该指针指向的数据分配空间，也不必在主机和设备之间传输。 Y N N delete(var1, ...) 可以与exit data结合使用，显式释放设备内存 N N Y 更多指令和运行时API可以参考官方文档Specification | OpenACC。 与CUDA结合 要结合CUDA与OpenACC，需要通过deviceptr子句来实现CUDA和OpenACC之间的数据共享。核心代码如下。 1234567891011121314#pragma acc parallel loop gang deviceptr(d_A, d_B, d_C)for (int i = 0; i &lt; M; i++){#pragma acc loop worker vector for (int j = 0; j &lt; P; j++) { float sum = 0.0f; for (int k = 0; k &lt; N; k++) { sum += d_A[i * N + k] * d_B[k * P + j]; } d_C[i * P + j] = sum; }} 详细代码参考cuda_openacc.cu。","link":"/posts/9782/"},{"title":"CUDA编程——性能分析工具","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 概述 在之前的CUDA版本中，所附带的性能分析工具主要是nvvp（NVIDIA Visual Profiler）和nvprof，前者是带有图形界面的分析工具，后者是命令行工具。 在CUDA官方文档中有这样一段描述： Note that Visual Profiler and nvprof will be deprecated in a future CUDA release. The NVIDIA Volta platform is the last architecture on which these tools are fully supported. It is recommended to use next-generation tools NVIDIA Nsight Systems for GPU and CPU sampling and tracing and NVIDIA Nsight Compute for GPU kernel profiling. 所以nvvp与nvprof已经是过去时了，后面的介绍都围绕新的性能分析工具nsys（Nsight System）和ncu（Nsight Compute）。 nsys是系统层面的分析工具，可以分析主机与设备端的信息。ncu则是用于分析核函数的工具。两者均有图形界面版本和命令行版本。 Nsight System nsys是系统级别的分析工具，它可以捕捉CPU和GPU上的各种事件以及两者之间的交互。可以通过流水线观察整个应用程序的性能瓶颈，帮助从整体层面优化程序。nsys还支持NVTX，可以更加精准的分析流水线。 NVTX即Nvidia Tools Extension，是对CUDA代码的一种注释，使其在profiling过程中能够获取到更加细粒度的信息。在CUDA C代码中只需引入nvToolsExt.h头文件即可，下面是一个示例。 123456789101112131415#include &lt;cuda_runtime.h&gt;#include \"nvToolsExt.h\"__global__ void Kernel() { ...}void kernelLaunch() { nvtxRangePushA(__FUNCTION__); ... nvtxRangePushA(\"Kernel\"); Kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(); nvtxRangePop(); nvtxRangePop();} 打开nsys后看到如下界面。 左侧是项目管理器，右侧是项目的配置页面。点击Select target for profiling...可以选择要进行性能分析的目标机器。可以选择本机，也可以使用SSH连接远程机器。这里以本机为例，选择本机后看到如下界面。 这里需要先在Command line with arguments中填写执行命令以及所需参数，Working directory指的是执行所填命令的目录，如果所填的命令全部为绝对路径，则Working directory就不是很重要了。填写后往下拉可以看到另一些配置项。 上图是默认情况，这些选项就根据需要选择即可。例如在程序中使用了OpenMP，若想将OpenMP带来的影响也体现在分析结果中，则需勾选Collect OpenMP trace，其他的选项同理。 完成配置后就可以点击右侧的Start开始profiling，结束后就会看到生成了一个分析报告，如下图所示。 到此，使用nsys的分析工作就结束了。 使用nsys时可能会遇到如下报错。 12345Collection of CPU IP/backtrace samples or context switch data disabled. perf event paranoid level is 4.Change the paranoid level to 2 to enable CPU IP/backtrace sample or context switch data collection. Change the paranoid level to 1 to enable CPU kernel sample collection.Trysudo sh -c 'echo [level] &gt;/proc/sys/kernel/perf_event_paranoid'where 'level' equals 1 or 2. 根据提示执行命令： 1sudo sh -c 'echo 1 &gt;/proc/sys/kernel/perf_event_paranoid' 这里建议直接将level修改为1，如果level为2可能还会存在一些警告。 Nsight Compute ncu是核函数级别的分析工具，它可以捕捉核函数执行过程中的各种数据。能够从显存使用、SM占用、warp状态等角度来分析核函数的瓶颈所在。 打开ncu后看到如下界面。 左侧是项目管理器，双击项目即可开始配置。 这里的必填项是上方带黄色感叹号的Application Executable和下方的Output File。Application Executable和Working Directory与nsys的同理，Output File是指输出的性能分析结果的文件名。填写完成后就可以点击Launch开始性能分析。 Output File可以使用%i来在文件名中生成变量，例如output%i.log。这样生成的报告就会以output1.log、output2.log来命令，避免了之前的报告被覆写。 到此，使用ncu的分析工作就结束了。 初次使用ncu可能会遇到权限问题。 1==ERROR== ERR_NVGPUCTRPERM - The user does not have permission to access NVIDIA GPU Performance Counters on the target device 0. For instructions on enabling permissions and to get more information see https://developer.nvidia.com/ERR_NVGPUCTRPERM 这个问题就参考给出的链接，Linux的解决方案为在/etc/modprobe.d目录下创建一个后缀为.conf的文件，在其中加上下面一行语句。 1options nvidia NVreg_RestrictProfilingToAdminUsers=0 这样就将访问权限开放给了所有用户，如果想要仅root可用，则将上面的选项修改为1。添加好文件后reboot即可。","link":"/posts/50255/"},{"title":"CUDA编程——全局内存","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 CUDA内存模型概述 CUDA内存模型 对于开发者来说，存储器分为两大类： 可编程的：需要显式控制哪些数据存放在可编程内存中； 不可编程的：不能决定数据的存放位置，由程序自动生成存放位置。 CUDA内存模型提出了多种可编程内存： 寄存器； 共享内存； 本地内存； 常量内存； 纹理内存； 全局内存。 这些内存空间的层次结构如下图所示。 寄存器 寄存器是GPU上速度最快的内存空间，在核函数中声明一个没有其他修饰符的变量，通常存储在寄存器中。在核函数中声明的数组，若用于引用该数组的索引是常量且能在编译时确定，则该数组也存储在寄存器中。 寄存器是线程私有的，寄存器变量与核函数生命周期相同。若核函数使用的寄存器超过了硬件限制，则会用本地内存替代多占用的寄存器。nvcc编译器使用启发式策略来最小化寄存器使用，以免寄存器溢出。也可以手动显式添加额外信息来辅助编译器优化。 1__global__ void __launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor) kernel(...) {} maxThreadsPerBlock指出每个线程块可以包含的最大线程数，minBlocksPerMultiprocessor是可选参数，指出在每个SM中预期的最小常驻线程块数量。 还可以使用编译器选项maxrregcount来控制一个编译单元中所有核函数使用的寄存器的最大数量，例如-maxrregcount=32。 本地内存 核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有： 在编译时使用未知索引引用的本地数组； 可能会占用大量寄存器空间的较大本地结构体或数组； 任何不满足核函数寄存器限定条件的变量。 溢出到本地内存中的变量本质上与全局内存在同一存储区域，因此本地内存的访问特点是高延迟和低带宽。 共享内存 在核函数中使用__shared__修饰符修饰的变量存放在共享内存中。 由于共享内存是片上内存，所以与本地内存和全局内存相比，具有更高的带宽和更低的延迟，是可编程的。每个SM都有一定数量的由线程块分配的共享内存，因此不能过度使用共享内存，避免在不经意间限制活跃线程束的数量。共享内存在核函数内声明，生命周期伴随整个线程块。 共享内存是线程之间通信的基本方式，访问共享内存必须使用__syncthreads()来进行同步。该函数设置了一个执行障碍点，使得同一线程块中的所有线程必须在其他线程开始执行前到达该处。 SM中的一级缓存和共享内存都使用64KB的片上内存，它通过静态划分，但在运行时可以使用cudaFuncSetCacheConfig()来进行动态配置。该API传入两个参数，第一个是函数指针，第二个是CUDA提供的一个枚举类cudaFuncCache成员，它包含4个成员： cudaFuncCachePreferNone：没有参考值（默认）； cudaFuncCachePreferShared：建议48KB共享内存和16KB一级缓存； cudaFuncCachePreferL1：建议48KB一级缓存和16KB共享内存； cudaFuncCachePreferEqual：建议相同尺寸的一级缓存和共享内存，均为32KB。 这里的cudaFuncSetCacheConfig()API已经是比较旧的方式了，在计算能力7.x及以上的设备中，更推荐使用cudaFuncSetAttribute()来配置。该API传入三个参数，第一个参数是函数指针，第二个是CUDA提供的一个枚举类cudaFuncAttribute成员，第三个是具体的提示值。 cudaFuncAttribute有9个成员，但常用的只有两个（其它成员是关于线程块集群的，这里不多描述）： cudaFuncAttributeMaxDynamicSharedMemorySize：指定最大动态共享内存大小； cudaFuncAttributePreferredSharedMemoryCarveout：首选的共享内存和一级缓存拆分大小； 通过第三个参数来指定第二个参数成员的具体值，例如下面的语句提示编译器将片上内存的50%分配给共享内存。 1cudaFuncSetAttribute(MyKernel, cudaFuncAttributePreferredSharedMemoryCarveout, 50); cudaFuncSetAttribute()放松了对指定共享内存容量的强制，分割被视为一种提示。而旧的cudaFuncSetCacheConfig()将共享内存容量视为核函数启动的硬性要求。因此，使用不同共享内存配置的核函数将进行一些不必要地序列化。 常量内存 常量内存驻留在设备内存中，并在每个SM专用的常量缓存中缓存，使用__constant__来修饰。 常量变量必须在全局空间内和所有核函数之外进行声明，所有计算能力的设备都只能声明64KB的常量内存。常量内存是静态声明的，并对同一编译单元中的所有核函数可见。 核函数只能从常量内存中读取数据，因此常量内存必须在主机端使用cudaMemcpyToSymbol()来初始化，大多数情况下这个函数是同步的。 线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。 纹理内存 纹理内存驻留在设备内存中，并在每个SM的只读缓存中缓存。纹理内存是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对二维空间局部性的优化，所以线程束中使用纹理内存访问二维数据的线程可以达到最优性能。 全局内存 全局内存是GPU中最大、延迟最高且最常使用的内存。它的声明可以在任何SM设备上被访问到，并贯穿程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明，可以使用__device__在设备代码中静态声明一个变量。 从多个线程访问全局内存时要注意，由于线程的执行不能跨线程块同步，不同线程块内的多个线程并发修改全局内存的同一位置可能会导致未定义的行为。 全局内存常驻于设备内存中，可通过32字节、64字节或128字节的内存事务进行访问。这些内存事务必须自然对齐，也就是说首地址必须是32字节、64字节或128字节的倍数。当一个线程束执行内存加载 / 存储时，需要满足的传输数量取决于两个因素： 跨线程的内存地址分布； 每个事务内存地址的对齐方式。 一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就导致了数据吞吐率的降低。 GPU缓存 GPU缓存是不可编程的内存，有四种类型的缓存： 一级缓存； 二级缓存； 只读常量缓存； 只读纹理缓存。 每个SM都有一个一级缓存，所有的SM共享一个二级缓存。一级和二级缓存用于存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。GPU上只有内存加载操作可以被缓存，内存存储操作不能被缓存。每个SM有一个只读常量缓存和只读纹理缓存，用于在设备内存只提高来自于各自内存空间中的读取性能。 CUDA变量声明小结 CUDA变量和类型修饰符总结如下表。 修饰符 变量类型 存储器 作用域 生命周期 标量 寄存器 线程 线程 数组 本地内存 线程 线程 __shared__ 标量 / 数组 共享内存 线程块 线程块 __device__ 标量 / 数组 全局内存 全局 应用程序 __constant__ 标量 / 数组 常量内存 全局 应用程序 设备存储器的特征总结如下表。 存储器 位置 缓存 存取 范围 生命周期 寄存器 片上 n/a R/W 一个线程 线程 本地内存 片外 Yes (2.x以上) R/W 一个线程 线程 共享内存 片上 n/a R/W 块内所有线程 线程块 全局内存 片外 Yes (2.x以上) R/W 所有线程+主机 主机配置 常量内存 片外 Yes R 所有线程+主机 主机配置 纹理内存 片外 Yes R 所有线程+主机 主机配置 静态全局内存 实现一段静态声明全局内存变量的代码，在主机端传入值，在核函数中对值进行修改，再传回主机端，核心代码如下。 12345678910111213141516__device__ float devData;__global__ void checkGlobalVariable(){ devData += 2.0f;}int main(int argc, char const *argv[]){ ... float value = 3.14f; cudaMemcpyToSymbol(devData, &amp;value, sizeof(float)); checkGlobalVariable&lt;&lt;&lt;1, 1&gt;&gt;&gt;(); cudaMemcpyFromSymbol(&amp;value, devData, sizeof(float)); ...} 值的注意的是，尽管设备的全局变量声明与主机代码在同一文件中，主机代码也不能直接访问设备变量。类似地，设备代码也不能直接访问主机变量。 唯一比较像是主机代码访问设备变量的地方是(devData, &amp;value, sizeof(float))，但该接口是在CUDA运行时API中的，内部可以隐式的使用GPU来访问。而且在这里devData作为一个标识符，并不是全局内存变量的地址。在核函数中，devData被当作全局内存中的一个变量。 cudaMemcpy()并不能直接以下面语句中的变量地址传递数据给devData。 1cudaMemcpy(&amp;devData, &amp;value, sizeof(float), cudaMemcpyHostToDevice); 我们无法在主机端的设备变量中使用&amp;运算符，因为它只是一个在GPU上表示物理位置的符号。但可以通过下面的语句显式获取一个全局变量的地址。 12float *dptr;cudaGetSymbolAddress((void **)&amp;dptr, devData); 然后就可以使用cudaMemcpy()来进行拷贝操作。 1cudaMemcpy(dptr, &amp;value, sizeof(float), cudaMemcpyHostToDevice) 详细代码参考global_variable.cu，其中展示了cudaMemcpyToSymbol()和cudaMemcpy()两种操作方式。 有一种例外可以直接从主机引用GPU内存：CUDA固定内存。将会在后续进行介绍。 内存管理 设备内存 设备内存可以作为线性内存分配，也可以作为CUDA 数组来分配。CUDA数组是为了纹理获取而优化过的不透明内存布局。 线性内存是由一个统一的地址空间分配的，分开分配的实体可以通过指针相互引用。地址空间的大小取决于主机系统（CPU）和所用GPU的计算能力。 计算能力 x86_64 (AMD64) POWER (ppc64le) ARM64 5.3及之前 40bit 40bit 40bit 6.0及以后 47bit 49bit 48bit 线性内存使用cudaMalloc()分配，使用cudaFree()释放，主机内存与设备内存之间的数据搬移通过cudaMemcpy()完成。 下面以向量加法为例。 123456789101112131415161718192021222324252627282930313233343536373839// 设备代码__global__ void VecAdd(float* A, float* B, float* C, int N){ int i = blockDim.x * blockIdx.x + threadIdx.x; if (i &lt; N) C[i] = A[i] + B[i];}// 主机代码int main(){ int N = ...; size_t size = N * sizeof(float); // 在主机端申请输入向量h_A和h_B及结果向量h_C的内存 float* h_A = (float*)malloc(size); float* h_B = (float*)malloc(size); float* h_C = (float*)malloc(size); // 初始化输入向量 ... // 在设备端申请向量内存 float* d_A; cudaMalloc(&amp;d_A, size); float* d_B; cudaMalloc(&amp;d_B, size); float* d_C; cudaMalloc(&amp;d_C, size); // 从主机端拷贝数据到设备端 cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice); cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice); // 核函数调用 int threadsPerBlock = 256; int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock; VecAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N); // 从设备端拷贝数据到主机端 cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost); // 释放设备内存 cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); // 释放主机内存 ...} 上例详细代码见example_vec_add.cu，代码中的注释是关于GPU算子开发的基本思路。 也可以通过cudaMallocPitch()和cudaMalloc3D()来分配线性内存。推荐用于2D或3D数组的分配，这样可以确保分配被适当填充，以满足内存对齐要求。同时可以保证在访问行地址或者执行2D数组与其他设备内存区域的拷贝操作时的性能（2D或3D内存拷贝使用cudaMemcpy2D()与cudaMemcpy3D()）。 必须使用返回的pitch（或stride）来访问数组元素，下面以分配一个width * height的二维浮点型数组为例。 1234567891011121314151617// 主机代码int width = 64, height = 64;float* devPtr;size_t pitch;cudaMallocPitch(&amp;devPtr, &amp;pitch, width * sizeof(float), height);MyKernel&lt;&lt;&lt;100, 512&gt;&gt;&gt;(devPtr, pitch, width, height);// 设备代码__global__ void MyKernel(float* devPtr, size_t pitch, int width, int height){ for (int r = 0; r &lt; height; ++r) { float* row = (float*)((char*)devPtr + r * pitch); for (int c = 0; c &lt; width; ++c) { float element = row[c]; } }} 下面以分配width * height * depth的三维浮点型数组为例。 1234567891011121314151617181920212223// 主机代码int width = 64, height = 64, depth = 64;cudaExtent extent = make_cudaExtent(width * sizeof(float), height, depth);cudaPitchedPtr devPitchedPtr;cudaMalloc3D(&amp;devPitchedPtr, extent);MyKernel&lt;&lt;&lt;100, 512&gt;&gt;&gt;(devPitchedPtr, width, height, depth);// 设备代码__global__ void MyKernel(cudaPitchedPtr devPitchedPtr, int width, int height, int depth){ char* devPtr = devPitchedPtr.ptr; size_t pitch = devPitchedPtr.pitch; size_t slicePitch = pitch * height; for (int z = 0; z &lt; depth; ++z) { char* slice = devPtr + z * slicePitch; for (int y = 0; y &lt; height; ++y) { float* row = (float*)(slice + y * pitch); for (int x = 0; x &lt; width; ++x) { float element = row[x]; } } }} 下面是通过运行时API访问全局变量的各种方式的例子。 12345678910111213__constant__ float constData[256];float data[256];cudaMemcpyToSymbol(constData, data, sizeof(data));cudaMemcpyFromSymbol(data, constData, sizeof(data));__device__ float devData;float value = 3.14f;cudaMemcpyToSymbol(devData, &amp;value, sizeof(float));__device__ float* devPointer;float* ptr;cudaMalloc(&amp;ptr, 256 * sizeof(float));cudaMemcpyToSymbol(devPointer, &amp;ptr, sizeof(ptr)); cudaGetSymbolAddress()可以获取声明在全局内存空间中的已分配内存的变量地址，通过cudaGetSymbolSize()来获取分配内存的大小。 内存传输 内存传输使用cudaMemcpy()函数，其最后一个参数用来指定数据拷贝方向，有四个取值： cudaMemcpyHostToHost； cudaMemcpyHostToDevice； cudaMemcpyDeviceToHost； cudaMemcpyDeviceToDevice。 如果目的地址和源地址与最后一个参数指定的方向不一致，则cudaMemcpy()的行为是未定义的。大多数情况下该函数是同步的。 锁页主机内存（固定主机内存） CUDA运行时提供了一些函数，来允许使用锁页主机内存（Page-Locked Host Memory）,也称为固定主机内存（Pinned Host Memory），与malloc()分配的可分页主机内存相对。 cudaHostAlloc()和cudaFreeHost()分配并释放锁页主机内存； cudaHostRegister()将malloc()分配的内存中某范围内的页面锁定。 使用锁页主机内存的优势： 锁页主机内存与设备内存之间的数据搬移可以与异步并发执行中提到的某些设备的核函数并发执行； 在某些设备上，锁页主机内存可以映射到设备的地址空间中，无需在主机和设备之间搬移数据，映射内存中有详细说明； 在具有前端总线（Front-side Bus, FSB）的系统上，若主机内存被分配为锁页内存，则主机内存和设备内存之间的带宽会变高；若主机内存还被分配为写组合内存，则带宽会更大，详见写组合内存。 分配的主机内存默认是可分页的（pageable），但GPU不能在可分页主机内存上安全地访问数据。因为当主机的操作系统在物理位置上移动这些数据的时候，GPU时无法控制的。 当从可分页主机内存传输数据到设备时，CUDA驱动程序首先分配临时的锁页内存，将主机源数据拷贝到锁页内存中后，再将锁页内存中的数据拷贝到设备中。 我们对比在相同数据量下，可分页内存与设备内存之间的拷贝性能与锁页内存与设备内存之间的拷贝性能，详细代码参考pageable_memory.cu与page_locked_memory.cu。使用nsys中的nvprof来分析内存拷贝操作的耗时。 可分页内存与设备内存之间的拷贝耗时如下。 1234Time (%) Total Time (ns) Count Avg (ns) Med (ns) Min (ns) Max (ns) StdDev (ns) Operation -------- --------------- ----- ----------- ----------- --------- --------- ----------- ------------------ 50.0 1,144,966 1 1,144,966.0 1,144,966.0 1,144,966 1,144,966 0.0 [CUDA memcpy HtoD] 50.0 1,142,693 1 1,142,693.0 1,142,693.0 1,142,693 1,142,693 0.0 [CUDA memcpy DtoH] 锁页内存与设备内存之间的拷贝耗时如下。 1234Time (%) Total Time (ns) Count Avg (ns) Med (ns) Min (ns) Max (ns) StdDev (ns) Operation -------- --------------- ----- --------- --------- -------- -------- ----------- ------------------ 51.9 686,915 1 686,915.0 686,915.0 686,915 686,915 0.0 [CUDA memcpy HtoD] 48.1 637,475 1 637,475.0 637,475.0 637,475 637,475 0.0 [CUDA memcpy DtoH] 可以观察到，锁页内存与设备内存之间的拷贝耗时要大幅度小于可分页内存与设备内存之间的拷贝操作。 可移植内存 锁页内存可以与系统中的任何设备结合使用，但默认情况下，上述提到的锁页内存的优势只有分配这片锁页内存的设备可以享受到（如有与该设备共享统一地址空间（详见统一虚拟地址空间）的设备，则这些设备也能享受这些优势）。 可以通过将cudaHostAllocPortable标志传给cudaHostAlloc()来分配锁页内存，或将cudaHostRegisterPortable标志传给cudaHostRegister()来锁定页面，使得所有设备都能够享受上面提到的优势。 写组合内存 默认情况下，锁页主机内存是作为可缓存状态申请的。此外有一种可选的申请方式，通过将cudaHostAllocWriteCombined标志传给cudaHostAlloc()来申请写组合内存（Write-Combining Memory）。 写组合内存释放了主机的L1和L2缓存，使程序的其他部分可以使用更多的缓存。此外，在PCI-E总线上传输时，写组合内存不会被窥探，使得传输性能提高40%。 从主机的写组合内存中读取数据速度非常慢，故写组合内存通常只用于仅主机写入内存的情况。 应该避免在写组合内存上使用CPU原子指令，因为不是所有CPU实现都能保证该功能。 映射内存（零拷贝内存） 通常情况下，主机不能直接访问设备变量，设备也不能直接访问主机变量。但有一种主机和设备都可以访问的内存——零拷贝内存。 通过将cudaHostAllocMapped标志传给cudaHostAlloc()，或将cudaHostRegisterMapped标志传给cudaHostRegister()，可以使锁页主机内存映射到设备的地址空间中。因此，这样的内存区域通常有两个地址：一个在主机内存中，由cudaHostAllco()或malloc()返回；另一个在设备内存中，可以使用cudaHostGetDevicePointer()来检索，从而在核函数中访问该内存空间。 唯一的例外是使用cudaHostAlloc()分配的指针，以及主机和设备使用统一地址空间（详见统一虚拟地址空间）的情况下。 直接从核函数中访问主机内存并不能提供与设备内存相同的带宽，但确实具有一些优势： 无需在设备内存中分配空间，也不需要在主机内存和设备内存之间搬移数据，会根据核函数的需要隐式地进行数据传输； 无需使用流（详见并发数据传输）来使数据传输和核函数同时执行，核函数发起的数据传输将自动地与核函数同时执行。 但是，由于主机和设备共享映射后的锁页内存，因此程序必须使用流或事件同步内存访问（详见异步并发执行），以避免任何写后读、读后写或写后写等潜在危险行为。 为了能够检索到所有映射后的锁页内存的设备指针，在执行任何CUDA调用之前，必须通过将cudaDeviceMapHost标志传给cudaSetDeviceFlags()来启动锁页内存映射。否则cudaHostGetDevicePointer()将返回一个错误。 如果设备不支持锁页内存的映射，cudaHostGetDevicePointer()也会返回一个错误。程序可以通过检查设备属性canMapHostMemory来判断是否支持该功能，若支持，则该属性为1。 值得注意的是，从主机或其他设备的角度来看，在映射后的锁页内存上的原子操作并不是原子操作（详见官方文档Atomic Functions）。 还要注意的是，从主机和其他设备的角度来看，CUDA运行时要求由设备发起的对主机内存的1字节、2字节、4字节和8字节天然对齐的加载和存储保留为单一访问。在某些平台上，对内存的原子操作可能会被设备分解为单独的加载和存储操作。这些加载和存储操作对天然对齐访问的保留有相同的要求。例如，某PCI-E拓扑将8字节天然对齐写入拆分为两个4字节写入，CUDA运行时不支持在主机和设备之间基于这种PCI-E总线拓扑进行访问。 我们尝试利用映射内存来执行一个向量求和的操作，对比使用设备内存和映射内存的情况，详细代码参考mapped_memory.cu。经过分析不同数据量情况下的性能，计算减速比，可以总结出下表。减速比使用映射内存的耗时使用设备内存的耗时。 数据量 设备内存（ns） 映射内存（ns） 减速比 1KB 1,312 2,688 2.0488 4KB 1,344 3,200 2.3810 16KB 1,312 4,800 3.6585 64KB 1,472 8,351 5.6732 256KB 1,856 24,511 13.2064 1MB 5,312 89,950 16.9334 4MB 27,232 350,232 12.8610 16MB 105,405 1,377,504 13.0687 64MB 428,246 5,514,658 12.8773 从这样的结果可以看出，如果想要在主机和设备间共享的少量数据，映射内存是一个不错的选择。但对于大的数据量来说，映射内存并不是好的选择，会导致性能显著的下降。 统一虚拟地址空间 从CUDA 4.0开始引入了一种特殊的寻址方式，成为统一虚拟寻址（UVA）。通过CUDA API分配的所有主机内存以及支持UVA的设备分配的所有设备内存都在此虚拟地址范围内。 通过CUDA分配的任何主机内存，或使用统一地址空间的设备内存，可以使用cudaPointerGetAttributes()来获取指针的信息。 当与使用统一地址空间的任何设备之间发生内存拷贝时，cudaMemcpy*()的cudaMemcpyKind参数可以设置为cudaMemcpyDefault。这也适用于未通过CUDA分配的主机指针，只要当前设备使用统一寻址即可。 通过cudaHostAlloc()分配的内存可以自动移植到使用统一地址空间的设备上（详见可移植内存），并且cudaHostAlloc()返回的指针可以直接从这些设备上运行的核函数中使用，即不需要像映射内存中描述的那样通过cudaHostGetDevicePointer()获取设备指针。 应用程序可以通过检查unifiedAddressing设备属性是否等于1来查询设备是否支持统一地址空间。 详细示例代码参考unified_virtual_address.cu。 统一内存寻址 CUDA 6.0中引入了统一内存寻址，用于简化CUDA中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的指针在CPU和GPU上访问。底层在统一内存空间中自动在主机和设备之间进行数据传输。 统一内存寻址依赖于统一虚拟寻址（UVA），但它们是完全不同的技术。UAV只是为系统中所有处理器提供了单一的虚拟内存地址空间。但UAV不会自动改变数据的物理位置，这是统一内存寻址的一个特有功能。 托管内存指的是由底层系统自动分配的统一内存，与特定设备的分配内存可以互操作，如它们的创建都使用cudaMalloc()。故可以在核函数中使用两种内存： 由系统控制的托管内存； 由程序明确分配和调用的未托管内存。 在设备内存上的有效CUDA操作也同样适用于托管内存，主要区别是主机也能引用和访问托管内存。 托管内存可以被静态分配，也可以被动态分配。使用__managed__修饰符静态声明一个设备变量作为托管变量，该变量可以从主机或设备代码中直接被引用。 1__device__ __managed__ int y; 也可以使用CUDA运行时APIcudaMallocManaged()来动态分配托管内存。 设备内存L2访问管理 当CUDA核心反复访问全局内存中的数据区域时，这种数据访问是持久化的。若数据只被访问一次，则这种数据访问是流式的。从CUDA 11.0开始，计算能力8.0及以上的设备能够影响L2缓存中的数据持久化，从而提供更高的带宽和更低的全局内存访问延迟。 为持久化访问预留的L2缓存 可以预留一部分L2缓存用于持久化全局内存的数据访问，持久化访问优先使用L2缓存的这个部分。只有当持久化访问未使用这一部分时，普通或流式访问才能使用L2缓存。 用于持久化访问的L2预留缓存大小可以在一定范围内调整。 1234cudaGetDeviceProperties(&amp;prop, device_id);size_t size = min(int(prop.l2CacheSize * 0.75), prop.persistingL2CacheMaxSize);// 预留3/4的L2缓存用于持久化访问，或用最大L2持久化缓存大小cudaDeviceSetLimit(cudaLimitPersistingL2CacheSize, size); 当GPU配置为多实例GPU（MIG）模式时，将禁用L2缓存预留功能。当使用多进程服务（MPS）时，cudaDeviceSetLimit()无法改变L2缓存的预留大小，只能通过MPS服务器启动时的环境变量CUDA_DEVICE_DEFAULT_PERSISTING_L2_CACHE_PERCENTAGE_LIMIT来指定。 L2持久化访问策略 访问策略窗口指定了一个连续的全局内存区域及其持久化属性。 下面的例子使用CUDA流（CUDA Stream）设置L2持久化访问窗口。 12345678910111213141516// 流级别属性数据结构cudaStreamAttrValue stream_attribute;// 全局内存数据指针stream_attribute.accessPolicyWindow.base_ptr = reinterpret_cast&lt;void*&gt;(ptr);// 持久化访问的总字节数，必须小于cudaDeviceProp::accessPolicyMaxWindowSizestream_attribute.accessPolicyWindow.num_bytes = num_bytes;// 缓存命中率stream_attribute.accessPolicyWindow.hitRatio = 0.6;// 缓存命中时的访存方式stream_attribute.accessPolicyWindow.hitProp = cudaAccessPropertyPersisting;// 缓存未命中时的访存方式stream_attribute.accessPolicyWindow.missProp = cudaAccessPropertyStreaming;// 将属性配置到cudaStream_t类型的CUDA流中cudaStreamSetAttribute(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute); 当核函数在CUDA流中执行时，全局内存范围[ptr..ptr+num_bytes)内的数据比其他地方的数据更有可能被持久化在L2缓存中。 下面的例子是L2缓存持久化在CUDA图核结点（CUDA Graph Kernel Node）中的应用。 12345678910111213141516// 核级别的属性数据结构cudaKernelNodeAttrValue node_attribute;// 全局内存数据指针node_attribute.accessPolicyWindow.base_ptr = reinterpret_cast&lt;void*&gt;(ptr);// 持久化访问的总字节数，必须小于cudaDeviceProp::accessPolicyMaxWindowSizenode_attribute.accessPolicyWindow.num_bytes = num_bytes;// 缓存命中率node_attribute.accessPolicyWindow.hitRatio = 0.6;// 缓存命中时的访存方式node_attribute.accessPolicyWindow.hitProp = cudaAccessPropertyPersisting; // 缓存未命中时的访存方式node_attribute.accessPolicyWindow.missProp = cudaAccessPropertyStreaming;// 将属性配置到cudaGraphNode_t类型的CUDA图核结点中cudaGraphKernelNodeSetAttribute(node, cudaKernelNodeAttributeAccessPolicyWindow, &amp;node_attribute); hitRatio参数可以指定以hitProp方式访存的占比。在上面两个例子中，全局内存区域[ptr..ptr+num_bytes)内，60%的内存访问是持久化的，40%的访问是流式的。具体哪些内存访问是hitProp方式是随机的，这个概率是接近hitRatio的，概率分布取决于硬件结构和存储范围。 例如，若L2预留预测大小为16KB，accessPolicyWindow.num_bytes为32KB： 当hitRatio = 0.5时，硬件将随机选择32KB窗口中的16KB作为持久化缓存存入预留的L2缓存中； 当hitRatio = 1时，硬件会尝试在预留的L2缓存区中缓存整个32KB的窗口。但由于预留区小于窗口，缓存行将被移除，以将最近使用的32KB数据中的16KB持久化在L2缓存的预留区中。 hitRatio可以用来避免缓存行抖动，从宏观上减少进出L2缓存的数据量。可以利用低于1的hitRatio来手动控制不同accessPolicyWindow的并发CUDA流能够缓存在L2中的数据量。例如，假设L2的预留缓存大小为16KB，两个不同CUDA流中的核函数是并发的，每个核函数的accessPolicyWindow均为16KB，hitRatio均为1，在竞争共享的L2缓存时可能会移除彼此的缓存行。但如果两个accessPolicyWindow的hitRatio均为0.5，则不太可能会清楚自己或对方的持久缓存行。 L2访问属性 针对不同的全局内存数据访问，定义了3种类型的访问属性： cudaAccessPropertyStreaming：伴随流式属性发生的内存访问不太可能持久化在L2缓存中，因为这些访问会被优先清除； cudaAccessPropertyPersisting：伴随持久化属性发生的内存访问更可能持久化在L2缓存中，因为这些访问会优先被保留在L2缓存中的预留区； cudaAccessPropertyNormal：该访问属性会将之前持久化的访问强制重置为正常访问。之前CUDA核函数中的持久化属性的内存访问可能会在很长时间内留在L2缓存中，这个时间是远超预期的使用时间的。这种情况会导致后续的核函数不强制使用持久化属性内存访问时可用的L2缓存空间。而使用cudaAccessPropertyNormal可以重置访问属性，改变其持久状态，使得后续的核函数可以利用更多的L2缓存。 L2持久化示例 下面是为持久访问预留L2缓存的例子，通过CUDA流在CUDA核函数中使用预留的L2缓存并重置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647cudaStream_t stream;// 创建CUDA流cudaStreamCreate(&amp;stream);// CUDA设备属性变量cudaDeviceProp prop;// 查询GPU属性cudaGetDeviceProperties(&amp;prop, device_id);size_t size = min(int(prop.l2CacheSize * 0.75) , prop.persistingL2CacheMaxSize);// 预留3/4的L2缓存用于持久化访问，或用最大L2持久化缓存大小cudaDeviceSetLimit(cudaLimitPersistingL2CacheSize, size);// 取用户定义的num_bytes和最大窗口大小的较小值作为最终窗口大小size_t window_size = min(prop.accessPolicyMaxWindowSize, num_bytes);// 流级别属性数据结构cudaStreamAttrValue stream_attribute;// 全局内存数据指针stream_attribute.accessPolicyWindow.base_ptr = reinterpret_cast&lt;void*&gt;(data1);// 持久化访问的总字节数stream_attribute.accessPolicyWindow.num_bytes = window_size;// 缓存命中率stream_attribute.accessPolicyWindow.hitRatio = 0.6;// 缓存命中时的访存方式stream_attribute.accessPolicyWindow.hitProp = cudaAccessPropertyPersisting;// 缓存未命中时的访存方式stream_attribute.accessPolicyWindow.missProp = cudaAccessPropertyStreaming;// 将属性配置到CUDA流中cudaStreamSetAttribute(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);for(int i = 0; i &lt; 10; i++) { // data1被核函数多次使用 cuda_kernelA&lt;&lt;&lt;grid_size,block_size,0,stream&gt;&gt;&gt;(data1);} // [data1..data1 + num_bytes)范围内的数据受益于L2持久化// 在同一个CUDA流中的不同核函数也能受益于data1的持久化cuda_kernelB&lt;&lt;&lt;grid_size,block_size,0,stream&gt;&gt;&gt;(data1);// 将窗口总字节数设置为0来禁用持久化stream_attribute.accessPolicyWindow.num_bytes = 0;// 覆写CUDA流的访问属性cudaStreamSetAttribute(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);// 将L2中的所有持久化缓存行重置为普通状态cudaCtxResetPersistingL2Cache();// 由于之前的清除操作，data2当前也可以以普通访存模式受益于L2持久化访问cuda_kernelC&lt;&lt;&lt;grid_size,block_size,0,stream&gt;&gt;&gt;(data2); 将L2访问重置为普通 主要有三种方式： 通过cudaAccessPropertyNormal访问属性来重置支持持久化内存区域的访存属性； 通过cudaCtxResetPersistingL2Cache()调用将所有持久化L2缓存行重置为普通状态； 最终未受影响的缓存行将自动重置为普通状态，在开发过程中不应该依赖于自动重置，因为自动重置所需的时间是不确定的。 管理L2预留缓存的利用率 不同CUDA流中并发执行的多个CUDA核函数可能分配不同的访问策略窗口，但L2的预留缓存部分在所有核函数之间共享，故L2预留区的使用量是所有并发CUDA核函数使用量的总和。当持久化访问的容量超过了L2缓存的容量时，将内存访问指定为持久化状态的收益就会降低。 综上，程序应该考虑以下因素： L2缓存预留区的大小； 可能并发执行的CUDA核函数； 所有可能并发执行的核函数的访问策略窗口； 重置L2的时机和方式，以允许普通访问或流式访问以同等优先级利用L2缓存的预留区。 查询L2缓存属性 与L2缓存相关的属性是cudaDeviceProp结构体的一部分，可以通过CUDA运行时APIcudaGetDeviceProperties获取。 CUDA设备属性包括： l2CacheSize：GPU上可用的L2缓存容量； persistingL2CacheMaxSize：L2缓存中可用于持久化访存的最大预留容量； accessPolicyMaxWindowSize：访问策略窗口的最大大小。 控制持久化访存的L2缓存预留大小 用于持久化访存的L2预留缓存大小可以使用CUDA运行时APIcudaDeviceGetLimit查询，使用cudaLimit通过cudaDeviceSetLimit设置预留区大小。该设置的最大值是cudaDeviceProp::persistingL2CacheMaxSize。 1234enum cudaLimit { /* other fields not shown */ cudaLimitPersistingL2CacheSize}; 内存访问模式 CUDA执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行，存储操作也是同样的。在执行内存指令时，线程束中每个线程都提供了一个正在加载或存储的内存地址。在线程束的32个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以分为不同的模式。 对齐与合并访问 全局内存通过缓存来实现加载 / 存储。全局内存是一个逻辑内存空间，可以通过核函数来访问。所有的程序数据最初存在DRAM上，即物理设备内存中。核函数的内存请求通常是在DRAM设备和片上内存间以128字节或32字节的内存事务来实现的。 若一个内存访问同时用到了一级和二级缓存，则该访问由128字节的内存事务实现； 若一个内存访问只用到了二级缓存，则该访问由32字节的内存事务实现。 对于允许使用一级缓存的设备，可以在编译时选择是否启用一级缓存。 一个一级缓存行是128字节，它映射到设备内存中的一个128字节对齐段。若线程束中的每个线程请求4字节的值，则每次请求就会获取128字节的数据，这恰好与一级缓存行大小一致。在优化程序时，需要注意内存访问的两个特性： 对齐内存访问：当设备内存事务的第一个地址是缓存粒度的偶数倍时（32B的L2或128B的L1），就会出现对齐内存访问，非对齐的加载会造成带宽浪费； 合并内存访问：当一个线程束中全部的32个线程访问一个连续的内存块时，就会出现合并内存访问。 对齐合并内存访问的理想状态是线程束从对齐内存地址开始访问一个连续的内存块。一个理想的对齐合并访问如下图所示。 这种情况下，只需要一个128字节的内存事务就可以从设备内存中完成读取。但下面这种情况就可能需要3个128字节的内存事务，大大浪费了带宽。 全局内存读取 在SM中，数据通过一级和二级缓存、常量缓存、只读缓存3种缓存路径进行传输，具体使用哪种方式取决于所引用的设备内存类型。一、二级缓存是默认路径。若想通过其他两种路径传递数据则需要显式说明，但若想提升性能还要取决于使用的访问模式。全局内存加载是否通过一级缓存取决于设备的计算能力和编译器选项两个因素。使用编译器选项-Xptxas -dlcm=fg来禁用一级缓存，-Xptxas -dlcm=ca来启动一级缓存。 若一级缓存被禁用，所有对全局内存的加载请求将直接进入二级缓存。若二级缓存未命中，则由DRAM完成请求。每次内存事务可由一个、两个或四个部分执行，每个部分32字节。 若一级缓存被启用，全局内存加载请求首先尝试通过一级缓存。若一级缓存未命中，则请求转向二级缓存。若二级缓存也未命中，则请求由DRAM完成。这种模式下，一个内存加载请求由一个128字节的设备内存事务实现。 缓存加载 缓存加载操作经过一级缓存，在粒度为128字节的一级缓存行上由设备内存事务进行传输。缓存加载可以分为对齐、非对齐、合并、非合并几种情况。 下图为一个理性情况，即对齐与合并内存访问。线程束中的所有请求均在128字节的缓存行范围内。只需要一个128字节的事务，总线利用率为100%，事务中没有未使用数据。 而下图则是另一种情况，访问是对齐的，但引用的地址不是连续的线程ID，是128字节内的随机值。只需要一个128字节的事务，总线利用率为100%，只有每个线程请求的地址均不同的情况下，该事务中才没有未使用数据。 下图中线程束请求32个连续的4字节非对齐数据。需要两个128字节的事务，总线利用率为50%，两个事务中各有一半的数据是未使用的。 下图线程束中的所有线程都请求相同的地址。需要一个128字节的事务，若请求的值是4字节的，则总线利用率为3.125%（）。 下图则是最坏的情况，线程束中线程请求分散于全局内存中的32个不同地点。地址需要占用N个缓存行（），需要N个128字节的事务。 没有缓存的加载 没有缓存的加载不经过一级缓存，它在内存段的粒度上（32B）而非缓存池的粒度（128B）执行。这种更细粒度的加载，可以为非对齐或非合并的内存访问带来更好的总线利用率。 下图是对齐与合并的内存访问，128字节请求的地址占用了4个内存段，总线利用率为100%。 下图的内存访问是对齐的，但线程访问是不连续的，而是在128个字节范围内随机进行。只要每个线程请求唯一的地址，则地址将占用4个内存段，且不会有加载浪费。这样的随机访问不会抑制核函数性能。 下图中线程束请求32个连续的4字节元素，但加载没有对齐。请求的地址最多落在5个内存段内，总线利用率至少为80%。与类似情况的缓存加载相比，非缓存加载会提升性能，因为加载了更少的未请求字节。 下图线程束中所有线程请求相同的数据。地址落在一个内存段内，总线利用率为12.5%（）。在这种情况下，非缓存加载的性能也是优于缓存加载的。 下图则是最坏的情况，线程束请求32个分散在全局内存中的不同地方。请求的128个字节最多落在N个32字节的内存段内，而不是N个128字节的缓存行内，所以相比于缓存加载，即便是最坏情况也有所改善。 read_segment.cu是一个非对齐读取的示例，实现一个带偏移量的向量求和核函数。 1234567__global__ void sumArraysReadOffset(float *A, float *B, float *C, const int size, int offset){ unsigned tid = blockIdx.x * blockDim.x + threadIdx.x; unsigned j = tid + offset; if (tid &lt; size) C[tid] = A[j] + B[j];} 这样可以通过offset来强制其进行非对齐内存访问，对不同的offset性能测试的结果如下。 123readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 0 elapsed 0.094464 msreadOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 11 elapsed 0.102912 msreadOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 128 elapsed 0.094112 ms 可以看到在offset为11的情况下速度是最慢的，此时两个输入向量的读取是非对齐的。我们借助ncu来分析这三种情况的全局加载效率和全局加载事务。 1234 全局加载效率 全局加载事务readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 0 100% 1048576readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 11 80% 1310716readOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 128 100% 1048544 关于这里的全局加载效率，在《CUDA C编程权威指南》一书中，在开启一级缓存的情况下，全局加载效率仅有50%左右，但禁用一级缓存后提升到了80%。但笔者测试了开启和禁用一级缓存两种情况，加载效率均为80%。 只读缓存 只读缓存最初是预留给纹理内存加载使用的，对计算能力3.5以上的GPU，只读缓存也支持使用全局内存加载代替一级缓存。 只读缓存的加载粒度是32字节，有两种方式可以指导内存通过只读缓存读取： 使用函数__ldg； 在间接引用的指针上使用修饰符。 例如下面的核函数。 1234__global__ void copyKernel(int *out, int *in) { int idx = blockIdx.x * blockDim.x + threadIdx.x; out[idx] = in[idx];} 可以通过在核函数内部使用__ldg来通过只读缓存直接对数组进行读取访问。 1234__global__ void copyKernel(int *out, int *in) { int idx = blockIdx.x * blockDim.x + threadIdx.x; out[idx] = __ldg(&amp;in[idx]);} 也可以将限制修饰符__restrict__应用到指针上，该修饰符会使nvcc编译器将指针识别为无别名指针。nvcc将自动通过只读缓存来指导无别名指针的加载。 1234__global__ void copyKernel(int * __restrict__ out, const int * __restrict__ in) { int idx = blockIdx.x * blockDim.x + threadIdx.x; out[idx] = in[idx];} 全局内存写入 内存的存储操作相对简单，存储操作不能使用一级缓存进行，在发送到设备内存之前只通过二级缓存。存储操作在32字节段的粒度上被执行。内存事务可以同时被分为一段、两段或四段。 下图中为最理想的情况，内存访问是对齐的，且线程束中的所有线程访问一个连续的128字节范围。存储请求由一个四段事务实现。 下图的内存访问是对齐的，但地址分散在192字节范围内，存储请求由三个一段事务实现。 下图中内存访问同样是对齐的，且地址访问在一个连续的64字节范围内，存储请求由一个两段事务实现。 write_segment.cu是一个非对齐写入的示例，实现一个带偏移量的向量求和核函数。 1234567__global__ void sumArraysWriteOffset(float *A, float *B, float *C, const int size, int offset){ unsigned tid = blockIdx.x * blockDim.x + threadIdx.x; unsigned j = tid + offset; if (j &lt; size) C[j] = A[tid] + B[tid];} 与上面非对齐读取的例子不同，这次将C与A、B的索引颠倒了过来。通过offset来强制其进行非对齐写入，性能测试结果如下。 123writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 0 elapsed 0.109920 mswriteOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 11 elapsed 0.111616 mswriteOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 128 elapsed 0.110592 ms 类似地，利用ncu来分析全局存储效率和全局存储事务。 1234 全局存储效率 全局存储事务writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 0 100% 524288writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 11 80% 655358writeOffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 128 100% 524272 值的注意的是，若写入的两个地址同属于一个128字节区域，但不属于一个对齐的64字节区域，则会执行一个四段事务，而不是两个一段事务。 结构体数组与数组结构体 C语言中有两种数据组织方式： 数组结构体（AoS）； 结构体数组（SoA）。 假设要存储一组成对的浮点数，两种不同的方式如下。 AoS方式： 12345struct innerStruct { float x; float y;};struct innerStruct myAoS[N]; SoA方式： 12345struct innerArray { float x[N]; float y[N];};struct innerArray mySoA; 观察两种存储方式的内存布局。 可以发现SoA模式充分利用了GPU的内存带宽，由于没有相同字段元素的交叉存取，GPU上的SoA布局提供了合并内存访问，可以对全局内存实现更高效的利用。 array_of_structure.cu和structure_of_array.cu是使用AoS模式和SoA模式下的对比，性能测试结果如下。 12AoS innerStruct&lt;&lt;&lt;8192, 128&gt;&gt;&gt; elapsed 0.033280 msSoA innerArray&lt;&lt;&lt;8192, 128&gt;&gt;&gt; elapsed 0.032640 ms 通过分析它们的全局加载和存储效率可以印证上面的观点，即SoA布局充分利用了GPU的内存带宽。 123 全局加载效率 全局存储效率AoS innerStruct&lt;&lt;&lt;8192, 128&gt;&gt;&gt; 50% 50%SoA innerArray&lt;&lt;&lt;8192, 128&gt;&gt;&gt; 100% 100% 性能调整 优化设备内存带宽利用率有两个目标： 对齐及合并内存访问，以减少带宽的浪费； 足够的并发内存操作，以隐藏内存延迟。 展开技术 将之前提到的非对齐读取的例子read_segment.cu，将其循环展开。 123456789101112__global__ void readOffsetUnroll4(float *A, float *B, float *C, const int size, int offset){ unsigned int tid = blockIdx.x * blockDim.x * 4 + threadIdx.x; unsigned int j = tid + offset; if (j + 3 * blockDim.x &lt; size) { C[tid] = A[j] + B[j]; C[tid + blockDim.x] = A[j + blockDim.x] + B[j + blockDim.x]; C[tid + blockDim.x * 2] = A[j + blockDim.x * 2] + B[j + blockDim.x * 2]; C[tid + blockDim.x * 3] = A[j + blockDim.x * 3] + B[j + blockDim.x * 3]; }} 性能测试结果如下。 123456offset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 0 elapsed 0.107520 msunroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt; offset 0 elapsed 0.099104 msoffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 11 elapsed 0.109216 msunroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt; offset 11 elapsed 0.100640 msoffset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 128 elapsed 0.108352 msunroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt; offset 128 elapsed 0.098976 ms 分析其全局加载和存储效率，以及全局加载和存储事务。 123 全局加载效率 全局存储效率 全局加载事务 全局存储事务offset&lt;&lt;&lt;8192, 512&gt;&gt;&gt; offset 11 80% 100% 1310704 524284unroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt; offset 11 80% 100% 1310716 524287 这里笔者的测试结果没有太大的差距，原因是笔者开启和禁用一级缓存两种情况下，未展开的核函数差别本就不大。所以即使展开之后，性能提升也不明显，但这个优化手段是值的参考的。 增大并行性 用不同的线程块大小测试上面展开的核函数，结果如下。 123456789unroll4&lt;&lt;&lt;1024, 1024&gt;&gt;&gt; offset 0 elapsed 0.099104 msunroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt; offset 0 elapsed 0.095840 msunroll4&lt;&lt;&lt;4096, 256&gt;&gt;&gt; offset 0 elapsed 0.096096 msunroll4&lt;&lt;&lt;8192, 128&gt;&gt;&gt; offset 0 elapsed 0.096320 msunroll4&lt;&lt;&lt;1024, 1024&gt;&gt;&gt; offset 11 elapsed 0.098624 msunroll4&lt;&lt;&lt;2048, 512&gt;&gt;&gt; offset 11 elapsed 0.097504 msunroll4&lt;&lt;&lt;4096, 256&gt;&gt;&gt; offset 11 elapsed 0.097568 msunroll4&lt;&lt;&lt;8192, 128&gt;&gt;&gt; offset 11 elapsed 0.097408 ms 不管是对齐的还是非对齐的访问，增大并行性都可以带来一些提升。 核函数可达到的带宽 内存带宽 大多数核函数对内存带宽非常敏感，也就是说它们有内存带宽限制。全局内存中数据的排布方式，以及线程束访问该数据的方式都对带宽有显著的影响。一般分为两个概念： 理论带宽：当前硬件可以实现的绝对最大带宽； 有效带宽：核函数实际达到的带宽，是测量带宽，公式如下。 有效带宽读字节数写字节数运行时间 矩阵转置问题 在主机端利用错位转置算法可以很容易的实现上述操作。 123456void transposeHost(float *out, float *in, const int nx, const int ny){ for (int iy = 0; iy &lt; ny; iy++) for (int ix = 0; ix &lt; nx; ix++) out[ix * ny + iy] = in[iy * nx + ix];} 观察原矩阵和转置矩阵的内存数据排布。 可以很容易的分析出，读取过程是访问原矩阵的行，是合并访问，写入过程是访问转置矩阵的列，是交叉访问。 核函数有两种主要方式来实现矩阵的转置： 按行读取，按列存储； 按列读取，按行存储。 为转置核函数设置性能的上限和下限 实现两个核函数，一个读取和存储都按行，另一个读取和存储都按列。 123456789101112131415__global__ void copyRow(float *out, float *in, const int nx, const int ny){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; if (ix &lt; nx &amp;&amp; iy &lt; ny) out[iy * nx + ix] = in[iy * nx + ix];}__global__ void copyCol(float *out, float *in, const int nx, const int ny){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; if (ix &lt; nx &amp;&amp; iy &lt; ny) out[ix * ny + iy] = in[ix * ny + iy];} 这两个核函数可以分别测得与转置操作相同内存操作情况下，全部使用合并访问（按行读写）以及全部使用交叉访问（按列读写）的有效带宽。 核函数 带宽（GB/s） 备注 CopyRow 1367.11 上限 CopyCol 595.78 下限 朴素转置 分别实现矩阵转置问题中提到的两种转置方式，即按行加载按列存储与按列加载按行存储。 123456789101112131415__global__ void transposeNaiveRow(float *out, float *in, const int nx, const int ny){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; if (ix &lt; nx &amp;&amp; iy &lt; ny) out[ix * ny + iy] = in[iy * nx + ix];}__global__ void transposeNaiveCol(float *out, float *in, const int nx, const int ny){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; if (ix &lt; nx &amp;&amp; iy &lt; ny) out[iy * nx + ix] = in[ix * ny + iy];} 像上面那样测试有效带宽，对比结果如下，同时分析其全局加载、存储吞吐量和全局加载、存储效率。 核函数 带宽（GB/s） 加载吞吐量（GB/s） 存储吞吐量（GB/s） 加载效率（%） 存储效率（%） 备注 NaiveRow 321.25 126.85 507.42 100 25 合并读取，交叉存储 NaiveCol 911.80 609.64 152.41 25 100 交叉读取，合并存储 可以发现两种方式的性能相近，这是因为在交叉读取的过程中，会有数据进入一级缓存。虽然读取的数据不连续，但在后续的读取过程中，仍然有可能发生缓存命中。禁用一级缓存后，有效带宽表现如下， 核函数 带宽（GB/s） 加载吞吐量（GB/s） 存储吞吐量（GB/s） 加载效率（%） 存储效率（%） 备注 NaiveRow 330.99 128.38 513.50 100 25 合并读取，交叉存储，禁用一级缓存 NaiveCol 489.07 472.76 118.19 25 100 交叉读取，合并存储，禁用一级缓存 可以看到，没有一级缓存的帮助后，交叉读取的有效带宽下降了。对于NaiveCol实现来说，由于写入是合并的，存储请求未被重复执行。但由于交叉读取，多次重复执行了加载请求。即使不是最好的加载方式，但有一级缓存的帮助，也能限制交叉读取对性能的负面影响。 后面的讨论都默认启用一级缓存。 展开转置 利用循环展开技术改进两个朴素转置核函数。 1234567891011121314151617181920212223242526272829303132__global__ void transposeUnroll4Row(float *out, float *in, const int nx, const int ny){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; unsigned int ti = iy * nx + ix; unsigned int to = ix * ny + iy; if (ix + blockDim.x * 3 &lt; nx &amp;&amp; iy &lt; ny) { out[to] = in[ti]; out[to + ny * blockDim.x] = in[ti + blockDim.x]; out[to + ny * blockDim.x * 2] = in[ti + blockDim.x * 2]; out[to + ny * blockDim.x * 3] = in[ti + blockDim.x * 3]; }}__global__ void transposeUnroll4Col(float *out, float *in, const int nx, const int ny){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; unsigned int ti = ix * ny + iy; unsigned int to = iy * nx + ix; if (ix + blockDim.x * 3 &lt; nx &amp;&amp; iy &lt; ny) { out[to] = in[ti]; out[to + blockDim.x] = in[ti + ny * blockDim.x]; out[to + blockDim.x * 2] = in[ti + ny * blockDim.x * 2]; out[to + blockDim.x * 3] = in[ti + ny * blockDim.x * 3]; }} 进行性能测试，总结如下。 核函数 带宽（GB/s） 加载吞吐量（GB/s） 存储吞吐量（GB/s） 加载效率（%） 存储效率（%） 备注 Unroll4Row 72.88 117.29 469.16 100 25 合并读取，交叉存储，展开 Unroll4Col 324.44 1843.45 465.67 25 100 交叉读取，合并存储，展开 启用一级缓存，并展开后，可以观察到Unroll4Col的加载吞吐量有了质的提升。 对角转置 当启动一个线程块网格时，线程块会被分配给SM。虽然编程模型可能将网格抽象成一维、二维或三维，但在硬件看来所有块都是一维的。当启动一个核函数时，线程块被分配给SM的顺序由块ID来确定。一开始可能还会以顺序来分配线程块，直到所有SM被完全占满。由于线程块完成的速度和顺序是不确定的，随着核函数的执行，活跃的线程块ID将变得不太连续。 虽然无法直接调控线程块的顺序，但可以利用对角坐标来间接调控，下图展示了直角坐标与对角坐标的区别。 可以利用对角坐标来确定线程块的ID，但仍需要直角坐标来访问数据。将blockIdx.x和blockIdx.y当作对角坐标后，对于方阵来说，可以用如下映射关系来访问正确的数据块。 12blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;blk_y = blockIdx.x; 这里的blk_x和blk_y即为线程块对应的直角坐标。下面分别实现行读列写和列读行写的对角转置核函数。 1234567891011121314151617181920212223__global__ void transposeDiagonalRow(float *out, float *in, const int nx, const int ny){ unsigned int blk_x = (blockIdx.x + blockIdx.y) % gridDim.x; unsigned int blk_y = blockIdx.x; unsigned int ix = blockDim.x * blk_x + threadIdx.x; unsigned int iy = blockDim.y * blk_y + threadIdx.y; if (ix &lt; nx &amp;&amp; iy &lt; ny) out[ix * ny + iy] = in[iy * nx + ix];}__global__ void transposeDiagonalCol(float *out, float *in, const int nx, const int ny){ unsigned int blk_x = (blockIdx.x + blockIdx.y) % gridDim.x; unsigned int blk_y = blockIdx.x; unsigned int ix = blockDim.x * blk_x + threadIdx.x; unsigned int iy = blockDim.y * blk_y + threadIdx.y; if (ix &lt; nx &amp;&amp; iy &lt; ny) out[iy * nx + ix] = in[ix * ny + iy];} 性能测试结果如下。 核函数 带宽（GB/s） 加载吞吐量（GB/s） 存储吞吐量（GB/s） 加载效率（%） 存储效率（%） 备注 DiagonalRow 330.99 133.47 533.90 100 25 合并读取，交叉存储，对角 DiagonalCol 910.22 592.08 148.02 25 100 交叉读取，合并存储，对角 通过使用对角坐标来修改线程块的执行顺序，使得基于行读列写的核函数性能大幅度提升，但列读行写的核函数没有什么提升。对角核函数的实现依然可以使用展开技术来优化，但不像直角坐标那样直观。 这种性能的提升与DRAM的并行访问有关。核函数发起的全局内存请求由DRAM分区完成，设备内存中连续的256字节区域被分配到连续的分区。当使用直角坐标线程块时，全局内存的访问无法被均匀分配到DRAM的分区中，就可能发生分区冲突。进而导致内存请求在某些分区中排队，而某些分区一直未被调用。由于对角坐标是一种线程块与数据块之间的非线性映射，所以交叉访问不太可能会落入同一个分区中，进而带来了性能的提升。 使用瘦块增加并行性 对之前实现的列读行写的朴素转置进行测试，分别使用不同的块大小设计，测试结果如下。 核函数 块大小 带宽（GB/s） 加载吞吐量（GB/s） 存储吞吐量（GB/s） 加载效率（%） 存储效率（%） NaiveCol (32, 32) 491.14 1073.98 133.64 12.5 100 NaiveCol (32, 16) 718.69 1076.43 133.88 12.5 100 NaiveCol (32, 8) 739.48 872.00 109.00 12.5 100 NaiveCol (16, 32) 1061.31 778.74 194.69 25 100 NaiveCol (16, 16) 963.76 583.35 145.84 25 100 NaiveCol (16, 8) 910.22 432.14 108.03 25 100 NaiveCol (8, 32) 1057.03 410.24 205.12 50 100 NaiveCol (8, 16) 1064.54 327.78 163.89 50 100 NaiveCol (8, 8) 731.22 233.07 116.53 50 100 性能最佳的为(16, 32)、(8, 32)和(8, 16)的块，这种性能提升是由瘦块带来的。可以观察到(8, 32)的存储吞吐量是最高的。 我们进一步测试(8, 32)的块在各个核函数下的性能表现。 核函数 块大小 带宽（GB/s） 加载吞吐量（GB/s） 存储吞吐量（GB/s） 加载效率（%） 存储效率（%） 备注 CopyRow (8, 32) 1071.06 206.66 206.66 100 100 合并读取，合并存储 CopyCol (8, 32) 1057.03 422.47 422.47 50 50 交叉读取，交叉存储 NaiveRow (8, 32) 627.13 197.70 395.39 100 50 合并读取，交叉存储 NaiveCol (8, 32) 1097.98 426.77 213.39 50 100 交叉读取，合并存储 Unroll4Row (8, 32) 138.26 239.83 479.65 100 50 合并读取，交叉存储，展开 Unroll4Col (8, 32) 341.33 1236.83 598.49 50 100 交叉读取，合并存储，展开 笔者的测试结果与书中有所不同，书中测试结果最好的是Unroll4Col，但笔者这里最好的是NaiveCol。但从加载吞吐量来说，的确是Unroll4Col最优秀。 使用统一内存的矩阵加法* 用统一内存的方式实现矩阵加法，可以提高代码的可读性和易维护性，消除所有的显式内存副本。 具体代码参考matrix_sum_managed.cu和matrix_sum_manual.cu。 性能测试结果如下。 12sum matrix managed&lt;&lt;&lt;(128, 128), (32, 32)&gt;&gt;&gt; elapsed 17.284096 mssum matrix manual&lt;&lt;&lt;(128, 128), (32, 32)&gt;&gt;&gt; elapsed 0.470016 ms 可以观察到，虽然使用统一内存减少了编程的工作量，但性能却大幅度下降。更具体的性能测试如下。 任务 使用托管内存（ms） 不使用托管内存（ms） 数据初始化 355.60 354.77 CPU侧计算 7.07 15.02 CUDA memcpy HtoD 14.73 10.16 GPU侧计算（核函数） 19.90 0.50 CUDA memcpy DtoH 2.90 4.92 可以观察到，在使用托管内存的情况下，HtoD任务要花费更长的时间，核函数计算也需要更长的时间。 有趣的一点是，在关于数据初始化耗时的测试结果上，笔者与书中的描述相差甚远。在书中，使用托管内存的情况下，数据初始化的耗时要大于不使用托管内存的情况，但笔者的两种方式却相差无几。通过这一点可以看到CUDA在统一内存方面的优化痕迹。","link":"/posts/47184/"},{"title":"CUDA编程——共享内存和常量内存","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 共享内存概述 GPU中有两种类型的内存： 板载内存：全局内存是较大的板载内存，延迟相对较高； 片上内存：共享内存是较小的片上内存，延迟相对较低，同时带宽比全局内存高得多。 共享内存可以视作一个可编程的缓存，一般用于块内线程的通信，全局内存数据的可编程管理缓存，以及高速暂存存储器，用于转换数据以优化全局内存访问模式。 共享内存 使用内存空间说明符__shared__分配共享内存（Shared Memory）。再次回顾下图中的内存层次结构。 共享内存比全局内存快的多，可以当作暂存器或由程序管理的高速缓存来使用，以最小化block对全局内存的访问。 下面是直接实现矩阵乘法的例子，未使用共享内存，每个线程读取矩阵A的一行和矩阵B的一列进行计算。矩阵A将被从全局内存中读取B.width次，矩阵B将被从全局内存中读取A.height次。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 矩阵为行优先存储// M(row, col) = *(M.elements + row * M.width + col)typedef struct { int width; int height; float* elements;} Matrix;// 定义block的大小#define BLOCK_SIZE 16// 矩阵乘法核函数__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C){ // 每个线程计算一个C的元素 float Cvalue = 0; int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x; for (int e = 0; e &lt; A.width; ++e) Cvalue += A.elements[row * A.width + e * B.elements[e * B.width + col]; C.elements[row * C.width + col] = Cvalue;}// 主机代码// 假设矩阵的维数能够被BLOCK_SIZE整除void MatMul(const Matrix A, const Matrix B, Matrix C){ // 将A和B加载到设备内存 Matrix d_A; d_A.width = A.width; d_A.height = A.height; size_t size = A.width * A.height * sizeof(float); cudaMalloc(&amp;d_A.elements, size); cudaMemcpy(d_A.elements, A.elements, size, cudaMemcpyHostToDevice); Matrix d_B; d_B.width = B.width; d_B.height = B.height; size = B.width * B.height * sizeof(float); cudaMalloc(&amp;d_B.elements, size); cudaMemcpy(d_B.elements, B.elements, size, cudaMemcpyHostToDevice); // 在设备上申请结果矩阵 Matrix d_C; d_C.width = C.width; d_C.height = C.height; size = C.width * C.height * sizeof(float); cudaMalloc(&amp;d_C.elements, size); // 调用核函数 dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE); dim3 dimGrid(B.width / dimBlock.x, A.height / dimBlock.y); MatMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_A, d_B, d_C); // 从设备内存中读取结果矩阵C cudaMemcpy(C.elements, d_C.elements, size, cudaMemcpyDeviceToHost); // 释放设备内存 cudaFree(d_A.elements); cudaFree(d_B.elements); cudaFree(d_C.elements);} 整个访存过程如下图所示。 下面是使用共享内存实现矩阵乘法的例子。在下例中，每个block负责计算C的一个子矩阵Csub（方阵），block内的每个线程负责计算Csub的一个元素，Csub等于两个子矩阵的乘积。其中，A的子矩阵维度为(A.width, block_size)，行索引与Csub的行索引相同，B的子矩阵维度为(block_size, A.width)，列索引与Csub的列索引相同。 为了适配设备的资源，A、B的两个子矩阵被划分为多个维度为block_size的方阵，Csub即为这些方阵的乘积之和。将两个对应的方阵从全局内存中加载到共享内存中，其中每个线程加载两个对应方阵中的各一个元素，然后每个线程计算一个乘积。每个参与计算的线程都将乘积累加到一个寄存器中，完成累加后将结果写入全局内存。 通过这种方式，利用了共享内存的速度优势，节省了大量全局内存带宽。A只从全局内存中读取(B.width / block_size)次，而B只读取了(A.height / block_size)次。 下例还引入了stride，可以用相同的类型有效地表示子矩阵。利用了一个设备函数来获取和设置元素，并从矩阵中构建子矩阵。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// 矩阵为行优先存储// M(row, col) = *(M.elements + row * M.stride + col)typedef struct { int width; int height; int stride; float* elements;} Matrix;// 获取一个矩阵元素__device__ float GetElement(const Matrix A, int row, int col){ return A.elements[row * A.stride + col];}// 设置一个矩阵元素__device__ void SetElement(Matrix A, int row, int col, float value){ A.elements[row * A.stride + col] = value;}// 获取A的BLOCK_SIZE*BLOCK_SIZE子矩阵Asub，通过row、col以及stride和BLOCK_SIZE来定位 __device__ Matrix GetSubMatrix(Matrix A, int row, int col){ Matrix Asub; Asub.width = BLOCK_SIZE; Asub.height = BLOCK_SIZE; Asub.stride = A.stride; Asub.elements = &amp;A.elements[A.stride * BLOCK_SIZE * row + BLOCK_SIZE * col]; return Asub;}// 定义block的大小#define BLOCK_SIZE 16// 矩阵乘法核函数的前置声明__global__ void MatMulKernel(const Matrix, const Matrix, Matrix);// 矩阵乘法核函数 __global__ void MatMulKernel(Matrix A, Matrix B, Matrix C){ // block的行和列 int blockRow = blockIdx.y; int blockCol = blockIdx.x; // 每个block计算的子矩阵Csub Matrix Csub = GetSubMatrix(C, blockRow, blockCol); // 每个线程计算Csub的一个元素 float Cvalue = 0; // Csub中的线程的行和列 int row = threadIdx.y; int col = threadIdx.x; // 循环计算Csub所需的A和B的所有子矩阵，将每对子矩阵相乘并累加结果 for (int m = 0; m &lt; (A.width / BLOCK_SIZE); ++m) { // 获取A的子矩阵Asub Matrix Asub = GetSubMatrix(A, blockRow, m); // 获取B的子矩阵Bsub Matrix Bsub = GetSubMatrix(B, m, blockCol); // 用于分别存储Asub和Bsub的共享内存 __shared__ float As[BLOCK_SIZE][BLOCK_SIZE]; __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE]; // 将Asub和Bsub从设备内存加载到共享内存 // 每个线程加载每个子矩阵的一个元素 As[row][col] = GetElement(Asub, row, col); Bs[row][col] = GetElement(Bsub, row, col); // 同步，确保在开始计算之前子矩阵加载完整 __syncthreads(); // 将Asub和Bsub相乘 for (int e = 0; e &lt; BLOCK_SIZE; ++e) Cvalue += As[row][e] * Bs[e][col]; // 同步，确保下一次循环加载A和B的两个新子矩阵之前完成之前的计算 __syncthreads(); } // 将Csub写入设备内存，每个线程写入一个元素 SetElement(Csub, row, col, Cvalue);}// 主机代码基本一致，此处省略 整个访存过程如下图所示。 物理上，每个SM都有一个小的低延迟内存池，该内存池被当前正在该SM上执行的线程块中的所有线程共享。 当每个线程块开始工作时，会分配给它一定数量的共享内存。它的内容和创建时所在的线程块具有相同的生命周期。每个线程束发出的共享内存访问请求，理想情况下，每个请求在一个事务中完成。最坏情况下，每个共享内存的请求在32个不同的事务中顺序执行。若多个线程访问共享内存中的同一个字，一个线程读取该字后，会通过多播把它发给其他线程。 共享内存被SM中所有常驻线程块划分，因此共享内存是限制设备并行性的关键资源。一个核函数使用的共享内存越多，处于并发活跃状态的线程块就越少。 分布式共享内存 在计算能力9.0中引入的线程块集群为线程块集群中的线程提供了访问集群中所有参与线程块的共享内存能力。属于线程块集群的线程可以在分布式地址空间中读取、写入或执行原子，无论目标地址属于当前线程块还是集群中的其他线程块。无论核函数是否使用分布式共享内存（Distributed Shared Memory），共享内存范围仍然属于各自的线程块。分布式共享内存的大小就是每个集群的线程块数乘以每个线程块的共享内存大小。 访问分布式共享内存中的数据需要所有线程块都存在。使用cluster GroupAPI中的cluster.sync()可以保证所有线程块都已开始执行。还需要确保所有分布式共享内存操作都发生在线程块退出之前。 下面是一个计算直方图的例子，以及如何使用线程块集群在GPU上优化计算。计算直方图的一个标准方法是在每个线程块的共享内存中进行计算，然后在全局内存中执行原子操作。这种方法的一个限制是共享内存的容量，如果直方图的数据量无法与共享内存适配，就只能在全局内存中直接进行原子操作。 而对于分布式共享内存，CUDA提供了一个中间步骤，可以根据直方图的数据量，选择在共享内存、分布式共享内存或全局内存中计算直方图。 下面的CUDA核函数实现了根据直方图数据量选择计算直方图的内存空间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;cooperative_groups.h&gt;// 分布式共享内存计算直方图核函数__global__ void clusterHist_kernel(int *bins, const int nbins, const int bins_per_block, const int *__restrict__ input, size_t array_size){ extern __shared__ int smem[]; namespace cg = cooperative_groups; int tid = cg::this_grid().thread_rank(); // 集群初始化，获取集群尺寸，并计算局部数据偏移 cg::cluster_group cluster = cg::this_cluster(); unsigned int clusterBlockRank = cluster.block_rank(); int cluster_size = cluster.dim_blocks().x; for (int i = threadIdx.x; i &lt; bins_per_block; i += blockDim.x) { smem[i] = 0; //将共享内存中的直方图初始化为0 } // 集群同步，确保集群中的所有block的共享内存初始化为0，并确保所有block都开始执行且同时存在 cluster.sync(); for (int i = tid; i &lt; array_size; i += blockDim.x * gridDim.x) { int ldata = input[i]; // 寻找正确的直方图数据 int binid = ldata; if (ldata &lt; 0) binid = 0; else if (ldata &gt;= nbins) binid = nbins - 1; // 寻找目标block的行索引和行内偏移，以计算分布式共享内存的直方图 int dst_block_rank = (int)(binid / bins_per_block); int dst_offset = binid % bins_per_block; // 指向目标block共享内存的指针 int *dst_smem = cluster.map_shared_rank(smem, dst_block_rank); // 执行原子更新操作 atomicAdd(dst_smem + dst_offset, 1); } // 这里的集群同步是必须的，以确保所有分布式共享内存的操作都已完成 // 并确保当某个block在访问分布式共享内存时，不会有其他block结束。 cluster.sync(); // 使用局部分布式内存中的直方图，计算全局内存的直方图 int *lbins = bins + cluster.block_rank() * bins_per_block; for (int i = threadIdx.x; i &lt; bins_per_block; i += blockDim.x) { atomicAdd(&amp;lbins[i], smem[i]); }} 上面的核函数可以在运行时指定集群大小，集群的大小取决于分布式共享内存的需求。若直方图足够小，只能填满一个block的共享内存，则可以启动集群大小为1的核函数。 下面的代码实现了根据共享内存需求动态确定集群大小。 123456789101112131415161718192021222324252627282930// Launch via extensible launch// { cudaLaunchConfig_t config = {0}; config.gridDim = array_size / threads_per_block; config.blockDim = threads_per_block; // 集群大小取决于直方图的大小 // cluster_size == 1意味着不会有分布式共享内存，只有block局部共享内存 int cluster_size = 2; // 以集群大小2为例 int nbins_per_block = nbins / cluster_size; // 每个block的动态共享内存大小 // 分布式共享内存大小为cluster_size * nbins_per_block * sizeof(int) config.dynamicSmemBytes = nbins_per_block * sizeof(int); CUDA_CHECK(::cudaFuncSetAttribute((void *)clusterHist_kernel, cudaFuncAttributeMaxDynamicSharedMemorySize, config.dynamicSmemBytes)); cudaLaunchAttribute attribute[1]; attribute[0].id = cudaLaunchAttributeClusterDimension; attribute[0].val.clusterDim.x = cluster_size; attribute[0].val.clusterDim.y = 1; attribute[0].val.clusterDim.z = 1; config.numAttrs = 1; config.attrs = attribute; cudaLaunchKernelEx(&amp;config, clusterHist_kernel, bins, nbins, nbins_per_block, input, array_size);} 共享内存的分配 共享内存可以被静态或动态分配。上面也提到过，使用__shared__修饰符来申请共享内存。 下面的代码申请了一个共享内存中的二维数组。若该声明在核函数内，则该变量的作用域为该核函数中。若在文件的任何核函数外声明，则作用域对所有核函数来说是全局的。 1__shared__ float tile[size_y][size_x]; 若共享内存的大小在编译时无法确定，则可以用extern关键字进行声明。该声明同样可以在核函数内或核函数外。 1extern __shared__ int tile[]; 由于该数组的大小编译时是未知的，所以在核函数被调用时，需要动态分配共享内存。将所需的共享内存字节数在&lt;&lt;&lt;...&gt;&gt;&gt;的第三个参数传入。 1kernel&lt;&lt;&lt;grid, block, size * sizeof(int)&gt;&gt;&gt;(...) 注意：只能动态声明一维数组。 共享内存存储体和访问模式 内存存储体 为了获取高内存带宽，共享内存被分为32个同样大小的内存模型，被成为存储体，它们可以被同时访问。共享内存是一个一维地址空间。根据GPU的计算能力，共享内存的地址在不同模式下会映射到不同的存储体中。 如果通过线程束发布共享内存加载或存储操作，且在每个存储体上只访问不多于一个的内存地址，则该操作可以由一个内存事务来完成。否则该操作由多个内存事务完成，这样就降低了内存带宽的利用率。 存储体冲突 在共享内存中，多个地址请求落在同一个存储体时，就会发生存储体冲突，这会导致请求被重复执行。硬件会将存储体冲突的请求分割到尽可能多的独立无冲突事务中。当线程束发出共享内存请求时，有3种典型模式： 并行访问：多个地址访问多个存储体； 串行访问：多个地址访问同一个存储体； 广播访问：单一地址读取单一存储体。 并行访问是最常见的模式，这种模式下如果访问的不是范围内的所有地址，则至少有一些地址可以在一个内存事务中完成。最佳情况是每个地址都位于一个单独的存储体中，执行无冲突的共享内存访问。 串行访问是最坏的模式。如果线程束中的32个线程全都访问同一存储体中的不同地址，则需要32个内存事务，且是串行执行的。 广播访问的情况下，线程束中的所有线程都读取同一存储体的同一地址。若一个内存事务被执行，则被访问的字会广播到所有请求线程中。虽然只需要一个内存事务，但因为只有一小部分字节被读取，所以带宽利用率很差。 访问模式 内存存储体的宽度和设备计算能力有关，根据官方文档的描述，总结如下： 计算能力2.x、5.x、6.x、7.x、8.x存储体数量均为32个，宽度均为32bit； 计算能力3.x比较特殊，存储体数量为32个，宽度64bit。 对于32个32位的存储体来说，每个存储体在每两个时钟周期内都有32位的带宽，连续的32位字映射到连续的存储体中，因此共享内存地址到存储体索引的映射可以由下列公式计算。 存储体索引字节地址 映射关系如下图所示。 对于计算能力3.x的设备，存储体宽度为64bit，但它有两种地址模式，64位模式与32位模式。 在64模式下，每个存储体在每两个时钟周期内都有64位的带宽，连续的64位字映射到连续的存储体中，因此共享内存地址到存储体索引的映射可以由下列公式计算。 存储体索引字节地址 在32位模式下，在同一存储体中访问两个32位字不一定是重复操作。在一个时钟周期内读64位并只将32位请求传输给线程是允许的。由于64位宽度的存储体比较少见，这里不过多阐述。 内存填充 内存填充是避免存储体冲突的一种方法。以下图为例，假设只有5个存储体，若所有线程都访问bank0的不同地址，则会发生存储体冲突。但在每N个字后添加一个字，会使得原先同在bank0中的字改变位置，从而解决这种冲突。这里的N是存储体的数量。 配置共享内存容量 每个SM都有64KB的片上内存，共享内存和一级缓存共享硬件资源。CUDA为配置一级缓存和共享内存容量提供了两种方法： 按设备进行配置； 按核函数进行配置。 使用cudaDeviceSetCacheConfig()运行时API可以在设备层面设置一级缓存和共享内存大小，可选参数与下面的运行时API一致。 使用cudaFuncSetCacheConfig()运行时API可以在核函数层面设置，相关参数已经在共享内存阐述过了。 同步 CUDA提供的块内同步有两个基本方法： 障碍：所有调用的线程等待其余调用的线程达到障碍点； 内存栅栏：所有调用的线程必须等到全部内存修改对其余调用线程可见。 弱排序内存模型 GPU线程在不同内存中写入数据的顺序，不一定和这些数据在源代码中访问的顺序相同。一个线程的写入顺序对其他线程可见时，它可能和写操作被执行的实际顺序不一致。 若指令间是相互独立的，线程从不同内存中读取数据的顺序和读指令在程序中出现的顺序不一定相同。 显式障碍 设置障碍点的方法在前面已经见过了，即__syncthreads()函数。它要求块内的线程必须等待直到所有线程都到达该点。__syncthreads()还确保在障碍点之前，被这些线程访问的所有全局和共享内存对同一块中的所有线程可见。__syncthreads()用于协调同一块中线程间的通信。 在使用__syncthreads()时，必须保证一个条件能对整个线程块中的线程进行评估，否则执行很可能挂起甚至产生意料之外的问题。 12345if (threadID % 2 == 0) { __syncthreads();} else { __syncthreads();} 上面的例子中，可能会导致线程无限期的等待对方，因为块中的所有线程没有到达相同的障碍点。 如果需要进行块间同步，可以尝试在同步点分割核函数并执行多个核函数启动，其中会产生隐式全局障碍以达到预期效果。 内存栅栏 CUDA提供3种内存栅栏： 块：__threadfence_block()； 网格：__threadfence()； 系统：__threadfence_system()。 __threadfence_block()保证了栅栏前被调用线程产生的对共享内存和全局内存的所有写操作对栅栏后同一块中的其他线程可见。内存栅栏不执行任何线程同步，所以对于一个块中的所有线程来说，没必要实际执行这个指令。 __threadfence()会挂起调用的线程，直到全局内存中的所有写操作对同一网格内的所有线程均可见。 __threadfence_system()会挂起调用的线程，以确保该线程对全局内存、锁页主机内存和其他设备内存中的所有写操作对全部设备中的线程和主机线程都可见。 内存同步域 内存栅栏实例 某些CUDA程序可能会因为内存栅栏/刷新操作等待的事务多于CUDA内存一致性模型所需的事务而导致性能下降。 123__managed__ int x = 0;__device__ cuda::atomic&lt;int, cuda::thread_scope_device&gt; a(0);__managed__ cuda::atomic&lt;int, cuda::thread_scope_system&gt; b(0); Thread 1 (SM)： 12x = 1;a = 1; Thread 2 (SM)： 123while(a != 1);assert(x == 1);b = 1; Thread 3 (CPU)： 12while(b != 1);assert(x == 1); 考虑上述例子，CUDA内存一致性模型将保证断言的条件为真，故在线程2写入b之前，线程1对x的写入必须对线程3可见。 释放和获取a所提供的内存排序仅能够使x对线程2可见，但线程3不可见，因为它是设备范围的操作。故由释放和获取b所提供的系统范围的内存排序需要确保从线程2发起的写入对线程3可见，同时要保证从线程2可见的其他线程发起的写入也是可见的。这要求称为累积性（cumulativity）。由于GPU在执行时不知道哪些写入在源码级别下是可见的，也不知道哪些写入仅在偶然的时间是可见的，所以它必须为所有活动状态的内存操作撒下一个保守的广域网。 上述情况会使GPU等待源码级别不需要的内存操作，进而使得内存栅栏/刷新操作花费不必要的时间，对整个程序产生干扰。 注意，内存栅栏可以在代码中显式的作为内部结构或原子操作出现，也可以隐式的实现任务边界上的同步关系。 用域隔离流量 从Hopper架构的GPU和CUDA 12.0开始，内存同步域提供了一种减轻上述干扰的方法。使用代码来显式辅助，可以减少GPU的光撒网行为。每次核函数启动都会被赋予一个域ID。写操作和栅栏都用该ID来标识，而栅栏只会对与栅栏域匹配的写操作进行排序。通信的核函数可以放在不同的域中。 使用域时，代码必须使同一GPU上不同域之间的排序或同步需要系统范围的栅栏。而在同一域中，设备范围的栅栏就足够了。这种栅栏范围要求对于累积性来说是必要的，因为一个核函数的写操作不会被另一个域中的核函数发出的栅栏所包围。本质上，累积性是通过确保跨域流量提前刷新到系统范围来满足的。 注意，这会修改thread_scope_device的定义。但由于核函数将默认采用域0，所以保证了向后兼容。 在CUDA中使用域 域可以通过新的启动属性cudaLaunchAttributeMemSyncDomain和cudaLaunchAttributeMemSyncDomainMap来访问。前者在逻辑域cudaLaunchMemSyncDomainDefault和cudaLaunchMemSyncDomainRemote之间选择，后者提供从逻辑域到物理域的映射。远程域可供核函数进行远程内存访问，以便将其内存流量与本地核函数隔离。选择特定的域不会影响核函数可以合法执行的内存访问。 可以通过设备属性cudaDevAttrMemSyncDomainCount来获取域的数量。Hopper有4个域。为了便于代码移植，域功能可以在所有设备上使用，在Hopper架构之前的架构下，该计数将返回1。 详细参考官方文档Using Domains in CUDA。 volatile修饰符 在全局或共享内存中使用volatile修饰符声明一个变量，可以防止编译器优化，编译器优化可能会将数据暂时缓存在寄存器或本地内存中。当使用volatile修饰符时，编译器假定任何其他线程在任何时间都可以更改或使用该变量的值。因此，这个变量的任何引用都会直接被编译到全局内存读指令或全局内存写指令中，它们都会忽略缓存。 共享内存的数据布局 方形共享内存 方形矩阵可以很容易从二维线程索引计算出一维内存偏移，声明一个方形二维共享内存变量。 1__shared__ int tile[N][N]; 它可以有两种访问方式： tile[threadIdx.y][threadIdx.x] tile[threadIdx.x][threadIdx.y] 显然，两种方式相比，第一种方式拥有更少的存储体冲突，因为邻近线程在最内层数组维度上访问相邻的阵列单元。 访问方式实例 我们分别实现三种读写共享内存的方法： 按行写入，按行读取； 按列写入，按列读取； 按列写入，按行读取。 按行写入，按列读取。 详细代码参考square_shared_memory.cu。 利用nsys来分析其耗时，并利用ncu来分析它们的共享内存加载和存储事务来体现存储体冲突，结果如下。 12345 耗时 加载事务 存储事务writeRowReadRow(int *) (1, 1, 1)x(32, 32, 1) 1248 ns 32 32writeColReadCol(int *) (1, 1, 1)x(32, 32, 1) 1920 ns 1024 1024writeColReadRow(int *) (1, 1, 1)x(32, 32, 1) 1280 ns 32 1024writeRowReadCol(int *) (1, 1, 1)x(32, 32, 1) 1280 ns 1024 32 可以看出行读行写的核函数性能最高，加载和存储事务最少，没有存储体冲突。不管是按列读还是写，都会存在存储体冲突，导致加载或存储事务大量增多。 动态共享内存 使用动态声明共享内存的方式实现与上述功能相同的核函数。动态共享内存必须被声明为一个未定大小的一维数组，因此需要基于二维线程索引来计算内存访问索引。 再测试其性能，结果如下。 12 耗时 加载事务 存储事务writeRowReadColDynamic(int *) (1, 1, 1)x(32, 32, 1) 1280 ns 1024 32 可以发现结果与writeRowReadCol相同。 填充静态声明的共享内存 使用前面提到的内存填充来解决存储体冲突，并测试其性能。 12 耗时 加载事务 存储事务writeRowReadColPadding(int *) (1, 1, 1)x(32, 32, 1) 896 ns 32 32 可以发现，通过填充完美的解决了存储体冲突。 填充动态声明的共享内存 实现基于动态共享内存填充的核函数，并测试其性能。 12 耗时 加载事务 存储事务writeRowReadColDynPad(int *) (1, 1, 1)x(32, 32, 1) 896 ns 32 32 可以发现基于动态共享内存的填充也是有效的。 矩形共享内存 将上述的方形共享内存推广到矩形这个更为一般的情况。实现与上述功能相同的几个核函数，并分析其性能。 12345678 耗时 加载事务 存储事务writeRowReadRow(int *) (1, 1, 1)x(32, 32, 1) 1119 ns 16 16writeColReadCol(int *) (1, 1, 1)x(32, 32, 1) 1248 ns 256 256writeColReadRow(int *) (1, 1, 1)x(32, 32, 1) 928 ns 16 256writeRowReadCol(int *) (1, 1, 1)x(32, 32, 1) 992 ns 256 16writeRowReadColDynamic(int *) (1, 1, 1)x(32, 32, 1) 960 ns 256 16writeRowReadColPadding(int *) (1, 1, 1)x(32, 32, 1) 896 ns 16 16writeRowReadColDynPad(int *) (1, 1, 1)x(32, 32, 1) 896 ns 16 16 详细代码参考rectangle_shared_memory.cu。 减少全局内存访问 使用共享内存的并行归约 将之前实现的线程束展开的并行归约作为性能基准，利用共享内存的操作代替全军内存的原地操作，观察两者性能差距。 详细代码参考reduce_with_shared_memory.cu。 12345Array Size: 16777216cpu reduce elapsed 16.0859 ms cpu_sum: 206464799gpu Gemm elapsed 0.384192 ms gpu_sum: 206464799 &lt;&lt;&lt;131072, 128&gt;&gt;&gt;gpu Semm elapsed 0.278624 ms gpu_sum: 206464799 &lt;&lt;&lt;131072, 128&gt;&gt;&gt;Result correct! 123 全局加载事务 全局存储事务reduceGmem(int *, int *, unsigned int) (131072, 1, 1)x(128, 1, 1) 8912896 4325376reduceSmem(int *, int *, unsigned int) (131072, 1, 1)x(128, 1, 1) 2097152 131072 可以看到，通过使用共享内存代替全局内存的原地操作，大幅度减少了全局内存事务，从而提升了总体性能。 使用展开的并行归约 在使用共享内存进行归约的基础上，再利用技术展开，每个线程处理4个数据块的元素，再次对比它们的性能。 123456Array Size: 16777216cpu reduce elapsed 16.0439 ms cpu_sum: 206464799gpu Gemm elapsed 0.384 ms gpu_sum: 206464799 &lt;&lt;&lt;131072, 128&gt;&gt;&gt;gpu Semm elapsed 0.278464 ms gpu_sum: 206464799 &lt;&lt;&lt;131072, 128&gt;&gt;&gt;gpu SemmUnroll elapsed 0.214976 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 128&gt;&gt;&gt;Result correct! 分析其全局加载和存储事务。 1234 全局加载事务 全局存储事务reduceGmem(int *, int *, unsigned int) (131072, 1, 1)x(128, 1, 1) 8912896 4325376reduceSmem(int *, int *, unsigned int) (131072, 1, 1)x(128, 1, 1) 2097152 131072reduceSmemUnroll(int *, int *, unsigned int) (32768, 1, 1)x(128, 1, 1) 2097152 32768 观察发现，虽然全局加载事务并没有减少，但全局存储事务却减少到了原来的1/4。 使用动态共享内存的并行归约 上述基于共享内存的展开并行归约也可以使用动态共享内存，性能表现与使用静态共享内存时接近，这里不再赘述。 合并的全局内存访问 使用共享内存可以避免对未合并的全局内存进行访问，矩阵转置是一个典型的例子，读操作是合并的，但写操作是交叉访问的。 朴素转置 实现一个朴素转置，核函数如下。 12345678910#define INDEX(ROW, COL, INNER) ((ROW) * (INNER) + (COL))__global__ void naiveGmem(float *out, float *in, const int rows, const int cols){ unsigned int col = blockIdx.x * blockDim.x + threadIdx.x; unsigned int row = blockIdx.y * blockDim.y + threadIdx.y; if (row &lt; rows &amp;&amp; col &lt; cols) out[INDEX(col, row, rows)] = in[INDEX(row, col, cols)];} 再实现一个读写操作都是合并访问的核函数，用来模拟性能的近似上界。 12345678__global__ void copyGmem(float *out, float *in, const int rows, const int cols){ unsigned int col = blockIdx.x * blockDim.x + threadIdx.x; unsigned int row = blockIdx.y * blockDim.y + threadIdx.y; if (row &lt; rows &amp;&amp; col &lt; cols) out[INDEX(row, col, cols)] = in[INDEX(row, col, cols)];} 详细代码参考transpose_with_shared_memory.cu。 这里使用的二维线程块来调用，经过测试，上面两个核函数的性能表现如下。 123Kernel Elapsed time Effective bandwidthcopyGmem 0.291488 ms 0.460457 GB/snaiveGmem 0.994176 ms 0.135004 GB/s 分析其每次请求中的全局内存事务数量，结果如下。 123 全局加载事务 全局存储事务copyGmem(float *, float *, int, int) (256, 256, 1)x(16, 16, 1) 4 4naiveGmem(float *, float *, int, int) (256, 256, 1)x(16, 16, 1) 4 32 可以发现，由于朴素转置的写操作是交叉访问的，所以每次请求中的全局存储事务要更多。 使用共享内存的矩阵转置 可以使用二维共享内存来缓存原始矩阵的数据，从而避免交叉的全局内存写操作。首先从全局内存中读取块内的一行写入共享内存的一行，然后从共享内存读取一列写入全局内存的一行。 实现该核函数时，需要注意索引的计算方式。 1234567891011121314151617181920212223242526__global__ void transposeSmem(float *out, float *in, const int rows, const int cols){ __shared__ float tile[BDIMY][BDIMX]; // 原始矩阵索引 unsigned int col = blockIdx.x * blockDim.x + threadIdx.x; unsigned int row = blockIdx.y * blockDim.y + threadIdx.y; if (row &lt; rows &amp;&amp; col &lt; cols) tile[threadIdx.y][threadIdx.x] = in[INDEX(row, col, cols)]; // 由于转置过程中，不仅block需要转置，block内的thread也需要转置 // 所以利用irow和icol来代替原来的threadIdx的x和y维度 unsigned int bidx = threadIdx.y * blockDim.x + threadIdx.x; unsigned int irow = bidx / blockDim.y; unsigned int icol = bidx % blockDim.y; // 转置矩阵中，blockDim和blockIdx的x维度计算列索引，y维度计算行索引，与原始矩阵相反 row = blockIdx.x * blockDim.x + irow; col = blockIdx.y * blockDim.y + icol; __syncthreads(); if (row &lt; cols &amp;&amp; col &lt; rows) out[INDEX(row, col, rows)] = tile[icol][irow];} 分析其性能与全局内存事务。 1234Kernel Elapsed time Effective bandwidthcopyGmem 0.291072 ms 0.461115 GB/snaiveGmem 1.007616 ms 0.133203 GB/stransposeSmem 0.343520 ms 0.390713 GB/s 1234 全局加载事务 全局存储事务copyGmem(float *, float *, int, int) (256, 256, 1)x(16, 16, 1) 4 4naiveGmem(float *, float *, int, int) (256, 256, 1)x(16, 16, 1) 4 32transposeSmem(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 4 4 上面提到了，这种方式虽然在共享内存中读取列的时候依然会发生存储体冲突，但这样的结果已经比直接对全局内存进行交叉写入要好的多。共享内存中的存储体冲突可以通过分析其共享内存事务数量来解释。 12 共享加载事务 共享存储事务transposeSmem(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 8460165 533345 使用填充共享内存的矩阵转置 使用之前提到的内存填充技术来优化上面的核函数。 123456789101112131415161718192021222324__global__ void transposeSmemPad(float *out, float *in, int rows, int cols){ __shared__ float tile[BDIMY][BDIMX + PAD]; // 原始矩阵索引 unsigned int col = blockIdx.x * blockDim.x + threadIdx.x; unsigned int row = blockIdx.y * blockDim.y + threadIdx.y; if (row &lt; rows &amp;&amp; col &lt; cols) tile[threadIdx.y][threadIdx.x] = in[INDEX(row, col, cols)]; // 转置block中的线程索引 unsigned int bidx = threadIdx.y * blockDim.x + threadIdx.x; unsigned int irow = bidx / blockDim.y; unsigned int icol = bidx % blockDim.y; row = blockIdx.x * blockDim.x + irow; col = blockIdx.y * blockDim.y + icol; __syncthreads(); if (row &lt; cols &amp;&amp; col &lt; rows) out[INDEX(row, col, rows)] = tile[icol][irow];} 这里选择填充2个位置，这样可以完全消除共享内存的存储体冲突。可以通过分析其性能及共享内存事务来证明这一点。 12345Kernel Elapsed time Effective bandwidthcopyGmem 0.292448 ms 0.458946 GB/snaiveGmem 0.987136 ms 0.135967 GB/stransposeSmem 0.404192 ms 0.332064 GB/stransposeSmemPad 0.326272 ms 0.411368 GB/s 123 共享加载事务 共享存储事务transposeSmem(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 8460165 533345transposeSmemPad(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 545540 533686 使用展开的矩阵转置 在上述使用了内存填充的核函数基础上，使用展开技术进行优化，使每个线程处理两个元素。 123456789101112131415161718192021222324252627282930__global__ void transposeSmemUnrollPad(float *out, float *in, int rows, int cols){ // 使用一维的共享内存 __shared__ float tile[BDIMY][BDIMX * 2 + PAD]; // 原始矩阵索引 unsigned int col = 2 * blockIdx.x * blockDim.x + threadIdx.x; unsigned int row = blockIdx.y * blockDim.y + threadIdx.y; if (row &lt; rows &amp;&amp; col + blockDim.x &lt; cols) { tile[threadIdx.y][threadIdx.x] = in[INDEX(row, col, cols)]; tile[threadIdx.y][threadIdx.x + blockDim.x] = in[INDEX(row, col + blockDim.x, cols)]; } unsigned int bidx = threadIdx.y * blockDim.x + threadIdx.x; unsigned int irow = bidx / blockDim.y; unsigned int icol = bidx % blockDim.y; row = 2 * blockIdx.x * blockDim.x + irow; col = blockIdx.y * blockDim.y + icol; __syncthreads(); if (row + blockDim.x &lt; cols &amp;&amp; col &lt; rows) { out[INDEX(row, col, rows)] = tile[icol][irow]; out[INDEX(row + blockDim.x, col, rows)] = tile[icol][irow + blockDim.x]; }} 进行性能对比后发现，相比使用内存填充的核函数，有略微的提升。 123456Kernel Elapsed time Effective bandwidthcopyGmem 0.292864 ms 0.458294 GB/snaiveGmem 0.987008 ms 0.135984 GB/stransposeSmem 0.377856 ms 0.355209 GB/stransposeSmemPad 0.326656 ms 0.410884 GB/stransposeSmemUnrollPad 0.322560 ms 0.416102 GB/s 使用展开技术使得更多的内存请求将同时处于运行状态，且会提高读写吞吐量。ncu分析设备内存的读写吞吐量可以佐证这一点。 12345 读吞吐量(GB/s) 写吞吐量(GB/s)naiveGmem(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 55.81 52.64transposeSmem(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 193.00 177.18transposeSmemPad(float *, float *, int, int) (128, 256, 1)x(32, 16, 1) 205.98 178.52transposeSmemUnrollPad(float *, float *, int, int) (64, 256, 1)x(32, 16, 1) 206.65 186.28 常量内存 常量内存对于核函数来说是只读的，但对于主机来说是可读可写的。常量内存位于设备的DRAM上（与全局内存一样），且有一个专用的片上缓存。与一级缓存和共享内存类似，从每个SM的常量缓存中读取的延迟，比直接从常量内存中读取的延迟低得多。每个SM常量缓存大小限制为64KB。 常量内存与之前提到的所有类型的内存有着不同的最优访问模式。在常量内存中，若线程束中的所有线程都访问相同的位置，则这个访问模式是最优的。若线程束中的线程访问不同地址，则访问需要串行。 在全局作用域中必须使用__constant__修饰符来声明常量变量。常量内存变量的生命周期与应用程序的生命周期相同，对所有线程都是可访问的，并且可以通过运行时函数对主机也可访问。 由于设备只能读取常量内存，所以常量内存中的值必须通过运行时函数cudaMemcpyToSymbol()来初始化。 使用常量内存实现一维模板 在数值分析中，模板计算在点的集合上应用一个函数，并使用该函数的输出更新单一点的值。在一维中，位置周围的的九点模板会给如下位置上的值应用一些函数。 我们不需要理解这个公式的实际意义，只需要观察到它会将上述的九个点作为输入，产生单一输出。下面使用一个实际公式作为示例。 可以比较容易的观察到，公式中这些系数是不变的，所以很适合存入常量内存中。且线程束中的所有线程都是访问这几个常量，这恰好满足常量内存的最优访问模式。 计算过程如下图所示。 借助共享内存来缓存数据，同时在其两侧添加一些光环数据，类似于卷积中的填充操作，是为了计算的合法性。通过如下核函数来实现整个计算过程。 12345678910111213141516171819202122232425262728293031323334353637__global__ void stancli1DGPU(float* in, float* out, int size){ // 包含光环的共享内存 __shared__ float smem[BDIM + 2 * RADIUS]; unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x + RADIUS; while (idx &lt; size + RADIUS) { // 共享内存的索引，为模板计算作准备 int sidx = threadIdx.x + RADIUS; // 将数据部分写入共享内存 smem[sidx] = in[idx]; // 将光环部分度写入共享内存 if (threadIdx.x &lt; RADIUS) { smem[sidx - RADIUS] = in[idx - RADIUS]; smem[sidx + BDIM] = in[idx + BDIM]; } __syncthreads(); float tmp = 0.0f;#pragma unroll for (int i = 1; i &lt;= RADIUS; i++) { tmp += coef[i] * (smem[sidx + i] - smem[sidx - i]); } out[idx] = tmp; idx += gridDim.x * blockDim.x; }} 详细代码参考constant_stencli.cu。 与只读缓存比较 只读缓存实质上是GPU的纹理流水线，用于存储全局内存中的数据。只读缓存是独立的，它拥有从标准全局内存读取的独立内存带宽，所以使用只读缓存可以为受制于内存带宽的核函数提供一些性能优势。 只读缓存不同于常量内存，其最优访问模式是线程束中的线程访问不同的位置。只读缓存的粒度为32字节。 当通过只读缓存访问全局内存时，需要在核函数中向编译器指出数据是只读的，可以通过如下两种方式： 内部函数__ldg()； 全局内存的限定指针； 内部函数__ldg()用于代替标准指针解引用，并强制加载通过只读数据缓存。 12345__global__ void kernel(float* output, float* input) { ... output[idx] += __ldg(&amp;input[idx]); ...} 也可以限定指针为const __restrict__，以表明它应该通过只读缓存被访问。 12345__global__ void kernel(float* output, const float* __restrict__ input) { ... output[idx] += input[idx]; ...} 在只读缓存需要很多显式控制，或代码非常复杂以至于编译器无法检测到只读缓存的使用是否安全的情况下，内部函数__ldg()是更好的选择。 通过只读缓存加载的数据可以比较大，且能够在一个非统一的模式下进行访问。利用只读缓存来实现上述模板算法的核函数，唯一的区别就是函数声明。 1234__global__ void stancliReadOnly(float* in, float* out, int size, const float* __restrict__ dcoef){ ...} 但要注意的是，不同于常量内存，在核函数调用之前，必须提前分配只读缓存的设备内存。 123456789const float h_coef[] = {a0, a1, a2, a3, a4};// 使用常量内存只需要调用如下运行时API，无需申请设备内存ERROR_CHECK(cudaMemcpyToSymbol(coef, h_coef, (RADIUS + 1) * sizeof(float)));// 使用只读缓存时需要提前申请设备内存float* d_coef;ERROR_CHECK(cudaMalloc((void**)&amp;d_coef, (RADIUS + 1) * sizeof(float)));ERROR_CHECK(cudaMemcpy(d_coef, h_coef, (RADIUS + 1) * sizeof(float), cudaMemcpyHostToDevice)); 使用nsys统计两个核函数的耗时可以观察到，对于以广播模式访问的数据来说，常量内存是更适合的。 1234Time (%) Total Time (ns) Name -------- --------------- ----------------------------------------------------- 50.2 408,376 stancliReadOnly(float *, float *, int, const float *) 49.8 405,463 stancliConstant(float *, float *, int) 线程束洗牌指令 从计算能力3.0开始加入了一种机制称为洗牌指令（shuffle instruction），只要两个线程在相同的线程束中，就允许这两个线程直接读取另一个线程的寄存器。这种直接的数据交换不是通过共享内存或全局内存来进行的，拥有比共享内存更低的延迟，且在执行数据交换时不消耗额外的内存。 这里引入一个概念——束内线程（lane），线程束中的每一个线程都是束内线程，每个束内线程都有一个唯一的束内线程索引。在一维线程块中，对于一个给定线程的束内线程索引和线程束索引可以通过如下方式计算。 12laneID = threadIdx.x % 32;warpID = threadIdx.x / 32; 对于多维的线程块，可以将多维线程坐标转换为一维线程索引，再应用上述公式来计算。 线程束洗牌指令的不同形式 洗牌指令共有两组，一组用于整型变量，另一组用于浮点型变量。每组有4种形式的洗牌指令： 广播传递； 向上传递； 向下传递； 异或传递。 广播传递 1int __shfl(int var, int srcLane, int width=warpSize); 其中var是待传递的变量，srcLane是提高该变量的线程的束内线程索引。最后一个参数width允许将线程束进一步划分为段，每段包含width个线程，取值范围是[2, 32]，每个段上会执行独立的洗牌操作。对于非32的其他width值，线程的束内线程索引可以通过threadIdx.x % width来确定。 上图展示了__shfl(val, 2)的调用示例。 向上传递和向下传递 向上传递和向下传递非常类似，两者的区别仅是传递方向不同。 12int __shfl_up(int var, unsigned int delta, int width=warpSize);int __shfl_down(int var, unsigned int delta, int width=warpSize); delta参数用来计算提供变量的束内线程索引： 向上传递时，当前束内线程接受来自于束内线程索引为当前束内线程索引 - delta线程中的变量var； 向下传递时，当前束内线程接受来自于束内线程索引为当前束内线程索引 + delta线程中的变量var； 若向上或向下传递过程中没有对应的源束内线程，则线程中的变量保持不变。 异或传递 1int __shfl_xor(int var, int laneMask, int width=warpSize); 异或传递较为特殊，它根据自身的束内线程索引与laneMask按位异或来确定源束内线程。 上图展示了蝴蝶寻址模式的示例。 上面提到的4种洗牌指令均有单精度浮点数版本。 注意：在6.0以后的PTX ISA中，已经不再支持这一系列的洗牌指令，新版本改为了带有sync的洗牌指令。 上述的几个函数整体变化不大，只是在参数列表的最前面添加了一个参数mask： int __shfl_sync(unsigned mask, int var, int srcLane, int width=warpSize); int __shfl_up_sync(unsigned mask, int var, int srcLane, int width=warpSize); int __shfl_down_sync(unsigned mask, int var, int srcLane, int width=warpSize); int __shfl_xor_sync(unsigned mask, int var, int srcLane, int width=warpSize); 当然也有对应的单精度浮点数版本，并且拥有64位的版本，即long与double类型的接口。 该mask参数用于指定参与洗牌指令的束内线程，每个bit代表一个束内线程。mask给予编译器一个提示，为了保证正确性，所指向的束内线程必须全部参与洗牌指令，这样编译器就会生成一些必要的指令将这些线程重新汇聚起来。 简单来说，若使用默认的线程束大小，想要使所有束内线程都参与洗牌指令，则mask指定为0xffffffff即可。 对于mask参数，英伟达官方论坛有一个帖子对此进行了描述。 以及shuffle_instruction.cu和reduce_with_shuffle.cu有一系列详细的示例。","link":"/posts/38038/"},{"title":"CUDA编程——执行模型","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 CUDA运行时 cudart库是CUDA运行时的实现，该库可以通过cudart.lib或libcudart.a静态链接到程序中，也可以通过cudart.dll或libcudart.so动态链接。需要动态链接的该库的程序，通常将cudart.dll或libcudart.so作为程序安装包的一部分。 只有在链接到同一个CUDA运行时实例的组件之间传递CUDA运行时符号地址才是安全的。 该库的所有API均带有cuda前缀。 初始化 从CUDA 12.0开始，cudaInitDevice()和cudaSetDevice()调用会初始化与指定设备关联的运行时和主上下文。如不进行这些调用，运行时会隐式地使用设备0，并按需进行自初始化来执行其他运行时API请求。 在CUDA 12.0之前，cudaSetDevice()不会初始化运行时，程序通常使用空操作运行时调用cudaFree(0)，将运行时初始化与其他API活动隔离开。 运行时将会为每个设备创建一个CUDA上下文，称之为主上下文（primary context）。该上下文将在调用第一个需要活动上下文的运行时函数时被初始化。主机端的所有线程共享该上下文。在创建上下文过程中，必要情况下会将设备代码即时编译并加载到设备内存中 当主机线程调用cudaDeviceReset()时，将销毁该线程当前操作设备的主上下文。任何拥有该设备的主机线程进行下一个运行时函数调用时，将为该设备创建一个新的主上下文。 CUDA执行模型概述 GPU架构概述 GPU是围绕流式多处理器（SM）的可扩展阵列搭建的，通过复制这种架构的构建块来实现GPU的硬件并行。 SM的核心组件如下： CUDA核心； 共享内存 / 一级缓存； 寄存器文件； 加载 / 存储单元； 特殊功能单元； 线程束调度器。 每个SM可以支持数百个线程并发执行，每个GPU通常有多个SM，所以一个GPU上并发执行数千个线程是有可能的。启动一个核函数时，线程块被分配在了可用的SM上，线程块一旦被调度到一个SM上，其中的线程只会在当前的SM上执行。多个线程块可能被分配在同一个SM上，是根据SM资源的可用性进行调度的。同一线程值的指令利用指令级并行性进行流水线化。 CUDA采用单指令多线程（SIMT）架构来管理和执行线程，每32个线程为一组，成为线程束（warp）。 在并行线程中共享数据可能会引起竞争，CUDA提供了一种用来同步线程块内线程的方法，但没有提供块间同步的原语。 虽然线程块内的线程束可以任意顺序调度，但活跃的线程束仍会受到SM资源的限制。当线程束闲置时，SM可以从同一SM上的常驻线程块中调度其他可用的线程束。在并发的线程束之间切换没有开销，因为硬件资源已经被分配到了SM上的所有线程和块中。 线程束的本质 线程束和线程块 线程束是SM中基本的执行单元。一旦线程块被调度到一个SM上，线程块中的线程会被进一步划分为线程束。一个线程束由32个连续的线程组成，在一个线程束中，所有的线程按照SIMT方式执行。 虽然线程块可以组织为一维、二维或三维的，但从硬件角度看，所有线程都被组织成了一维的。例如有一个128线程的一维线程块，它将被组织进4个线程束中，如下所示。 1234Warp 0: thread 0, thread 1, thread 2, ... thread 31Warp 1: thread 32, thread 33, thread 34, ... thread 63Warp 2: thread 64, thread 65, thread 66, ... thread 95Warp 3: thread 96, thread 97, thread 98, ... thread 127 二维、三维的线程块是同理的，只需要计算出其唯一线程ID即可。 一个线程块的线程束数量由下式确定。 中的数量中的数量大小 线程束不会在不同的线程块之间分离，若线程块的大小不是线程束大小的整数倍，则在最后的线程束中会有些线程处于不活跃状态。例如有一个二维的的线程块，他会被分配在3个线程束中，最后一个线程束的后半段是不活跃的，但依然会占用SM的资源。 线程束分化 首先要注意一点，一个线程束中的所有线程在同一周期内必须执行相同的指令。考虑下列语句： 12345if (cond) { ...} else { ...} 假设在一个线程束中，有16个线程的cond为true，另外16个线程为false。此时，一半的线程需要执行if语句块中的指令，另一半需要执行else中的指令。这种在同一线程束中的线程执行不同指令的现象，被称为线程束分化。 当发生线程束分化时，线程束将连续执行每个分支路径，同时禁用不执行这一路径的线程，这会导致性能明显下降。条件分支越多，并行性削弱越严重。 线程束分化只发生在同一线程束中，不同线程束的不同条件值不会引起线程束分化。 这里引入一个概念，分支效率，即未分化分支与全部分支之比。 分支效率分支数分化分支数分支数 设想以下三种情况： 情况一：线程ID为偶数的执行if，线程ID为奇数的执行else； 情况二：线程束ID为偶数的执行if， 线程束ID为奇数的执行else； 情况三：线程ID为偶数的执行if，线程ID为奇数的执行另一个if。 具体到代码即为： 123456789101112// 线程ID为偶数的执行if，线程ID为奇数的执行else__global__ void mathKernel1(float *c){ int tid = blockIdx.x * blockDim.x + threadIdx.x; float a, b; a = b = 0.0f; if (tid % 2 == 0) a = 100.0f; else b = 200.0f; c[tid] = a + b;} 123456789101112// 线程束ID为偶数的执行if， 线程束ID为奇数的执行else__global__ void mathKernel2(float *c){ int tid = blockIdx.x * blockDim.x + threadIdx.x; float a, b; a = b = 0.0f; if ((tid / warpSize) % 2 == 0) a = 100.0f; else b = 200.0f; c[tid] = a + b;} 12345678910111213// 线程ID为偶数的执行if，线程ID为奇数的执行另一个if__global__ void mathKernel3(float *c){ int tid = blockIdx.x * blockDim.x + threadIdx.x; float a, b; a = b = 0.0f; bool ipred = (tid % 2 == 0); if (ipred) a = 100.0f; if (!ipred) b = 200.0f; c[tid] = a + b;} 调用这三个核函数，使用ncu来统计分支效率，结果如下所示。 分支效率 mathKernel1(float *) (1, 1, 1)x(64, 1, 1) 80% mathKernel2(float *) (1, 1, 1)x(64, 1, 1) 100% mathKernel3(float *) (1, 1, 1)x(64, 1, 1) 71.43% 为了阅读方便，这里简化了ncu的输出信息，实际的输出比上述形式要丰富，后续的ncu分析结果也以同样的方式简化。 可以观察到，情况一由于发生了分支分化，导致分支效率降低。而情况二由于分支分化的粒度是线程束大小的整倍数，所以分支效率统计为100%。情况三在情况一的前提下改造为了两个if，这样可以使得分化分支的数量翻倍。 分化分支数量翻倍但效率没有降低至一半是因为，虽然在编译时加上了-G参数来阻止分支预测优化，但还有其他优化手段，以保证分支效率在50%以上。 详细代码示例参考warp_divergence.cu 资源分配 线程束的本地执行上下文主要由以下资源组成： 程序计数器； 寄存器； 共享内存。 由SM处理的每个线程束的执行上下文，在整个线程束的生存期中是保存在芯片内的。所以从一个执行上下文切换到另一个执行上下文没有损失。对于一个给定的核函数，同时存在于同一个SM中的线程块和线程束的数量，取决于在SM中可用的与核函数所需的寄存器和共享内存数量。 如上图所示，每个线程消耗的寄存器较少，同一SM上就可以多分配一些线程。同理，每个线程块消耗的共享内存较少，同一SM上就可以多分配一些线程块。 如果每个SM没有足够的寄存器或共享内存去处理至少一个块，那么核函数就无法启动。 当计算资源已经分配给线程块时，线程块被称为活跃的块。它所包含的线程束被称为活跃的线程束。活跃的线程束可以分为以下三种类型： 选定的线程束：正在执行的活跃线程束； 阻塞的线程束：未准备好执行的线程束； 符合条件的线程束：准备执行但尚未执行的活跃线程束。 同时满足以下两个条件则线程束符合执行条件： 32个CUDA核心可用于执行； 当前指令中所有的参数都已就绪。 延迟隐藏 指令延迟是指在指令发出和完成之间的时钟周期数。指令可以被分为两种基本类型： 算术指令：一个算术操作从开始到产生输出之间的时钟周期，一般为10～20个周期； 内存指令：发送出的加载或存储操作和数据到达目的地之间的时钟周期，全局内存访问一般为400～800个周期。 当每个时钟周期内所有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。在GPU中往往有着大量的线程，通过在其他常驻线程束中发布其他指令来隐藏指令延迟至关重要。 可以通过利特尔法则来估算隐藏延迟所需的活跃线程束数量。 所需线程束数量指令平均延迟欲达到的吞吐量 此处是一个粗略化的公式，并不是直接套用即可算出所需线程束数量，后面将具体的介绍如何运用该法则。 算术延迟隐藏 对于算术运算，所需的并行数可以表示为隐藏算术延迟所需的操作数量。 假设某个算术指令延迟为20个周期，我们想要令SM保持32个操作的吞吐量，即每个周期进行32次操作。根据上面提到的利特尔法则，我们可以得到所需并行数为，也就是说要保证程序中有640个该计算操作才能完全隐藏算术延迟。 我们再假设每个线程中仅执行一次该算术操作，则可以进一步得到线程束数量为个。 观察上述例子会发现，算术延迟隐藏所需的并行数可以用操作数量来表示，也可以用线程束数量来表示。这表明我们可以有两个不同的层次来提高并行： 指令级并行（ILP）：一个线程中有很多独立的指令； 线程级并行（TLP）：很多并发地符合条件的线程。 内存延迟隐藏 对于内存操作，所需的并行数可以表示为在每个周期内隐藏内存延迟所需的字节数。 假设某个内存指令延迟为800个周期，我们想要令设备保持200GB/s的吞吐量，根据内存频率可以将吞吐量的单位由GB/s转换为B/CP（字节/周期）。笔者的设备内存频率为10.501GHz，所以转换后为。接着根据利特尔法则，我们可以得到所需的并行数为。 使用如下命令来获取内存频率。 1nvidia-smi -a -q -d CLOCK | grep -A 3 \"Max Clocks\" | grep \"Memory\" 我们再假设每个线程中仅从全局内存中读取一个浮点数到SM上用于计算，则根据并行数可以计算出所需的线程数，即个线程。进一步得到线程束数量为个。若每个线程执行多个独立的4字节加载，则隐藏内存延迟所需的线程就可以更少。 上述计算出的线程束数量只是下界，也就是说在相同假设下，提供更多的线程数量同样能够达到延迟隐藏的效果。 占用率 占用率是每个SM中活跃的线程束占最大线程束数量的比值。 占用率活跃线程束数量最大线程数数量 最大线程束数量可以通过cudaGetDeviceProperties()获取到设备属性后，由其成员maxThreadsPerMultiProcessor / 32取得。详细代码参考，笔者的设备获取到的结果如下所示。 123456789Device 0: NVIDIA GeForce RTX 4070Number of multiprocessors: 46Total amount of constant memory: 64.00 KBTotal amount of shared memory per block: 48.00 KBTotal amount of registers available per block: 65536Warp size: 32Maximum number of threads per block: 1024Maximum number of threads per multiprocessor: 1536Maximum number of warps per multiprocessor: 48 CUDA官方以前提供一个占用率计算器，是一个Excel表格，可以填入一些核函数资源信息后，自动计算SM占用率。但目前在官网已经找不到该文件的下载途径了，可能是因为当前最新的设备已经不适合用这种方式来计算占用率了。 若想体验该计算器，笔者在Github上找到一个项目，提供相同的功能，但该项目仅支持计算能力8.6及以前的设备，CUDA版本仅支持11.0和11.1两个版本，链接：cuda-calculator。 为了提高占用率，需要调整线程块配置或重新调整资源的使用情况，以允许更多的线程束同时处于活跃状态并提高计算资源的利用率。要避免极端的情况： 线程块过小：每个块中的线程太少，会在所有资源被充分利用之前导致硬件达到每个SM的线程束数量限制； 线程块过大：每个块中的线程太多，会导致SM中每个线程可用的硬件资源较少。 同步 CUDA中提供了两个级别的同步原语： 系统级别：等待主机和设备完成所有工作； 块级别：在设备执行过程中等待一个线程块中所有线程到达同一点。 系统级别的同步通过cudaDeviceSynchronize()API实现，块级别的同步通过__syncthreads()实现。线程块中要注意避免各种访存冲突，例如读后写、写后读、写后写等。 不同块之间没有线程同步，实现块间同步可以通过全局变量+原子操作的方式实现。从CUDA 9.x开始提供了协作组的概念，cooperative_groups::grid_group下有一个sync()函数可以提供块间同步的功能。关于块间同步这里不过多展开。 可扩展性 能够在可变数量的计算核心上执行相同代码的能力被成为透明可扩展性。拥有这种能力的平台能够避免不同的硬件产生的变化，减轻了开发者的负担。 可扩展性比效率更重要，一个可扩展但效率很低的系统可以通过简单添加硬件核心来处理更大的工作负载，一个效率很高但不可扩展的系统可能很快就会达到性能上限。 CUDA核函数启动时，线程块分布在多个SM中，网格中的线程块以并行或连续或任意的顺序执行。这种独立性使得CUDA程序可以在任意数量的计算核心间扩展。 并行性表现 定义一个二维矩阵求和的核函数。 123456789__global__ void sumMatrixOnGPU2D(float *A, float *B, float *C, int NX, int NY){ unsigned int ix = blockIdx.x * blockDim.x + threadIdx.x; unsigned int iy = blockIdx.y * blockDim.y + threadIdx.y; unsigned int idx = iy * NX + ix; if (ix &lt; NX &amp;&amp; iy &lt; NY) C[idx] = A[idx] + B[idx];} 详细代码参考parallelism.cu。 检测活跃线程束 我们利用不同的线程块大小设计来执行上面的核函数，统计核函数执行事件，并使用ncu分析不同情况下的占用率。 这里的占用率指的是：每周期内活跃线程束的平均数量与一个SM支持的线程束最大数量的比值。 这里对线程块采用四种不同的设计：(32, 32)、(32, 16)、(16, 32)、(16, 16)，得到的分析结果如下所示。 核函数耗时情况如下。 1234sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt; elapsed 7.0817 mssumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt; elapsed 7.02669 mssumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt; elapsed 7.03258 mssumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt; elapsed 7.03968 ms 占用率分析结果如下。 占用率 sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt; 48.07% sumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt; 59.31% sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt; 63.41% sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt; 67.98% 观察上述结果： 情况二(32, 16)中的线程块比情况一(32, 32)更多，所以设备可以有更多活跃的线程束，是其占用率更高可能的原因之一； 情况四(16, 16)的占用率最高，但并不是最快的，因此，更高的占用率并不一定代表更高的性能。 检测内存操作 上面提到的矩阵求和的核函数中有三个内存操作，两次加载和一次存储。同样使用ncu来分析核函数的内存读取效率和全局加载效率，分析结果如下。 全局加载效率指的是被请求的全局加载吞吐量占所需的全局加载吞吐量的比值，它衡量了程序的加载操作利用设备内存带宽的程度。 内存读取效率 全局加载效率 sumMatrixOnGPU2D &lt;&lt;&lt;(512, 512), (32, 32)&gt;&gt;&gt; 296.77 GB/s 100% sumMatrixOnGPU2D &lt;&lt;&lt;(512, 1024), (32, 16)&gt;&gt;&gt; 297.72 GB/s 100% sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 512), (16, 32)&gt;&gt;&gt; 295.40 GB/s 100% sumMatrixOnGPU2D &lt;&lt;&lt;(1024, 1024), (16, 16)&gt;&gt;&gt; 297.79 GB/s 100% 如果阅读过《CUDA C编程权威指南》一书中的相关介绍，会发现我们这里得到的分析结果与书中提到的截然不同。书中描述的情况三和情况四下，全局加载效率会有明显的下降。但这里不同的线程块设计并没有导致太大的内存操作性能波动，笔者推测是因为nvcc编译器在这方面做了比以前更多的优化，来保证线程在SM中的调度更加合理。 根据书中的描述，在一节分析到的结果是，对网格和线程块的启发式算法来说，最内层的维数（block.x）应该是线程束大小的整倍数，这一结论还是有参考意义的。 增大并行性 我们来探讨一个问题，根据上一节得到的结论，继续增加block.x会增大吞吐量吗？同样是利用上一节中的例子，使用不同的线程块设计来执行核函数。 12345678sumMatrixOnGPU2D &lt;&lt;&lt;(256, 8192), (64, 2)&gt;&gt;&gt; elapsed 7.03245 mssumMatrixOnGPU2D &lt;&lt;&lt;(256, 4096), (64, 4)&gt;&gt;&gt; elapsed 7.05654 mssumMatrixOnGPU2D &lt;&lt;&lt;(256, 2048), (64, 8)&gt;&gt;&gt; elapsed 7.02928 mssumMatrixOnGPU2D &lt;&lt;&lt;(128, 8192), (128, 2)&gt;&gt;&gt; elapsed 7.03757 mssumMatrixOnGPU2D &lt;&lt;&lt;(128, 4096), (128, 4)&gt;&gt;&gt; elapsed 7.03094 mssumMatrixOnGPU2D &lt;&lt;&lt;(128, 2048), (128, 8)&gt;&gt;&gt; elapsed 7.04643 mssumMatrixOnGPU2D &lt;&lt;&lt;(64, 8192), (256, 2)&gt;&gt;&gt; elapsed 7.10362 mssumMatrixOnGPU2D &lt;&lt;&lt;(64, 4096), (256, 4)&gt;&gt;&gt; elapsed 7.03165 ms 虽然笔者这里的测试结果差距并不明显，不必过多纠结，了解思想即可。 分析结果可以得出几条规律： 情况一(64, 2)中启动的线程块数量最多，但并不是速度最快的； 情况二(64, 4)与情况四(128, 2)相比，两者有相同数量的线程块（(256, 4096)与(128, 8192)），但情况四的表现优于情况二。这恰好印证了前一节中的结论，线程块最内层的维数对性能起着关键作用； 除了情况一、二、四外，其余情况的线程块数量均比最优情况少。故增大并行性是性能优化的一个重要因素。 接下来分析上述各个情况的占用率，分析方法同之前的检测活跃线程束。分析结果如下。 占用率 sumMatrixOnGPU2D &lt;&lt;&lt;(256, 8192), (64, 2)&gt;&gt;&gt; 82.38% sumMatrixOnGPU2D &lt;&lt;&lt;(256, 4096), (64, 4)&gt;&gt;&gt; 73.27% sumMatrixOnGPU2D &lt;&lt;&lt;(256, 2048), (64, 8)&gt;&gt;&gt; 61.94% sumMatrixOnGPU2D &lt;&lt;&lt;(128, 8192), (128, 2)&gt;&gt;&gt; 79.33% sumMatrixOnGPU2D &lt;&lt;&lt;(128, 4096), (128, 4)&gt;&gt;&gt; 64.16% sumMatrixOnGPU2D &lt;&lt;&lt;(128, 2048), (128, 8)&gt;&gt;&gt; 50.34% sumMatrixOnGPU2D &lt;&lt;&lt;(64, 8192), (256, 2)&gt;&gt;&gt; 73.05% sumMatrixOnGPU2D &lt;&lt;&lt;(64, 4096), (256, 4)&gt;&gt;&gt; 52.63% 书中描述的情况一(64, 2)是占用率最低的情况，因为线程块是最多的，触及到了书作者当时的硬件瓶颈。但在笔者的环境下，情况一反而占用率是最高的，这也体现了硬件进步带来的效果。 虽然与书中描述的情况有所不同，但这也恰恰印证了提高并行性的重要程度，当硬件资源不再是限制和瓶颈的时候，更大的并行程度将带来更高的性能。 经过上面一系列的分析我们能够发现，性能最好的线程块设计，既没有最高的占用率，也没有最高的加载吞吐量。可见，没有一个单独的指标可以直接优化性能，我们需要在几个相关的指标之间寻找一个平衡来获得全局最优性能。 避免分支分化 并行归约问题 一般的并行求和是将较多的数据分块计算，每个线程负责一个数据块的求和，再对每个数据块的和求和即为最终结果。一个常用方法是使用迭代成对实现，一个数据块只包含一对元素，每个线程求得这对元素的和，作为下一次迭代的输入。当输出向量长度为1时，表明最终结果已经被计算出来了。 成对的并行求和可以进一步分为两种类型： 相邻配对：元素与它们相邻的元素配对； 交错配对：根据给定的步长配对元素。 虽然上述介绍的是加法，但任何满足交换律和结合律的运算都可以采用这种思路。 在向量中执行满足交换律和结合律的运算，被称为归约问题。并行归约问题是这种归约运算的并行执行。 并行归约中的分化 首先实现一个相邻配对的并行归约求和核函数。 1234567891011121314151617181920212223__global__ void reduceNeighbored(int *g_idata, int *g_odata, unsigned int size){ int tid = threadIdx.x; int idx = blockIdx.x * blockDim.x + tid; // 将全局数据指针转换为当前block的局部数据指针 int *idata = g_idata + blockIdx.x * blockDim.x; // 边界检查 if (idx &gt;= size) return; // 在全局内存中原地归约 for (int stride = 1; stride &lt; blockDim.x; stride *= 2) { if ((tid % (2 * stride)) == 0) idata[tid] += idata[tid + stride]; __syncthreads(); // 同步线程，保证下一轮迭代正确 } // 将当前block的结果写入全局内存 if (tid == 0) g_odata[blockIdx.x] = idata[0];} 两个相邻元素之间的距离成为步长（stride），初始化为1。每次归约循环后，步长被乘以2。由于块间同步很不方便，所以将每个块的求和结果拷贝回主机之后再进行串行求和。 具体求和过程如图所示。 测试后得到的性能如下所示。 1234Array Size: 16777216cpu reduce elapsed 16.2122 ms cpu_sum: 206464799gpu neighbored elapsed 0.628512 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;Result correct! 这里采用一维网格与一维线程块，详细代码参考reduction.cu，后面将以这个核函数的表现作为性能基准。这个cu文件将伴随整个避免分支分化和展开循环两个小节。 改善并行归约的分化 注意上面核函数中的条件表达式。 1if ((tid % (2 * stride)) == 0) 我们在前面也介绍过，这会导致非常严重的线程束分化。第一次迭代只有ID为偶数的线程是活跃的，第二次迭代就只有四分之一的线程活跃了，但那些不活跃的线程依旧会被调度。 改进这一现象的方法是强制ID相邻的线程执行求和操作，线程束分化就可以被归约了。将核函数修改为如下形式。 123456789101112131415161718192021__global__ void reduceNeighboredLess(int *g_idata, int *g_odata, unsigned int size){ unsigned tid = threadIdx.x; unsigned idx = blockIdx.x * blockDim.x + tid; int *idata = g_idata + blockIdx.x * blockDim.x; if (idx &gt;= size) return; for (int stride = 1; stride &lt; blockDim.x; stride *= 2) { // 将tid转换为局部数组索引 int index = 2 * stride * tid; if (index &lt; blockDim.x) idata[index] += idata[index + stride]; __syncthreads(); } if (tid == 0) g_odata[blockIdx.x] = idata[0];} 这样就将具体的运算过程变为了如下所示的状态。 虽然这种改进在一定程度上降低了线程束分化的程度，但在最后几轮迭代中，还是会存在线程束分化的情况。例如对于一个有512个线程的块来说，第一轮迭代由前8个线程束完成，后8个线程束不处于活跃状态。前几轮迭代都同理，但当最后五轮迭代中，活跃的线程数量小于线程束大小的时候，还是会发生线程束分化。 性能测试的表现如下所示。 12345Array Size: 16777216cpu reduce elapsed 16.167 ms cpu_sum: 206464799gpu neighbored elapsed 0.67648 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;gpu neighboredL elapsed 0.424576 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;Result correct! 虽然在最后几轮还是会发生线程束分化，但依旧比不做任何处理快了1.6倍左右。我们可以利用ncu来分析每个线程束中执行的指令数量和内存读取效率来解释这种现象，分析结果如下所示。 每线程束执行指令数 内存读取效率 reduceNeighbored(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1) 341.94 inst/warp 690.98 GB/s reduceNeighboredLess(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1) 115.38 inst/warp 1.27 TB/s 可以观察到，在改善线程束分化后，每个线程束执行的指令数量大幅下降。而且拥有更大的加载吞吐量，因为虽然I/O操作数量相同，但耗时更短。 交错配对的归约 与相邻配对的方法相比，交错配对的方法反转了元素步长的变化，初始化为数据块大小的一半，然后每轮迭代减少一半。 12345678910111213141516171819__global__ void reduceInterleaved(int *g_idata, int *g_odata, unsigned int size){ unsigned int tid = threadIdx.x; unsigned int idx = blockIdx.x * blockDim.x + tid; int *idata = g_idata + blockIdx.x * blockDim.x; if (idx &gt;= size) return; for (int stride = blockDim.x / 2; stride &gt; 0; stride &gt;&gt;= 1) { if (tid &lt; stride) idata[tid] += idata[tid + stride]; __syncthreads(); } if (tid == 0) g_odata[blockIdx.x] = idata[0];} 具体运算过程如下图所示。 性能测试表现如下。 123456Array Size: 16777216cpu reduce elapsed 15.991 ms cpu_sum: 206464799gpu neighbored elapsed 0.676736 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;gpu neighboredL elapsed 0.422176 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;gpu interleaved elapsed 0.364032 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;Result correct! 虽然交错配对的方式与优化后的相邻配对方式拥有相同的线程束分化情况，但仍然有性能的提升。这种性能提升是由全局内存加载 / 存储模式导致的，在后续的文章中会进一步讨论。 展开循环 循环展开是一种尝试减少分支出现频率和循环维护指令来优化循环的技术。在循环展开中，循环主体在代码中要多次编写，任何封闭循环都可以将它的迭代次数减少或完全消除。循环体的复制数量被成为循环展开因子，迭代次数以下列公式得到。 迭代次数原始循环迭代次数循环展开因子 为了方便理解，观察如下示例。 123for (int i = 0; i &lt; 100; i++) { a[i] = b[i] + c[i];} 如果像下面这样重复一次循环体，迭代次数就可以减少一半。 1234for (int i = 0; i &lt; 100; i += 2) { a[i] = b[i] + c[i]; a[i + 1] = b[i + 1] + c[i + 1];} 展开的归约 我们用上面的思路来将之前提到的交错配对的归约求和操作进行循环展开。 先将两个数据块汇聚到一个线程块中，每个线程作用于多个数据块，并处理每个数据块的一个元素。 12345678910111213141516171819202122__global__ void reduceUnrolling2(int *g_idata, int *g_odata, unsigned int size){ unsigned int tid = threadIdx.x; unsigned int idx = blockIdx.x * blockDim.x * 2 + tid; // 与之前不同，这里将两个数据库汇总到一个线程块中 int *idata = g_idata + blockIdx.x * blockDim.x * 2; if (idx + blockDim.x &lt; size) g_idata[idx] += g_idata[idx + blockDim.x]; __syncthreads(); for (int stride = blockDim.x / 2; stride &gt; 0; stride &gt;&gt;= 1) { if (tid &lt; stride) idata[tid] += idata[tid + stride]; __syncthreads(); } if (tid == 0) g_odata[blockIdx.x] = idata[0];} 比较关键的修改如下，每个线程都添加一个来自于相邻数据块的元素。可以把它作为归约循环的一个迭代，可以在数据块间进行归约。 12if (idx + blockDim.x &lt; size) g_idata[idx] += g_idata[idx + blockDim.x]; 然后调整全局数组索引，只需要一半的线程块来处理数据。 12unsigned int idx = blockIdx.x * blockDim.x * 2 + tid;int *idata = g_idata + blockIdx.x * blockDim.x * 2; 进行性能测试，结果如下。 12345Array Size: 16777216cpu reduce elapsed 16.2422 ms cpu_sum: 206464799gpu interleaved elapsed 0.364096 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;gpu unrolling2 elapsed 0.28352 ms gpu_sum: 206464799 &lt;&lt;&lt;16384, 512&gt;&gt;&gt;Result correct! 可以观察到性能得到了进一步的提升，我们尝试进一步提高展开程度，性能测试结果如下。 1234567Array Size: 16777216cpu reduce elapsed 16.0142 ms cpu_sum: 206464799gpu interleaved elapsed 0.364608 ms gpu_sum: 206464799 &lt;&lt;&lt;32768, 512&gt;&gt;&gt;gpu unrolling2 elapsed 0.281024 ms gpu_sum: 206464799 &lt;&lt;&lt;16384, 512&gt;&gt;&gt;gpu unrolling4 elapsed 0.262944 ms gpu_sum: 206464799 &lt;&lt;&lt;8192, 512&gt;&gt;&gt;gpu unrolling8 elapsed 0.256736 ms gpu_sum: 206464799 &lt;&lt;&lt;4096, 512&gt;&gt;&gt;Result correct! 可以观察到，在一个线程中有更多的独立内存操作会得到更好的性能，因为内存延迟可以得到很好的隐藏。我们利用ncu来分析设备内存读取吞吐量来解释性能提升的理由。 设备内存读取吞吐量 reduceInterleaved(int *, int *, unsigned int) (32768, 1, 1)x(512, 1, 1) 187.98 GB/s reduceUnrolling2(int *, int *, unsigned int) (16384, 1, 1)x(512, 1, 1) 293.78 GB/s reduceUnrolling4(int *, int *, unsigned int) (8192, 1, 1)x(512, 1, 1) 335.35 GB/s reduceUnrolling8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1) 342.42 GB/s 这里可以得到一个结论，归约的循环展开程度和设备读取吞吐量之间是成正比的。 展开线程的归约 上面提到过，当最后几轮迭代的时候，线程数量少于线程束大小时，线程束分化依旧会发生。由于线程束的执行时SIMT的模式，每条指令之后有隐式的线程束内同步。所以可以借助这一隐式同步，将最后几轮迭代用下列语句展开。 12345678910if (tid &lt; 32){ volatile int *vmem = idata; vmem[tid] += vmem[tid + 32]; vmem[tid] += vmem[tid + 16]; vmem[tid] += vmem[tid + 8]; vmem[tid] += vmem[tid + 4]; vmem[tid] += vmem[tid + 2]; vmem[tid] += vmem[tid + 1];} 注意：变量vmem是被volatile修饰符修饰的，它告诉编译器每次赋值时必须将vmem[tid]的值存回全局内存中。如果省略了volatile修饰符，编译器或缓存可能优化对全局或共享内存的读写。若位于全局或共享内存中的变量有volatile修饰符，则编译器会假定其值可以被其他线程在任何时间修改或使用。故任何带有volatile修饰符的变量会强制直接读写内存，而不是简单的读写缓存或寄存器。 性能测试结果如下。 12gpu unrolling8 elapsed 0.22992 ms gpu_sum: 206464799 &lt;&lt;&lt;4096, 512&gt;&gt;&gt;gpu unrolWarps8 elapsed 0.227296 ms gpu_sum: 206464799 &lt;&lt;&lt;4096, 512&gt;&gt;&gt; 我们可以通过分析被阻塞线程束的占比来作证这个性能提升。 阻塞线程束占比 reduceUnrolling8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1) 20.83% reduceUnrollWarps8(int *, int *, unsigned int) (4096, 1, 1)x(512, 1, 1) 12.56% 可以观察到，通过展开最后的线程束，被阻塞的线程束占比大幅度下降，所以进一步提升了性能。 完全展开的归约 由于当前计算能力的设备，每个线程块最大的线程束是1024，且上述的归约核函数中循环迭代次数是基于一维网格与一维线程块的，所以完全展开归约循环是可行的。 12345678910111213141516171819202122232425262728__global__ void reduceCompleteUnrollWarps8(int *g_idata, int *g_odata, unsigned int size){ ... // 完全展开 if (blockDim.x &gt;= 1024 &amp;&amp; tid &lt; 512) idata[tid] += idata[tid + 512]; __syncthreads(); if (blockDim.x &gt;= 512 &amp;&amp; tid &lt; 256) idata[tid] += idata[tid + 256]; __syncthreads(); if (blockDim.x &gt;= 256 &amp;&amp; tid &lt; 128) idata[tid] += idata[tid + 128]; __syncthreads(); if (blockDim.x &gt;= 128 &amp;&amp; tid &lt; 64) idata[tid] += idata[tid + 64]; __syncthreads(); if (tid &lt; 32) { volatile int *vmem = idata; vmem[tid] += vmem[tid + 32]; vmem[tid] += vmem[tid + 16]; vmem[tid] += vmem[tid + 8]; vmem[tid] += vmem[tid + 4]; vmem[tid] += vmem[tid + 2]; vmem[tid] += vmem[tid + 1]; } ...} 性能测试的结果如下所示，又有小小的提升。 12gpu unrolWarps8 elapsed 0.227264 ms gpu_sum: 206464799 &lt;&lt;&lt;4096, 512&gt;&gt;&gt;gpu CmptUnroll8 elapsed 0.224992 ms gpu_sum: 206464799 &lt;&lt;&lt;4096, 512&gt;&gt;&gt; 模板函数的归约 虽然可以手动展开循环，但使用模板函数有助于进一步减小分支消耗，关键代码如下。 123456789101112131415161718template &lt;unsigned int iBlockSize&gt;__global__ void reduceCompleteUnroll(int *g_idata, int *g_odata, unsigned int size){ ... if (iBlockSize &gt;= 1024 &amp;&amp; tid &lt; 512) idata[tid] += idata[tid + 512]; __syncthreads(); if (iBlockSize &gt;= 512 &amp;&amp; tid &lt; 256) idata[tid] += idata[tid + 256]; __syncthreads(); if (iBlockSize &gt;= 256 &amp;&amp; tid &lt; 128) idata[tid] += idata[tid + 128]; __syncthreads(); if (iBlockSize &gt;= 128 &amp;&amp; tid &lt; 64) idata[tid] += idata[tid + 64]; __syncthreads(); ...} 这样做的好处是，检查块大小的if语句在编译时会被评估，若这一条件为false，则该分支块在编译时就会被删除。这类核函数一定要在switch-case结构中被调用，这样可以使编译器为特定大小的线程块自动优化代码。 123456789101112131415161718switch (blocksize){case 1024: reduceCompleteUnroll&lt;1024&gt;&lt;&lt;&lt;grid.x / 8, block&gt;&gt;&gt;(d_idata, d_odata, size); break;case 512: reduceCompleteUnroll&lt;512&gt;&lt;&lt;&lt;grid.x / 8, block&gt;&gt;&gt;(d_idata, d_odata, size); break;case 256: reduceCompleteUnroll&lt;256&gt;&lt;&lt;&lt;grid.x / 8, block&gt;&gt;&gt;(d_idata, d_odata, size); break;case 128: reduceCompleteUnroll&lt;128&gt;&lt;&lt;&lt;grid.x / 8, block&gt;&gt;&gt;(d_idata, d_odata, size); break;case 64: reduceCompleteUnroll&lt;64&gt;&lt;&lt;&lt;grid.x / 8, block&gt;&gt;&gt;(d_idata, d_odata, size); break;} 归约小结 至此，我们借助归约求和探讨了核函数的几个优化方案，大致分为避免分支分化和展开循环两个思路，细节上述部分已经充分讨论过了。下表中展示了从一开始的相邻配对归约，到改善了线程束分化问题，最后到完全展开循环核函数的性能对比。 核函数描述 耗时 (ms) 单步加速 累计加速 加载效率 存储效率 相邻配对（分化） 0.674112 25.02 25 相邻配对（改善分化） 0.581312 1.16 1.16 25.02 25 交错配对 0.364192 1.60 1.85 96.15 95.52 循环展开（2块） 0.255392 1.43 2.64 98.04 97.71 循环展开（4块） 0.252832 1.01 2.67 98.68 97.71 循环展开（8块） 0.229664 1.10 2.94 99.21 97.71 循环展开（8块）+ 最后线程束展开 0.225184 1.02 2.99 99.43 99.40 循环展开（8块）+ 完全循环展开 + 最后线程束展开 0.224096 1.00 3.01 99.43 99.40 模板化核函数 0.211616 1.06 3.19 99.43 99.40 动态并行 CUDA的动态并行允许在GPU端直接创建和同步新的GPU核函数，可以在一个核函数的任意点动态增加并行性。动态并行可以在运行时才决定网格和线程块的大小。 嵌套执行 在GPU进行核函数调用的方法与主机端的调用方法相同。 在动态并行中，核函数执行分为双亲和孩子两种类型。父线程、父线程块或父网格启动一个新的网格，即子网格。子线程、子线程块或子网格被双亲启动。子网格必须在父线程、父线程块或父网格完成之前完成。只有在所有子网格都完成后，双亲才会完成。 若调用的线程没有显式地同步子网格，则CUDA运行时会保证双亲与孩子之间的隐式同步。 当双亲启动一个子网格，父线程块与孩子显式同步后，孩子才能开始执行。 关于动态并行的内存访问有以下几点： 父网格和子网格共享相同的全局和常量内存，但它们有不同的局部内存和共享内存； 双亲和孩子之间以弱一致性为保证，使得父子网格可以对全局内存并发存取； 在子网格开始和完成两个时刻，子网格和它的父线程见到的内存完全相同； 当父线程优先于子网格调用时，所有的全局内存操作要保证子网格可见； 当双亲在子网格完成时进行同步后，子网格所有的内存操作要保证双亲可见； 在GPU上嵌套Hello World 实现一个嵌套调用的核函数来在GPU上输出Hello World，具体的嵌套调用方式如下图所示。 实现核函数如下。 1234567891011121314__global__ void nestedHelloWorld(int const size, int depth){ int tid = threadIdx.x; printf(\"Recursion=%d: Hello World from thread %d block %d\\n\", depth, tid, threadIdx.x); if (size == 1) return; int threads = size &gt;&gt; 1; if (tid == 0 &amp;&amp; threads &gt; 0) { nestedHelloWorld&lt;&lt;&lt;1, threads&gt;&gt;&gt;(threads, ++depth); printf(\"-------&gt; nested execution depth: %d\\n\", depth); }} 详细代码参考nestedHelloWorld.cu。注意需要编译选项-rdc为true，一些资料中提到还需要链接cudadevrt库，但笔者这里没有显式链接也正常执行了，推测是自动链接了。 嵌套归约 由于CUDA从11.6开始就不允许在设备端执行cudaDeviceSynchronize()来同步子网格，并且CUDA 12.x开始CDP（CUDA Dynamic Parallelism）替换成了CDP2，在细节上与CDP1有所不同。 首先我们实现一个嵌套归约求和的核函数。 123456789101112131415161718192021222324__global__ void gpuRecursiveReduce(int *g_idata, int *g_odata, unsigned int size){ unsigned int tid = threadIdx.x; int *idata = g_idata + blockIdx.x * blockDim.x; int *odata = &amp;g_odata[blockIdx.x]; // 递归中止条件 if (size == 2 &amp;&amp; tid == 0) { g_odata[blockIdx.x] = idata[0] + idata[1]; return; } int stride = size &gt;&gt; 1; if (stride &gt; 1 &amp;&amp; tid &lt; stride) idata[tid] += idata[tid + stride]; __syncthreads(); // 嵌套调用生成子网格 if (tid == 0) gpuRecursiveReduce&lt;&lt;&lt;1, stride, 0, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride); __syncthreads();} 注意下面的语句。 1gpuRecursiveReduce&lt;&lt;&lt;1, stride, 0, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride); 这里迫使该核函数在cudaStreamTailLaunch特殊流中执行，这是CDP2的新特性，这个流允许父网格在完成工作后才启动新网格。在大多数情况下，可以使用该流来实现与cudaDeviceSynchronize()相同的功能。 在实际的实验过程中，笔者发现大多数情况下，这种嵌套的归约计算结果是错误的，但在小数据量的情况下是正确的，具体原因还有待分析。 详细代码参考nested_reduce.cu。 对该核函数进行性能测试，结果如下所示。 12345Array size: 524288Execution Configuration: grid 1024 block 512cpu reduce elapsed 0.470947 ms cpu_sum: 6451596gpu nested elapsed 83.5106 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;Result correct! CUDA官方文档对于CDP2的同步有如下描述： 任何线程的CUDA运行时操作，包括核函数启动，在网格中的所有线程中都是可见的。这意味着父网格中的调用线程可以执行同步，以控制由网格中的任意线程在网格中的任何线程创建的流上启动网格的顺序。直到网格中所有线程的所有任务都已完成，网格的执行才被视为完成。如果网格中的所有线程在所有子网格完成之前退出，则将自动触发隐式同步操作。 大概意思就是，从CDP2开始，开发者已经不需要再核函数内进行显式的同步操作了，一切同步交给流和编译器来控制。去掉显式同步后的核函数实现如下所示。 123456789101112131415161718192021__global__ void gpuRecursiveReduceNosync(int *g_idata, int *g_odata, unsigned int size){ unsigned tid = threadIdx.x; int *idata = g_idata + blockIdx.x * blockDim.x; int *odata = &amp;g_odata[blockIdx.x]; if (size == 2 &amp;&amp; tid == 0) { g_odata[blockIdx.x] = idata[0] + idata[1]; return; } int stride = size &gt;&gt; 1; if (stride &gt; 1 &amp;&amp; tid &lt; stride) { idata[tid] += idata[tid + stride]; if (tid == 0) gpuRecursiveReduceNosync&lt;&lt;&lt;1, stride, 0, cudaStreamTailLaunch&gt;&gt;&gt;(idata, odata, stride); }} 性能测试如下。 123456Array size: 524288Execution Configuration: grid 1024 block 512cpu reduce elapsed 0.496094 ms cpu_sum: 6451596gpu nested elapsed 78.52 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;gpu nestedNosyn elapsed 69.1308 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;Result correct! 可以观察到性能有一些提升。在这个版本的实现中，每个线程块产生一个子网格，并引起了大量的调用，具体过程如下图所示。 为了减少其创建的子网格数量，可以将启动方式改为下图所示的方法。 即只令第一个线程块的第一个线程来启动子网格，每次嵌套调用时，子线程块大小就会减小到其父线程块的一半。对于之前的实现来说，每个嵌套层的核函数执行过程都会有一半的线程空闲。但在这种实现方式中，所有空闲线程都会在每次核函数启动时被移除。这样会释放更多的计算资源，使得更多的线程块活跃起来。 同时，由于子线程块的大小是父线程块的一半，为了正确的计算数据的偏移，必须将一开始父线程块的大小传递进去。 123456789101112131415__global__ void gpuRecursiveReduce2(int *g_idata, int *g_odata, int stride, int const dim){ int *idata = g_idata + blockIdx.x * dim; if (stride == 1 &amp;&amp; threadIdx.x == 0) { g_odata[blockIdx.x] = idata[0] + idata[1]; return; } idata[threadIdx.x] += idata[threadIdx.x + stride]; if (threadIdx.x == 0 &amp;&amp; blockIdx.x == 0) gpuRecursiveReduce2&lt;&lt;&lt;gridDim.x, stride / 2&gt;&gt;&gt;(g_idata, g_odata, stride / 2, dim);} 性能测试如下。 12345678Array size: 524288Execution Configuration: grid 1024 block 512cpu reduce elapsed 0.48291 ms cpu_sum: 6451596gpu nested elapsed 76.7643 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;gpu nestedNosyn elapsed 69.8579 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;gpu nested2 elapsed 0.082464 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;gpu neighbored elapsed 0.025632 ms gpu_sum: 6451596 &lt;&lt;&lt;1024, 512&gt;&gt;&gt;Result correct! 虽然对比之前的嵌套归约提升很大，但其性能甚至不如之前实现的性能最差的相邻匹配的归约。","link":"/posts/47225/"},{"title":"CUDA编程——流和并发","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 异步并发执行 CUDA将以下几个操作暴露为可以互相并发执行的操作： 主极端的运算； 设备端的运算； 从主机端到设备端的数据传输； 从设备端到主机端的数据传输； 给定设备内的数据传输； 设备之间的数据传输。 这些操作之间实现的并发级别将取决于设备的特性集和计算能力，如下所述。 主机和设备之间的并发执行 主机和设备的并发执行是通过在设备完成所请求的任务之前，将控制权交还给主机线程完成的，这一过程由异步库函数实现。使用异步调用，多个设备可以同时排队，以便在设备资源满足时，由CUDA驱动程序执行。这减轻了主机线程管理设备的责任，使其有更多的精力去执行其他操作。 以下设备操作对于主机是异步的： 核函数启动； 在单个设备内的内存拷贝； 从主机到设备的64KB或更小的内存拷贝； 由带有Async后缀的函数发起的内存拷贝； 内存集合（Memory Set）函数调用。 可以将环境变量CUDA_LAUNCH_BLOCKING设为1来全局禁用所有CUDA程序的核函数异步启动。该功能仅用于调试，不应该用于生产环境。 若通过分析软件（Nsight，Visual Profiler等）收集硬件计数器，则核函数启动时同步的，除非启用了并发核函数分析。若异步内存拷贝没有涉及锁页内存，则该拷贝也可能是同步的。 并发核函数执行 部分计算能力2.x以及更高的设备能够并发执行多个核函数。程序可以通过设备属性concurrentKernels来检查这种能力，该属性为1则表示支持该功能。 核函数的最大并发量取决于设备的计算能力，详见官方文档表格。 来自一个CUDA上下文中的核函数无法与另一个CUDA上下文中的核函数并发执行。GPU可能以时间划分来为每个上下文提供前向过程。若用户想在SM上同时执行多个过程的核函数，则必须启动MPS。 若核函数使用了很多纹理内存或大量的本地内存，则与其他核函数并发执行的可能性会更小。 数据传输与核函数的交叠 一些设备可以利用核函数并发地执行（与设备之间的）异步内存拷贝。可以通过设备属性asyncEngineCount来检查这种能力，若该值大于0则表明设备支持该功能。如果内存拷贝涉及到了主机内存，则必须是锁页内存。 通过核函数同时执行设备内部的内存拷贝（需要设备支持设备属性concurrentKernels）和与设备之间的内存拷贝（需要设备支持设备属性asyncEngineCount）也是可能的。设备内部的内存拷贝通过使用目的地址与源地址处于同一设备的标准内存拷贝函数发起。 并发数据传输 部分计算能力2.x以及更高的设备可以将与设备之间的内存拷贝操作交叠。可以通过设备属性asyncEngineCount来检查这种能力，若该值为2则表明设备支持该功能。为了实现这种交叠，任何涉及到的主机内存必须是锁页内存。 流和事件 CUDA流是一系列异步的CUDA操作，这些操作按照主机代码确定的顺序在设备上执行。流可以封装这些操作，保持操作的顺序，允许操作在流中排队，并使其在先前的所有操作之后执行，并且可以查询排队操作的状态。流中操作的执行相对于主机总是异步的。在同一个CUDA流中的操作有严格的执行顺序，而不同流中的操作在执行顺序上不受限制。 CUDA的API函数一般分为同步和异步。具有同步行为的函数会阻塞主机端线程，直到它们完成。具有异步行为的函数被调用后，会立即将控制权归还给主机。 CUDA流 创建和销毁流 通过创建一个流对象并将其指定为一系列核函数启动与host &lt;-&gt; device间内存拷贝的参数来定义流。下列代码创建了两个流对象，并在锁页主机内存中分配一个float型的数组hostPtr。 12345cudaStream_t stream[2];for (int i = 0; i &lt; 2; ++i) cudaStreamCreate(&amp;stream[i]);float* hostPtr;cudaMallocHost(&amp;hostPtr, 2 * size); 下面的代码通过三个操作定义了一系列流，三个操作分别是host -&gt; device内存拷贝、核函数启动、device -&gt; host内存拷贝。 12345for (int i = 0; i &lt; 2; ++i) { cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size, size, cudaMemcpyHostToDevice, stream[i]); MyKernel &lt;&lt;&lt;100, 512, 0, stream[i]&gt;&gt;&gt;(outputDevPtr + i * size, inputDevPtr + i * size, size); cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size, size, cudaMemcpyDeviceToHost, stream[i]);} 上面的例子中，每个流将输入数组HostPtr的一部分拷贝到设备内存中的数组InputDevPtr，通过调用核函数MyKernel()来处理这些数据，最后将结果outputDevPtr拷贝回HostPtr的同一位置。注意：hostPtr必须指向锁页内存才会发生交叠行为。 通过调用cudaStreamDestroy()来释放流。 12for (int i = 0; i &lt; 2; ++i) cudaStreamDestroy(stream[i]); 如果在调用cudaStreamDestroy()时设备仍在流中工作，则该函数将立即返回，并且一旦设备完成流中的所有工作，与流关联的资源将被自动释放。 CUDA提供两个API来检查流中的操作是否都已完成： cudaStreamSynchronize()：强制阻塞主机，直到所给流中的操作全部完成； cudaStreamQuery()：检查流中的所有操作是否完成，在完成之前不会阻塞主机。所有操作都完成时会返回cudaSuccess，当还有操作仍在执行或等待执行时返回cudaErrorNotReady。 默认流 当启动核函数与执行host &lt;-&gt; device间内存拷贝时未指定流参数，或将流参数指定为0，命令将提交到默认流。他们是顺序执行的。 使用编译选项--default-stream per-thread编译的代码，或在引入CUDA头文件之间定义了宏CUDA_API_PER_THREAD_DEFAULT_STREAM的代码，默认流是常规流，每个主机线程均有自己的默认流。 对于使用了编译选项--default-stream legacy编译的代码，默认流是称为空流（NULL Stream）的特殊流，每个设备都有一个用于所有主机线程的空流。空流是特殊的，因为它会导致隐式同步。 对于未指定编译选项--default-stream的代码，默认值为--default-stream legacy。 流调度 从逻辑上看，所有流都可以同时执行，但映射到硬件上时并不总是这样。 虚假的依赖关系 虽然GPU支持多个grid同时执行，但所有流最终是被多路复用到单一的硬件工作队列中的。当选择一个grid执行时，在队列前面的任务由CUDA运行时调度。运行时会检查任务的依赖关系，若仍有任务在执行，则将等待该任务依赖的任务执行完成。当所有依赖关系都执行结束后，新任务才会被调度到可用的SM上。 上述的这种单一流水线可能会导致虚假的依赖关系。图中的A、P与X本来没有依赖关系，但由于队列是单一的，故P只能等待A-B均执行完成才会和C一起被并发调度，X同理。 Hyper-Q技术 Hyper-Q使用多个硬件工作队列，从而减少虚假的依赖关系。该技术通过在主机和设备之间维持多个硬件管理上的连接，允许多个CPU线程或进程在单一GPU上同时启动工作。 这种技术可以实现全流级并发，并具有最小的虚假流间依赖关系。 流的优先级 流的相对优先级可以在创建时使用cudaStreamCreateWithPriority()来指定。可以使用cudaDeviceGetStreamPriorityRange()函数获取允许的优先级范围，按 [最高优先级，最低优先级] 排序。在运行时，较高优先级流中的挂起工作优先于较低优先级流中的挂起工作。 下面的代码展示了如何获取当前设备允许的优先级范围，并创建具有最高和最低优先级的流。 1234567// 获取当前设备允许的优先级范围int priority_high, priority_low;cudaDeviceGetStreamPriorityRange(&amp;priority_low, &amp;priority_high);// 创建具有最高和最低优先级的流cudaStream_t st_high, st_low;cudaStreamCreateWithPriority(&amp;st_high, cudaStreamNonBlocking, priority_high);cudaStreamCreateWithPriority(&amp;st_low, cudaStreamNonBlocking, priority_low); 流优先级不会影响数据传输操作，只对计算核函数有影响。 如果指定的优先级超出了设备定义的范围，它会被自动限制为定义范围内的最低值或最高值。 CUDA事件 CUDA运行时提供了一种方法来密切监视设备的进度，并通过让应用程序异步记录程序中任意点的事件并查询这些事件何时完成来执行准确的计时。当事件之前的所有任务（或者给定流中的所有命令）都完成时，事件就完成了。在所有流中的所有前面的任务和命令完成之后，流0中的事件才会完成。 创建和销毁事件 下面的代码创建两个事件。 123cudaEvent_t start, stop;cudaEventCreate(&amp;start);cudaEventCreate(&amp;stop); 用如下方式销毁。 12cudaEventDestroy(start);cudaEventDestroy(stop); 对于事件，CUDA也提供了检查先前操作是否完成的API： cudaEventSynchronize()：强制阻塞主机，直到该事件所在流中先前的操作执行结束，与cudaStreamSynchronize()类似； cudaEventQuery()：不阻塞主机，与cudaStreamQuery()类似。 记录事件和计算运行时间 下面的代码展示了如何利用事件统计运行时间。 12345678910cudaEventRecord(start, 0);for (int i = 0; i &lt; 2; ++i) { cudaMemcpyAsync(inputDev + i * size, inputHost + i * size, size, cudaMemcpyHostToDevice, stream[i]); MyKernel&lt;&lt;&lt;100, 512, 0, stream[i]&gt;&gt;&gt;(outputDev + i * size, inputDev + i * size, size); cudaMemcpyAsync(outputHost + i * size, outputDev + i * size, size, cudaMemcpyDeviceToHost, stream[i]);}cudaEventRecord(stop, 0);cudaEventSynchronize(stop);float elapsedTime;cudaEventElapsedTime(&amp;elapsedTime, start, stop); 事件的启动和停止不必在同一个流中。 注意：若在非默认流中记录启动事件或停止事件，返回的时间可能比预期的要大。因为cudaEventRecord()函数是异步的，并且不能保证计算的延迟正好处于两个事件之间。 流同步 在非默认流中，所有操作对于主机线程都是非阻塞的，因此会遇到需要在同一个流中令主机和运算操作同步的情况。 从主机角度来讲，CUDA操作可以分为两大类： 内存操作； 核函数启动。 对于主机来说，核函数启动总是异步的。很多内存操作本质上是同步的，但CUDA也提供了异步版本。 CUDA的流可以分为两种： 异步流（非默认流）； 同步流（默认流）。 在主机上，非默认流是异步流，其上所有操作都不阻塞主机执行。而被隐式声明的默认流是同步流，大多数添加到默认流上的操作都会导致主机在先前所有的操作上阻塞。 非默认流可以进一步分为两种： 阻塞流； 非阻塞流。 虽然非默认流对于主机是非阻塞的，但非默认流中的操作可以被默认流中的操作所阻塞。若一个非默认流是阻塞流，则默认流可以阻塞该非默认流中的操作。若一个非默认流是非阻塞流，则它不会阻塞默认流中的操作。 阻塞流和非阻塞流 使用cudaStreamCreate()创建的流是阻塞流，即这些流中的操作可以被阻塞，一直等到默认流中先前的操作执行结束。默认流是隐式流，在相同的CUDA上下文中它和其他所有的阻塞流同步。一般情况下，当操作被发布到默认流中，在该操作被执行之前，CUDA上下文会等待所有先前的操作发布到所有的阻塞流中。此外，任何发布到阻塞流中的操作会被挂起等待，指导默认流中先前的操作执行结束才开始执行。 CUDA运行时提供了一个函数： 1cudaError_t cudaStreamCreateWithFlags(cudaStream_t* pStream, unsigned int flags); 参数flags决定了所创建流的行为，可选如下两个值： cudaStreamDefault； cudaStreamNonBlocking。 指定为cudaStreamNonBlocking使得默认流对于非默认流的阻塞行为失效。 隐式同步 若主机线程在来自不同流的两个命令之间发出以下任何一个操作，它们均不能同时执行： 锁页主机内存分配； 设备内存分配； 设备内存初始化； 同一设备内存地址之间的内存拷贝； 任何提交至空流的CUDA命令； L1/共享内存配置之间的切换（见计算能力7.x）。 一些操作需要依赖关系检查，这些操作包括与被检查的启动项相同流中的任何其他命令，以及该流上对cudaStreamQuery()的任何调用。故程序应该遵循以下原则，以提高核函数的并发潜力： 所有独立操作应该在有依赖关系的操作之前提交； 任何形式的同步操作都应该尽可能的延迟。 显式同步 以下多种方法可以显式同步流。 cudaDeviceSynchronize()：会等待此调用前的所有主机线程中的所有流中的所有命令全部完成； cudaStreamSynchronize()：接受一个流作为参数，等待给定流中的此调用前的所有命令全部完成。可以用于使主机与特定流同步，从而允许其他流继续在设备上执行； cudaStreamWaitEvent()：接受流和事件作为参数，使该调用之后添加到给定流的所有命令延迟执行，直到给定事件完成。该函数允许跨流同步； cudaStreamQuery()：返回流中此调用前的所有命令的完成情况。 可配置事件 与流类似，CUDA也提供了API来创建不同行为的事件： 1cudaError_t cudaEventCreateWithFlags(cudaEvent_t* event, unsigned int flags); 参数flags的可选项有4个： cudaEventDefault； cudaEventBlockingSync； cudaEventDisableTiming； cudaEventInterprocess。 指定为cudaEventBlockingSync的事件在同步时会阻塞调用的线程。cudaEventSynchronize()函数的默认操作是围绕事件进行的，使用CPU周期不断检查事件的状态。而指定为cudaEventBlockingSync后，会将这种轮询交给另一个线程，而调用线程本身继续执行，直到事件依赖关系满足才通知调用线程。这样可以减少CPU周期的浪费，但也会使得事件满足依赖关系与激活调用线程之间的延迟被拉长。 指定为cudaEventDisableTiming表明事件只能用来同步，节省了记录时间戳带来的开销。 指定为cudaEventInterprocess表明时间可能被用作进程间事件。 并发核函数执行 非默认流中的并发核函数 现在已经几乎不存在不支持Hyper-Q的GPU设备了。想要实现核函数的并发执行，必须要令核函数在非默认流中执行。使用类似如下代码使核函数在不同的非默认流中并发执行。 1234567for (int i = 0; i &lt; stream_count; i++){ kernel_1&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_2&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_3&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_4&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data);} 详细代码参考hyper-Q_depth.cu。 通过NVIDIA Nsight System分析核函数在流中的执行情况，可以借助可视化流水线来观察核函数在各个流中的执行情况，分析结果如下图所示。 可以观察到核函数在stream 14，stream 15，stream 16中是并发执行的。 关于这里有一些待解决和讨论的问题，为什么stream 13中的核函数没有和其他三个流中的核函数并发执行。我们来尝试一下每个流执行一个、两个和三个核函数，分别得到了如下结果。 可以观察到，每个流只有一个核函数时，并发执行情况是符合预期的。但每个流中执行的核函数超过一个，就会先在某个流中全部执行一遍，然后在其他流中并发执行。在英伟达开发者论坛中询问后，官方人员给出了解释，这是由于核函数初始化时机导致的，这里放上帖子的链接。 从CUDA 11.7开始，引入了一种懒加载机制，并在CUDA 11.8中进行了重大更新，相见官方文档Lazy Loading。懒加载会使得核函数在真正要执行之前才进行初始化，而不是先全部初始化后再根据安排来执行。我们可以通过环境变量CUDA_MODULE_LOADING来控制是否开启懒加载，开启则设为LAZY，不开启则设为EAGER。 我们将环境变量设置为EAGER便可以得到所有流同时启动核函数的结果。 虚假依赖关系的并发核函数 接下来我们模拟一下不支持Hyper-Q技术的设备。可以通过环境变量CUDA_DEVICE_MAX_CONNECTIONS来控制队列个数，这里设为1来模拟只有一个硬件队列的情况。 1setenv(\"CUDA_DEVICE_MAX_CONNECTIONS\", \"32\", 1); 在此基础上使用nsys分析核函数执行情况。 可以观察到，如同虚假的依赖关系中介绍的那样，核函数的并发执行只发生在了流的边缘。在这种情况下，可以通过广度优先的调用方式来缓解。 12345678for (int i = 0; i &lt; stream_count; i++) kernel_1&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data);for (int i = 0; i &lt; stream_count; i++) kernel_2&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data);for (int i = 0; i &lt; stream_count; i++) kernel_3&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data);for (int i = 0; i &lt; stream_count; i++) kernel_4&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); 详细代码参考hyper-Q_breadth.cu。 深度优先和广度优先的调用方式的区别可以通过下图来理解。 这样就可以在只有一个硬件队列的情况下，实现核函数的并发执行。不过鉴于现代的GPU设备基本都支持Hyper-Q，所以此处简单了解即可。通过nsys分析来佐证上述的观点。 使用OpenMP的调度操作 借助OpenMP开启多线程，每个线程来管理一个流。 123456789omp_set_num_threads(stream_count);#pragma omp parallel{ int i = omp_get_thread_num(); kernel_1&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_2&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_3&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_4&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data);} 详细代码参考hyper-Q_OpenMP.cu。 注意，主机代码中若包含OpenMP的内容，则在编译CUDA程序时需要添加如下几个编译器选项。 1-Xcompiler -fopenmp -lgomp 默认流的阻塞行为 将非默认流中的并发核函数中提到的kernel_3放在默认流中调用，以此来理解默认流的阻塞行为。 1234567for (int i = 0; i &lt; stream_count; i++){ kernel_1&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_2&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_3&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_data); kernel_4&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data);} 核函数执行情况如下图所示。 可以观察到，由于kernel_3在默认流中启动，所以在非默认流上的所有之后的操作都会被阻塞，直到默认流中的操作完成。 创建流间依赖关系 在复杂的应用程序中，引入流间依赖关系是非常有用的，它可以在一个流中阻塞操作，直到另一个流中的指定操作完成。事件可以用来添加流间依赖关系。 通过如下代码来创建同步事件。 12345cudaEvent_t* kernelEvent = (cudaEvent_t*)malloc(stream_count * sizeof(cudaEvent_t));for (int i = 0; i &lt; stream_count; i++){ ERROR_CHECK(cudaEventCreateWithFlags(&amp;kernelEvent[i], cudaEventDisableTiming));} 通过如下方式调用，令每个流完成时记录不同的事件，然后使最后一个流等待其他所有流完成。 123456789101112for (int i = 0; i &lt; stream_count; i++){ kernel_1&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_2&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_3&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); kernel_4&lt;&lt;&lt;grid, block, 0, streams[i]&gt;&gt;&gt;(d_data); // 每个流完成时记录不同的事件 ERROR_CHECK(cudaEventRecord(kernelEvent[i], streams[i])); // 使最后一个流等待其他所有流 ERROR_CHECK(cudaStreamWaitEvent(streams[stream_count - 1], kernelEvent[i], 0));} 详细代码参考hyper-Q_dependence.cu。 观察下图可以看出，最后一个流被其他流阻塞，直到所有流都完成操作后，最后一个流才执行。 核函数执行与数据传输的交叠 想要令核函数执行与数据传输交叠，不仅需要设备支持，还需要在内存申请和搬移的时候注意。要实现交叠，必须使用异步的内存搬移函数，而异步的内存搬移函数所搬移的内存又需要通过cudaHostAlloc来申请。 12345float *h_A, *h_B, *hostRef, *gpuRef;ERROR_CHECK(cudaHostAlloc((void **)&amp;h_A, bytes, cudaHostAllocDefault));ERROR_CHECK(cudaHostAlloc((void **)&amp;h_B, bytes, cudaHostAllocDefault));ERROR_CHECK(cudaHostAlloc((void **)&amp;hostRef, bytes, cudaHostAllocDefault));ERROR_CHECK(cudaHostAlloc((void **)&amp;gpuRef, bytes, cudaHostAllocDefault)); 详细代码参考multi_add_depth.cu。 这里以向量加法为例，实现一个向量加法的核函数，并分别使用不交叠和交叠的调用方式来观察其执行情况。 下图是不交叠的调用方式，可以观察到核函数的执行必须要等到H2D的内存搬移完成后才能开始，D2H的内存搬移也只能等核函数执行完毕后才可以开始。 但当我们使用多个流，将这些操作分散在各个流中，同时使用异步的内存搬移操作后，效果如下。 可以观察到，不同流中的内存搬移操作和核函数执行产生了交叠，大大提高了并发度。 流回调 流回调是另一种可以到CUDA流中排列等待的操作。一旦流回调之前所有的流操作全部完成，被流回调指定的主机端函数就会被CUDA运行时调用。流回调允许任意主机端逻辑插入到CUDA流中。 在较老版本的CUDA中通过如下函数来调用。 1cudaError_t cudaStreamAddCallback(cudaStream_t stream, cudaStreamCallback_t callback, void *userData, unsigned int flags); callback：传入自定义的回调函数； userData：传入回调函数的数据； flags：是保留参数，必须指定为0。 回调函数以如下格式定义。 1234void CUDART_CB my_callback(cudaStream_t stream, cudaError_t status, void* data){ printf(\"callback from stream %d\\n\", (int*)data);} 上述的流回调方式会在未来被弃用，但目前还没有代替方案，所以依然是有效的。 在较新版本的CUDA中通过如下函数来调用。 1cudaError_t cudaLaunchHostFunc(cudaStream_t stream, cudaHostFn_t fn, void *userData); 回调函数以如下格式定义。 1234void CUDART_CB my_callback(void* data){ printf(\"callback from stream %d\\n\", (int*)data);} 详细代码参考stream_callback.cu。同时，关于上述问题，Stack Overflow上有一个帖子提到了。","link":"/posts/4919/"},{"title":"CUDA编程——调整指令集原语","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 CUDA指令概述 浮点指令 一些前值知识： 浮点型数值无法精确存储，只能在四舍五入后再存储； 浮点数存在粒度问题，即浮点数只能在离散的区间间隔里存储数据。随着浮点数离零越来越远，表示数值的区间将随之增大； C语言中的数学函数nextafterf()可以从给定值找到下一个最高位浮点数。 在浮点数值上进行操作的指令被成为浮点指令。CUDA支持所有在浮点数上常见的算术元算。CUDA遵循IEEE-754标准，支持32位和64位两种浮点精度。所有CUDA设备都支持单精度，计算能力1.3及以上的设备均支持双精度。 内部函数和标准函数 CUDA将所有算术函数分为内部函数和标准函数。 标准函数：可对主机和设备进行访问并标准化主机和设备的操作； 内部函数：只能对设备代码进行访问，在编译时对内部函数的行为会有特殊响应，从而产生更积极的优化和更专业化的指令生成。 在CUDA中，很多内部函数和标准函数是有关联的，存在着与内部函数功能相同的标准函数。如标准函数sqrt()对应的内部函数是__dsqrt_rn()。内部函数分解成了比与它们等价的标准函数更少的指令。这会导致内部函数比等价的标准函数更快，但数值精度更低。 原子操作指令 CUDA提供了在32位或64位全局内存或共享内存上执行“读-改-写”操作的原子函数。所有计算能力1.1及以上的设备都支持原子操作。 与标准函数和内部函数类似，每个原子函数都能实现一个基本的数学运算。不同于其他指令类型，当原子操作指令在两个竞争线程共享的内存空间进行操作时，会有一个定义好的行为。 原子运算函数分为3种： 算术运算函数：在目标内存位置上执行简单的算术运算； 按位运算函数：在目标内存位置上执行按位操作； 替换函数：可以用一个新值来替换内存位置上原有的值，可以是有条件的也可以是无条件的，无论成功与否，原子替换函数均返回最初的值。 atomicExch()可以无条件的替换已有的值； atomicCAS()可以有条件的替换已有的值。 虽然原子函数没有精度上的顾虑，但它们的使用可能会严重降低性能。 程序优化指令 单精度与双精度 这里进行一个简单的实验，在主机端和设备端分别将一个单精度浮点数和一个双精度浮点数的值设为12.1，分别对比两种精度的浮点数。 123456Host single-precision representation of 12.1 = 12.10000038146972656250Host double-precision representation of 12.1 = 12.09999999999999964473Device single-precision representation of 12.1 = 12.10000038146972656250Device double-precision representation of 12.1 = 12.09999999999999964473Device and host single-precision representation equal? yesDevice and host double-precision representation equal? yes 详细代码参考floating_point_accuracy.cu。 可以发现，主机和设备上的数值都是近似于12.1，都不是精确值。这个例子中，双精度数值比单精度数值更接近于真实值。 双精度数值的精确性是以空间和性能消耗为代价的。这里再进行一个简单的实验进行验证。将一批单精度和双精度浮点数置于GPU中进行大量的数学运算，再将结果搬移回主机。 123456789101112131415161718192021Input Diff Between Single- and Double-Precision------ -----------------------------------------0 3.13614849292207509279e-021 2.67553565208800137043e-032 2.57291377056390047073e-033 7.82136313500814139843e-034 3.38051875296514481306e-025 4.95682619221042841673e-026 1.57542112574446946383e-027 1.02473393344553187490e-028 1.06261099135736003518e-029 2.36870593798812478781e-02For single-precision floating point, mean times for: Copy to device: 178.990894 ms Kernel execution: 39.176985 ms Copy from device: 673.705701 msFor double-precision floating point, mean times for: Copy to device: 356.848785 ms (1.99x slower than single-precision) Kernel execution: 1922.416699 ms (49.07x slower than single-precision) Copy from device: 1347.894141 ms (2.00x slower than single-precision) 详细代码参考floating_point_perf.cu。 这个例子说明单精度和双精度浮点运算在通信和计算上的性能差异是不可忽略的。同时也说明了单精度与双精度的结果有较大的数值差异，这些结果可能在迭代过程中不断被积累，导致最终结果偏差很大。 由于双精度数值所占空间是单精度数值的两倍，所以当在寄存器中存储一个双精度数值时，一个线程块总的共享寄存器空间会比使用单精度浮点数小的多。 标准函数与内部函数 为了比较标准函数和内部函数的差异，我们需要将代码编译成PTX代码来观察生成的类汇编指令。以下面两个核函数为例。 123456789__global__ void standardKernel(float a, float* out){ *out = powf(a, 2.0f);}__global__ void intrinsicKernel(float a, float* out){ *out = powf(a, 2.0f);} 在编译时加上--ptx选项可以将该代码编译成PTX代码。 详细代码参考intrinsic_standard_comp.cu，对应的PTX代码参考intrinsic_standard_comp.ptx。 通过观察二者的PTX代码，最为明显的一点就是，标准函数的PTX代码量要远大于内部函数。进一步测试其性能表现。 123456789Host calculated 18345290.000000Standard Device calculated 18345290.000000Intrinsic Device calculated 18345288.000000Host equals Standard? Yes diff=0.000000e+00Host equals Intrinsic? No diff=2.000000e+00Standard equals Intrinsic? No diff=2.000000e+00Mean execution time for standard function powf: 0.249888 msMean execution time for intrinsic function __powf: 0.070720 ms 观察精度及性能表现可以发现，内部函数的性能比标准函数要好，但精度不如标准函数。 虽然CUDA代码转化为GPU指令集这一过程通常是编译器完成的，但可以通过一些手段来引导编译器倾向于精度或性能，或两者的平衡。主要有两种方法可以引导指令级优化的类型： 编译器标志； 内部或标准函数调用。 内部或标准函数调用在上面的例子中已经体现了，下面介绍通过编译器标志来引导编译器的代码生成。 有如下核函数，实现一个乘加运算。 1234__global__ void fmad(float* ptr){ *ptr = (*ptr) * (*ptr) + (*ptr);} nvcc编译器中提供一个选项--fmad来控制乘加运算是否融合，默认情况下为true。观察上述核函数的PTX代码可以发现，乘加运算被编译器融合为了一个运算。这样可以提高性能，但精度会有所损失。 1fma.rn.f32 %f2, %f1, %f1, %f1; 接着使用--fmad=false编译同样的代码，PTX代码如下。 12mul.rn.f32 %f2, %f1, %f1;add.rn.f32 %f3, %f1, %f2; 详细代码参考manipulation_instruction_generation.cu，对应的PTX代码参考manipulation_instruction_generation.ptx。 类似于--fmad的控制指令生成的选项还有很多。 选项 描述 默认值 性能影响 精度影响 --ftz=[bool] 将所有单精度非正规浮点数置为零。 false true时可能会提高性能，具体取决于待处理的值和算法。 false时可能会提高精度，具体取决于待处理的值和算法。 --prec-div=[bool] 提高了所有单精度除法和倒数数值的精度。 true true时可能会降低性能。 true时可能会提高与IEEE标准数值的兼容性。 --prec-sqrt=[bool] 强制执行精度更高的平方根函数。 true true时可能会降低性能。 true时可能会提高与IEEE标准数值的兼容性。 --fmad=[bool] 控制编译器是否将乘加运算融合到一个FMAD指令中。 true 若程序中存在浮点型变量的MAD运算，启动FMAD会提高性能。 启用FMAD可能会降低精度。 --use_fast_math 用等价的内部函数替换程序中所有的标准函数。同时设置--ftz=true、--prec-div=false和--prec-sqrt=false。 false 启用该选项则表明启动了一系列提高性能的优化。 启用该选项可能会降低精度。 除了--fmad选项，CUDA还包含一对控制FMAD指令生成的内部函数：__fmul和__dmul。这些函数不会影响乘法运算的性能，在有*运算符的地方调用可以组织编译器将乘法作为乘加优化的一部分来使用。 还是之前的乘加例子，除了使用--fmad=false来阻止乘加优化外，还可以用下列方式来实现相同的效果。 1234__global__ void fmadBlocked(float* ptr){ *ptr = __fmul_rn((*ptr), (*ptr)) + (*ptr);} 这里调用函数时，实际调用的是__fmul_rn()，这个后缀显式地表达了四舍五入的模式，具体如下表所示。 后缀 含义 rn 在当前浮点模式（单或双精度）下不能精确表示的数值，用可表示的最近似值来表示。这是默认模式。 rz 总是向零取整。 ru 总是向上取整到正无穷。 rd 总数向下取整到负无穷。 这样就可以通过这些内部函数的调用来单独控制某些计算的精度，提升某些数值的健壮性，从而可以全局启用MAD优化。 原子指令 原子函数 一个很重要的操作就是原子级CAS，它可以令程序员在CUDA中自定义原子函数。CAS接受三个参数： 内存地址； 存储在此地址中的期望值； 实际想要存储在此位置的新值。 CAS的整体流程为： 读取目标地址并将其存储值与预期值进行比较。 若存储值与预期值相等，则新值将存入目标位置； 若存储值与预期值不等，则目标位置不发生变化； 无论发生什么情况，CAS总是返回目标地址的值。使用返回值可以检查是否替换成功。若返回值等于预期值，则CAS一定成功了。 下面借助CAS来实现一个原子加操作。 1234567891011121314__device__ int myAtomicAdd(int *address, int incr){ int expected = *address; // 记录当前内存地址的值 int oldValue = atomicCAS(address, expected, expected + incr); // 尝试增加incr，CAS会返回目标地址的值 while (oldValue != expected) // 如果返回值与预期值不等，则CAS没有成功 { // 重复执行CAS直到成功 expected = oldValue; // 获取目标地址的新值 oldValue = atomicCAS(address, expected, expected + incr); // 继续尝试增加incr } return oldValue; // 为了匹配其他CUDA原子函数的语义，这里返回目标地址的值} 详细代码参考atomic_operation.cu。 CUDA中内置了一系列的原子函数，如下表所示。 函数 操作 支持的数据类型 atomicAdd 加法 int, unsigned int, unsigned long long int, float atomicSub 减法 int, unsigned int atomicExch 无条件替换 int, unsigned int, unsigned long long int, float atomicMin 最小值 int, unsigned int, unsigned long long int atomicMax 最大值 int, unsigned int, unsigned long long int atomicInc 增量 unsigned int atomicDec 减量 unsigned int atomicCAS CAS int, unsigned int, unsigned long long int atomicAnd 与 int, unsigned int, unsigned long long int atomicOr 或 int, unsigned int, unsigned long long int atomicXor 异或 int, unsigned int, unsigned long long int 原子操作的代价 原子操作可能会付出很高的代价： 当在全局或共享内存中执行原子操作时，能保证所有的数值变化对所有线程都是立即可见的。如果原子指令操作成功，则必须把实际需要的值写入到全局或共享内存中； 共享地址冲突的原子访问可能要求发生冲突的线程不断地重试； 当线程在同一个线程束中时必须执行不同的指令，线程束执行是序列化的。若一个线程束中的多个线程在相同的内存地址发出一个原子操作，就会产生类似于线程冲突的问题； 下面用一个例子来展示原子操作的代价。实现一个核函数不断累加一个共享变量，然后实现一个功能类似，但线程不安全的核函数。 123456789101112131415161718192021222324252627282930__global__ void atomics(int* shared_var, int* values_read, int size, int iterations){ unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x; if (tid &gt;= size) return; values_read[tid] = atomicAdd(shared_var, 1); for (int i = 0; i &lt; iterations; i++) { atomicAdd(shared_var, 1); }}__global__ void unsafe(int* shared_var, int* values_read, int size, int iterations){ unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x; if (tid &gt;= size) return; int old = *shared_var; *shared_var = old + 1; values_read[tid] = old; for (int i = 0; i &lt; iterations; i++) { old = *shared_var; *shared_var = old + 1; }} 详细代码参考atomic_ordering.cu。 测试两个核函数，结果如下。 123456In total, 30 runs using atomic operations took 18.691618 ms Using atomic operations also produced an output of 6400064In total, 30 runs using unsafe operations took 2.103617 ms Using unsafe operations also produced an output of 100001Threads performing atomic operations read values 0 1 2 3 4 5 6 7 8 9Threads performing unsafe operations read values 0 0 0 0 0 0 0 0 0 0 发现原子操作保证了数值的正确性，但性能却大幅度下降。 为了应对上述情况，可以使用局部操作来增强全局原子操作，这些局部操作能从同一线程块的线程中产生一个中间结果。这些操作必须是顺序无关的，即操作的顺序不应影响最终的结果。","link":"/posts/53610/"},{"title":"ITK线上环境编译与VSCode远程环境接入","text":"最近学校的一个项目需要在服务器上编译安装ITK，顺便记录以下VS Code接入远程环境的配置过程。 ITK编译与安装 前期准备 首先将源码压缩包上传至线上环境，解压源码。 1tar -xvf InsightToolkit-5.2.1.tar.gz 创建一个文件夹用于存放Cmake构建出来的文件。 1mkdir ITK-build 再创建一个文件夹用于ITK的安装目标路径。 1mkdir ITK-install 截止目前，文件结构应该为如下所示。 1234|--InsightToolkit-5.2.1|--InsightToolkit-5.2.1.tar.gz|--ITK-build|--ITK-install 上述四个文件及文件夹应处在同一层级下。 Cmake配置 进入ITK-build文件夹，并执行cmake命令。 12cd ITK-buildcmake ../InsightToolkit-5.2.1 按下回车后cmake会开始进行配置，耐心等待配置完成。 完成后会发现当前文件夹下构建出来很多东西，此时需要执行ccmake进行配置。 1ccmake ../InsightToolkit-5.2.1 按下回车后会进入ccmake的TUI界面。 此时按t进入高级模式。 第一次配置 首先要配置的是编译器，更改如下两项为图中所示的路径。 此时按下c开始配置，耐心等待配置完成。 目前由于线上环境的cmake和ccmake版本不匹配，ccmake版本过低导致无法配置。 解决方案：正常按下c即可，ccmake会提示版本过低，此时按下e退出提示界面，再按下q退出ccmake的TUI界面，再去执行cmake命令。 1cmake ../InsightToolkit-5.2.1 在ccmake中的配置，会由于按下了c而得以保存，故执行cmake的时候会沿用在ccmake中更改后的配置项。 后面所有关于cmake的配置都需要如此执行，以下不再赘述。 第二次配置 第一次配置完成后再次执行ccmake，并按下t进入高级模式。 1ccmake ../InsightToolkit-5.2.1 打开编译动态链接库的选项。 按下Page Down翻到下一页，或者使用方向键下键也可以翻页，改动如图。 这里的CMAKE_INSTALL_PREFIX指定到前期准备过程中创建的ITK安装目标路径中。 再次按下c进行配置。 第三次配置（视情况而定） 再次执行ccmake命令，按t进入高级模式，检查所有之前改动过的配置项。 如果发现所有的配置项都是已经更改过的状态，就可以按q退出，不进行配置。 如果发现有些配置被恢复为了默认状态，则需要再次更改后再进行配置，知道所有配置项都符合要求。 Make构建 配置完成后，直接在ITK-build目录下执行make命令。 1make -j8 加上参数-jN开启多线程以加速编译 安装 make构建结束后，在同一目录下执行安装命令。 1make install 到此ITK就安装完成了。 安装完成后，需要将ITK的链接库文件导入环境变量中。 1export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/bisheng_tester2/Example/ITK-install/lib 执行该语句时，切记不要忘记加上$LD_LIBRARY_PATH，否则会将当前的环境变量覆盖掉，导致线上环境出现问题。 VS Code接入远程环境 前期准备 下载Remote - SSH插件。 配置文件如下。 123456# Read more about SSH config files: https://linux.die.net/man/5/ssh_configHost BiSheng HostName 10.8.3.1 User bisheng_tester2 Port 22 IdentityFile \"...\\id_rsa\" 最后一项IdentityFile指向配置Open VPN时用到的私钥。 提前在线上环境创建一个放置代码的文件夹，在VS Code中打开远程文件夹。 配置 c_cpp_properties.json 按下Ctrl + Shift + P，在弹出的窗口中选择C/C++：编辑配置(UI)。 选择编译器路径。 往下翻页，找到包含路径配置项，配置到与图中一致。 该路径请指向自己安装的ITK目录。 此时在文件夹中生成了一个.vscode文件夹，其中有一个c_cpp_properties.json配置文件。 内容与刚才的配置对应。 1234567891011121314151617{ \"configurations\": [ { \"name\": \"Linux\", \"includePath\": [ \"${workspaceFolder}/**\", \"/data/bisheng_tester2/Example/ITK-install/include/**\" ], \"defines\": [], \"compilerPath\": \"/home/bisheng_tester2/Ascend/ascend-toolkit/latest/aarch64-linux/bisheng_cpp/bin/clang++\", \"cStandard\": \"c17\", \"cppStandard\": \"c++14\", \"intelliSenseMode\": \"linux-clang-arm64\" } ], \"version\": 4} tasks.json 任意新建一个cpp文件并打开。 点击菜单栏终端 -&gt; 配置任务，在弹出的窗口中选择clang++ 此时在.vscode文件夹中会生成一个tasks.json配置文件，修改编译器的参数如下所示。 12345678910111213141516171819202122232425262728293031323334{ \"version\": \"2.0.0\", \"tasks\": [ { \"type\": \"cppbuild\", \"label\": \"C/C++: clang++ 生成活动文件\", \"command\": \"/home/bisheng_tester2/Ascend/ascend-toolkit/latest/aarch64-linux/bisheng_cpp/bin/clang++\", \"args\": [ \"-fsycl\", // 添加 \"-fsycl-targets=ascend_910-cce\", // 添加 \"-fcolor-diagnostics\", \"-fansi-escape-codes\", \"-g\", \"-gdwarf\", // 添加 \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\", \"-I\", // 添加，指定包含文件路径 \"/data/bisheng_tester2/Example/ITK-install/include/ITK-5.2\", // 添加 \"-L\", // 添加，指定链接库路径 \"/data/bisheng_tester2/Example/ITK-install/lib\", // 添加 \"-lxxx\" // 添加，指定具体要链接的库文件，xxx代表链接库名称，需要依据实际情况更改 ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": \"build\", \"detail\": \"编译器: /home/bisheng_tester2/Ascend/ascend-toolkit/latest/aarch64-linux/bisheng_cpp/bin/clang++\" } ]} launch.json 点击菜单栏运行 -&gt; 添加配置，此时会在.vscode文件夹下生成一个launch.json，点击右下角的添加配置。 选择(gdb) 启动。 修改配置文件如下。 1234567891011121314151617181920212223242526272829{ \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(gdb) 启动\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/${fileBasenameNoExtension}\", // 主要修改此处 \"args\": [], \"stopAtEntry\": false, \"cwd\": \"${fileDirname}\", \"environment\": [], \"externalConsole\": false, \"MIMode\": \"gdb\", \"setupCommands\": [ { \"description\": \"为 gdb 启用整齐打印\", \"text\": \"-enable-pretty-printing\", \"ignoreFailures\": true }, { \"description\": \"将反汇编风格设置为 Intel\", \"text\": \"-gdb-set disassembly-flavor intel\", \"ignoreFailures\": true } ] } ]} 到此VS Code的配置就完成了。 Demo 在刚才创建的cpp文件中，写一个小Demo。 1234567891011#include &lt;iostream&gt;#include &lt;vnl/vnl_matrix.h&gt; // itk中的一个第三方库int main(){ vnl_matrix&lt;int&gt; A(100, 100, 1); // 实例化一个100*100的矩阵，元素均为1 std::cout &lt;&lt; A &lt;&lt; std::endl; // 输出该矩阵 return 0;} 点击菜单栏终端 -&gt; 运行生成文件，或直接按快捷键Ctrl + Shift + B进行编译。终端输出如下。 此时点击右上角的调试或运行，在弹出的窗口中选择刚才配置的launch任务，即可执行该Demo。 如果提示如下报错信息。 1error while loading shared libraries: libitkvnl-5.2.so.1: cannot open shared object file: No such file or directory 则需要在VS Code的终端中将ITK的链接库路径添加至环境变量中，参考ITK安装步骤的最后一步。 Demo执行结果如下。","link":"/posts/51688/"},{"title":"CUDA编程模型概述","text":"很多人是参考《Professional CUDA C Programming》一书来入门CUDA的，这本书本身是很好的入门材料，但由于CUDA版本迭代非常快，导致书中的一些内容已经是过时的了。这也是笔者撰写本系列博客的初衷之一，这个系列参考了本书以及CUDA 12.x的官方文档，并在每个章节都附有详细的代码参考，并且代码是基于CUDA 12.x的，可以解决一些由于版本迭代带来的问题。本系列的博客由《Professional CUDA C Programming》一书、CUDA官方文档、互联网上的一些资料以及笔者自己的理解构成，希望能对你有一些帮助，若有错误也请大胆指出。 核函数 CUDA的核函数（Kernel）是通过__global__说明符定义的，通过C++扩展语法&lt;&lt;&lt;...&gt;&gt;&gt;来启动。下面是一个向量加法的例子。 1234567891011121314// 核函数定义__global__ void VecAdd(float* A, float* B, float* C){ int i = threadIdx.x; C[i] = A[i] + B[i];}int main(){ ... // 核函数调用，该核函数包含N个线程 VecAdd&lt;&lt;&lt;1, N&gt;&gt;&gt;(A, B, C); ...} 核函数的编写是无需考虑并行性的，并行调度是由编译器和GPU自动完成的，只需要针对每个线程需要处理的逻辑编写代码即可。 核函数的返回类型必须是void，限定符__global__和返回类型的顺序可以调换，上面的核函数也可以写成如下形式。 1void __global__ VecAdd(float* A, float* B, float* C); 核函数有一些注意事项： 核函数只能访问GPU内存； 核函数不能使用变长参数； 核函数不能使用静态变量； 核函数不能使用函数指针； 核函数具有异步性； 具体例子参考hello_world.cu。 CUDA除了核函数还有两种函数，设备函数和主机函数。 设备函数使用__device__限定符修饰，只能在设备上执行，只能被核函数或其他设备函数调用； 主机函数使用__host__限定符修饰，可以与__device__限定符同时使用，编译器会针对主机和设备分别编译该函数； 注意：__global__不能与__host__或__device__同时使用。 除此之外，还需要掌握两个常用技巧，一个是错误处理，一个是性能分析。这两个技巧将在整个GPU算子开发和优化过程中起到重要的作用。关于错误处理，示例代码见error_handle.cu。关于性能分析，详见性能分析，以及代码示例profiling.cu。 线程层级结构 为了方便的定位和访问线程，CUDA提供了线程索引threadIdx，这是一个具有三个分量的向量，可以使用一维、二维或三维的线程索引来标识线程。 线程的索引和ID对应关系如下： 一维block：索引与ID相等； 大小为(Dx, Dy)的二维block：索引(x, y)对应ID为(x + y * Dx)； 大小为(Dx, Dy, Dz)的三维block：索引(x, y, z)对应ID为(x + y * Dx + z * Dx * Dy)。 下面是一个矩阵加法的例子。 123456789101112131415__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]){ int i = threadIdx.x; int j = threadIdx.y; C[i][j] = A[i][j] + B[i][j];}int main(){ ... // 核函数调用，该核函数包括N * N * 1个线程 int numBlocks = 1; dim3 threadsPerBlock(N, N); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ...} 对于当前的GPU，每个线程块（block）最多可以容纳1024个线程。但每个核函数可以被多个形状相同的线程块执行，故总线程数为线程块数量 * 每块线程数。 线程块由一维、二维或三维的线程块网格（grid）组织起来，网格中线程块的数量通常由被处理的数据决定，通常这个数量是超过物理处理单元数量的。 grid和block的数量可以由&lt;&lt;&lt;...&gt;&gt;&gt;来指定，其中的数据类型可以是int或dim3。 每个block可以由一维、二维或三维的blockIdx唯一标识，block的维度可以通过blockDim在核函数内获取。 扩展一下上面的矩阵加法的例子。 1234567891011121314151617__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]){ int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadIdx.y; if (i &lt; N &amp;&amp; j &lt; N) C[i][j] = A[i][j] + B[i][j];}int main(){ ... // 每个block有16 * 16共256个线程 dim3 threadsPerBlock(16, 16); // grid大小是由矩阵的大小决定的，来确保每个矩阵元素都有线程处理 dim3 numBlocks(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ...} 上面的例子是基于每个grid的线程数在每个维度上都能被每个block的线程数整除，但实际中可能不是这样的。 同一个block中的线程可以通过共享内存（shared memory）来协作，并可以通过内部函数__syncthreads()来同步线程以协调访存，这些后面会再提到。 详细来说，CUDA可以组织最多三个维度的grid和block，如果不指定维度，则默认都是一维的。 有一些内建变量可以用来索引线程，这些变量只在核函数内有效，定义在device_launch_parameters.h头文件中。 其中，blockIdx和threadIdx是类型为uint3的结构体，分别都有x, y, z三个成员，该结构体源码长下面这样。 1234struct __device_builtin__ uint3{unsigned int x, y, z;}; 而gridDim和blockDim是类型为dim3的结构体，同样有x, y, z三个成员，源码是下面这样。 12345struct __device_builtin__ dim3{unsigned int x, y, z; // 还有其他部分...}; 对于上述几个变量，他们有下列范围关系： blockIdx.x范围为[0, gridDim.x-1]； blockIdx.y范围为[0, gridDim.y-1]； blockIdx.z范围为[0, gridDim.z-1]； threadIdx.x范围为[0, blockDim.x-1]; threadIdx.y范围为[0, blockDim.y-1]; threadIdx.z范围为[0, blockDim.z-1]; 定义多维grid和block可以使用C++构造函数的形式。 12dim3 grid_size(Gx, Gy, Gz);dim3 block_size(Bx, By, Bz); grid和block是有大小限制的： gridDim.x最大值为； gridDim.y最大值为； gridDim.z最大值为； blockDim.x最大值为1024； blockDim.y最大值为1024； blockDim.z最大值为64； 但block有一个额外限制，总的block数最大为1024，即满足上述限制的同时要满足blockDim.x * blockDim.y * blockDim.z &lt;= 1024。 具体例子参考threads_management.cu 线程块集群 线程块集群（Thread Block Cluster）是一个可选的层级。在线程块中，线程会被协调安排在流式多处理器（streaming multiprocessor）中。类似地，一个线程块集群中的线程会被协调安排在GPU处理簇（GPU Processing Cluster, GPC）中。 与block类似，簇也有一维、二维或三维的形式。簇中的block数量是可以由用户定义的，但CUDA支持的可移植的簇中最多包含8个block。对于不能支持最大簇的GPU设备或MIG配置中，会相应减小这个最大数量。在特定体系结构下，可以用cudaOccupancyMaxPotentialClusterSize接口来查询簇支持的最大block数量。 MIG是英伟达提供的多实例GPU框架，能够独立划分GPU资源，使得GPU在运行不同任务的时候不会争抢资源。 可以使用编译时核函数属性__cluster_dims__(X, Y, Z)或者使用CUDA核函数的启动APIcudaLanunchKernelEx来启用线程块集群。若核函数使用编译时属性确定簇大小，则核函数启动时就无法改变簇大小。下面是使用编译时核函数属性使用线程块集群的例子。 12345678910111213// 编译时确定线程块集群尺寸为2 * 1 * 1__global__ void __cluster_dims__(2, 1, 1) cluster_kernel(float *input, float* output) {}int main(){ float *input, *output; dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); // grid的维度不受线程块集群启动方式影响 // grid的维度必须是线程块集群尺寸的倍数 cluster_kernel&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(input, output);} 线程块集群大小也可以在运行时设置，并且使用CUDA核函数的启动APIcudaLaunchKernelEx来启动内核。 1234567891011121314151617181920212223242526__global__ void cluster_kernel(float *input, float* output) {}int main(){ float *input, *output; dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); { cudaLaunchConfig_t config = {0}; // grid的维度不受线程块集群启动方式影响 // grid的维度必须是线程块集群尺寸的倍数 config.gridDim = numBlocks; config.blockDim = threadsPerBlock; cudaLaunchAttribute attribute[1]; attribute[0].id = cudaLaunchAttributeClusterDimension; attribute[0].val.clusterDim.x = 2; // 线程块集群的X维度大小 attribute[0].val.clusterDim.y = 1; // 线程块集群的Y维度大小 attribute[0].val.clusterDim.z = 1; // 线程块集群的Z维度大小 config.attrs = attribute; config.numAttrs = 1; cudaLaunchKernelEx(&amp;config, cluster_kernel, input, output); }} 在计算能力9.0的GPU中，线程块集群中所有的线程块都保证在单个GPC上调度，并且允许簇中的线程块使用Cluster Group中的APIcluster.sync()来执行硬件支持的同步操作。同时Cluster Group还提供成员函数num_threads()和num_blocks()来获取簇中的线程数和线程块数。dim_threads()和dim_blocks()获取线程和线程块的维度排列方式。 对于同一线程块集群中的线程块来说，共享内存是分布式的，可以互相访问彼此的共享内存。 内存层级结构 CUDA线程可以从不同的内存空间中访问数据。 每个线程拥有私有的本地内存（Local Memory）； 每个线程块拥有所有块内线程可见的共享内存（Shared Memory），这些块内线程与线程块有着相同的生命周期； 每个线程块集群中的线程块可以在彼此的共享内存中进行读、写和原子操作； 所有线程共享全局内存（Global Memory）。 此外还有两片可以被所有线程访问的读内存空间，常量内存（Constant Memory）和纹理内存（Texture Memory）空间。全局、常量、纹理内存针对不同的内存使用进行了优化，纹理内存还为一些特定的数据格式提供不同的访存模式以及数据过滤。这三片内存在同一个程序的核函数启动期间是持久的。 CUDA的内存管理与标准C语言的内存管理非常类似。 标准C函数 CUDA C函数 功能 malloc cudaMalloc 内存分配 memcpy cudaMemcpy 内存般移 memset cudaMemset 内存初始化 free cudaFree 内存释放 函数签名的对比如下。 标准C函数 CUDA C函数 extern void *malloc(size_t __size) __host__ __device__ cudaError_t cudaMalloc(void **devPtr, size_t size) extern void *memcpy(void *__restrict __dest, const void *__restrict __src, size_t __n) __host__ cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind) extern void *memset(void *__s, int __c, size_t __n) __host__ cudaError_t cudaMemset(void *devPtr, int value, size_t count) extern void free(void *__ptr) __host__ __device__ cudaError_t cudaFree(void *devPtr) 上表中cudaMemcpy接口中的最后一个参数cudaMemcpyKind是一个枚举类，有五个成员。 cudaMemcpyHostToHost：主机 -&gt; 主机； cudaMemcpyHostToDevice：主机 -&gt; 设备； cudaMemcpyDeviceToHost：设备 -&gt; 主机； cudaMemcpyDeviceToDevice：设备 -&gt; 设备； cudaMemcpyDefault：默认方式，仅允许在支持统一虚拟寻址的系统中使用。 详细代码见memory_management.cu。 异构编程 CUDA 编程模型假设主机和设备维护自己独立的内存空间，分别称为主机内存（Host Memory）和设备内存（Device Memory），程序通过CUDA运行时来管理设备内存，包括内存申请、释放以及主机和设备之间的数据搬移。 CUDA还提供了统一内存管理，贯通了主机内存和设备内存，使得系统中所有CPU和GPU都能够通过一个单一的、连续的内存视图来管理内存。统一内存使得设备端可以超额订阅内存，且不必再显式地将数据从主机端镜像到设备端，从而简化程序的移植。 异步SIMT编程模型 在CUDA中，线程是运算或内存操作的最低层级抽象。异构编程模型定义了CUDA线程的异步操作，为CUDA线程之间的同步定义了异步屏障（Asynchronous Barrier）行为。该模型还解释并定义了cuda::memcpy_async如何在GPU计算的同时从全局内存中异步搬移数据。 异步操作 异步操作的定义是，由CUDA线程发起，并且看起来像由另一个线程异步执行的操作。在良好的程序中，一个或多个CUDA线程与异步操作同步。发起异步操作的CUDA线程不需要位于同步线程中。这样的异步线程（类似线程）始终与启动异步操作的CUDA线程相关联。 异步操作使用同步对象来同步操作的完成，同步对象可以由用户显式管理（cuda::memcpy_async）或由库隐式管理（cooperative_groups::memcpy_async）。同步对象可以是cuda::barrier或cuda::pipeline，后续会详细介绍。这些同步对象可以在不同的线程域中使用，详见下表。 线程域 描述 cuda::thread_scope::thread_scope_thread 仅在发起异步操作的线程内同步。 cuda::thread_scope::thread_scope_block 在发起异步操作的线程所属的block内同步所有或任意线程。 cuda::thread_scope::thread_scope_device 在发起异步操作的线程所属的GPU设备上同步所有或任意线程。 cuda::thread_scope::thread_scope_system 在发起异步操作的线程所属的整个系统中同步所有或任意线程。 计算能力 设备的计算能力由版本号表示，也称为“SM 版本”。 该版本号标识 GPU 硬件支持的功能，并由应用程序在运行时使用来确定当前 GPU 上可用的硬件功能和指令。计算能力包括主版本号X和次版本号Y，用X.Y表示。 Hopper架构：9 Ampere架构：8 Volta架构：7 Turing架构：7.5 Pascal架构：6 Maxwell架构：5 Kepler架构：3 若想知道自己的GPU对应的计算能力可以在英伟达官网给出的列表中查询GPU Compute Capability。 支持的虚拟架构计算能力见Virtual Architecture Feature List，实际架构计算能力见GPU Feature List。 性能分析 这里对性能分析手段只需有一个初步了解，不讨论过多细节。CUDA性能分析大致有6种方法： CPU计时 事件计时 NVVP（Nidia Visual Profiler） nvprof Nsight Systems（nsys） Nsight Compute（ncu） CPU计时 是最简单粗暴的方式，统计精度不高，不推荐使用。 事件计时 通过CUDA提供的事件API来统计时间，精度比CPU计时高，但只能统计到某代码段的运行时间，没有其他性能信息。 NVVP和nvprof NVVP是带有图形界面的性能分析工具，nvprof是针对命令行的。这两个工具是有局限性的，当文件较大的时候，性能分析的速度会很慢。 这两个工具是上一代的CUDA性能分析工具，工具定位也不是很清楚。对于计算能力7.5及以上的设备已经不支持使用nvprof来进行性能分析了。 Nsight Systems和Nsight Compute 这两个是新一代的CUDA性能分析工具，Nsight Systems是系统层面的分析工具，不仅会分析GPU的使用情况，还会给出CPU使用情况，以及CPU和GPU之间的交互情况。而Nsight Compute则用于分析核函数。 Nvidia官方推荐的使用顺序是： 先使用Nsight Systems从系统层面进行分析，优化不必要的同步和数据传输等操作。 如果是计算程序，则使用Nsight Compute进行分析来优化核函数性能； 如果是图形程序，则使用Nsight Graphics进行分析，由于重点在于计算算子的开发，所以不对这一工具作过多介绍。 优化过核函数后，再使用Nsight Systems重新进行系统层面的分析，继续优化。 重复以上过程，直到达到一个比较满意的性能。 组织并行线程 在此之前，我们已经了解了CUDA的基本编程模型，接下来用一系列实例来加深理解。 二维grid二维block 使用二维grid和二维block可以最好的理解矩阵加法映射到CUDA线程的过程，如果将grid中的每个block平铺开，再将每个block中的线程也平铺开，那么正好每个线程就对应矩阵的一个元素。 这种情况下，可以先分别定位线程在x维度和y维度上的索引： x维度索引ix = blockDim.x * blockIdx.x + threadIdx.x； y维度索引iy = blockDim.y * blockIdx.y + threadIdx.y； 然后再得到全局索引idx = iy * nx + ix，当然这个的前提是矩阵为行优先存储。 详细代码见example_sum_matrix_2D-grid_2D-block.cu。 一维grid一维block 使用一维grid一维block就意味着每个线程必须处理矩阵的一列数据，如图所示。 此时，x维度上的线程索引仍然为ix = blockDim.x * blockIdx.x + threadIdx.x。但y维度的线程只有1个，所以需要在线程内部遍历该线程待处理列向量中的每一个元素。元素在线程内部的索引为idx = iy * nx + ix，其中iy的范围是[0, ny)。 详细代码见example_sum_matrix_1D-grid_1D-block.cu。 二维grid一维block 这种情况下，每个线程都只处理矩阵的一个元素，可以看作是二维grid二维block的一种特殊情况，其中block的y维度为1，映射关系如图所示。 还是从x和y两个维度来分别索引线程： x维度索引ix = blockDim.x * blockIdx.x + threadIdx.x； y维度索引iy = blockIdx.y； 然后得到线程的全局索引为idx = iy * nx + ix。 详细代码见example_sum_matrix_2D-grid_1D-block.cu。 设备管理 运行时API查询GPU信息 可以通过运行时APIcudaGetDeviceProperties()来获取关于GPU的所有信息，通过给该API传入一个cudaDeviceProp和设备id来获取带有设备信息的结构体。结构体的成员详见cudaDeviceProp。 常用的一些属性请参考device_management.cu，代码中还给出了在多GPU系统中确定最优GPU的方法。 使用nvidia-smi查询GPU信息 nvidia-smi 选项-L可以列出系统中安装了多少个GPU，以及每个GPU的设备ID。 12$ nvidia-smi -LGPU 0: NVIDIA GeForce RTX 4070 (UUID: GPU-2792043a-40d8-faf2-cf4e-e94d68836d2f) 选项-q -i ${DeviceID}可以获取指定设备的详细信息。 1$ nvidia-smi -q -i 0 可以通过下列参数精简显示的信息： MEMORY UTILIZATION ECC TEMPERATURE POWER CLOCK COMPUTE PIDS PERFORMANCE SUPPORTED_CLOCKS PAGE_RETIREMENT ACCOUNTING 1$ nvidia-smi -q -i 0 -d MEMORY 1$ nvidia-smi -q -i 0 -d UTILIZATION 通过环境变量设置设备 可以通过环境变量CUDA_VISIBLE_DEVICES来指定设备。 若CUDA_VISIBLE_DEVICES = 2，则设备2将在CUDA程序中以设备0的身份出现； 若CUDA_VISIBLE_DEVICES = 2,3，则设备2，3将在CUDA程序中以设备0，1的身份出现。","link":"/posts/57516/"},{"title":"JVM垃圾回收详解","text":"对JVM垃圾回收算法及垃圾回收器的宏观讲解，先了解宏观，再去纠结细节。 垃圾定位方式 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 Root Searching：根可达算法 以被称为GC Roots的对象作为起点向下搜索，这些节点所走过的路径成为引用链，当一个对象到GC Roots没有任何引用链相连，则证明此对象是不可用的，需要被回收。 垃圾回收算法 Mark-Sweep（标记清除） 该算法分为“标记”和“清除”两个阶段： 标记处所有不需要回收的对象； 标记完成后统一回收没有被标记的对象。 缺点： 效率问题 碎片问题 Copying（拷贝） 该算法将内存分为大小相同的两块，每次使用其中一块。当这块内存占满后，将依旧存活的对象复制到另一块内存区域，再将这一块区域全部清理掉。 缺点： 空间利用率问题 复制消耗资源 Mark-Compact（标记压缩） 该算法分为“标记”和“压缩”两个阶段： 标记处所有不需要回收的对象； 标记完成后让存活的对象向一端移动，并清理掉端边界以外的内存区域。 缺点： 效率问题 移动消耗资源 堆内存逻辑分区 将堆内存区域分为三个区域，对对象进行分代管理： Eden（伊甸）：对象刚诞生时放入伊甸区，发生YGC时Eden中的存活对象会被复制到Survivor区中； Survivor（幸存者）：幸存者区分为大小相等的两块内存，当其中一个Survivor区中有存活对象，此时若发生YGC，则会将Eden与该Survivor区中所有存活对象放入另一块Survivor区中； Tenured（终身）： Eden与Survivor属于年轻代，Tenured属于老年代： 年轻代与老年代默认比例为1:2，该比例可以通过参数指定； Eden与两个Survivor区的默认比例为8:1:1，该比例同样可以通过参数指定。 发生在年轻代的GC叫YGC，发生在老年代的GC叫OGC，年轻代与老年代全发生的GC叫FGC。 由于YGC发生非常频繁，故年轻代使用效率较高的Copying算法，YGC一般能回收掉90%的对象； 老年代使用Mark-Compact算法 垃圾回收器 GC的演化 随着内存大小的不断增长而演进： 几兆~几十兆：Serial 单线程STW（Stop The World）垃圾回收器，分为年轻代、老年代； 几十兆~上百兆甚至1G：Parallel 并行多线程垃圾回收器 几十G：Concurrent GC 垃圾回收器种类 迄今为止，垃圾回收器共有十种 基于分代管理，产生了6种垃圾回收器： 垃圾回收器需要组合使用，一个负责年轻代，一个负责老年代 Serial与Serial Old Serial ：是最基本、历史最悠久的垃圾回收器，是单线程回收器； Serial Old ：Serial的老年代版本； 对于这组回收器，当垃圾回收线程工作时，所有业务线程必须暂停一切工作，这种现象成为Stop The World——STW。这种现象是不可避免的，随着内存的增长，STW的时间会越来越长。 ParNew与CMS ParNew ：就是Serial的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样； CMS ：即Concurrent Mark Sweep，以获取最短回收停顿时间为目标的收集器，它非常符合在注重用户体验的应用上使用；CMS是HotSpot虚拟机第一款真正意义上的并发回收器，它第一次实现了让垃圾回收线程与业务线程基本上同时工作。 Parallel Scavenge与Parallel Old（PS+PO，是JDK 1.8默认的） Parallel Scavenge ：也是使用Copying算法的多线程垃圾回收器，它的关注点是吞吐量；当手动优化存在困难的时候，可以使用该回收器配合自适应调节策略，将内存管理优化交给虚拟机完成； Parallel Old ：Parallel Scavenge的老年代版本； 物理上不分代 G1 ：JDK 1.9以后默认，G1采用物理上分区（Region），逻辑上分代的概念； 所有的区域都可以动态的指定所属代 ZGC ：完全部分代，纯分区模式； Shenandoah ： Epsilon ： 并发垃圾回收需要解决的问题 垃圾回收器通过根可达算法标记对象的过程中，各个对象的引用链随时都会发生变化，垃圾回收线程工作时标记好的对象，可能在它的时间片用完后状态发生变化，如果不解决这个问题，那么并发将毫无意义。 三色标记算法 三色标记法利用三种颜色对所有对象进行标记，标记规则如图所示： 但这种标记存在两种情况，会使得所标记的颜色与对象的实际状态不符合，这种现象会发生在垃圾回收线程暂停，业务线程运行的过程中。 情况一： 在业务线程运行过程中，B-&gt;C消失了，则垃圾回收线程回来继续工作的时候，会发现C找不到了。 此时的C成为浮动垃圾，虽然本次GC无法将其回收，但当GC再次发生时，C会由于根不可达而被标记为垃圾。 ​ 由于浮动垃圾的存在，使用CMS时不建议在整个老年代空间占满后再进行GC，应当在老年代空间被占到一定比例后就进行GC，该比例可以通过参数调整。 ​ 并且该比例不建议很大，因为业务线程运行时可能会产生大量的老年代对象，剩余的空间会被迅速占满。而当老年代的空间被占满后，CMS会发生STW，然后对老年代进行单线程的清理。 情况二： 在业务线程运行过程中，B-&gt;C消失了，但增加了A-&gt;C，但此时A已经被标记为黑色，垃圾线程回来后不会再从A开始标记，而通过B已经找不到C了，在垃圾回收线程的视角C是根不可达的，所以C会被垃圾回收线程视作垃圾。 这种情况是真正根源的问题，必须解决该问题，并行垃圾回收才有意义。 CMS的解决方案：Incremental Update 任何黑色对象指向白色对象时，通过写屏障将该黑色的对象标记为灰色，则当垃圾回收线程继续工作时，会重新标记产生变化的引用链。 写屏障：它主要实现让当前线程写入高速缓存中的最新数据更新写入到内存，让其他线程也可见。 但该方案有一个严重且隐蔽的问题： 假设有两个垃圾回收线程m1、m2，一个业务线程t1。开始时m1将A及其的孩子1标记，则此时在m1视角中A是灰色的； 此时发生了情况二，即B-&gt;C消失了，但增加了A-&gt;C，则通过写屏障将A标记为灰色（A此时本来就是灰色）； 然后m1回来继续工作，此时m1的视角下，A是灰色，但它只直到A的孩子2还没有标记，故m1将孩子2标记，此时对于m1来说，A的所有孩子已经标记完成，故会将A标记为黑色，此时出现了漏标C的情况。 为了解决这个问题，CMS在最后有一个阶段叫做remark，在remark阶段会将引用链从头扫描一次，这个阶段必须STW，虽然这个阶段的STW没有原来想象中的那么长，但在业务逻辑非常复杂的情况下，STW的时间可能非常长。 G1的解决方案：SATB（Snapshot At the Beginning） 当灰色对象指向白色对象的引用消失时，将这个引用的信息推到GC的堆栈，保证白色对象还能被GC扫描到。","link":"/posts/54227/"},{"title":"Java反射机制及注解在框架中的应用","text":"想知道Spring这类框架中的注解为什么能实现那么强大的功能，请看本篇博客，用几乎逐行的注释讲解原理。 反射 利用反射可以动态获取类的信息，并在程序运行期间动态创建对象，许多框架如spring、mybatis等均利用到了这一机制。 在编写代码或编译的过程中，可能无法得知要创建哪个对象，只有在运行时才能确定，这种情况下就需要利用反射机制，在运行时获取对象的各种信息。 利用一个例子帮助理解： 创建两个实体类； 12345public class Pizaa { // 省略构造方法及Getter和Setter等方法 private Integer id; private String type;} 12345public class Hamburger { // 省略构造方法及Getter和Setter等方法 private Integer id; private String type;} 创建一个配置文件，模拟spring等框架的配置文件，此处以properties配置文件为例； 12# 指定要在运行时创建的类bean=reflection.Pizaa 创建一个测试类； 1234567891011121314151617181920212223242526public class Test { private static Properties properties; static { try { properties = new Properties(); // 获取类加载器，调用getResourceAsStream方法将配置文件作为流读入 properties.load(Test.class.getClassLoader().getResourceAsStream(&quot;bean.properties&quot;)); } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) throws Exception{ // 获取配置文件中的参数 String bean = properties.getProperty(&quot;bean&quot;); // 获取参数指定的类 Class clazz = Class.forName(bean); // 获取该类的无参构造器 Constructor constructor = clazz.getConstructor(null); // 利用构造器新建实例，此时已经获取到了配置文件中指定类型的实例 Object target = constructor.newInstance(null); System.out.println(target); }} 此时运行结果为： 1Pizaa{id=null, type='null'} 如果将配置文件改为 1bean=reflection.Hamburger 则运行结果为 1Hamburger{id=null, type='null'} 利用这一机制可以实现一定程度上的解耦，无需用在编码时就指定要创建的实例类型，只需在配置文件中指定即可，使得类型的修改变得容易。 注解 注解需要结合反射来实现，注解本身只起到标记的作用，不进行实际的操作，实际操作由反射进行。 创建两个自定义注解，这里模拟Spring框架中的@Component注解和@Value注解； 注意：此处自定义注解的名称和Spring框架中相同，是因为笔者并未引入Spring相关的依赖，故不会产生冲突。 1234567// 如下两个注解用来描述该注解// 指定该注解生效的时机，此处为运行时生效@Retention(RetentionPolicy.RUNTIME)// 指定标记的目标，此处表示该注解用来标记一个Java类型@Target(ElementType.TYPE)public @interface Component {} 12345678@Retention(RetentionPolicy.RUNTIME)// 此处表示该注解用来标记一个属性// 可以通过这种格式指定多个目标：@Target({ElementType.TYPE,ElementType.FIELD})@Target(ElementType.FIELD)public @interface Value { // 利用一个方法来接收参数 String value();} 然后在实体类上打注解； 1234567@Componentpublic class Pizaa { @Value(&quot;1&quot;) private Integer id; @Value(&quot;bacon&quot;) private String type;} 创捷另一个测试类； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Test2 { private static Properties properties; static { try { properties = new Properties(); // 获取类加载器，调用getResourceAsStream方法将配置文件作为流读入 properties.load(Test.class.getClassLoader().getResourceAsStream(&quot;bean.properties&quot;)); } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) throws Exception { // 获取到目标类 String bean = properties.getProperty(&quot;bean&quot;); Class clazz = Class.forName(bean); // 获取目标类的Component注解 Annotation componentAnno = clazz.getAnnotation(Component.class); // 若该注解不为空则说明该类添加了该注解 if (componentAnno != null) { // 该类添加了Component注解 // 该注解的作用是创建对象，故获取该类的构造器 Constructor constructor = clazz.getConstructor(null); // 利用构造器创建实例 Object target = constructor.newInstance(null); // 处理Value注解 // 获取该类所有的属性，但不包括继承得来的属性，仅有该类自身的属性 Field[] declaredFields = clazz.getDeclaredFields(); for (Field declaredField : declaredFields) { Value valueAnnoOnId = declaredField.getAnnotation(Value.class); if (valueAnnoOnId != null) { // 该属性添加了Value注解 // 通过调用注解中定义的方法即可取得参数 String value = valueAnnoOnId.value(); // 暴力反射机制，设置为ture，则可以强行给private修饰的属性赋值 declaredField.setAccessible(true); // 处理属性的类型问题 switch (declaredField.getType().getName()) { // 可以添加多个case以处理不同类型 case &quot;java.lang.Integer&quot;: Integer val = Integer.parseInt(value); // 通过set方法将value的值赋给target对象的该属性 declaredField.set(target, val); break; default: declaredField.set(target, value); break; } } } System.out.println(target); } else { // 该类未添加Component注解 System.out.println(&quot;无法创建&quot; + clazz.getName() + &quot;对象&quot;); } }} 此时运行结果为： 1Pizaa{id=1, type='bacon'} 若将实体类上的注解注释掉； 1234567// @Componentpublic class Pizaa { @Value(&quot;1&quot;) private Integer id; @Value(&quot;bacon&quot;) private String type;} 则运行结果为： 1无法创建reflection.Pizaa对象 通过上述例子可以看到，注解并不进行任何实际的操作，仅仅作为标记作用，而实际的操作需要通过反射机制，在运行时获取目标类后进行判断，若不为空则说明添加了该注解，而后进行一系列的业务处理。","link":"/posts/46441/"},{"title":"PoseFormer论文阅读笔记-ICCV2021","text":"论文题目为：3D Human Pose Estimation with Spatial and Temporal Transformers。本文提出的模型PoseFormer是第一个用于3D人体姿态估计问题的纯Transformer模型。 大纲 引言 3D人体姿态估计的工作通常可分为两类：直接估计方法和2D-to-3D提升方法。直接估计方法从2D图像或视频帧直接推断3D人体姿态。2D-to-3D提升方法从中间估计的2D姿态推断出3D人体姿态。得益于最先进的2D姿态检测器的卓越性能，2D-to-3D提升方法通常优于直接估计方法。 然而，这些2D姿态到3D的映射是非常重要的；由于深度歧义和遮挡，可以从相同的2D姿态生成各种潜在的3D姿态。为了缓解其中的一些问题并保持自然连贯性，最近的许多工作中利用了视频中的时间信息。 由于Transformer的自注意机制，可以清楚地捕获长序列之间的全局相关性。这使得它成为一种特别适合序列数据问题的架构，因此自然可以扩展到3D人体姿态估计。凭借其全面的连接性和表达，Transformer可以跨帧学习到更强的时间表示。 研究表明，Transformer需要特定的设计，才能在视觉任务中实现与CNN相当的性能。它们通常需要超大规模的训练数据集，如果应用于较小的数据集，则需要增强的数据扩充和正则化。此外，现有的视觉Transformer主要局限于图像分类、对象检测和分割，但如何利用Transformer进行3D人体姿态估计仍不清楚。 作者首先将Transformer直接应用于2D-to-3D提升的人体姿态估计。在这种情况下，将给定序列中每个帧的整个2D姿态作为token（如图1a）。虽然这种基线方法在一定程度上是可行的，但它忽略了空间关系（关节到关节）的自然区别，留下了潜在的改进。该基线的一个自然扩展是将每个2D关节坐标视为token，并从序列的所有帧中提供由这些关节形成的输入（如图1b）。然而，在这种情况下，当使用长的帧序列时，token的数量会越来越大（在3D HPE中，可多达243个帧，每帧17个关节，token数量将为243×17=4131）。由于Transformer是计算每个token对另一个token的直接关注，因此模型的内存需求接近不合理的水平。 图1. 时间Transformer基线及其扩展 基于上述问题，作者提出了PoseFormer，这是首个用于视频中2D-to-3D提升HPE的纯Transformer网络。PoseFormer使用两个Transformer模块直接对空间和时间两个维度进行建模。PoseFormer不仅在时空交叉上产生了强大的表示，而且不会对较长的输入序列产生巨量的token。在更高的层次上，PoseFormer只需从现成的2D姿态估计器中获取一系列检测到的2D姿态，并输出中心帧的3D姿态。 具体地说，作者构建了一个空间Transformer模块来编码每个帧中2D关节之间的局部关系。空间自关注层考虑2D关节的位置信息，并返回该帧的潜在特征表示。而时间Transformer模块分析每个空间特征表示之间的全局相关性，并生成准确的3D姿态估计。 本文的贡献有三个方面： 提出了第一个基于Transformer用于2D-to-3D提升3D HPE的模型PoseFormer； 设计了一个有效的时空Transformer模型，其中空间Transformer模块编码人体关节之间的局部关系，而时间Transformer模块捕获整个序列中帧之间的全局相关性； PoseFormer在Human3.6M和MPI-INF-3DHP数据集上都取得了当时最好的结果。 相关工作 2D-to-3D提升HPE 2D-to-3D提升方法利用从输入图像或视频帧估计的2D姿态。OpenPose、CPN、AlphaPose和HRNet已被广泛用作2D姿态检测器。基于该中间表示，可以使用多种方法生成3D姿态。 Martinez等人提出了一种简单有效的全连接残差网络，以基于仅来自单个帧的2D关节位置来回归3D关节位置。然而，相较于从单目图像中估计3D人体姿态，视频可以提供时间信息以提高准确性和鲁棒性。Hossain和Little提出了一种使用长短期记忆（LSTM）单元来利用输入序列中的时间信息的循环神经网络。此外还有几项工作利用时空关系和约束（如骨骼长度和左右对称性）来提高性能。Pavlo等人引入了时间卷积网络，以从连续2D序列中估计2D关键点上的3D姿态。而Chen等人添加了骨骼方向模块和骨骼长度模块，以确保视频帧之间的时间一致性。Liu等人利用注意力机制来识别重要帧。 然而，先前最先进的方法依赖于扩展的时间卷积来捕获全局依赖性，这在时间连接性方面固有地受到限制。此外，大多数工作使用简单的操作将关节坐标投影到潜在空间，而不考虑人体关节的运动学相关性。 3D HPE中的图神经网络 自然地，人体姿态可以表示为一个图形，其中关节是结点，骨骼是边。图形神经网络（GNN）也已应用于2D-to-3D姿态提升问题，并提供了较好的性能。 Ci等人提出了一个名为本地连接网络（Locally Connected Networks, LCN）的框架，该框架利用全连接网络和GNN操作来编码本地相邻关节之间的关系。Zhao等人解决了图卷积网络（GCN）操作的局限性，特别是如何在结点之间共享权重矩阵，引入语义图卷积运算来学习边的通道权重。 对于本文的PoseFormer，Transformer可以被视为一种具有独特的且通常是有利的图形操作的图形神经网络。具体而言，Transformer的编码器模块基本上形成了一个全连通图，其中使用基于输入条件的、多头自注意力机制来计算边的权重。该操作还包括结点特征的归一化，跨注意力头输出的前馈聚合器，以及使其能够与堆叠层有效缩放的残差连接。与其他图形操作相比，这种操作可能是有利的。 视觉Transformer Carion等人提出了一种用于目标检测和全景分割的Detection Transformer（DETR）。Dosovitskiy等人提出了一种纯Transformer架构，即视觉Transformer（Vision Transformer, ViT），它在图像分类方面达到了最先进的性能。然而，ViT是在需要大量计算资源的大规模数据集ImageNet-21k和JFT300M上训练的。然后，提出了一种数据高效的图像Transformer（Data-efficient image Transformer, DeiT），它基于知识蒸馏后的ViT。对于HPE等回归问题，Yang等人提出了一种Transformer网络Transpose，它仅从图像中估计2D姿态。Lin等人在其方法METRO（Mesh Transformer）中将神经网络与Transformer网络相结合，从单个图像重建3D姿态和网格顶点。与我们的方法不同，METRO属于直接估算的范畴。此外，METRO中忽略了时间一致性，这限制了其鲁棒性。我们的时空Transformer架构利用每个帧中的关键点相关性，并保持视频中的自然时间一致性。 本文方法 每个帧的2D姿态由现成的2D姿态检测器获得，然后连续帧的2D姿态序列被用作估计中心帧的3D姿态的输入。与以前基于神经网络的最先进模型相比，本文生产了一个极具竞争力的无卷积Transformer网络。 时间Transformer基线 作为Transformer在2D-to-3D提升中的基线应用，作者将每个2D姿态视为输入token，并使用Transformer捕获输入之间的全局相关性，如图2a所示。 图2. 时间和空间Transformer架构 作者将每个输入token称为patch，在术语上类似于ViT。对于输入序列，是输入序列的帧数，是每个2D姿态的关节数，2表示关节坐标在2D空间中。表示每帧的输入向量。Patch Embedding是一个可训练的线性投影层，用来将每个patch嵌入到一个高维的特征中。Transformer网络利用位置嵌入来保留序列的位置信息，该过程用公式表示如下： 通过线性投影矩阵嵌入，再与位置嵌入求和之后，输入序列变为了，其中是嵌入维度。将被送入时间Transformer编码器。 作为Transformer的核心功能，自注意力机制将输入序列的不同位置与嵌入特征关联起来。该Transformer的编码器由多头自注意力块和多层感知机（MLP）块组成。每个块之前都应用了层归一化（Layer Normalization, LN），每个块之后应用了残差连接。 缩放点积注意力 缩放点积注意力（Scaled Dot-Product Attention）可以描述为将查询矩阵，键矩阵和值矩阵映射到输出注意力矩阵的一个映射函数。，其中是序列中向量的数量，是维数。在该注意力操作中使用比例因子进行适当的归一化，以防止较大的导致的点积巨大增长时出现的极其小的梯度。缩放点积注意力的输出可以表示为： 在本文的时间Transformer中，。矩阵由嵌入特征矩阵经过线性变换得到： 多头自注意力层 多头自注意力层（Multi-head Self Attention Layer, MSA）利用多个头部从不同位置的不同表示子空间对信息进行联合建模，每个头部并行的使用缩放点积注意力操作。该MSA层的输出由个头部的输出进行连结操作得出： 回到对时间Transformer编码器的讨论： 对于给定的嵌入特征矩阵，本文的L个时间Transformer编码器层的结构可表示为： 其中，表示层归一化操作（与ViT中的相同），时间Transformer编码器由L个相同的层组成，编码器的输出与输入保持一致。 为了预测中心帧的3D姿态，通过在帧维度上取平均值，将编码器输出收缩为向量。最后，MLP块将输出回归到，即中心帧的3D姿态。 PoseFormer：时空Transformer 可以观察到，时间Transformer基线主要关注序列中帧之间的全局相关性。patch嵌入是一种线性变换，用于将关节坐标投影到隐藏维度。然而简单的线性投影层不能学习注意力信息，因此局部关节坐标之间的运动信息在时间Transformer基线中没有强力的表示。一种可能的解决方案是将每个关节坐标视为一个单独的patch，并将所有帧中的关节作为Transformer的输入（图1b）。 图1. 时间Transformer基线及其扩展 然而patch的数量会迅速增加（），导致模型计算复杂度为。为了有效地学习局部关节相关性，作者分别对空间和时间信息使用了两个独立的Transformer。如图2b所示，PoseFormer由三个模块组成：空间Transformer、时间Transformer和回归头模块。 空间Transformer模块 空间Transformer模块用于从单帧中提取高维特征嵌入。给定具有个关节的2D姿态，将每个关节视作一个patch，并利用通用视觉Transformer流水线在所有patch上执行特征提取。 首先，使用可训练的线性投影将每个关节坐标映射到高维，该过程称为空间patch嵌入。然后将空间patch嵌入与可学习的空间位置嵌入相加，因此第i帧的输入变为，其中为空间嵌入维度。得到的特征的关节序列被送入空间Transformer编码器，该编码器利用自注意力机制来整合所有关节上的信息。对于第帧，具有L层的空间Transformer编码器的输出应为。 时间Transformer模块 由于空间Transformer模块对每个单帧的高维特征进行编码，所以时间Transformer模块的目标是对帧序列中的相关性进行建模。对于第帧，空间Transformer的输出被展平为一个向量。然后将来自个输入帧的向量连结为。在时间Transformer模块之前添加了可学习的时间位置嵌入来保留帧位置信息。时间Transformer编码器使用了与空间Transformer编码器相同的架构，由多头自注意力块和MLP块组成。时间Transformer模块的输出为。 回归头 由于使用了一个帧序列来预测中心帧的3D姿态，时间Transformer模块的输出需要减少到，在帧维度上使用加权平均（习得的权重）运算来实现。最后，由具有层归一化和一个线性层的MLP返回输出，即中心帧的3D姿态。 损失函数 变为使用标准MPJPE损失来最小化预测姿态和真实姿态之间的误差： 其中，和分别为第个关节的真实位置和预测的位置。 实验 数据集和评价指标 Human3.6M 本文在S1，S5，S6，S7，S8上进行训练，在S9，S11上进行测试。 使用MPJPE（协议1）和PMPJPE（协议2）来评估模型。 MPI-INF-3DHP 在训练集中所有的8个演员上进行训练，使用独立的MPI-INF-3DHP测试集上进行测试。 使用MPJPE、阈值为150mm的PCK、曲线下面积（AUC）来评估模型。 实现细节 作者基于Pytorch实现本文的方法。用两个NVIDIA RTX 3090 GPU进行训练和测试。实验过程中选择了3中不同的帧序列长度，即。在训练和测试中采用姿态水平翻转作为数据增强。采用Adam优化器对模型进行了130个epoch的训练，权重衰减为0.1。学习率采用指数衰减策略，初始学习率为2e-4，每个epoch的衰减因子为0.98。批量大小为1024，并采用随即深度的Transformer编码器层，丢弃率为0.1。 随机深度（Stochastic depth） 在训练过程中随机去掉某些层，并不影响算法的收敛性。这种方法可以解决深度网络的训练时间难题，并能够改善模型的精度。 对于2D姿态，本文在Human3.6M上使用级联金字塔网络（CPN）作为检测器，在MPI-INF-3DHP上使用真实2D姿态。 与SOTA对比 Human3.6M 表1. Human3.6M上的定量结果 表1展示了测试集（S9，S11）所有的15个动作上的结果。表中协议1和协议2分别采用MPJPE和PMPJPE作为评价指标。表示方法中输入序列的帧数；表示2D姿态是由CPN检测得到的；表示该方法基于Transformer。红色数字表示最优结果，蓝色表示次优结果。 在协议1和协议2下，PoseFormer分别以大幅度（6.1%和6.4%）优于本文之前提到的的基线，清楚地证明了使用空间Transformer对每个帧中关节之间的相关性进行表达性建模的优点。PoseFormer可以在拍照、坐下、遛狗和抽烟等困难动作上实现更准确的姿态预测。与其他简单动作不同，这些动作中的姿态变化更快，一些长距离帧具有很强的相关性。在这种情况下，全局依赖性起着重要的作用，Transformer的注意力机制尤其有利。 为了研究本文方法的下界，作者直接使用真实2D姿态作为输入，以减轻由带噪声的2D姿态数据引起的误差，结果如表2所示。 表2. 使用真实2D姿态为输入的结果 图3. 单个关节的MPJPE对比 在图3中比较了一些单个关节的MPJPE，这些关节在Human3.6M测试集S11的拍照动作上具有最大的误差。PoseFormer在这些困难关节上的性能优于其他两个模型。 MPI-INF-3DHP 表3展示了在MPI-INF-3DHP数据集上的定量结果。由于该数据集的序列长度通常较短，故本文使用9帧的2D姿态作为模型输入。 表3. MPI-INF-3DHP上的定量结果 定性结果 图4展示了Human3.6M的测试集S11中的拍照动作，这是最具挑战性的动作之一。 图4. 定性结果 消融实验 消融实验基于Human3.6M的协议1。 PoseFormer的设计 本文研究了空间Transformer以及空间和时间Transformer中位置嵌入的影响。 以9帧CPN检测到的2D姿态（）作为输入来预测3D姿态。所有架构参数都是固定的，以便公平地比较每个模块的影响。空间Transformer的嵌入维度为，空间Transformer编码器层数为4；时间Transformer的嵌入维度与空间Transformer一致（544），使用了4个时间Transformer层。 表4展示了与本文提到的基线模型的比较，即时空设计的影响。 表4. 消融实验 表4结果表明，本文的时空Transformer产生了显著的影响，因为对关节之间的相关性进行了强有力的建模。当时与表1的结果一致。 此外还评估位置嵌入的影响。本文探讨了四种可能的组合：无位置嵌入、仅空间位置嵌入、仅时间位置嵌入、空间和时间位置嵌入。比较这些组合的结果，很明显，位置嵌入提高了性能。通过将这些应用于空间和时间模块，可以获得最佳的总体结果。 架构参数分析 本文探索了各种参数组合，以寻求表5中的最佳网络架构。 表5. 架构参数分析 表示空间Transformer中的嵌入特征维度，表示Transformer编码器中使用了多少层。在PoseFormer中，空间Transformer的输出被平坦化，并与时间位置嵌入相加，以形成时间Transformer编码器的输入。因此，时间Transformer编码器中的嵌入特征维数为。本文模型的最佳参数为＝＝＝。 计算复杂度分析 表6中展示了模型性能、参数总数、每帧的估计浮点运算（FLOPs）以及具有不同输入序列长度（）的每秒输出帧数（FPS）。 表6. 计算复杂度分析 当序列长度增加时，本文的模型获得了更好的精度，并且参数总数不会增加太多。因为帧的数量只影响时间位置嵌入层，而该层不需要很多参数。尽管本文模型的推理速度不是最快的，但该速度对于实时推理来说仍然是可接受的。普通2D姿态检测器的FPS通常低于80，故本模型的推理速度不会成为瓶颈。 注意力可视化 在Human3.6M测试集S11中的坐下动作上可视化了空间和时间Transformer的自注意力热图，如图5、6所示。 图5. 空间Transformer自注意力 对于空间Transformer自注意力，x轴对应17个关节的查询，y轴表示注意力输出。注意力头返回不同的注意力强度，这表示在输入关节之间学习到的各种局部关系。例如Head 3主要集中于关节15和16，即右手肘和右手腕；而Head 5建立了关节4、5、6与11、12、13的关系，即左腿和左臂的连接。 图6. 时间Transformer自注意力 而对于时间Transformer自注意力，x轴对应81帧的查询，y轴表示注意力输出。长期的全局依赖性由不同的注意力头学习。例如Head 3的注意力与中心帧右侧的某些帧高度相关，即帧58、62、69等。 空间和时间注意力热图表明，PoseFormer成功地建模了关节之间的局部关系，并捕获了整个输入序列的长期全局相关性。 针对小数据集的泛化性 作者用本文的模型进行了一项实验，以研究小数据集HumanEva上Transformer的学习能力。表7展示了从头开始训练的结果，以及微调Human3.6M上的预训练模型的结果。 表7. 小数据集泛化性 微调时，性能可以大幅提高，Transformer在大规模数据集上预训练时可以表现良好。","link":"/posts/31545/"},{"title":"MHFormer论文阅读笔记-CVPR2022","text":"文章题目为：MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation。文章提出了一个基于Transformer的多假设模型，不同于之前单纯的一对多映射，MHFormer在自假设之间进行通信以细化估计，并最终生成一个可信的3D姿态。 大纲 引言 从单目视频中进行3D人体姿态估计是一项具有广泛应用的基本视觉任务。该任务通常通过将其划分为两个分离的子任务来解决，即利用2D姿态检测以定位图像上的关键点，然后利用2D-to-3D提升从2D关键点推断3D空间中的关节位置。由于2D表示中的自遮挡和深度歧义，它仍然是一个固有的不适定问题。 不适定问题就是不满足适定性条件的问题，适定性条件为： 有且只有一个解（存在性、唯一性）； 解连续地依赖于数据，即（稳定性）。 为了缓解这些问题，大多数方法侧重于探索空间和时间关系。要么使用图卷积网络来估计具有人类骨架的时空图表示的3D姿态，要么应用纯基于Transformer的模型来从2D姿态序列中捕获空间和时间信息。然而，从单目视频中2D-to-3D是一个反问题，其中存在多个可行的解决方案（即假设），因为其在给定缺失深度的情况下具有不适定性。这些方法忽略了这个问题，只估计了一个单一的解决方案，这通常会导致不满意的结果，尤其是当目标产生严重自遮挡的情况下，如图1所示。 图1. 多假设概念 最近，针对该反问题提出了两种生成多个假设的方法。这些方法通常依赖于一对多映射，通过向具有共享特征提取器的现有架构中添加多个输出头来实现，但无法建立不同假设特征之间的关系。这是一个重大的缺点，因为这种能力对于提高模型的表现和性能至关重要。鉴于3D HPE是具有歧义的反问题，作者认为，首先进行一对多映射，然后使用各种中间假设进行多对一映射更合理，这种方法可以丰富特征的多样性，并生成更好的最终3D姿态。 图2. 三阶段模型 本文提出了多假设Transformer（MHFormer），模型的关键是使模型从不同的姿态假设中学习时空表示。为此，本文构建了一个三阶段框架，首先生成多个初始表示，然后以独立和相互的方式在多假设之间进行通信，以合成更精确的估计，如图2所示。 接下来，本文提出了两个新的模块来建模时间一致性，并增强时间域中的粗糙表示。在第二阶段，提出了自我假设细化（Self-Hypothesis Refinement, SHR）模块来细化每个假设特征。SHR由两个块组成。第一个模块是多假设自我关注（Multi-Hypothesis Self-Attention, MH-SA），它独立地对单个假设依赖性进行建模，以构建自假设通信，使信息能够在每个假设内传递以增强特征。第二块是一个假设混合多层感知器（Hypothesis-Mixing MLP），它跨假设交换信息。将多个假设合并为单个收敛表示，然后将该表示划分为几个发散假设。 尽管SHR对这些假设进行了细化，但由于SHR中的MH-SA仅传递假设内信息，因此不同假设之间的联系不够强。为了解决这个问题，在最后阶段，交叉假设交互（Cross-Hypothesis Interaction, CHI）模块对多假设特征之间的交互进行建模。它的关键组成部分是多假设交叉关注（Multi-Hypothesis Cross-Attention, MH-CA），它捕获相互的多假设相关性，以建立跨假设通信，从而实现假设之间的信息传递，从而更好地进行交互建模。随后，使用假设混合多层感知机（Hypothesis-Mixing MLP）来聚合多个假设以合成最终预测。 利用所提出的MHFormer，多假设时空特征层次被明确地纳入Transformer模型，其中身体关节的多假设信息能够以端到端的方式被独立和交叉的处理。潜在地增强了表示能力，并且合成的姿态更加准确。 本文的贡献如下： 本文提出了一种新的基于Transformer的用于单目视频3D HPE的方法，称为多假设Transformer（MHFormer）。MHFormer可以以端到端的方式有效地学习多个姿态假设的时空表示。 提出了在多假设特征之间独立和相互的交流，提供强大的自假设和跨假设信息传递，以加强假设之间的关系。 MHFormer在3D HPE的两个具有挑战性的数据集上实现了最先进的性能，超过PoseFormer约3%。 相关工作 3D人体姿态估计 现有的单视图3D姿态估计方法可分为两种主流类型：一阶段方法和两阶段方法。一阶段方法直接从输入图像中推断3D姿态，而不需要中间的2D姿态表示，而两阶段方法首先从预训练的2D姿态检测中获得2D关键点，然后将其送入到2D-to-3D网络中以估计3D姿态。受益于2D人体姿态估计的优异性能，这种2D-to-3D的方法可以使用检测到的2D关键点来高效且准确地回归3D姿态。尽管通过使用全卷积或基于图的架构获取时间相关性有良好的结果，但这些方法在跨帧捕获全局上下文信息方面效率较低。 视觉Transformer 对于基本图像分类任务，ViT提出将标准Transformer架构直接应用于图像patch序列。对于姿势估计任务，PoseFormer应用纯Transformer来捕获人类关节相关性和时间相关性。跨步Transformer（Strided Transformer）引入了一种基于Transformer的架构，该架构具有跨步卷积，以将长2D姿态序列提升为单个3D姿态。 本文的工作受到了它们的启发，同样使用Transformer作为基本架构。但不只是利用具有单一表示的简单架构；相反，多假设和多层次特征层次结构的开创性思想在Transformer中被联系起来，这使得模型不仅具有表现力，而且强大。此外，为有效的多假设学习引入了交叉注意机制。 多假设方法 单视图3D HPE是不适定的，因此只有一个假设的解决方案可能是次优的。一些工作为该反问题生成了不同的假设，并实现了实质性的性能增益。与这些专注于一对多映射的工作不同，本文方法首先学习一对多的映射，然后学习多对一的映射，这允许对与各种假设相对应的不同特征进行有效建模，以提高表示能力。 多假设Transformer MHFormer的概述如图3a所示。给定由现成的2D姿态检测器从视频中估计的连续2D姿态序列，本文的方法旨在通过充分利用多假设特征层次中的空间和时间信息来重建中心帧的3D姿态。 图3. MHFormer架构 为了实现本文提出的三阶段框架，MHFormer基于 三个主要模块：多假设生成（MHG）、自假设细化（SHR）和交叉假设交互（CHI） 两个辅助模块：时间嵌入和回归头。 预备工作 在这项工作中，因为Transformer在长期依赖性建模中表现良好，故作者采用了基于Transformer的架构。首先简要描述Transformer中的基本组件，包括多头自注意力（MSA）和多层感知器（MLP）。 多头自注意力（MSA） 在多头自注意力中，输入被线性映射到查询矩阵、键矩阵和值矩阵，其中是序列长度，是维度，缩放点积注意力由下式计算： MSA将查询、键、值矩阵拆分次，然后并行的执行关注，最后对个注意力头的输出进行连结。 多层感知机（MLP） MLP由两个线性层组成，用于非线性和特征变换。公式描述为： 其中，表示GELU激活函数，和分别为两个线性层的权重，和为偏置项。 多假设生成（MHG） 在空域中，通过设计一个基于Transformer的级联架构来解决该反问题，以在潜在空间的不同深度中生成多个特征。为此，引入多假设生成（MHG）来建模人类关节关系并初始化多假设表示，如图3b所示。假设MHG中有个不同的假设和个层，它以个视频帧和个身体关节的2D姿态序列为输入，并输出多个假设，其中是第个假设。 更具体地说，该模块将每个帧的关节坐标连结为，通过一个可学习的空间位置嵌入来保留关节的空间信息，并将嵌入的特征送入MHG的编码器中。为了鼓励梯度传播，在编码器的原始输入和输出特征之间使用跳跃残差连接（skip residual connection）。该过程可形式化为： 其中，是层归一化，是MHG层的索引，，并且。MHG的输出（例如）是包含不同语义信息的多级特征。因此，这些特征可以被视为不同状态假设的初始表示，这些初始表示需要进一步增强。 时间嵌入 MHG有助于在空间域中生成初始多假设特征，而这些特征的能力不够强。考虑到这一限制，本文使用两个模块来构建跨假设特征的关系，并捕获时域中的时间相关性，即自假设细化（SHR）模块和交叉假设交互（CHI）模块，如图3c和3d所示。 为了利用时间信息，首先将空间域转换为时间域。为此，使用换位操作和线性嵌入将每个帧编码后的假设特征嵌入到高维特征中。其中，是嵌入维度。然后利用一个可学习的时间位置嵌入来保留帧的位置信息。用公式表示为： 自假设细化（SHR） 在时域中，首先构建SHR以细化单个假设特征。每个SHR层由多假设自注意力（MH-SA）块和假设混合MLP块组成。 多假设自注意力（MH-SA） Transformer模型的核心是MSA，通过MSA，任意两个元素都可以相互作用，从而建模长期依赖关系。相反，MH-SA旨在独立地捕获每个假设中的单假设依赖性，以进行自假设沟通。具体而言，不同假设的嵌入特征被送入几个并行的MSA块中，可以表示为： 其中，是SHR层的索引，因此不同假设特征的信息可以以自假设的方式传递，用于特征增强。 假设混合多层感知机（Hypothesis-Mixing MLP） 多个假设在MH-SA中独立处理，但假设之间没有信息交换。为了处理该问题，在MH-SA后添加了一个混合假设MLP。将多个假设的特征连结起来并输入到假设混合MLP中合并（即收敛过程）。然后，将收敛的特征沿通道维度均匀地划分为不重叠的块（即发散过程），以形成精炼的假设表示。用公式描述为： 其中，是连结运算，为假设混合MLP函数，该函数的与Transformer中的MLP的公式化表达一致，即。该过程探索了不同假设通道之间的关系。 交叉假设交互（CHI） 通过CHI对多假设特征之间的相互作用进行建模，CHI包含两个模块：多假设交叉注意力（MH-CA）和假设混合MLP。 多假设交叉注意力（MH-CA） MH-SA缺乏跨假设的联系，限制了其交互建模的能力。为了捕获多假设之间的关系以进行跨假设通信，提出了由多个多头交叉注意力（MCA）元素并行组成的MH-CA。 MCA度量交叉假设特征之间的相关性，具有与MSA相似的结构。MCA的常见配置是在键和值之间使用相同的输入。然而，这种配置将导致需要更多的块（例如，3个假设需要6个MCA块）。而本文采用了一种更有效的策略，通过使用不同的输入（只需要3个MCA块）来减少参数量，如图4右半部分所示。 图4. MSA与MCA对比 多个假设被交替地视为查询、键和值，并被送入MH-CA： 其中，是CHI层的索引，，而和是其他两个相应的假设，表示MCA函数。由于MH-CA，可以以交叉的方式执行消息传递，从而显著提高了模型的建模能力。 假设混合多层感知机（Hypothesis-Mixing MLP） CHI中的HM-MLP与SHR中的具有相同的功能。MH-CA的输出被送入该HM-MLP中： 在最后一个CHI层的HM-MLP中，不进行分离操作，从而最终聚合所有假设的特征以合成单个假设表示。 回归头 在回归头中，在输出上使用线性变换层来执行回归以产生3D姿态序列。最终，从中选择中心帧的3D姿态作为最终预测。 损失函数 整个模型以端到端的方式进行训练，采用均方误差（MSE）损失来最小化估计和真实姿态之间的误差： 其中，和分别表示第帧关节的预测值和真实值。 实验 数据集和评价指标 Human3.6M 与之前工作相同，在五个受试者（S1，S5，S6，S7，S8）上训练单个模型，并在两个受试对象（S9和S11）上进行测试。采用协议1的MPJPE和协议2的P-MPJPE。 MPI-INF-3DHP 在训练集中所有的8个演员上进行训练，使用独立的MPI-INF-3DHP测试集上进行测试。 使用MPJPE、阈值为150mm的PCK、曲线下面积（AUC）来评估模型。 实现细节 本文对MHFormer的实现中，包含个MHG层，个SHR层，以及个CHI层。模型基于Pytorch实现，在RTX 3090上训练。使用Amsgrad优化器以端到端的方式从头训练模型。初始学习率为0.001，每个周期的衰减因子为0.95。使用了水平翻转姿态作为数据增强。使用级联金字塔网络（CPN）对Human3.6M进行2D姿态检测，在MPI-INF-3DHP中使用真实2D姿态。 与SOTA比较 Human3.6M上的结果 表1展示了MHFormer的结果，该模型具有351帧的感受野。 表1. Human3.6M的结果 其中，表中上半部分使用2D姿态检测器的输出作为输入，下半部分使用2D真实姿态作为输入，以探索模型的上界。表示使用了时间信息，粗体表示最优结果，下划线表示次优结果。 图5展示了在一些具有挑战性的姿势上与PoseFormer和基线模型（与ViT相同的架构）的定性比较。 图5. 与PoseFormer对比 此外，表2中展示了与之前采用多假设的方法比较的结果。由于其他方法采用一对多映射，故这些方法都报告了最佳假设的评价指标，而本文的方法通过学习确定映射来得出评价指标，这在现实中更加使用。且本文的假设数更少。 表2. 与其他多假设方法比较 其中，为方法使用的假设数量，粗体表示最优结果，下划线表示次优结果。 MPI-INF-3DHP上的结果 使用9帧的2D姿势序列作为该模型输入，因为与Human3.6M相比，该数据集的样本更少，序列长度更短。表3中的结果表明，本文的方法在所有指标（PCK、AUC和MPJPE）上都达到了最佳性能。它强调了MHFormer在户外场景中提高性能的有效性。 表3. MPI-INF-3DHP的结果 消融实验 消融实验基于Human3.6M数据集的协议1，以MPJPE为评价指标。 感受野的影响 对于基于视频的3D HPE任务，大的感受野对于估计精度至关重要。表4展示了本文的方法在不同输入帧下的结果。 表4. 感受野消融实验 其中，CPN和GT分别表示使用CPN的输出和真实2D姿态作为输入的情况。 接下来的消融实验使用27帧的感受野进行，以平衡计算效率和性能。 MHG中参数的影响 表5上半部分展示了不同数量MHG层的影响。实验表明，在MHG中堆叠更多的层可以稍微提高性能，但参数很少增加，但当层数大于4时，增益消失。 表5的下半部分展示了在MHG中使用不同假设数量的影响。增加假设的数量可以改善结果，但当使用3个假设表示时，性能会饱和。本文的模型与单一假设模型相比有着显著的进步，这表明利用多个姿态假设的不同表示有助于提高模型的性能，从而验证了本文的动机。 表5. MHG参数消融实验 其中，代表假设数量，表示MHG的层数。 SHR和CHI中参数的影响 表6展示了SHR和CHI的不同参数对该模型的性能和计算复杂性的影响。结果表明，将嵌入维数从256扩展到512可以提高性能，但使用大于512的维数不能带来进一步的改进。此外，通过堆叠更多SHR或CHI层而没有更多的增益。因此，该模型的最佳参数为，，。 表6. SHR和CHI参数消融实验 其中，和分别为SHR和CHI的层数，为嵌入维度。 模型组件的影响 表7展示了该模型的各个组件对性能的影响。 表7. 模型组件消融实验 其中，表示在MHG中使用了多个并行的Transformer编码器以利用多级特征。 定性结果 虽然本文的方法不旨在产生多个3D姿态预测，但为了更好地观察，添加了额外的回归层，并对模型进行了微调，以可视化中间假设。几个定性结果如图6所示。可以看出，本文的方法能够生成不同的可信3D姿态解决方案，特别是对于具有深度歧义、自遮挡和2D检测器不确定性的模糊身体部位。此外，通过聚合多假设信息合成的最终3D姿态更加合理和准确。 图6. 定性结果 本文方法的一个局限性是相对较大的计算复杂性。Transformer的卓越性能是以高计算成本为代价的。","link":"/posts/16725/"},{"title":"Pytorch中Tensor的创建","text":"Pytorch中Tensor的各种定义方式。 Tensor的创建 首先引入torch包 1import torch Tensor的一般定义方式 定义一个Tensor并直接初始化 1a = torch.Tensor([[1, 2], [3, 4]]) 参数给出Tensor的每个元素的值，打印效果如下 12tensor([[1., 2.], [3., 4.]]) 类型默认为torch.FloatTensor 定义一个给定形状的Tensor 1a = torch.Tensor(2, 3) 参数为Tensor的形状，为一个2 × 3的Tensor 12tensor([[0., 0., 0.], [0., 0., 0.]]) 定义一个给定尺寸或形状的全为1的Tensor 1a = torch.ones(2, 2) 参数为Tensor的形状 12tensor([[1., 1.], [1., 1.]]) 定义一个给定形状的对角线为1的Tensor 1a = torch.eye(2, 2) 参数为Tensor的形状 12tensor([[1., 0.], [0., 1.]]) 定义一个给定尺寸的全为0的Tensor 1a = torch.zeros(2, 2) 参数为Tensor的形状 12tensor([[0., 0.], [0., 0.]]) 通过已有的Tensor定义一个形状相同的Tensor 定义一个与给定Tensor大小相同的全0/1的Tensor 123template = torch.Tensor(2, 3)a = torch.zeros_like(template)b = torch.ones_like(template) 1234tensor([[0., 0., 0.], [0., 0., 0.]])tensor([[1., 1., 1.], [1., 1., 1.]]) 定义一个元素为0~1之间随机值的Tensor 1a = torch.rand(2, 2) 参数为Tensor的形状 12tensor([[0.1935, 0.1548], [0.9900, 0.6763]]) 其他定义方式 normal()函数 torch.normal()函数返回一个Tensor，Tensor的元素是从单独的正态分布中提取的随机数 12a = torch.normal(mean=0.0, std=torch.rand(5))b = torch.normal(mean=torch.rand(5), std=torch.rand(5)) 参数mean为正态分布的均值，std为标准差；均值与标准差均可以是Tensor 12tensor([ 0.1767, 1.5656, 0.2805, -0.0696, -0.6908])tensor([1.0059, 1.1477, 0.1194, 1.3413, 0.9816]) uniform_()函数 uniform_()函数需要提前定义好一个Tensor，通过Tensor对象去调用该函数；该函数使该Tensor对象在给定范围的均匀分布中采样 1a = torch.Tensor(2, 2).uniform_(-1, 1) 参数分别为from和to，指定均匀分布的范围 12tensor([[ 0.7738, -0.6772], [-0.9346, -0.2675]]) 类似uniform_()函数这样带_后缀的函数成为in-place函数，会直接改变调用它的变量 通过序列定义Tensor arange()函数 12a = torch.arange(0, 11, 1)b = torch.arange(0, 11, 2) 前两个参数构成序列范围的左闭右开区间，第三个参数为步长 12tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])tensor([ 0, 2, 4, 6, 8, 10]) linspace()函数 1a = torch.linspace(2, 10, 3) 前两个参数构成序列范围的左闭右闭区间，第三个参数指定Tensor的元素个数n，将返回一个元素为区间内的n个等间隔数的Tensor 1tensor([ 2., 6., 10.]) randperm()函数 1a = torch.randperm(10) 参数为n，将返回[0,n-1](包括n-1)随机打乱后的数字序列为元素的Tensor 1tensor([0, 4, 3, 1, 8, 7, 5, 6, 9, 2])","link":"/posts/44567/"},{"title":"Pytorch中Tensor的属性及稀疏张量","text":"介绍Pytorch中Tensor的属性以及稀疏张量的概念，还有一个小概念——COO风格矩阵。 Tensor的属性 每个Tensor有三个属性 torch.dtype：表示Tensor的类型 torch.device：表示Tensor对象在创建后所存储在的设备名称 torch.layout：表示Tensor对象的内存布局（稠密或稀疏） 1234# dev = torch.device(&quot;cpu&quot;)dev = torch.device(&quot;cuda&quot;)# 通过参数指定Tensor的类型和设备a = torch.tensor([2, 2], dtype=torch.float32, device=dev) 第一个参数为Tensor的元素值 1tensor([2., 2.], device='cuda:0') 稀疏张量 定义稀疏张量需要三个参数 非零元素的坐标 非零元素的值 Tensor的形状 其中，非零元素的坐标和值需要定义为Tensor 1234# i为非零元素的坐标i = torch.tensor([[0, 1, 2, 3], [0, 1, 2, 3]])# v为非零元素的值v = torch.tensor([1, 2, 3, 4]) 利用sparse_coo_tensor()函数定义稀疏张量 1a = torch.sparse_coo_tensor(i, v, (4, 4)) 最后一个参数为Tensor的形状 1234tensor(indices=tensor([[0, 1, 2, 3], [0, 1, 2, 3]]), values=tensor([1, 2, 3, 4]), size=(4, 4), nnz=4, layout=torch.sparse_coo) 可以转换为稠密张量 1a = a.to_dense() 1234tensor([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]]) 注意非零元素的坐标和值的定义，采用的是COO风格矩阵的表示方法 COO风格矩阵采用三元组表示元素的位置和值，即(row, col, value) sparse_coo_tensor()函数中 indices表示非零元素的位置，该参数定义为了含有两个向量的Tensor，第一个向量表示行，第二个向量表示列 values表示非零元素的值，该参数定义为了含有一个向量的Tensor，向量的值即为非零元素的值 两个参数共同组成了三元组，即COO风格矩阵 当然也可以同时指定Tensor的属性 1a = torch.sparse_coo_tensor(i, v, (4, 4), dtype=torch.float32, device=dev).to_dense() 1234tensor([[1., 0., 0., 0.], [0., 2., 0., 0.], [0., 0., 3., 0.], [0., 0., 0., 4.]], device='cuda:0')","link":"/posts/42093/"},{"title":"Pytorch中Tensor的运算","text":"关于Pytorch中Tensor的一系列基本运算及矩阵运算，同时介绍一下in-place操作和Tensor的广播机制；还提到了一些其他运算，如取整、取余、比较、排序等；最后介绍Tensor数据合法性校验的方法。 Tensor的算术运算 基本运算 四种基本运算都要求参与运算的两个Tensor形状相同 12a = torch.Tensor([[1, 2, 3], [1, 2, 3]])b = torch.Tensor([[3, 2, 1], [3, 2, 1]]) 加法 1234a + btorch.add(a, b)a.add(b)a.add_(b) 最后一种in-place函数的方式同之前提到的uniform_()函数类似，会将a的值改变为做完加法后的结果 减法 1234a - btorch.sub(a, b)a.sub(b)a.sub_(b) 乘法 这里的乘法结果是哈达玛积，即对应元素相乘 1234a * btorch.mul(a, b)a.mul(b)a.mul_(b) 除法 1234a / btorch.div(a, b)a.div(b)a.div_(b) 矩阵运算 矩阵乘法 12a = torch.eye(2, 3)b = torch.eye(3, 2) 12345a @ btorch.matmul(a, b)torch.mm(a, b)a.matmul(b)a.mm(b) 对于高维的Tensor，只要求最后两个维度满足矩阵乘法的维度要求 12a = torch.ones(1, 2, 3, 4)b = torch.ones(1, 2, 4, 3) 1a @ b 幂运算 这里并不是矩阵的幂运算，而是对每个元素进行幂运算 1a = torch.tensor([1, 2]) 1234a ** 3torch.pow(a, 3)a.pow(3)a.pow_(3) 对于指数为e的幂运算，有单独的函数可以实现 1a = torch.tensor([1, 2], dtype=torch.float32) 类型定义为float是因为exp_()函数不支持long类型的Tensor 1234torch.exp(a)torch.exp_(a)a.exp()a.exp_() 对数运算 对每个元素进行对数运算 1a = torch.tensor([10, 2], dtype=torch.float32) log_()、log2_()、log10_()均需要float类型的Tensor 123456789# 以e为底的对数torch.log(a)torch.log_(a)# 以2为底的对数torch.log2(a)torch.log2_(a)# 以10为底的对数torch.log10(a)torch.log10_(a) 开方运算 对每个元素进行开方 1a = torch.tensor([1, 2], dtype=torch.float32) 1234torch.sqrt(a)torch.sqrt_(a)a.sqrt()a.sqrt_() in-place与广播机制 in-place操作 在之前的讨论中已经见过很多in-place函数了，in-place操作——“就地”操作，即不允许使用临时变量，也称原位操作。 即满足x = x + y的操作，如上述的add_()、sub_()等。 广播机制 广播机制：张量参数可以自动扩展为相同的大小 广播机制需要满足两个条件 每个张量至少有一个维度 满足右对齐 判断是否满足右对齐需要从右往左看两个张量的维度 若两个维度的值相等或其中有一个为1，则认为两个张量满足右对齐；若遇到维数不相同的情况，则会在维数较少的张量之前补1。 例如两个维度分别为(2,1,1)的张量a和(3)的张量b： 张量b的维度会被补齐为(1,1,3)； 从右往左看，1和3对应，其中有一个为1，故第三个维度是对齐的；又因为张量b的前两个维度是补齐为1的，必然会对齐，故a和b满足右对齐 1234a = torch.rand(2, 1, 1)b = torch.rand(3)c = a + bprint(c.shape) 1torch.Size([2, 1, 3]) Tensor的其他运算 取整、取余运算 1a = torch.rand(2, 2) * 10 向下取整 12torch.floor(a)torch.floor_(a) 向上取整 12torch.ceil(a)torch.ceil_(a) 四舍五入取整 12torch.round(a)torch.round_(a) 裁剪，只取整数部分 12torch.trunc(a)torch.trunc_(a) 裁剪，只取小数部分 12torch.frac(a)torch.frac_(a) 取余 1a % 2 Tensor的比较运算 123456789101112131415161718# 比较运算a = torch.ones(2, 2)b = torch.eye(2, 2)# 对应位置的元素进行比较，返回一个由布尔类型构成的Tensortorch.eq(a, b)# 比较整个Tensor，若所有对应元素相同则返回Ture，否则返回Falsetorch.equal(a, b)# 以下函数均返回一个由布尔类型构成的Tensor# a &gt; btorch.gt(a, b)# a &gt;= btorch.ge(a, b)# a &lt; btorch.lt(a, b)# a &lt;= btorch.le(a, b)# a != btorch.ne(a, b) Tensor的排序 123a = torch.tensor([[3, 9, 7, 4, 5], [1, 4, 8, 5, 2]])print(torch.sort(a)) 默认状态下是升序排列，且会将每个维度都排序 12345torch.return_types.sort(values=tensor([[3, 4, 5, 7, 9], [1, 2, 4, 5, 8]]),indices=tensor([[0, 3, 4, 2, 1], [0, 4, 1, 3, 2]])) values为排序后的Tensor，indices为排序后的元素在原Tensor中对应的下标 还可以指定descending参数为True实现降序排列 1print(torch.sort(a, descending=True)) 12345torch.return_types.sort(values=tensor([[9, 7, 5, 4, 3], [8, 5, 4, 2, 1]]),indices=tensor([[1, 2, 4, 3, 0], [2, 3, 1, 4, 0]])) 还可以指定参与排序的维度 1print(torch.sort(a, dim=0)) 由于我们定义的例子Tensor是(2,5)的，当dim=0时会在2这个维度上排序 12345torch.return_types.sort(values=tensor([[1, 4, 7, 4, 2], [3, 9, 8, 5, 5]]),indices=tensor([[1, 1, 0, 0, 1], [0, 0, 1, 1, 0]])) 返回最大的k个元素 123a = torch.tensor([[2, 4, 3, 1, 5], [2, 3, 5, 1, 4]])print(torch.topk(a, k=2, dim=1)) 参数k指定返回降序排列的前k个元素，dim指定操作的维度 12345torch.return_types.topk(values=tensor([[5, 4], [5, 4]]),indices=tensor([[4, 1], [2, 4]])) 返回指定维度的升序排列的第k个元素 1print(torch.kthvalue(a, k=2, dim=1)) 123torch.return_types.kthvalue(values=tensor([2, 2]),indices=tensor([0, 0])) Tensor数据的合法性校验 12345678a = torch.rand(2, 3)# 以下函数均返回一个由布尔类型构成的Tensor# 元素为有界的则返回True，否则返回Falseprint(torch.isfinite(a / 0))# 元素为无界的则返回True，否则返回Falseprint(torch.isinf(a / 0))# 元素为非数值则返回True，否则返回Falseprint(torch.isnan(a)) 123456tensor([[False, False, False], [False, False, False]])tensor([[True, True, True], [True, True, True]])tensor([[False, False, False], [False, False, False]]) nan并不能通过pytorch定义出来，这里借助numpy定义一个含有nan元素的Tensor 1234import numpy as npa = torch.tensor([1, 2, np.nan])print(torch.isnan(a)) 1tensor([False, False, True])","link":"/posts/7822/"},{"title":"Pytorch常用数学与统计学函数","text":"Pytorch中常用的数学函数，包括三角函数、绝对值函数、sign()函数、误差函数等；还有一些统计学相关函数，包括histc()函数、bincount()函数等。 Pytorch中的数学函数 三角函数 123456789101112131415161718192021# 余弦torch.cos(input)# 反余弦torch.acos(input)# 双曲余弦torch.cosh(input)# 正弦torch.sin(input)# 反正弦torch.asin(input)# 双曲正弦torch.sinh(input)# 正切torch.tan(input)# 反正切torch.atan(input)# input中元素代表坐标y，other中元素代表坐标x# 返回向量(x,y)与向量(1,0)的夹角torch.atan2(input, other)# 双曲正切torch.tanh(input) 其他数学函数 abs()函数与neg()函数 abs()函数取张量中每个元素的绝对值 1torch.abs(input) neg()函数取张量中每个元素的相反数 1torch.neg(input) sign()函数 1torch.sign(input) 当元素小于0返回-1； 当元素等于0返回0； 当元素大于0返回1； 即： 函数图像如下： sigmoid()函数 1torch.sigmoid(input) 通过sigmoid函数，可以将元素映射到0~1之间 sigmoid函数本质上是连续化的sign函数，可以解决sign函数的结果不连续而导致无法求导的问题。 当元素趋于负无穷时，函数； 当元素趋于正无穷时，函数值无限趋近于1； 即： 函数图像如下： erf()与erfc()函数 1torch.erf(input) 函数是误差函数，是互补误差函数 函数图像如下： 红色曲线为误差函数，蓝色曲线为互补误差函数 erfinv()函数 1torch.erfinv(input) 是逆误差函数 函数图像参考函数的图像，若函数是给定值求得，则函数为给定求得 lerp()函数 1torch.lerp(start, end, weight) lerp()函数对两个张量以start、end做线性插值 addcdiv()函数与addcmul()函数 addcdiv()函数 1torch.addcdiv(input, tensor1, tensor2, value=1) addcdiv()函数将tensor1与tensor2的商乘以value再加上input addcmul()函数 1torch.addcmul(input, tensor1, tensor2, value=1) addcmul()函数将tensor1与tensor2的积乘以value再加上input cumprod()函数与cumsum()函数 cumprod()函数 1torch.cumprod(input, dim=0) cumprod()函数是向量维度上的计算，dim参数指定参与计算的维度 例如：定义一个形状为(2,3)的张量，指定cumprod()在3这个维度上运算 12input = torch.Tensor([[0, 1, 2], [3, 4, 5]])print(torch.cumprod(input, dim=1)) 返回结果为 12tensor([[ 0., 0., 0.], [ 3., 12., 60.]]) cumsum()函数 1torch.cumsum(input, dim=1) 与cumprod()函数类似，cumsum()函数也是向量维度上的计算，dim参数指定参与计算的维度 同上例，指定cumsum()函数在3这个维度上运算 12input = torch.Tensor([[0, 1, 2], [3, 4, 5]])print(torch.cumsum(input, dim=1)) 返回结果为 12tensor([[ 0., 1., 3.], [ 3., 7., 12.]]) reciprocal()函数 1torch.reciprocal(input) reciprocal()函数取张量中每个元素的倒数 sqrt()函数与rsqrt()函数 12torch.sqrt(input)torch.rsqrt(input) sqrt()函数取张量中每个元素的平方根 rsqrt()函数取张量中每个元素的平方根的倒数 Pytorch中的统计学相关函数 此处以求平均值函数mean()为例 123torch.mean(input)torch.mean(input, dim=0)torch.mean(input, dim=0, keepdim=True) 若只传入一个张量，则计算该张量中所有元素的平均值； 若指定维度，则计算出该维度的每个向量中元素的平均值； 若指定了keepdim为Ture，则返回的结果张量保持与输入张量相同的维度； 常用函数 函数名 功能 mean() 返回平均值 sum() 返回元素之和 prod() 返回元素之积 max() 返回最大值 min() 返回最小值 argmax() 返回最大值的索引值 argmin() 返回最小值的索引值 median() 返回中位数 mode() 返回众数 以上函数的参数均与上例mean()函数的参数大同小异 函数名 功能 std() 返回标准差 var() 返回方差 上述两个函数除与mean()函数相同的参数外，还有一个unbiased(bool)参数，指定是否使用贝叶斯矫正 在统计学中，贝塞尔矫正是在样本方差和样本标准差的公式中使用 n - 1 代替 n，其中 n 是样本中的观察数。该方法纠正了总体方差估计中的偏差。它还部分纠正了总体标准偏差估计中的偏差。然而，校正通常会增加这些估计中的均方误差。 histc()函数 计算输入张量的直方图 1torch.histc(input, bins=10, min=0, max=0) 参数bins指定直方图的统计区间个数； min和max分别指定直方图中的最小值和最大值，若这两个参数为0，则选取输入张量中的最小/大值作为直方图的最小/大值； bincount()函数 统计一维非负整型数组中每个值出现的频次，他的bins即区间个数比数组中的最大值大1，空数组除外 123torch.bincount(input)torch.bincount(input, weight)torch.bincount(input, weight, minlength=10) bincount()函数只能处理一维的非负整型数组 参数weight指定数组中每个元素的权重，weight应当是一个与input形状相同的数组，指定weight后返回的结果将是每个元素出现的频次与权重的乘积； 参数minlength指定统计结果的bins的最小长度，即区间个数的最小值，没有出现数的区间将用0补齐； distributions模块 在pytorch中有torch.distributions这样一个模块，里面包含了很多的分布函数，例如伯努利分布、正态分布、均匀分布等，具体参考官方手册。:link:torch.distributions 在随机抽样过程中，可以通过manual_seed(seed)函数来定义随机种子，以正太分布为例： 12345# manual_seed的参数要求是int型torch.manual_seed(1)mean = torch.rand(1, 2)std = torch.rand(1, 2)print(torch.normal(mean, std)) 定义随机种子后，无论执行多少次，随机产生的结果都是一样的","link":"/posts/47260/"},{"title":"Linux入门及常用命令","text":"转载文章，与Linux系统相关的知识。 Linux 基础 操作系统 操作系统 Operating System 简称 OS ，是软件的一部分，它是硬件基础上的第一层软件，是硬件和其它软件沟通的桥梁。 操作系统会控制其他程序运行，管理系统资源，提供最基本的计算功能，如管理及配置内存、决定系统资源供需的优先次序等，同时还提供一些基本的服务程序。 image.png 什么是 Linux Linux 系统内核与 Linux 发行套件的区别 Linux 系统内核指的是由 Linus Torvalds 负责维护，提供硬件抽象层、硬盘及文件系统控制及多任务功能的系统核心程序。 Linux 发行套件系统是我们常说的 Linux 操作系统，也即是由 Linux 内核与各种常用软件的集合产品。 总结：真正的 Linux 指的是系统内核，而我们常说的 Linux 指的是“发行版完整的包含一些基础软件的操作系统”。 Linux 对比 Windows 稳定且有效率； 免费（或少许费用）； 漏洞少且快速修补； 多任务多用户； 更加安全的用户与文件权限策略； 适合小内核程序的嵌入系统； 相对不耗资源。 Linux 系统种类 红帽企业版 Linux ： RHEL 是全世界内使用最广泛的 Linux 系统。它具有极强的性能与稳定性，是众多生成环境中使用的（收费的）系统。 Fedora ：由红帽公司发布的桌面版系统套件，用户可以免费体验到最新的技术或工具，这些技术或工具在成熟后会被加入到 RHEL 系统中，因此 Fedora 也成为 RHEL 系统的试验版本。 CentOS ：通过把 RHEL 系统重新编译并发布给用户免费使用的 Linux 系统，具有广泛的使用人群。 Deepin ：中国发行，对优秀的开源成品进行集成和配置。 Debian ：稳定性、安全性强，提供了免费的基础支持，在国外拥有很高的认可度和使用率。 Ubuntu ：是一款派生自 Debian 的操作系统，对新款硬件具有极强的兼容能力。 Ubuntu 与 Fedora 都是极其出色的 Linux 桌面系统，而且 Ubuntu 也可用于服务器领域。 终端连接阿里云服务器 image 通过执行 ssh root@121.42.11.34 命令，然后输入服务器连接密码就可以顺利登陆远程服务器。从现在开始我们就可以在本地电脑操作远程服务器。 这个黑色的面板就是终端也就是 Shell （命令行环境）。 ssh root@xxx 这是一条命令，必须要在 Shell 中才能执行。 Shell Shell 这个单词的原意是“外壳”，跟 kernel（内核）相对应，比喻内核外面的一层，即用户跟内核交互的对话界面。 Shell 是一个程序，提供一个与用户对话的环境。这个环境只有一个命令提示符，让用户从键盘输入命令，所以又称为命令行环境（ command line interface ，简写为 CLI ）。 Shell 接收到用户输入的命令，将命令送入操作系统执行，并将结果返回给用户。 Shell 是一个命令解释器，解释用户输入的命令。它支持变量、条件判断、循环操作等语法，所以用户可以用 Shell 命令写出各种小程序，又称为 Shell 脚本。这些脚本都通过 Shell 的解释执行，而不通过编译。 Shell 是一个工具箱，提供了各种小工具，供用户方便地使用操作系统的功能。 Shell 的种类 Shell 有很多种，只要能给用户提供命令行环境的程序，都可以看作是 Shell 。 历史上，主要的 Shell 有下面这些： Bourne Shell（sh） Bourne Again shell（bash） C Shell（csh） TENEX C Shell（tcsh） Korn shell（ksh） Z Shell（zsh） Friendly Interactive Shell（fish） 其中 Bash 是目前最常用的 Shell 。 MacOS 中的默认 Shell 就是 Bash 。 通过执行 echo $SHELL 命令可以查看到当前正在使用的 Shell 。还可以通过 cat /etc/shells 查看当前系统安装的所有 Shell 种类。 命令 命令行提示符 进入命令行环境以后，用户会看到 Shell 的提示符。提示符往往是一串前缀，最后以一个美元符号 $ 结尾，用户可以在这个符号后面输入各种命令。 执行一个简单的命令 pwd ： 12[root@iZm5e8dsxce9ufaic7hi3uZ ~]# pwd/root 命令解析： root：表示用户名； iZm5e8dsxce9ufaic7hi3uZ：表示主机名； ~：表示目前所在目录为家目录，其中 root 用户的家目录是 /root 普通用户的家目录在 /home 下； #：指示你所具有的权限（ root 用户为 # ，普通用户为 $ ）。 执行 whoami 命令可以查看当前用户名； 执行 hostname 命令可以查看当前主机名； 关于如何创建、切换、删除用户，在后面的用户与权限会具体讲解，这里先使用 root 用户进行演示。 [备注] root 是超级用户，具备操作系统的一切权限。 命令格式 1command parameters（命令 参数） 长短参数 12345单个参数：ls -a（a 是英文 all 的缩写，表示“全部”）多个参数：ls -al（全部文件 + 列表形式展示）单个长参数：ls --all多个长参数：ls --reverse --all长短混合参数：ls --all -l 参数值 12短参数：command -p 10（例如：ssh root@121.42.11.34 -p 22）长参数：command --paramters=10（例如：ssh root@121.42.11.34 --port=22） 快捷方式 在开始学习 Linux 命令之前，有这么一些快捷方式，是必须要提前掌握的，它将贯穿整个 Linux 使用生涯。 通过上下方向键 ↑ ↓ 来调取过往执行过的 Linux 命令； 命令或参数仅需输入前几位就可以用 Tab 键补全； Ctrl + R ：用于查找使用过的命令（history 命令用于列出之前使用过的所有命令，然后输入 ! 命令加上编号( !2 )就可以直接执行该历史命令）； Ctrl + L：清除屏幕并将当前行移到页面顶部； Ctrl + C：中止当前正在执行的命令； Ctrl + U：从光标位置剪切到行首； Ctrl + K：从光标位置剪切到行尾； Ctrl + W：剪切光标左侧的一个单词； Ctrl + Y：粘贴 Ctrl + U | K | Y 剪切的命令； Ctrl + A：光标跳到命令行的开头； Ctrl + E：光标跳到命令行的结尾； Ctrl + D：关闭 Shell 会话； 文件和目录 文件的组织 image 查看路径 pwd 显示当前目录的路径 image which 查看命令的可执行文件所在路径， Linux 下，每一条命令其实都对应一个可执行程序，在终端中输入命令，按回车的时候，就是执行了对应的那个程序， which 命令本身对应的程序也存在于 Linux 中。 总的来说一个命令就是一个可执行程序。 image 浏览和切换目录 ls 列出文件和目录，它是 Linux 最常用的命令之一。 【常用参数】 -a 显示所有文件和目录包括隐藏的 -l 显示详细列表 -h 适合人类阅读的 -t 按文件最近一次修改时间排序 -i 显示文件的 inode （ inode 是文件内容的标识） image cd cd 是英语 change directory 的缩写，表示切换目录。 123456cd / --&gt; 跳转到根目录cd ~ --&gt; 跳转到家目录cd .. --&gt; 跳转到上级目录cd ./home --&gt; 跳转到当前目录的home目录下cd /home/lion --&gt; 跳转到根目录下的home目录下的lion目录cd --&gt; 不添加任何参数，也是回到家目录 [注意] 输入cd /ho + 单次 tab 键会自动补全路径 + 两次 tab 键会列出所有可能的目录列表。 du 列举目录大小信息。 【常用参数】 -h 适合人类阅读的； -a 同时列举出目录下文件的大小信息； -s 只显示总计大小，不显示具体信息。 浏览和创建文件 cat 一次性显示文件所有内容，更适合查看小的文件。 1cat cloud-init.log 【常用参数】 -n 显示行号。 less 分页显示文件内容，更适合查看大的文件。 1less cloud-init.log 【快捷操作】 空格键：前进一页（一个屏幕）； b 键：后退一页； 回车键：前进一行； y 键：后退一行； 上下键：回退或前进一行； d 键：前进半页； u 键：后退半页； q 键：停止读取文件，中止 less 命令； = 键：显示当前页面的内容是文件中的第几行到第几行以及一些其它关于本页内容的详细信息； h 键：显示帮助文档； / 键：进入搜索模式后，按 n 键跳到一个符合项目，按 N 键跳到上一个符合项目，同时也可以输入正则表达式匹配。 head 显示文件的开头几行（默认是10行） 1head cloud-init.log 【参数】 -n 指定行数 head cloud-init.log -n 2 tail 显示文件的结尾几行（默认是10行） 1tail cloud-init.log 【参数】 -n 指定行数 tail cloud-init.log -n 2 -f 会每过1秒检查下文件是否有更新内容，也可以用 -s 参数指定间隔时间 tail -f -s 4 xxx.log touch 创建一个文件 1touch new_file mkdir 创建一个目录 1mkdir new_folder 【常用参数】 -p 递归的创建目录结构 mkdir -p one/two/three 文件的复制和移动 cp 拷贝文件和目录 1234cp file file_copy --&gt; file 是目标文件，file_copy 是拷贝出来的文件cp file one --&gt; 把 file 文件拷贝到 one 目录下，并且文件名依然为 filecp file one/file_copy --&gt; 把 file 文件拷贝到 one 目录下，文件名为file_copycp *.txt folder --&gt; 把当前目录下所有 txt 文件拷贝到 folder 目录下 【常用参数】 -r 递归的拷贝，常用来拷贝一整个目录 mv 移动（重命名）文件或目录，与cp命令用法相似。 1234mv file one --&gt; 将 file 文件移动到 one 目录下mv new_folder one --&gt; 将 new_folder 文件夹移动到one目录下mv *.txt folder --&gt; 把当前目录下所有 txt 文件移动到 folder 目录下mv file new_file --&gt; file 文件重命名为 new_file 文件的删除和链接 rm 删除文件和目录，由于 Linux 下没有回收站，一旦删除非常难恢复，因此需要谨慎操作 12rm new_file --&gt; 删除 new_file 文件rm f1 f2 f3 --&gt; 同时删除 f1 f2 f3 3个文件 【常用参数】 -i 向用户确认是否删除； -f 文件强制删除； -r 递归删除文件夹，著名的删除操作 rm -rf 。 ln 英文 Link 的缩写，表示创建链接。 学习创建链接之前，首先要理解链接是什么，我们先来看看 Linux 的文件是如何存储的： Linux 文件的存储方式分为3个部分，文件名、文件内容以及权限，其中文件名的列表是存储在硬盘的其它地方和文件内容是分开存放的，每个文件名通过 inode 标识绑定到文件内容。 Linux 下有两种链接类型：硬链接和软链接。 硬链接 使链接的两个文件共享同样文件内容，就是同样的 inode ，一旦文件1和文件2之间有了硬链接，那么修改任何一个文件，修改的都是同一块内容，它的缺点是，只能创建指向文件的硬链接，不能创建指向目录的（其实也可以，但比较复杂）而软链接都可以，因此软链接使用更加广泛。 1ln file1 file2 --&gt; 创建 file2 为 file1 的硬链接 image 如果我们用 rm file1 来删除 file1 ，对 file2 没有什么影响，对于硬链接来说，删除任意一方的文件，共同指向的文件内容并不会从硬盘上删除。只有同时删除了 file1 与 file2 后，它们共同指向的文件内容才会消失。 软链接 软链接就类似 windows 下快捷方式。 1ln -s file1 file2 image 执行 ls -l 命名查看当前目录下文件的具体信息 123total 0-rw-r--r-- 1 root root 0 Jan 14 06:29 file1lrwxrwxrwx 1 root root 5 Jan 14 06:42 file2 -&gt; file1 # 表示file2 指向 file1 其实 file2 只是 file1 的一个快捷方式，它指向的是 file1 ，所以显示的是 file1 的内容，但其实 file2 的 inode 与 file1 并不相同。如果我们删除了 file2 的话， file1 是不会受影响的，但如果删除 file1 的话， file2 就会变成死链接，因为指向的文件不见了。 用户与权限 用户 Linux 是一个多用户的操作系统。在 Linux 中，理论上来说，我们可以创建无数个用户，但是这些用户是被划分到不同的群组里面的，有一个用户，名叫 root ，是一个很特殊的用户，它是超级用户，拥有最高权限。 image 自己创建的用户是有限权限的用户，这样大大提高了 Linux 系统的安全性，有效防止误操作或是病毒攻击，但是我们执行的某些命令需要更高权限时可以使用 sudo 命令。 sudo 以 root 身份运行命令 1sudo date --&gt; 当然查看日期是不需要sudo的这里只是演示，sudo 完之后一般还需要输入用户密码的 useradd + passwd useradd 添加新用户 passwd 修改用户密码 这两个命令需要 root 用户权限 12useradd lion --&gt; 添加一个lion用户，添加完之后在 /home 路径下可以查看passwd lion --&gt; 修改lion用户的密码 userdel 删除用户，需要 root 用户权限 12userdel lion --&gt; 只会删除用户名，不会从/home中删除对应文件夹userdel lion -r --&gt; 会同时删除/home下的对应文件夹 su 切换用户，需要 root 用户权限 123sudo su --&gt; 切换为root用户（exit 命令或 CTRL + D 快捷键都可以使普通用户切换为 root 用户）su lion --&gt; 切换为普通用户su - --&gt; 切换为root用户 群组的管理 Linux 中每个用户都属于一个特定的群组，如果你不设置用户的群组，默认会创建一个和它的用户名一样的群组，并且把用户划归到这个群组。 groupadd 创建群组，用法和 useradd 类似。 1groupadd friends groupdel 删除一个已存在的群组 1groupdel foo --&gt; 删除foo群组 groups 查看用户所在群组 1groups lion --&gt; 查看 lion 用户所在的群组 usermod 用于修改用户的账户。 【常用参数】 -l 对用户重命名。需要注意的是 /home 中的用户家目录的名字不会改变，需要手动修改。 -g 修改用户所在的群组，例如 usermod -g friends lion 修改 lion 用户的群组为 friends 。 -G 一次性让用户添加多个群组，例如 usermod -G friends,foo,bar lion 。 -a -G 会让你离开原先的群组，如果你不想这样做的话，就得再添加 -a 参数，意味着 append 追加的意思。 chgrp 用于修改文件的群组。 1chgrp bar file.txt --&gt; file.txt文件的群组修改为bar chown 改变文件的所有者，需要 root 身份才能运行。 12chown lion file.txt --&gt; 把其它用户创建的file.txt转让给lion用户chown lion:bar file.txt --&gt; 把file.txt的用户改为lion，群组改为bar 【常用参数】 -R 递归设置子目录和子文件， chown -R lion:lion /home/frank 把 frank 文件夹的用户和群组都改为 lion 。 文件权限管理 chmod 修改访问权限。 1chmod 740 file.txt 【常用参数】 -R 可以递归地修改文件访问权限，例如 chmod -R 777 /home/lion 修改权限的确简单，但是理解其深层次的意义才是更加重要的。下面我们来系统的学习 Linux 的文件权限。 1234[root@lion ~]# ls -ldrwxr-xr-x 5 root root 4096 Apr 13 2020 climblrwxrwxrwx 1 root root 7 Jan 14 06:41 hello2.c -&gt; hello.c-rw-r--r-- 1 root root 149 Jan 13 06:14 hello.c 其中 drwxr-xr-x 表示文件或目录的权限。让我们一起来解读它具体代表什么？ d ：表示目录，就是说这是一个目录，普通文件是 - ，链接是 l 。 r ： read 表示文件可读。 w ： write 表示文件可写，一般有写的权限，就有删除的权限。 x ： execute 表示文件可执行。 - ：表示没有相应权限。 权限的整体是按用户来划分的，如下图所示： image 现在再来理解这句权限 drwxr-xr-x 的意思： 它是一个文件夹； 它的所有者具有：读、写、执行权限； 它的群组用户具有：读、执行的权限，没有写的权限； 它的其它用户具有：读、执行的权限，没有写的权限。 现在理解了权限，我们使用 chmod 来尝试修改权限。 chmod 它不需要是 root 用户才能运行的，只要你是此文件所有者，就可以用 chmod 来修改文件的访问权限。 数字分配权限 权限 数字 r 4 w 2 x 1 因此要改变权限，只要做一些简单的加法就行： 12345678chmod 640 hello.c # 分析6 = 4 + 2 + 0 表示所有者具有 rw 权限4 = 4 + 0 + 0 表示群组用户具有 r 权限0 = 0 + 0 + 0 表示其它用户没有权限对应文字权限为：-rw-r----- 用字母来分配权限 u ： user 的缩写，用户的意思，表示所有者。 g ： group 的缩写，群组的意思，表示群组用户。 o ： other 的缩写，其它的意思，表示其它用户。 a ： all 的缩写，所有的意思，表示所有用户。 + ：加号，表示添加权限。 - ：减号，表示去除权限。 = ：等于号，表示分配权限。 1234567chmod u+rx file --&gt; 文件file的所有者增加读和运行的权限chmod g+r file --&gt; 文件file的群组用户增加读的权限chmod o-r file --&gt; 文件file的其它用户移除读的权限chmod g+r o-r file --&gt; 文件file的群组用户增加读的权限，其它用户移除读的权限chmod go-r file --&gt; 文件file的群组和其他用户移除读的权限chmod +x file --&gt; 文件file的所有用户增加运行的权限chmod u=rwx,g=r,o=- file --&gt; 文件file的所有者分配读写和执行的权限，群组其它用户分配读的权限，其他用户没有任何权限 查找文件 locate 搜索包含关键字的所有文件和目录。后接需要查找的文件名，也可以用正则表达式。 安装 locate 12345yum -y install mlocate --&gt; 安装包updatedb --&gt; 更新数据库复制代码locate file.txtlocate fil*.txt [注意] locate 命令会去文件数据库中查找命令，而不是全磁盘查找，因此刚创建的文件并不会更新到数据库中，所以无法被查找到，可以执行 updatedb 命令去更新数据库。 find 用于查找文件，它会去遍历你的实际硬盘进行查找，而且它允许我们对每个找到的文件进行后续操作，功能非常强大。 1find &lt;何处&gt; &lt;何物&gt; &lt;做什么&gt; 何处：指定在哪个目录查找，此目录的所有子目录也会被查找。 何物：查找什么，可以根据文件的名字来查找，也可以根据其大小来查找，还可以根据其最近访问时间来查找。 做什么：找到文件后，可以进行后续处理，如果不指定这个参数， find 命令只会显示找到的文件。 根据文件名查找 123456find -name &quot;file.txt&quot; --&gt; 当前目录以及子目录下通过名称查找文件find . -name &quot;syslog&quot; --&gt; 当前目录以及子目录下通过名称查找文件find / -name &quot;syslog&quot; --&gt; 整个硬盘下查找syslogfind /var/log -name &quot;syslog&quot; --&gt; 在指定的目录/var/log下查找syslog文件find /var/log -name &quot;syslog*&quot; --&gt; 查找syslog1、syslog2 ... 等文件，通配符表示所有find /var/log -name &quot;*syslog*&quot; --&gt; 查找包含syslog的文件 [注意] find 命令只会查找完全符合 “何物” 字符串的文件，而 locate 会查找所有包含关键字的文件。 根据文件大小查找 1234find /var -size +10M --&gt; /var 目录下查找文件大小超过 10M 的文件find /var -size -50k --&gt; /var 目录下查找文件大小小于 50k 的文件find /var -size +1G --&gt; /var 目录下查找文件大小查过 1G 的文件find /var -size 1M --&gt; /var 目录下查找文件大小等于 1M 的文件 根据文件最近访问时间查找 1find -name &quot;*.txt&quot; -atime -7 --&gt; 近 7天内访问过的.txt结尾的文件 仅查找目录或文件 12find . -name &quot;file&quot; -type f --&gt; 只查找当前目录下的file文件find . -name &quot;file&quot; -type d --&gt; 只查找当前目录下的file目录 操作查找结果 1234find -name &quot;*.txt&quot; -printf &quot;%p - %u\\n&quot; --&gt; 找出所有后缀为txt的文件，并按照 %p - %u\\n 格式打印，其中%p=文件名，%u=文件所有者find -name &quot;*.jpg&quot; -delete --&gt; 删除当前目录以及子目录下所有.jpg为后缀的文件，不会有删除提示，因此要慎用find -name &quot;*.c&quot; -exec chmod 600 {} \\; --&gt; 对每个.c结尾的文件，都进行 -exec 参数指定的操作，{} 会被查找到的文件替代，\\; 是必须的结尾find -name &quot;*.c&quot; -ok chmod 600 {} \\; --&gt; 和上面的功能一直，会多一个确认提示 软件仓库 Linux 下软件是以包的形式存在，一个软件包其实就是软件的所有文件的压缩包，是二进制的形式，包含了安装软件的所有指令。 Red Hat 家族的软件包后缀名一般为 .rpm ， Debian 家族的软件包后缀是 .deb 。 Linux 的包都存在一个仓库，叫做软件仓库，它可以使用 yum 来管理软件包， yum 是 CentOS 中默认的包管理工具，适用于 Red Hat 一族。可以理解成 Node.js 的 npm 。 yum 常用命令 yum update | yum upgrade 更新软件包 yum search xxx 搜索相应的软件包 yum install xxx 安装软件包 yum remove xxx 删除软件包 切换 CentOS 软件源 有时候 CentOS 默认的 yum 源不一定是国内镜像，导致 yum 在线安装及更新速度不是很理想。这时候需要将 yum 源设置为国内镜像站点。国内主要开源的镜像站点是网易和阿里云。 1、首先备份系统自带 yum 源配置文件 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2、下载阿里云的 yum 源配置文件到 /etc/yum.repos.d/CentOS7 1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3、生成缓存 1yum makecache 阅读手册 Linux 命令种类繁杂，我们凭借记忆不可能全部记住，因此学会查用手册是非常重要的。 man 安装更新 man 12sudo yum install -y man-pages --&gt; 安装sudo mandb --&gt; 更新 man 手册种类 可执行程序或 Shell 命令； 系统调用（ Linux 内核提供的函数）； 库调用（程序库中的函数）； 文件（例如 /etc/passwd ）； 特殊文件（通常在 /dev 下）； 游戏； 杂项（ man(7) ，groff(7) ）； 系统管理命令（通常只能被 root 用户使用）； 内核子程序。 man + 数字 + 命令 输入 man + 数字 + 命令/函数，可以查到相关的命令和函数，若不加数字， man 默认从数字较小的手册中寻找相关命令和函数 12man 3 rand --&gt; 表示在手册的第三部分查找 rand 函数man ls --&gt; 查找 ls 用法手册 man 手册核心区域解析：(以 man pwd 为例) 123456789101112131415161718192021NAME # 命令名称和简单描述 pwd -- return working directory nameSYNOPSIS # 使用此命令的所有方法 pwd [-L | -P]DESCRIPTION # 包括所有参数以及用法 The pwd utility writes the absolute pathname of the current working directory to the standard output. Some shells may provide a builtin pwd command which is similar or identical to this utility. Consult the builtin(1) manual page. The options are as follows: -L Display the logical current working directory. -P Display the physical current working directory (all symbolic links resolved). If no options are specified, the -L option is assumed.SEE ALSO # 扩展阅读相关命令 builtin(1), cd(1), csh(1), sh(1), getcwd(3) help man 命令像新华词典一样可以查询到命令或函数的详细信息，但其实我们还有更加快捷的方式去查询， command --help 或 command -h ，它没有 man 命令显示的那么详细，但是它更加易于阅读。 Linux 进阶 文本操作 grep 全局搜索一个正则表达式，并且打印到屏幕。简单来说就是，在文件中查找关键字，并显示关键字所在行。 基础语法 12345678910grep text file # text代表要搜索的文本，file代表供搜索的文件# 实例[root@lion ~]# grep path /etc/profilepathmunge () { pathmunge /usr/sbin pathmunge /usr/local/sbin pathmunge /usr/local/sbin after pathmunge /usr/sbin afterunset -f pathmunge 常用参数 -i 忽略大小写， grep -i path /etc/profile -n 显示行号，grep -n path /etc/profile -v 只显示搜索文本不在的那些行，grep -v path /etc/profile -r 递归查找， grep -r hello /etc ，Linux 中还有一个 rgrep 命令，作用相当于 grep -r 高级用法 grep 可以配合正则表达式使用。 123grep -E path /etc/profile --&gt; 完全匹配pathgrep -E ^path /etc/profile --&gt; 匹配path开头的字符串grep -E [Pp]ath /etc/profile --&gt; 匹配path或Path sort 对文件的行进行排序。 基础语法 1sort name.txt # 对name.txt文件进行排序 实例用法 为了演示方便，我们首先创建一个文件 name.txt ，放入以下内容： 1234567ChristopherShawnTedRockNoahZacharyBella 执行 sort name.txt 命令，会对文本内容进行排序。 常用参数 -o 将排序后的文件写入新文件， sort -o name_sorted.txt name.txt ； -r 倒序排序， sort -r name.txt ； -R 随机排序， sort -R name.txt ； -n 对数字进行排序，默认是把数字识别成字符串的，因此 138 会排在 25 前面，如果添加了 -n 数字排序的话，则 25 会在 138 前面。 wc word count 的缩写，用于文件的统计。它可以统计单词数目、行数、字符数，字节数等。 基础语法 1wc name.txt # 统计name.txt 实例用法 12[root@lion ~]# wc name.txt 13 13 91 name.txt 第一个13，表示行数； 第二个13，表示单词数； 第三个91，表示字节数。 常用参数 -l 只统计行数， wc -l name.txt ； -w 只统计单词数， wc -w name.txt ； -c 只统计字节数， wc -c name.txt ； -m 只统计字符数， wc -m name.txt 。 uniq 删除文件中的重复内容。 基础语法 12uniq name.txt # 去除name.txt重复的行数，并打印到屏幕上uniq name.txt uniq_name.txt # 把去除重复后的文件保存为 uniq_name.txt 【注意】它只能去除连续重复的行数。 常用参数 -c 统计重复行数， uniq -c name.txt ； -d 只显示重复的行数， uniq -d name.txt 。 cut 剪切文件的一部分内容。 基础语法 1cut -c 2-4 name.txt # 剪切每一行第二到第四个字符 常用参数 -d 用于指定用什么分隔符（比如逗号、分号、双引号等等） cut -d , name.txt ； -f 表示剪切下用分隔符分割的哪一块或哪几块区域， cut -d , -f 1 name.txt 。 重定向 管道 流 在 Linux 中一个命令的去向可以有3个地方：终端、文件、作为另外一个命令的入参。 命令一般都是通过键盘输入，然后输出到终端、文件等地方，它的标准用语是 stdin 、 stdout 以及 stderr 。 标准输入 stdin ，终端接收键盘输入的命令，会产生两种输出； 标准输出 stdout ，终端输出的信息（不包含错误信息）； 标准错误输出 stderr ，终端输出的错误信息。 image 重定向 把本来要显示在终端的命令结果，输送到别的地方（到文件中或者作为其他命令的输入）。 输出重定向 &gt; &gt; 表示重定向到新的文件， cut -d , -f 1 notes.csv &gt; name.csv ，它表示通过逗号剪切 notes.csv 文件（剪切完有3个部分）获取第一个部分，重定向到 name.csv 文件。 我们来看一个具体示例，学习它的使用，假设我们有一个文件 notes.csv ，文件内容如下： 123456Mark1,951/100,很不错1Mark2,952/100,很不错2Mark3,953/100,很不错3Mark4,954/100,很不错4Mark5,955/100,很不错5Mark6,956/100,很不错6 执行命令： cut -d , -f 1 notes.csv &gt; name.csv 最后输出如下内容： 123456Mark1Mark2Mark3Mark4Mark5Mark6 【注意】使用 &gt; 要注意，如果输出的文件不存在它会新建一个，如果输出的文件已经存在，则会覆盖。因此执行这个操作要非常小心，以免覆盖其它重要文件。 输出重定向 &gt;&gt; 表示重定向到文件末尾，因此它不会像 &gt; 命令这么危险，它是追加到文件的末尾（当然如果文件不存在，也会被创建）。 再次执行 cut -d , -f 1 notes.csv &gt;&gt; name.csv ，则会把名字追加到 name.csv 里面。 123456789101112Mark1Mark2Mark3Mark4Mark5Mark6Mark1Mark2Mark3Mark4Mark5Mark6 我们平时读的 log 日志文件其实都是用这个命令输出的。 输出重定向 2&gt; 标准错误输出 1cat not_exist_file.csv &gt; res.txt 2&gt; errors.log 当我们 cat 一个文件时，会把文件内容打印到屏幕上，这个是标准输出； 当使用了 &gt; res.txt 时，则不会打印到屏幕，会把标准输出写入文件 res.txt 文件中； 2&gt; errors.log 当发生错误时会写入 errors.log 文件中。 输出重定向 2&gt;&gt; 标准错误输出（追加到文件末尾）同 &gt;&gt; 相似。 输出重定向 2&gt;&amp;1 标准输出和标准错误输出都重定向都一个地方 12cat not_exist_file.csv &gt; res.txt 2&gt;&amp;1 # 覆盖输出cat not_exist_file.csv &gt;&gt; res.txt 2&gt;&amp;1 # 追加输出 目前为止，我们接触的命令的输入都来自命令的参数，其实命令的输入还可以来自文件或者键盘的输入。 image 输入重定向 &lt; &lt; 符号用于指定命令的输入。 1cat &lt; name.csv # 指定命令的输入为 name.csv 虽然它的运行结果与 cat name.csv 一样，但是它们的原理却完全不同。 cat name.csv 表示 cat 命令接收的输入是 notes.csv 文件名，那么要先打开这个文件，然后打印出文件内容。 cat &lt; name.csv 表示 cat 命令接收的输入直接是 notes.csv 这个文件的内容， cat 命令只负责将其内容打印，打开文件并将文件内容传递给 cat 命令的工作则交给终端完成。 输入重定向 &lt;&lt; 将键盘的输入重定向为某个命令的输入。 123sort -n &lt;&lt; END # 输入这个命令之后，按下回车，终端就进入键盘输入模式，其中END为结束命令（这个可以自定义）wc -m &lt;&lt; END # 统计输入的单词 管道 | 把两个命令连起来使用，一个命令的输出作为另外一个命令的输入，英文是 pipeline ，可以想象一个个水管连接起来，管道算是重定向流的一种。 image 举几个实际用法案例： 12345678910111213cut -d , -f 1 name.csv | sort &gt; sorted_name.txt # 第一步获取到的 name 列表，通过管道符再进行排序，最后输出到sorted_name.txtdu | sort -nr | head # du 表示列举目录大小信息# sort 进行排序,-n 表示按数字排序，-r 表示倒序# head 前10行文件grep log -Ir /var/log | cut -d : -f 1 | sort | uniq# grep log -Ir /var/log 表示在log文件夹下搜索 /var/log 文本，-r 表示递归，-I 用于排除二进制文件# cut -d : -f 1 表示通过冒号进行剪切，获取剪切的第一部分# sort 进行排序# uniq 进行去重 流 流并非一个命令，在计算机科学中，流 stream 的含义是比较难理解的，记住一点即可：流就是读一点数据, 处理一点点数据。其中数据一般就是二进制格式。 上面提及的重定向或管道，就是把数据当做流去运转的。 到此我们就接触了，流、重定向、管道等 Linux 高级概念及指令。其实你会发现关于流和管道在其它语言中也有广泛的应用。 Angular 中的模板语法中可以使用管道。 Node.js 中也有 stream 流的概念。 查看进程 在 Windows 中通过 Ctrl + Alt + Delete 快捷键查看软件进程。 w 帮助我们快速了解系统中目前有哪些用户登录着，以及他们在干什么。 123456789101112131415161718[root@lion ~]# w 06:31:53 up 25 days, 9:53, 1 user, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 118.31.243.53 05:56 1.00s 0.02s 0.00s w 06:31:53：表示当前时间up 25 days, 9:53：表示系统已经正常运行了“25天9小时53分钟”1 user：表示一个用户load average: 0.00, 0.01, 0.05：表示系统的负载，3个值分别表示“1分钟的平均负载”，“5分钟的平均负载”，“15分钟的平均负载” USER：表示登录的用于 TTY：登录的终端名称为pts/0 FROM：连接到服务器的ip地址 LOGIN@：登录时间 IDLE：用户有多久没有活跃了 JCPU：该终端所有相关的进程使用的 CPU 时间，每当进程结束就停止计时，开始新的进程则会重新计时 PCPU：表示 CPU 执行当前程序所消耗的时间，当前进程就是在 WHAT 列里显示的程序 WHAT：表示当下用户正运行的程序是什么，这里我运行的是 w ps 用于显示当前系统中的进程， ps 命令显示的进程列表不会随时间而更新，是静态的，是运行 ps 命令那个时刻的状态或者说是一个进程快照。 基础语法 123456789[root@lion ~]# ps PID TTY TIME CMD 1793 pts/0 00:00:00 bash 4756 pts/0 00:00:00 ps PID：进程号，每个进程都有唯一的进程号 TTY：进程运行所在的终端 TIME：进程运行时间 CMD：产生这个进程的程序名，如果在进程列表中看到有好几行都是同样的程序名，那么就是同样的程序产生了不止一个进程 常用参数 -ef 列出所有进程; -efH 以乔木状列举出所有进程; -u 列出此用户运行的进程; -aux 通过 CPU 和内存使用来过滤进程 ps -aux | less ; -aux --sort -pcpu 按 CPU 使用降序排列， -aux --sort -pmem 表示按内存使用降序排列; -axjf 以树形结构显示进程， ps -axjf 它和 pstree 效果类似。 top 获取进程的动态列表。 1234567891011top - 07:20:07 up 25 days, 10:41, 1 user, load average: 0.30, 0.10, 0.07Tasks: 67 total, 1 running, 66 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.7 us, 0.3 sy, 0.0 ni, 99.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1882072 total, 552148 free, 101048 used, 1228876 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 1594080 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 956 root 10 -10 133964 15848 10240 S 0.7 0.8 263:13.01 AliYunDun 1 root 20 0 51644 3664 2400 S 0.0 0.2 3:23.63 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.05 kthreadd 4 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H top - 07:20:07 up 25 days, 10:41, 1 user, load average: 0.30, 0.10, 0.07 相当 w 命令的第一行的信息。 展示的这些进程是按照使用处理器 %CPU 的使用率来排序的。 kill 结束一个进程， kill + PID 。 123kill 956 # 结束进程号为956的进程kill 956 957 # 结束多个进程kill -9 7291 # 强制结束进程 管理进程 进程状态 主要是切换进程的状态。我们先了解下 Linux 下进程的五种状态： 状态码 R ：表示正在运行的状态； 状态码 S ：表示中断（休眠中，受阻，当某个条件形成后或接受到信号时，则脱离该状态）； 状态码 D ：表示不可中断（进程不响应系统异步信号，即使用kill命令也不能使其中断）； 状态码 Z ：表示僵死（进程已终止，但进程描述符依然存在，直到父进程调用 wait4() 系统函数后将进程释放）； 状态码 T ：表示停止（进程收到 SIGSTOP 、 SIGSTP 、 SIGTIN 、 SIGTOU 等停止信号后停止运行）。 前台进程 &amp; 后台进程 默认情况下，用户创建的进程都是前台进程，前台进程从键盘读取数据，并把处理结果输出到显示器。例如运行 top 命令，这就是一个一直运行的前台进程。 后台进程的优点是不必等待程序运行结束，就可以输入其它命令。在需要执行的命令后面添加 &amp; 符号，就表示启动一个后台进程。 &amp; 启动后台进程，它的缺点是后台进程与终端相关联，一旦关闭终端，进程就自动结束了。 1cp name.csv name-copy.csv &amp; nohup 使进程不受挂断（关闭终端等动作）的影响。 1nohup cp name.csv name-copy.csv nohup 命令也可以和 &amp; 结合使用。 1nohup cp name.csv name-copy.csv &amp; bg 使一个“后台暂停运行”的进程，状态改为“后台运行”。 1bg %1 # 不加任何参数的情况下，bg命令会默认作用于最近的一个后台进程，如果添加参数则会作用于指定标号的进程 实际案例1： 1231. 执行 grep -r &quot;log&quot; / &gt; grep_log 2&gt;&amp;1 命令启动一个前台进程，并且忘记添加 &amp; 符号2. ctrl + z 使进程状态转为后台暂停3. 执行 bg 将命令转为后台运行 实际案例2： 1234前端开发时我们经常会执行 yarn start 启动项目此时我们执行 ctrl + z 先使其暂停然后执行 bg 使其转为后台运行这样当前终端就空闲出来可以干其它事情了，如果想要唤醒它就使用 fg 命令即可（后面会讲） jobs 显示当前终端后台进程状态。 123[root@lion ~]# jobs[1]+ Stopped top[2]- Running grep --color=auto -r &quot;log&quot; / &gt; grep_log 2&gt;&amp;1 &amp; fg fg 使进程转为前台运行，用法和 bg 命令类似。 我们用一张图来表示前后台进程切换： image 我们可以使程序在后台运行，成为后台进程，这样在当前终端中我们就可以做其他事情了，而不必等待此进程运行结束。 守护进程 一个运行起来的程序被称为进程。在 Linux 中有些进程是特殊的，它不与任何进程关联，不论用户的身份如何，都在后台运行，这些进程的父进程是 PID 为1的进程， PID 为1的进程只在系统关闭时才会被销毁。它们会在后台一直运行等待分配工作。我们将这类进程称之为守护进程 daemon 。 守护进程的名字通常会在最后有一个 d ，表示 daemon 守护的意思，例如 systemd 、httpd 。 systemd systemd 是一个 Linux 系统基础组件的集合，提供了一个系统和服务管理器，运行为 PID 1 并负责启动其它程序。 123[root@lion ~]# ps -auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.2 51648 3852 ? Ss Feb01 1:50 /usr/lib/systemd/systemd --switched-root --system --deserialize 22 通过命令也可以看到 PID 为1的进程就是 systemd 的系统进程。 systemd 常用命令（它是一组命令的集合）： 123456789systemctl start nginx # 启动服务systemctl stop nginx # 停止服务systemctl restart nginx # 重启服务systemctl status nginx # 查看服务状态systemctl reload nginx # 重载配置文件(不停止服务的情况)systemctl enable nginx # 开机自动启动服务systemctl disable nginx # 开机不自动启动服务systemctl is-enabled nginx # 查看服务是否开机自动启动systemctl list-unit-files --type=service # 查看各个级别下服务的启动和禁用情况 文件压缩解压 打包：是将多个文件变成一个总的文件，它的学名叫存档、归档。 压缩：是将一个大文件（通常指归档）压缩变成一个小文件。 我们常常使用 tar 将多个文件归档为一个总的文件，称为 archive 。 然后用 gzip 或 bzip2 命令将 archive 压缩为更小的文件。 image tar 创建一个 tar 归档。 基础用法 12tar -cvf sort.tar sort/ # 将sort文件夹归档为sort.tartar -cvf archive.tar file1 file2 file3 # 将 file1 file2 file3 归档为archive.tar 常用参数 -cvf 表示 create（创建）+ verbose（细节）+ file（文件），创建归档文件并显示操作细节； -tf 显示归档里的内容，并不解开归档； -rvf 追加文件到归档， tar -rvf archive.tar file.txt ； -xvf 解开归档， tar -xvf archive.tar 。 gzip / gunzip “压缩/解压”归档，默认用 gzip 命令，压缩后的文件后缀名为 .tar.gz 。 12gzip archive.tar # 压缩gunzip archive.tar.gz # 解压 tar 归档+压缩 可以用 tar 命令同时完成归档和压缩的操作，就是给 tar 命令多加一个选项参数，使之完成归档操作后，还是调用 gzip 或 bzip2 命令来完成压缩操作。 12tar -zcvf archive.tar.gz archive/ # 将archive文件夹归档并压缩tar -zxvf archive.tar.gz # 将archive.tar.gz归档压缩文件解压 zcat、zless、zmore 之前讲过使用 cat less more 可以查看文件内容，但是压缩文件的内容是不能使用这些命令进行查看的，而要使用 zcat、zless、zmore 进行查看。 1zcat archive.tar.gz zip/unzip “压缩/解压” zip 文件（ zip 压缩文件一般来自 windows 操作系统）。 命令安装 123# Red Hat 一族中的安装方式yum install zip yum install unzip 基础用法 1234unzip archive.zip # 解压 .zip 文件unzip -l archive.zip # 不解开 .zip 文件，只看其中内容zip -r sort.zip sort/ # 将sort文件夹压缩为 sort.zip，其中-r表示递归 编译安装软件 之前我们学会了使用 yum 命令进行软件安装，如果碰到 yum 仓库中没有的软件，我们就需要会更高级的软件安装“源码编译安装”。 编译安装 简单来说，编译就是将程序的源代码转换成可执行文件的过程。大多数 Linux 的程序都是开放源码的，可以编译成适合我们的电脑和操纵系统属性的可执行文件。 基本步骤如下： 下载源代码 解压压缩包 配置 编译 安装 实际案例 1、下载 我们来编译安装 htop 软件，首先在它的官网下载源码：bintray.com/htop/source… 下载好的源码在本机电脑上使用如下命令同步到服务器上： 123scp 文件名 用户名@服务器ip:目标路径scp ~/Desktop/htop-3.0.0.tar.gz root@121.42.11.34:. 也可以使用 wegt 进行下载： 123wegt+下载地址wegt https://bintray.com/htop/source/download_file?file_path=htop-3.0.0.tar.gz 2、解压文件 123tar -zxvf htop-3.0.0.tar.gz # 解压cd htop-3.0.0 # 进入目录 3、配置 执行 ./configure ，它会分析你的电脑去确认编译所需的工具是否都已经安装了。 4、编译 执行 make 命令 5、安装 执行 make install 命令，安装完成后执行 ls /usr/local/bin/ 查看是否有 htop 命令。如果有就可以执行 htop 命令查看系统进程了。 网络 ifconfig 查看 ip 网络相关信息，如果命令不存在的话， 执行命令 yum install net-tools 安装。 1234567891011121314151617[root@lion ~]# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.24.78 netmask 255.255.240.0 broadcast 172.31.31.255 ether 00:16:3e:04:9c:cd txqueuelen 1000 (Ethernet) RX packets 1592318 bytes 183722250 (175.2 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 1539361 bytes 154044090 (146.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 参数解析： eth0 对应有线连接（对应你的有线网卡），就是用网线来连接的上网。 eth 是 Ethernet 的缩写，表示“以太网”。有些电脑可能同时有好几条网线连着，例如服务器，那么除了 eht0 ，你还会看到 eth1 、 eth2 等。 lo 表示本地回环（ Local Loopback 的缩写，对应一个虚拟网卡）可以看到它的 ip 地址是 127.0.0.1 。每台电脑都应该有这个接口，因为它对应着“连向自己的链接”。这也是被称之为“本地回环”的原因。所有经由这个接口发送的东西都会回到你自己的电脑。看起来好像并没有什么用，但有时为了某些缘故，我们需要连接自己。例如用来测试一个网络程序，但又不想让局域网或外网的用户查看，只能在此台主机上运行和查看所有的网络接口。例如在我们启动一个前端工程时，在浏览器输入 127.0.0.1:3000 启动项目就能查看到自己的 web 网站，并且它只有你能看到。 wlan0 表示无线局域网（上面案例并未展示）。 host ip 地址和主机名的互相转换。 软件安装 1yum install bind-utils 基础用法 12345[root@lion ~]# host github.combaidu.com has address 13.229.188.59 [root@lion ~]# host 13.229.188.5959.188.229.13.in-addr.arpa domain name pointer ec2-13-229-188-59.ap-southeast-1.compute.amazonaws.com. ssh 连接远程服务器 通过非对称加密以及对称加密的方式（同 HTTPS 安全连接原理相似）连接到远端服务器。 1234ssh 用户@ip:port1、ssh root@172.20.10.1:22 # 端口号可以省略不写，默认是22端口2、输入连接密码后就可以操作远端服务器了 配置 ssh config 文件可以配置 ssh ，方便批量管理多个 ssh 连接。 配置文件分为以下几种： 全局 ssh 服务端的配置： /etc/ssh/sshd_config ； 全局 ssh 客户端的配置： /etc/ssh/ssh_config（很少修改）； 当前用户 ssh 客户端的配置： ~/.ssh/config 。 【服务端 config 文件的常用配置参数】 服务端 config 参数 作用 Port sshd 服务端口号（默认是22） PermitRootLogin 是否允许以 root 用户身份登录（默认是可以） PasswordAuthentication 是否允许密码验证登录（默认是可以） PubkeyAuthentication 是否允许公钥验证登录（默认是可以） PermitEmptyPasswords 是否允许空密码登录（不安全，默认不可以） [注意] 修改完服务端配置文件需要重启服务 systemctl restart sshd 【客户端 config 文件的常用配置参数】 客户端 config 参数 作用 Host 别名 HostName 远程主机名（或 IP 地址） Port 连接到远程主机的端口 User 用户名 配置当前用户的 config ： 12345678# 创建configvim ~/.ssh/config# 填写一下内容Host lion # 别名 HostName 172.x.x.x # ip 地址 Port 22 # 端口 User root # 用户 这样配置完成后，下次登录时，可以这样登录 ssh lion 会自动识别为 root 用户。 [注意] 这段配置不是在服务器上，而是你自己的机器上，它仅仅是设置了一个别名。 免密登录 ssh 登录分两种，一种是基于口令（账号密码），另外一种是基于密钥的方式。 基于口令，就是每次登录输入账号和密码，显然这样做是比较麻烦的，今天主要学习如何基于密钥实现免密登录。 基于密钥验证原理 客户机生成密钥对（公钥和私钥），把公钥上传到服务器，每次登录会与服务器的公钥进行比较，这种验证登录的方法更加安全，也被称为“公钥验证登录”。 具体实现步骤 1、在客户机中生成密钥对（公钥和私钥） ssh-keygen（默认使用 RSA 非对称加密算法） 运行完 ssh-keygen 会在 ~/.ssh/ 目录下，生成两个文件： id_rsa.pub ：公钥 id_rsa ：私钥 2、把客户机的公钥传送到服务 执行 ssh-copy-id root@172.x.x.x（ssh-copy-id 它会把客户机的公钥追加到服务器 ~/.ssh/authorized_keys 的文件中）。 执行完成后，运行 ssh root@172.x.x.x 就可以实现免密登录服务器了。 配合上面设置好的别名，直接执行 ssh lion 就可以登录，是不是非常方便。 wget 可以使我们直接从终端控制台下载文件，只需要给出文件的HTTP或FTP地址。 123wget [参数][URL地址]wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip wget 非常稳定，如果是由于网络原因下载失败， wget 会不断尝试，直到整个文件下载完毕。 常用参数 -c 继续中断的下载。 备份 scp 它是 Secure Copy 的缩写，表示安全拷贝。 scp 可以使我们通过网络，把文件从一台电脑拷贝到另一台电脑。 scp 是基于 ssh 的原理来运作的， ssh 会在两台通过网络连接的电脑之间创建一条安全通信的管道， scp 就利用这条管道安全地拷贝文件。 1scp source_file destination_file # source_file 表示源文件，destination_file 表示目标文件 其中 source_file 和 destination_file 都可以这样表示： user@ip:file_name ， user 是登录名， ip 是域名或 ip 地址。 file_name 是文件路径。 12scp file.txt root@192.168.1.5:/root # 表示把我的电脑中当前文件夹下的 file.txt 文件拷贝到远程电脑scp root@192.168.1.5:/root/file.txt file.txt # 表示把远程电脑上的 file.txt 文件拷贝到本机 rsync rsync 命令主要用于远程同步文件。它可以同步两个目录，不管它们是否处于同一台电脑。它应该是最常用于“增量备份”的命令了。它就是智能版的 scp 命令。 软件安装 1yum install rsync 基础用法 12rsync -arv Images/ backups/ # 将Images 目录下的所有文件备份到 backups 目录下rsync -arv Images/ root@192.x.x.x:backups/ # 同步到服务器的backups目录下 常用参数 -a 保留文件的所有信息，包括权限，修改日期等； -r 递归调用，表示子目录的所有文件也都包括； -v 冗余模式，输出详细操作信息。 默认地， rsync 在同步时并不会删除目标目录的文件，例如你在源目录中删除一个文件，但是用 rsync 同步时，它并不会删除同步目录中的相同文件。如果向删除也可以这么做： rsync -arv --delete Images/ backups/ 。 系统 halt 关闭系统，需要 root 身份。 1halt reboot 重启系统，需要 root 身份。 1reboot poweroff 直接运行即可关机，不需要 root 身份。 Vim 编辑器 Vim 是什么？ Vim 是从 vi 发展出来的一个文本编辑器。其代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。和 Emacs 并列成为类 Unix 系统用户最喜欢的编辑器。 Vim 常用模式 交互模式 插入模式 命令模式 可视模式 交互模式 也成为正常模式，这是 Vim 的默认模式，每次运行 Vim 程序的时候，就会进入这个模式。 例如执行 vim name.txt 则会进入交互模式。 交互模式特征： 在这个模式下，你不能输入文本； 它可以让我们在文本间移动，删除一行文本，复制黏贴文本，跳转到指定行，撤销操作，等等。 插入模式 这个模式是我们熟悉的文本编辑器的模式，就是可以输入任何你想输入的内容。进入这个模式有几种方法，最常用的方法是按字母键 i （ i、I、a、A、o、O 都可以进入插入模式，只是所处的位置不同），退出这种模式，只需要按下 Esc 键。 i, I 进入输入模式 Insert mode ： i 为“从目前光标所在处输入”， I 为“在目前所在行的第一个非空格符处开始输入”； a, A 进入输入模式 Insert mode ： a 为“从目前光标所在的下一个字符处开始输入”， A 为“从光标所在行的最后一个字符处开始输入”； o, O 进入输入模式 Insert mode ： o 为“在目前光标所在的下一行处输入新的一行”； O 为在目前光标所在处的上一行输入新的一行。 命令模式 命令模式也称为底线命令模式，这个模式下可以运行一些命令例如“退出”，“保存”，等动作。 也可以用这个模式来激活一些 Vim 配置，例如语法高亮，显示行号，等。甚至还可以发送一些命令给终端命令行，例如 ls、cp 。 为了进入命令模式，首先要进入交互模式，再按下冒号键。 用一张图表示三种模式如何切换： 基本操作 打开 Vim 在终端命令行中输入 vim 回车后 Vim 就会被运行起来，也可以用 Vim 来打开一个文件，只需要在 vim 后面再加文件名。如 vim file.name ，如果文件不存在，那么会被创建。 插入 进入文件之后，此时处于交互模式，可以通过输入 i 进入插入模式。 移动 在 Vim 的交互模式下，我们可以在文本中移动光标。 h 向左移动一个字符 j 向下移动一个字符 k 向上移动一个字符 i 向右移动一个字符 当然也可以使用四个方向键进行移动，效果是一样的。 跳至行首和行末 行首：在交互模式下，为了将光标定位到一行的开始位置，只需要按下数字键 0 即可，键盘上的 Home 键也有相同效果。 行末：在交互模式下，为了将光标定位到一行的末尾，只需要按下美元符号键 $ 即可，键盘上的 End 键也有相同效果。 按单词移动 在交互模式下，按字母键 w 可以一个单词一个单词的移动。 退出文件 在交互模式下，按下冒号键 : 进入命令模式，再按下 q 键，就可以退出了。 如果在退出之前又修改了文件，就直接想用 :q 退出 Vim ，那么 Vim 会显示一个红字标明错误信息。此时我们有两个选择： 保存并退出 :wq 或 :x ； 不保存且退出 :q! 。 标准操作 删除字符 在交互模式下，将光标定位到一个你想要删除的字符上，按下字母键 x 你会发现这个字符被删除了。 也可以一次性删除多个字符，只需要在按 x 键之前输入数字即可。 删除（剪切）单词，行 删除一行：连按两次 d 来删除光标所在的那一行。 删除多行：例如先输入数字 2 ，再按下 dd ，就会删除从光标所在行开始的两行。 删除一个单词：将光标置于一个单词的首字母处，然后按下 dw 。 删除多个单词：例如先按数字键 2 再按 dw 就可以删除两个单词了。 从光标所在位置删除至行首： d0 。 从光标所在位置删除至行末： d$ 。 复制单词，行 复制行：按两次 y 会把光标所在行复制到内存中，和 dd 类似， dd 用于“剪切”光标所在行。 复制单词： yw 会复制一个单词。 复制到行末： y$ 是复制从光标所在处到行末的所有字符。 复制到行首： y0 是复制光标所在处到行首的所有字符。 粘贴 如果之前用 dd 或者 yy 剪切复制过来的，可以使用 p 来粘贴。同样也可以使用 数字+p 来表示复制多次。 替换一个字符 在交互模式下，将光标置于想要替换的字符上。按下 r 键，接着输入你要替换的字符即可。 撤销操作 如果要撤销最近的修改，只需要按下 u 键，如果想要撤销最近四次修改，可以按下4，再按下 u 。 重做 取消撤销，也就是重做之前的修改使用 ctrl + r 。 跳转到指定行 Vim 编辑的文件中，每一行都有一个行号，行号从1开始，逐一递增。 行号默认是不显示，如果需要它显示的话，可以进入命令模式，然后输入 set nu ，如果要隐藏行号的话，使用 set nonu 。 跳转到指定行： 数字+gg ，例如 7gg ，表示跳转到第7行。 要跳转到最后一行，按下 G 。 要跳转到第一行，按下 gg 。 高级操作 查找 处于交互模式下，按下 / 键，那么就进入查找模式，输入你要查找的字符串，然后按下回车。光标就会跳转到文件中下一个查找到的匹配处。如果字符串不存在，那么会显示 \"pattern not found\" 。 n 跳转到下一个匹配项； N 跳转到上一个匹配项。 [注意] 用斜杠来进行的查找是从当前光标处开始向文件尾搜索，如果你要从当前光标处开始，向文件头搜索则使用 ? ，当然也可以先按下 gg 跳转到第一行在进行全文搜索。 查找并替换 替换光标所在行第一个匹配的字符串： 12345# 语法:s/旧字符串/新字符串# 实例:s/one/two 替换光标所在行所有旧字符串为新字符串： 12# 语法:s/旧字符串/新字符串/g 替换第几行到第几行中所有字符串： 12345# 语法:n,m s/旧字符串/新字符串/g# 实例:2,4 s/one/two/g 最常用的就是全文替换了： 12# 语法:%s/旧字符串/新字符串/g 合并文件 可以用冒号 +r ( :r ) 实现在光标处插入一个文件的内容。 1:r filename # 可以用Tab键来自动补全另外一个文件的路径 分屏 Vim 有一个特别便捷的功能那就是分屏，可以同时打开好几个文件，分屏之后，屏幕每一块被称为一个 viewport ，表示“视口”。 横向分屏 :sp 文件名 垂直分屏 :vsp 文件名 分屏模式下的快捷键 Ctrl + w 再加 Ctrl + w ，表示从一个 viewport 移动光标到另外一个 viewport ； Ctrl + w 再加 “方向键”，就可以移动到这个方向所处的下一个视口了； Ctrl + w 再加 + 号，表示扩大当前视口； Ctrl + w 再加 - 号，表示缩小当前视口； Ctrl + w 再加 = 号，表示平均当前视口； Ctrl + w 再加 r 键，会反向调换视口位置； Ctrl + w 再加 q 键，会关闭当前视口； Ctrl + w 再加 o 键，会关闭除当前视口以外的所有视口； 运行外部命令 :! 在 Vim 中可以运行一些终端命令，只要先输入 :! ，然后接命令名称。 例如： 1:!ls # 在Vim中打开的文件所在的目录运行ls命令 可视模式 前面只讲了 Vim 的三种模式，其实还有一种模式叫做可视模式。 进入它的三种方式（都是从交互模式开始）： v 字符可视模式，进入后配合方向键选中字符后，然后再按 d 键可以删除选中。 V 行可视模式，进入后光标所在行默认被选中，然后再按 d 键可以删除所在行。 Ctrl + v 块可视模式，它是可视模式最有用的功能了，配合 d 和 I 键可以实现删除选中的内容和插入内容。 同时选中多行，并在选中行头部插入内容的具体操作步骤： 12341. ctrl + v 进入块可视模式2. 使用方向键进行选中（上下左右）假设选中5行3. 输入 I 键进行多行同时插入操作4. 插入完成后连续按两下 esc 键，实现多行同时插入相同字符 进入可视模式之后的操作键： d 键，表示删除选中； I 键，表示在选中之前插入； u 键，表示选中变为小写； U 键，表示选中变为大写； Vim 配置 选项参数 在 Vim 被启动后，可以运行一些指令来激活一些选项参数，但是这些选项参数的配置在退出 Vim 时会被忘记，例如前面讲解的激活行号。如果希望所在的配置是永久性的，那么需要在家目录（ cd ~ ）创建一个 Vim 的配置文件 .vimrc 。 .vimrc 12345set number &quot; 显示行号syntax on &quot; 激活语法高亮set showcmd &quot; 实时看到输入的命令set ignorecase &quot; 搜索时不区分大小写set mouse=a &quot; 激活鼠标，用鼠标选中时相当于进入可视模式 Vim 配置非常丰富，我们可以通过个性化配置把 Vim 打造成属于自己的 IDE 等等。在 github 上也可以搜索到一些强大的 Vim 配置文件。 作者：Lion 链接：https://juejin.cn/post/6938385978004340744 来源：稀土掘金","link":"/posts/50125/"},{"title":"Vue_CLI安装及项目搭建","text":"通过Vue-CLI搭建Vue项目的操作流程。 Vue-CLI (Command Line Interface) 安装 1npm install -g @vue/cli 检查版本 1vue --version 创建项目 1vue create &lt;Project Name&gt; 创建过程配置 12345Vue CLI v4.5.15? Please pick a preset: Default ([Vue 2] babel, eslint)&gt; Default (Vue 3) ([Vue 3] babel, eslint) Manually select features 选择Vue 3项目，默认自带babel和eslint babel：将ES6语法转换为ES5语法 eslint：检查语法，修复不规范代码 若选择第三项手动配置 1234567891011? Check the features needed for your project: (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)&gt;(*) Choose Vue version (*) Babel # 将ES6语法转换为ES5语法 ( ) TypeScript # JS的超集 ( ) Progressive Web App (PWA) Support # App支持 (*) Router # 路由 (*) Vuex # 状态管理 (*) CSS Pre-processors # sass，less转css (*) Linter / Formatter # 检查语法规范 ( ) Unit Testing # 单元测试 ( ) E2E Testing # 端对端测试 路由是否使用历史模式，选择Y 1? Use history mode for router? (Requires proper server setup for index fallback in production) (Y/n) 处理Sass还是Less，根据需求选择即可 12345? Pick a CSS pre-processor (PostCSS, Autoprefixer and CSS Modules are supported by default): (Use arrow keys)&gt; Sass/SCSS (with dart-sass) Sass/SCSS (with node-sass) Less Stylus 选择eslint标准，选择Airbnb 12345? Pick a linter / formatter config: (Use arrow keys) ESLint with error prevention only&gt; ESLint + Airbnb config ESLint + Standard config ESLint + Prettier 保存时修复与提交git时修复，可全选 123? Pick additional lint features: (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)&gt;(*) Lint on save (*) Lint and fix on commit (requires Git) 各插件的配置文件独立还是全部放入package.json 123? Where do you prefer placing config for Babel, ESLint, etc.? (Use arrow keys)&gt; In dedicated config files In package.json 是否为下次手动配置记录此次选择 1? Save this as a preset for future projects? (y/N) 项目名称 1? Save preset as: 基本操作 build 1npm run build 运行 1npm run serve","link":"/posts/8559/"},{"title":"Vue-router路由（下）","text":"Vue生态中的一员大将Vue-router，负责管理页面路由，书接上回，本节介绍路由重定向、别名及导航守卫。 重定向 重定向在routes配置中完成，要从/a重定向到/b 123456789101112const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/home', redirect: '/', // 访问/home时重定向到根 component: Home }] 也可以使用对象的形式 123456789101112const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/home', redirect: {name:'HomeRoot'}, // 访问/home时重定向到根 component: Home }] 还支持将params类型的参数传递转换为query类型的，但一般不这样做 123456789const routes = [ { path: 'page/:id', redirect: to =&gt; { return {path: '/about/article', query: {name: 'li', age: to.params.id}} }, component: () =&gt; import('../views/Page') },] 别名 12345678const routes = [ { path: '/about', name: 'About', alias: '/a', // 可以通过/a访问到/about component: () =&gt; import('../views/About.vue'), }] 可以起多个别名，以数组的形式 12345678const routes = [ { path: '/about', name: 'About', alias: ['/a', '/b', '/c'], // 可以通过/a访问到/about component: () =&gt; import('../views/About.vue'), }] 若路由中有params类型的参数传递，起别名时也要带上参数 1234567const routes = [ { path: 'page/:id', alias: 'p/:id', component: () =&gt; import('../views/Page') },] 导航守卫 导航守卫主要用来通过跳转或取消的方式守卫导航 有多种机会植入路由导航过程中： 全局导航守卫：在index.js中添加 前置守卫 1234router.beforeEach((to, from) =&gt; { // 处理 return true;}) 后置钩子 123router.afterEach((to, from) =&gt; { // 处理}) 路由独享守卫：在单个路由下添加 12345678910const routes = [ { path: '/users/:id', component: UserDetails, beforeEnter: (to, from) =&gt; { // reject the navigation return false }, },] 组件内的守卫 123456789101112131415161718const UserDetails = { template: `...`, beforeRouteEnter(to, from) { // 在渲染该组件的对应路由被验证前调用 // 不能获取组件实例 `this` ！ // 因为当守卫执行时，组件实例还没被创建！ }, beforeRouteUpdate(to, from) { // 在当前路由改变，但是该组件被复用时调用 // 举例来说，对于一个带有动态参数的路径 `/users/:id`，在 `/users/1` 和 `/users/2` 之间跳转的时候， // 由于会渲染同样的 `UserDetails` 组件，因此组件实例会被复用。而这个钩子就会在这个情况下被调用。 // 因为在这种情况发生的时候，组件已经挂载好了，导航守卫可以访问组件实例 `this` }, beforeRouteLeave(to, from) { // 在导航离开渲染该组件的对应路由时调用 // 与 `beforeRouteUpdate` 一样，它可以访问组件实例 `this` },} &lt;keep-alive&gt;与路由组合 在Vue3.x中不再支持如下形式 123&lt;keep-alive&gt; &lt;router-view/&gt;&lt;/keep-alive&gt; 而应该采用如下方式 1234567&lt;router-view v-slot=&quot;{ Component }&quot;&gt; &lt;transition&gt; &lt;keep-alive&gt; &lt;component :is=&quot;Component&quot;/&gt; &lt;/keep-alive&gt; &lt;/transition&gt;&lt;/router-view&gt; &lt;keep-alive&gt;有两个可选属性 include选择缓存的页面，可填字符串或正则表达式 exclude选择不缓存的页面，可填字符串或正则表达式","link":"/posts/52120/"},{"title":"Vue-router路由（上）","text":"Vue生态中的一员大将Vue-router，负责管理页面路由，本节介绍路由模式、嵌套路由及路由参数传递。 路由 创建index.js，引入createRouter和createWebHistory方法 1import { createRouter, createWebHistory } from 'vue-router' 声明一个routes变量 123456789101112131415161718import Home from '../views/Home.vue'const routes = [ { path: '/', name: 'Home', // 这种写法需要在上面import该组件 // 使用这种方式引入，在打包时会将所有页面打包到同一个js中 component: Home }, { path: '/about', name: 'About', // 这种写法是在该处直接import，故上面不需要引入 // 使用这种方式引入，可将各页面打包成多个chunk，可以实现懒加载，尽量使用该方法 component: () =&gt; import('../views/About.vue') }] 创建router实例 1234const router = createRouter({ history: createWebHistory(process.env.BASE_URL), // 历史模式 routes // 相当于routes:routes，JSON的简化写法}) 暴露接口 1export default router 在main.js中引入 123import router from './router'createApp(App).use(router).mount('#app') // 利用use将router作为参数传入 在页面中利用&lt;router-link&gt;标签创建路由，会自动渲染成&lt;a&gt;标签 1234&lt;!--to指明路径--&gt;&lt;router-link to=&quot;/&quot;&gt;Home&lt;/router-link&gt;&lt;!--激活的页面将填充到如下标签中--&gt;&lt;router-view/&gt; 激活路由的样式，默认为该样式 123#nav a.router-link-exact-active { color: #42b983;} 可通过active-class属性改变 1&lt;router-link active-class=&quot;active&quot; to=&quot;/&quot;&gt;Home&lt;/router-link&gt; 路由模式 Hash：vue-router默认使用该模式，该模式使用URL的hash值来作为路由，用来指导浏览器动作，对服务端完全无用，支持所有浏览器 引入 123456import { createRouter, createWebHashHistory } from 'vue-router'const router = createRouter({ history: createWebHashHistory(process.env.BASE_URL), // 历史模式 routes // 相当于routes:routes，JSON的简化写法}) History：创建一个 HTML5 历史，即单页面应用程序中最常见的历史记录。应用程序必须通过 http 协议被提供服务。 Abstract：支持所有JavaScript运行模式，若发现没有浏览器的API，路由会自动强制进入这个模式 嵌套路由 在路由的index.js中 1234567891011121314151617181920212223242526272829const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/about', name: 'About', component: () =&gt; import('../views/About.vue'), children: [ // 利用children字段声明子路由 { // 当进入about页面时子路径为空，会匹配到该处，从而实现默认显示 path: '', component: () =&gt; import('../views/Order') }, { path: 'order', name: 'Order', component: () =&gt; import('../views/Order') }, { path: 'setting', name: 'Setting', component: () =&gt; import('../views/Setting') } ] }] 在页面中 1234567&lt;div class=&quot;menu&quot;&gt; &lt;li&gt;&lt;router-link to=&quot;/about/order&quot;&gt;我的订单&lt;/router-link&gt;&lt;/li&gt; &lt;li&gt;&lt;router-link to=&quot;/about/setting&quot;&gt;个人设置&lt;/router-link&gt;&lt;/li&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt; &lt;router-view/&gt;&lt;/div&gt; 路由参数传递 params类型 带参数的路由定义 123456789101112131415161718192021const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/about', name: 'About', component: () =&gt; import('../views/About.vue'), children: [ { // 通过:id的方式可以绑定一个参数 // 从而实现用同一个组件模板显示不同内容 // id这个参数名是任意起 path: 'page/:id', component: () =&gt; import('../views/Page') } ] }] 传递参数 12345&lt;ul&gt; &lt;li v-for=&quot;item in articles&quot;&gt; &lt;router-link :to=&quot;'/about/page/'+item.id&quot;&gt;{{ item.title }}&lt;/router-link&gt; &lt;/li&gt;&lt;/ul&gt; 获取参数 12&lt;!--params.id中的id要和子路由中声明的参数名称一致--&gt;文章ID:{{ $route.params.id }} 也可以用计算属性的方式获取 1文章ID:{{ pageid }} 123456789export default { name: &quot;Page&quot;, computed: { pageid() { // params.id中的id要和子路由中声明的参数名称一致 return this.$route.params.id } }} query类型 路由定义用传统方式 123456789101112131415161718const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/about', name: 'About', component: () =&gt; import('../views/About.vue'), children: [ { path: 'article', component: () =&gt; import('../views/Article') } ] }] 传递参数 123456&lt;ul&gt; &lt;li&gt; &lt;!--以对象的形式传递--&gt; &lt;router-link :to=&quot;{path:'/about/article', query:{name:'zhang',age:20}}&quot;&gt;文章二&lt;/router-link&gt; &lt;/li&gt;&lt;/ul&gt; 12&lt;!--自定义方式传递参数--&gt;&lt;button @click=&quot;$router.push({path:'/about/article',query:{name:'sun',age:19}})&quot;&gt;文章三&lt;/button&gt; 获取参数 12姓名:{{ $route.query.name }}年龄:{{ $route.query.age }}","link":"/posts/14233/"},{"title":"VideoPose3D论文阅读笔记-CVPR 2019","text":"论文题目为3D human pose estimation in video with temporal convolutions and semi-supervised training，发表于CVPR 2019。本文提出了时间扩张卷积模型，并使用了半监督的方法。 大纲 引言 先前的工作依赖RNN建模时间信息来解决深度歧义。另一方面，卷积网络在建模时间信息方面非常成功，且卷积模型能够并行处理多个帧，而循环网络不可能实现。 本文提出了一种全卷积架构，该架构在2D关键点上执行时间卷积，以实现视频中的准确3D姿态预测。该方法与任何2D关键点检测器兼容，并可以通过扩展卷积有效地处理大量的上下文信息。与依赖RNN的方法相比，它在计算复杂度和参数数量方面有着更高的准确性、简单性和高效性。 同时本文利用未标记的视频数据进行半监督训练，该方法使用现成的2D关键点检测器预测未标记视频的2D关键点，接着预测3D姿态，然后将这些姿态映射回2D空间。 总结本文的两个贡献： 提出了一种基于2D关键点轨迹的扩展时间卷积的视频3D人体姿态估计方法。在相同精度水平下，无论是在计算复杂性还是模型参数数量方面，均比基于RNN的模型更有效。 引入了一种半监督方法，该方法利用未标记的视频。与以前的半监督方法相比，该方法只需要相机的固有参数，而不需要真实2D注释或具有外部相机参数的多视图图像。 图1. 时间卷积模型 相关工作 第一个使用CNN的方法专注于端到端的重建，通过从RGB图像直接估计3D姿态，无需中间监督。 两阶段姿态估计 新一批的3D姿态估计器建立在2D姿态估计的基础上，然后将其提升到3D。受益于中间监督，这些方法优于端到端的方法。本文遵循这种方法。 早期方法在3D姿态可用的一大组2D关键点上执行对2D关键点预测集的k近邻搜索，然后输出相应的3D姿态。一些方法同时利用图像特征和2D真实姿态。或者通过简单预测2D关键点的深度，从给定的一组2D关键点预测3D姿态。还有一些工作利用了关于骨骼长度和投影与2D真实姿态一致性的先验知识。 视频姿态估计 以前的大多数工作都是基于单帧图像的，但最近有些工作利用视频中的时间信息来产生更具鲁棒性的预测，并降低对噪声的敏感度。 如利用时空体积的HoG（histograms of oriented gradients，定向梯度直方图）推断3D姿态。LSTM已用于细化从单帧图像预测的3D姿态。然而最成功的方法是从2D关键点轨迹中学习，本文的工作属于这一类。 最近，已经提出了LSTM Seq2Seq学习模型，该模型将视频中的2D姿势序列编码为固定大小的向量，然后将其解码为3D姿势序列。然而，输入和输出序列都具有相同的长度，2D姿态的确定性变换是更自然的选择。本文用seq2seq模型进行的实验表明，输出姿势往往会在较长的序列上漂移。有些工作通过以时间一致性为代价每5帧重新初始化编码器来解决这个问题。也有关于RNN方法的工作，该方法考虑了身体部位连接的先验。 半监督训练 有人提出多任务网络的工作，用于联合2D和3D姿态估计以及动作识别。一些工作将在2D姿势估计学习到的特征转移到3D任务中。未标记的多视图记录已用于3D姿态估计的预训练表示，但这些记录在无监督设置中不易获得。生成对抗网络（GAN）可以在只有2D注释可用的第二数据集中区分现实姿态和不现实姿态，从而提供了一种有用的正则化形式。还有的工作使用GAN从未配对的2D/3D数据集学习，并包括2D投影一致性项。类似地，另一个工作在将生成的3D姿势随机投影到2D之后，对其进行区分。还有人提出了一种基于有序深度注释的弱监督方法，该方法利用了2D姿势数据集，并通过深度比较进行了增强，例如“左腿在右腿后面”。 3D形状恢复 虽然本文和所讨论的相关工作侧重于重建准确的3D姿态，但并行的研究目标是从图像中恢复人的完整3D形状。这些方法通常基于参数化的3D网格，对姿态精度的要求较小。 本文工作 与Pavlakos等人的方法相比，本文不使用热图，而是使用检测到的关键点坐标来描述姿势。这允许在坐标时间序列上使用有效的1D卷积，而不是在单个热图上使用2D卷积，或在热图序列上使用3D卷积。本文方法还使计算复杂性与关键点空间分辨率无关。 本文提出的模型可以用更少的参数达到高精度，并允许更快的训练和推断。与Martinez等人提出的单帧基线和Hossain等人提出的LSTM模型相比，我们通过在时间维度上执行1D卷积来利用时间信息，并提出了拥有较低重建误差的若干优化。与Hossain等人不同，我们学习的是确定性映射，而不是Seq2Seq模型。 与本节中提到的大多数两步模型相反，我们表明掩码R-CNN和级联金字塔网络（Cascaded Pyramid Network, CPN）检测对于3D人体姿态估计更为鲁棒。 时间扩张卷积模型 本文的模型是一个具有残差连接的完全卷积架构，它将一系列2D姿态作为输入，并通过时间卷积对其进行变换。 卷积模型可以在批处理和时间维度上实现并行化，而RNN不能随时间并行化。在卷积模型中，无论序列长度如何，输出和输入之间的梯度路径都具有固定长度，这减轻了RNN中梯度消失和爆炸的情况。卷积结构还提供了对时间感受野的精确控制，作者发现这有益于3D姿态估计任务中的时间依赖性建模。此外，作者使用扩张卷积来建模长期相关性，同时保持效率。 输入层获取每帧的个关节的级联坐标，并用具有卷积核大小为和的输出通道的时间卷积。接着是个由skip-connection包围的ResNet-style块。每个块首先执行卷积核大小为和膨胀因子为的1D卷积，接着执行卷积核大小为1的卷积。除了最后一层的卷积，其余卷积层后面都跟着batch normalization、ReLU和Dropout。 每个块都会使感受野以指数方式增长倍，而参数数量只会线性增加。设置滤波器超参数和使得任何输出帧的感受野形成包含所有输入帧的树，如图1所示。最后一层同时利用过去和未来的数据来利用时间信息为所有输入序列中的帧输出一个3D姿态预测。为了评估实时场景，本文还实验了因果卷积，即只能访问过去帧的卷积。 图2为该架构的一个实例，该架构的感受野为243帧，个块。卷积层设置个输出通道，dropout概率为。关键点个关节。其中绿色为卷积层，表示个输入通道，卷积核大小为3，扩张率为1，1024个输出通道。括号中的数字表示样本1帧预测的张量大小，表示243帧和34个通道。为了保证卷积运行的有效性，对残差（左右对称）进行切片以匹配后续张量的形状。 图2. 全卷积3D姿态估计架构实例 半监督方法 本文将未标记的视频与现成的2D关键点检测器相结合，以扩展具有反向投影损失项的监督损失函数。并解决了未标记数据的自编码问题。编码器（姿态估计器）利用2D关节坐标进行3D姿态估计，解码器（投影层）将3D姿态投影回2D关节坐标。当解码器投影的2D关节坐标远离原始输入坐标时，训练将受到惩罚。 图3为本文的方法，该方法将监督组件和非监督组件相结合，非监督组件充当正则化器。这两个目标是联合优化的，一个batch的前半部分是标记的数据，后半部分是未标记的数据。对于标记的数据，使用真实3D姿态作为目标，并训练监督损失。未标记的数据用于实现自编码器的损失，将预测的3D姿态投影回2D后检查与输入的一致性。 图3. 使用以预测的2D姿态序列作为输入的3D姿态模型进行半监督训练 轨迹模型 屏幕上的2D姿态取决于轨迹和3D姿态，即人类根关节的全局位置和其他关节相对于根关节的位置。如果没有全局位置，对象将始终以固定的比例重投影在屏幕中心。故本文还回归了人的3D轨迹，以便可以正确的执行到2D空间的反向投影。为此，本文优化了第二个网络，该网络回归了相机空间中的全局轨迹，并在将姿态投影回2D之前，将全局轨迹添加到姿态中。 轨迹模型和姿态估计模型具有相同的架构，但不共享任何权重，因为以多任务方式进行训练时，它们会对彼此产生负面影响。由于受试者距离相机越远，回归精确轨迹就越困难，所以本文为轨迹优化了一个加权平均每关节位置误差（WMPJPE）损失函数： 其中为相机空间中的真实深度，则上式即为使用该真实深度的倒数对每个样本进行加权。对本文来说，回归与相机距离较远对象的精确轨迹不是必要的，因为相应的2D关键点往往集中在一个小区域周围。 骨长度L2损失 本文希望鼓励模型对可能的3D姿态进行预测，而不是单纯的复制输入。为此，本文发现添加软约束是一个有效的方法，该约束使得未标记数据中受试者的平均骨长度与标记数据中受试者的大致匹配。该约束项在自监督中发挥着重要作用。 讨论 本文的方法只需要摄像机的固有参数，这些参数在通常的商业摄像机上均可获得。该方法不受任何特定网络架构的限制，可应用于任何以2D关键点为输入的3D姿态检测器。在上述提到的反向投影的过程中，使用了一个简单的投影层，该层考虑了线性系数（焦距、主点）和非线性透镜畸变系数（切向的和径向的）。虽然发现Human3.6M中使用的相机镜头失真对姿态估计的影响可以忽略不计，但本文的方法中仍包含了这些项，因为它们可以提供更加精确的真实相机投影建模。 实验设置 数据集和评价指标 本文使用了Human3.6M和HumanEva-I两个数据集。 本文实验考虑了三种评估协议： MPJPE，即平均每关节位置误差，这是预测关节位置和真实关节位置之间的平均欧几里德距离 P-MPJPE，即对数据进行平移、旋转、缩放后与真实位置对齐后的MPJPE N-MPJPE，即按比例将预测关节位置与真实关节位置对齐后的MPJPE 2D姿态估计的实现细节 大多数先前的工作从真实边界框中提取对象，然后应用基于堆叠沙漏网络的检测器来预测真实边界框内的2D关键点位置。而本文的方法不依赖于任何特定的2D关键点检测器。 作者研究了几种不依赖真实边界框的2D检测器，可以在户外场景中使用。作者研究了以ResNet-101-FPN作为backbone的Mask R-CNN，使用其在Detectron中的实现。以及FPN扩展的代表——级联金字塔网络（Cascaded Pyramid Network, CPN）。CPN实现需要外部提供边界框，在此情况下，本文使用了Mask R-CNN边界框 对于Mask R-CNN和CPN，从COCO上的预训练模型开始，并在Human3.6M的2D投影上微调检测器。 对于Mask R-CNN，作者采用ResNet-101作为backbone，并采用拉伸1倍（stretched 1x）的策略进行训练。在Human3.6M上微调时，作者重新初始化了关键点网络的最后一层，以及回归热图的去卷积层（deconvolution layer），以此来学习一组新的关键点。在4个GPU上以逐步衰减的学习率进行训练：先以1e-3的学习率迭代6万次，再以1e-4的学习率迭代1万次，最后以1e-5的学习率迭代1万次。推断阶段，在热图上使用softmax，并提取所得2D分布的预期值（soft argmax）。这将带来比hard-argmax更平滑、更精确的预测。 对于CPN，作者采用分辨率为的ResNet-50作为backbone。为了进行微调，作者重新初始化了GlobalNet和RefineNet的最终层（卷积权重和批量规范化统计）。在单个GPU上以32的批量大小和逐步衰减的学习率进行训练：先以5e-5的学习率迭代6千次，再以5e-6迭代4千次，最后以5e-7的学习率迭代2千次。作者在微调时启用了批量规范化（batch normalization）。使用真实边界框进行训练，并使用微调后的Mask R-CNN模型预测的边界框进行测试。 3D姿态估计的实现细节 为了和其他工作保持一致，作者在相机空间中进行3D姿态的训练和评估时仅根据相机变换旋转、平移真实姿态，而不使用全局轨迹（涉及半监督时除外）。 作者使用Amsgrad作为优化器，训练80轮。对于Human3.6M，使用指数衰减学习率策略，从开始，每个epoch的收缩因子均为 指数衰减学习率： 其中，为初始学习率，为收缩因子，为当前训练轮次，表示每轮衰减一次 所有时间模型，即感受野大于1的模型，对姿态序列中样本的相关性是敏感的。这将导致批量规范化中存在统计偏差，因为BN默认假设样本是独立的。作者在初步实验中发现，在训练期间预测大量相邻帧产生的结果比不利用时间信息的模型（在批处理中具有良好随机化的样本）更差。作者通过从不同的视频片段中选取训练clip来减少样本之间的相关性。clip集大小设置为本文架构的感受野宽度，以便模型预测每个训练clip的单个3D姿态。 可以通过用跨步卷积代替扩张卷积来极大的优化上述单帧场景，其中步幅设置为扩展因子（附录A.6）。这样可以避免未使用过的计算状态，并且仅在训练期间使用此优化。在推理时，可以处理整个序列，并重用其他3D帧的中间状态，以便更快地进行推理。这是可行的，因为本文的模型不在时间维度上使用任何的池化。为了避免帧丢失以及保证卷积的合法性，本文通过复制来进行填充，但只在序列的边界处进行这种填充。 作者观察到，批量规范化的默认超参数会导致测试误差的大幅波动，同时也会导致用于推断的运行时估计值的大幅波动。为了获得更稳定的运行时统计数据，作者为批量规范化的momentum参数制定了一个策略：从开始，并按指数衰减，使其在最后一个epoch达到。 最后，在训练和测试时执行水平翻转增强。 结果 时间扩张卷积模型 表1. Human3.6M数据集上的重建误差 表示该方法利用了时间信息；使用了真实边界框；使用了额外数据。粗体是最好的，下划线是第二好的。 有趣的是，真实边界框的性能与Mask R-CNN的预测边界框相似，这表明在本文的单帧场景中，预测几乎是完美的。 图4. 包括预测的2D关键点在内的预测姿势的示例 表2. 2D关键点检测器对最终结果的影响 (GT)表示ground-true；(SH)表示stacked hourglass，即堆叠沙漏网络；(D)表示Detectron；(CPN)表示cascaded pyramid network，即级联金字塔网络；(PT)表示pre-trained；(FT)表示fine-tuned，即微调过的 绝对位置误差不能测量预测随时间的平滑度，这对视频很重要。为了评估这一点，作者测量了与3D姿态序列的一阶导数的MPJPE相对应的关节速度误差（MPJVE）。 表3. 时间扩展卷积与单帧baseline的MPJVE对比 表3展示了时间扩展卷积与单帧baseline的MPJVE对比，相比提升了76%，从而使姿态更加平滑。 表4. HumanEva-I的结果 表4展示了HumanEva-I的结果，并且该模型推广到较小的数据集。结果基于预训练的Mask R-CNN 2D检测。本文的模型超越了当时的SOTA。 表5. 卷积模型和LSTM模型的复杂性对比 本文的最大模型具有243帧的感受野，其复杂度与该LSTM模型大致相同，但误差较低。该表还强调了扩张卷积的有效性，扩张卷积仅以对数方式增加了接受野的复杂性，详见表5。 由于本文的模型是卷积的，因此它可以在序列数量和时间维度上并行化，对于小批量来说效率要比RNN高得多。 半监督方法 本文将Human3.6M训练集的各种子集视为标记数据，剩余样本用作未标记数据。并将所有数据从50FPS降采样到10FPS。 由于数据集是下采样的，本文使用9帧的感受野，相当于上采样的45帧。对于非常小的子集使用3个帧。并仅在标记数据上微调CPN，通过在标记的数据上迭代几个epoch来预热训练。 图5a. 标记数据数量与半监督方法效果的关系（协议3下降采样到10FPS） 图5a显示，随着标记数据量的减少，本文的半监督方法变得更加有效 图5b. 协议1下对于数据集的非下采样版本（50 FPS）的结果 图5b中描述的设置更适合本文的方法，因为它允许模型利用视频中的全部时间信息，这里使用27帧的感受野。本文的半监督方法比监督基线提高了14.7mm MPJPE。 图5c. 将CPN 2D关键点切换为真实2D姿态 图5c证实了更好的2D检测可以提高性能。并且图中展示了移除了骨长度约束的半监督方法的效果（Ours semi-supervised GT abl.），结果显示删除该项会大大降低半监督训练的有效性。","link":"/posts/40498/"},{"title":"Vuex入门","text":"Vue生态中的又一员猛将Vuex，负责管理全局状态。 Vuex Vuex就相当于一个全局的状态管理，项目不复杂的情况下不建议引入Vuex vuex 由Vue Components分发一个Action，然后与后端进行交互，由Actions提交到Mutations，通过Mutations修改状态，这样修改可以通过Devtools记录下操作，再由State的改变渲染Vue Components 和路由类似，Vuex有一个全局的变量$store，利用该变量进行一系列操作 核心概念 state 定义全局变量 12345678export default createStore({ state: { num: 0, }, mutations: {}, actions: {}, modules: {}}) mutations 定义对state的操作 123456789101112131415export default createStore({ state: { dnum: 0, }, mutations: { sub(state) { state.dnum--; }, add(state) { state.dnum++; } }, actions: {}, modules: {}}) 调用mutations的方法时，应在组件内定义方法调用 1234567891011export default { name: 'Home', methods: { add1() { this.$store.commit('add'); }, sub1() { this.$store.commit('sub'); } }} 传参问题：组件向mutations传递参数 mutations的参数除state外只支持一个参数，所以： 传递单个参数直接传递 12345678910111213export default { name: 'Home', methods: { add2() { let count = 2; this.$store.commit('add2',count); }, sub2() { let count = 2; this.$store.commit('sub2',count); } }} 传递多个参数以对象的形式传递 12345678910111213141516171819export default { name: 'Home', methods: { add3() { let payload = { count: 2, num: 1, } this.$store.commit('add3', payload); }, sub3() { let payload = { count: 2, num: 1, } this.$store.commit('sub3', payload); }, }} Getter 全局的计算属性 12345678910111213export default createStore({ state: { num: 0, }, mutations: {}, getters: { vxnum(state) { return state.num * state.num; }, }, actions: {}, modules: {}}) 若想要在getters中定义的计算属性想要复用另一个getters中的计算属性，则： 1234567891011121314151617181920export default createStore({ state: { cartlist: [ {name: '《忒修斯之船》', price: 129}, {name: '《忒修斯之船2》', price: 139}, {name: '《忒修斯之船3》', price: 149}, ], }, mutations: {}, getters: { goodsnum(state) { return state.cartlist.filter(n =&gt; n.price &gt; 130); }, goodsprice(state, getters) { // 第二个参数传入getters return getters.goodsnum.reduce((s, n) =&gt; s + n.price, 0); } }, actions: {}, modules: {}}) 若想实现带参数的计算属性，则： 1234567891011121314151617181920212223export default createStore({ state: { cartlist: [ {name: '《忒修斯之船》', price: 129}, {name: '《忒修斯之船2》', price: 139}, {name: '《忒修斯之船3》', price: 149}, ], }, mutations: {}, getters: { goodsfilter(state) { // price处可以传多个参数 return function (price) { return state.cartlist.filter(n =&gt; n.price &gt; price); } // 简写 // return price =&gt; state.cartlist.filter(n =&gt; n.price &gt; price); } }, actions: {}, modules: {}}) Actions 处理异步请求 1234567891011121314151617181920212223import {createStore} from 'vuex'export default createStore({ state: { num: 0, }, mutations: { cnum(state) { state.num = 99; } }, getters: {}, actions: { demo(context) { // 操作 }, // 以解构的方式直接获取到context中的state等方法和属性 fun({state, commit, getters},payload) { // 操作 } }, modules: {}}) Action 函数接受一个与 store 实例具有相同方法和属性的 context 对象，因此你可以调用 context.commit 提交一个 mutation，或者通过 context.state 和 context.getters 来获取 state 和 getters。 Mudules 每个模块拥有自己的 state、mutation、action、getter、甚至是嵌套子模块 123456789101112131415161718export default createStore({ state: {}, mutations: {}, getters: {}, actions: {}, modules: { user: { state: () =&gt; ({ name: 'zhangsan', age: 100, }), getters: {}, mutations: {}, actions: {}, }, article: {}, }}) 也可以在外部定义 1234567891011121314151617181920const user = { state: () =&gt; ({ name: 'zhangsan', age: 100 }), mutations: {}, getters: {}, actions: {}, modules: {}}export default createStore({ state: {}, mutations: {}, getters: {}, actions: {}, modules: { user, }}) 注意调用子模块中的state时应为如下形式，模块相当于放在了state里面，而mutation、action、getter、不需要加模块名，所以这些中的方法名称不能重复 1{{ $store.state.user.name }} 子模块调用根模块的state如下，还可以通过rootGetters参数调用根模块的getters 1234567891011121314151617181920212223242526const user = { state: () =&gt; ({ name: 'zhangsan', age: 100 }), mutations: { setname(state, payload) { state.name = payload; } }, getters: { fullname(state) { return state.name + state.age; }, // 调用自身的其他getters fullname2(state, getters) { return getters.fullname + '222'; }, // 利用rootState参数调用根模块的state fullname3(state, getters, rootState) { return getters.fullname2 + rootState.num; } }, actions: {}, modules: {}} 可以根据需要将各个属性拆分成不同的js文件","link":"/posts/33216/"},{"title":"Vue模板语法","text":"Vue的模板语法及v-指令的基本用法。 options 123data &lt;!--数据--&gt;methods &lt;!--定义方法--&gt;computed &lt;!--计算属性--&gt; 计算属性的两种写法 12345678910computed: { prop: { get() { // 操作 }, set() { // 操作 }, }, }, 当属性只需要获取时简写为 12345computed: { prop() { // 操作 } }, 插值 1{{msg}} v-指令 v-pre：将不再渲染msg的内容，页面直接显示 1&lt;h1 v-pre&gt;{{msg}}&lt;/h1&gt; v-once：只引用一次变量的值，变量值的后续改变不会影响该引用 1&lt;h1 v-once&gt;{{num}}&lt;/h1&gt; v-text：指定显示的文本信息，使用该指令时标签中不可以有内容 12&lt;h1 v-text=&quot;Test&quot;&gt;&lt;/h1&gt;&lt;h1 v-text=&quot;Test&quot;&gt;content&lt;/h1&gt; content的位置不能有内容 v-html：若返回的变量中有html标签等，可以用该指令指定，能够自动渲染其中的html 1&lt;h1 v-html=&quot;url&quot;&gt;&lt;/h1&gt; v-bind：动态绑定属性，任何属性都可以绑定 12&lt;h2 v-bind:title=&quot;msg&quot;&gt;{{ msg }}&lt;/h2&gt;&lt;h2 :title=&quot;msg&quot;&gt;{{ msg }}&lt;/h2&gt; &lt;!--语法糖写法--&gt; v-on：绑定事件监听器 123&lt;button v-on:click=&quot;sub()&quot;&gt;-&lt;/button&gt;&lt;input type=&quot;text&quot; size=&quot;2&quot; v-model=&quot;num&quot;&gt;&lt;button @click=&quot;add&quot;&gt;+&lt;/button&gt; &lt;!--语法糖写法--&gt; 绑定事件调用函数时，若函数声明时有一个参数，调用时未传入参数，则该参数默认为事件监听对象；若函数声明时有多个参数，调用时需要用$event显式的将事件监听对象传入 v-on事件修饰符： .stop：阻止事件冒泡 .self：当事件在该元素本身触发时才触发事件 .capture：添加事件侦听器时，使用事件捕获模式，即优先捕获使用该修饰符的事件 .prevent：阻止默认事件 .once：事件只触发一次 v-if：条件分支 12345678910111213141516&lt;button @click=&quot;card=1&quot;&gt;①&lt;/button&gt;&lt;button @click=&quot;card=2&quot;&gt;②&lt;/button&gt;&lt;button @click=&quot;card=3&quot;&gt;③&lt;/button&gt;&lt;button @click=&quot;card=4&quot;&gt;④&lt;/button&gt;&lt;div v-if=&quot;card==1&quot;&gt; 111 &lt;br&gt;&lt;/div&gt;&lt;div v-else-if=&quot;card==2&quot;&gt; 222 &lt;br&gt;&lt;/div&gt;&lt;div v-else-if=&quot;card==3&quot;&gt; 333 &lt;br&gt;&lt;/div&gt;&lt;div v-else&gt; ### &lt;br&gt;&lt;/div&gt; v-if与v-show： v-if：是真正的条件渲染，它会确保在切换过程中条件块内的事件监听器和子组件适当被销毁和重建 v-show：不管初始条件是什么，元素总是会被渲染，只是简单的基于CSS进行切换 v-for：循环 注意要显式的绑定:key 123&lt;ul&gt; &lt;li v-for=&quot;item in list&quot; :key=&quot;item&quot;&gt;{{item}}&lt;/li&gt;&lt;/ul&gt; 可以利用slice()限制循环区间： 123&lt;ul&gt; &lt;li v-for=&quot;item in list.slice(0,3)&quot; :key=&quot;item&quot;&gt;{{item}}&lt;/li&gt;&lt;/ul&gt; 若需要数组下标： 123&lt;ul&gt; &lt;li v-for=&quot;(item,index) in list&quot; :key=&quot;item&quot;&gt;{{index}}-{{ item }}&lt;/li&gt;&lt;/ul&gt; 遍历对象时，键、值、下标都可以遍历 123&lt;ul&gt; &lt;li v-for=&quot;(item,key,index) in obj&quot; :key=&quot;item&quot;&gt;{{key}}-{{item}}-{{index}}&lt;/li&gt;&lt;/ul&gt; 遍历对象数组 123&lt;ul&gt; &lt;li v-for=&quot;(item,index) in books&quot; :key=&quot;item.id&quot;&gt;{{index}}-{{item.name}}-{{item.price}}&lt;/li&gt;&lt;/ul&gt; v-model：双向绑定，常与表单一起使用 1&lt;input type=&quot;text&quot; v-model=&quot;msg&quot;&gt; v-model修饰符： .lazy：懒加载 .number：让其转换为number类型 .trim自动过滤掉输入框的首尾空格","link":"/posts/37641/"},{"title":"Vue生命周期钩子详解","text":"Vue页面的生命周期及特殊方法$nextTick。 生命周期 123456789101112131415161718192021222324beforeCreate() { console.log(&quot;创建实例之前&quot;);},created() { console.log(&quot;实例创建完成&quot;);},beforeMount() { console.log(&quot;模板编译之前&quot;);},mounted() { console.log(&quot;模板编译完成&quot;);},beforeUpdate() { console.log(&quot;数据更新之前&quot;);},updated() { console.log(&quot;模板内容更新完成&quot;);},beforeUnmount() { console.log(&quot;实例销毁之前&quot;);},unmounted() { console.log(&quot;实例销毁完成&quot;);} 用&lt;keep-alive&gt;标签使组件缓存 123&lt;keep-alive&gt; &lt;MyConn&gt;&lt;/MyConn&gt;&lt;/keep-alive&gt; 与之相关的两个生命周期函数 123456activated() { console.log(&quot;缓存的组件激活时&quot;);},deactivated() { console.log(&quot;缓存的组件停用时&quot;);} 特殊方法$nextTick 该函数将回调延迟到下次DOM更新循环之后执行，可用在任何option及生命周期钩子中 12345activated() { this.$nextTick(() =&gt; { this.$refs.username.focus(); }) }, 在修改数据之后立即使用它，然后等待DOM更新","link":"/posts/27624/"},{"title":"axios前置知识","text":"学习axios必须的前置知识，包括RESTFul API规范、Promise的基本用法。 RESTFul API规范 GET (SELECT)：从服务器取出资源（一个或多个） POST (CREATE)：在服务器新建一个资源 PUT (UPDATE)：在服务器更新资源（客户端提供改变后的完整资源） PATCH (UPDATE)：在服务器更新资源（客户端提供改变的属性） DELETE (DELETE)：从服务器删除资源 Promise 基本原理 主要用于异步计算，可以将异步操作队列化，按照期望的顺序执行，返回符合预期的结果，可以在对象之间传递和操作promise，辅助我们处理队列 可以解决回调地狱的问题 基本语法 可以嵌套很多层 123456789101112131415new Promise((resolve,reject)=&gt;{ //第一层的Promise console.log(&quot;&quot;); if(statement){ resolve(&quot;success&quot;)//成功会调用这个 }else{ reject(&quot;fail&quot;)//失败会调用这个 }}).then(res=&gt;{//成功则进入这里 console.log(res); return new Promise((resolve,reject)=&gt;{//第二层的Promise resolve(&quot;success&quot;) })},err=&gt;{//失败则进入这个 console.log(err);}) 并发请求 12345678910Promise.all([ new Promise((resolve,reject)=&gt;{ resolve('first request') }), new Promise((resolve,reject)=&gt;{ resolve('second request') })]).then(res=&gt;{ console.log(res);});","link":"/posts/4623/"},{"title":"axios全局配置","text":"axios的两种配置方式，全局配置与按实例配置。 全局配置 将配置写入一个js文件中，在需要的地方引入该js文件即可 123axios.defaults.baseURL=&quot;http://127.0.0.1&quot;;axios.defaults.timeout=5000;axios.defaults.headers.post['content-type']='application/x-www-form-urlencoded'; 应用全局配置后url直接在baseURL基础上拼接即可 12345axios.get('xxx/xxx?id=1').then(res=&gt;{ console.log(res);}).catch(err=&gt;{ console.log(err);}) 按实例进行配置 若与全局配置共存，则优先使用实例配置 12345678910let request1 = axios.create({ baseURL:&quot;http://www.xxx.com/xxx&quot; timeout:5000})let request2 = axios.create({ baseURL:&quot;http://localhost/xxx&quot; timeout:3000}) 使用方式 123456789101112request1.get('xxx/xxx?id=1').then(res=&gt;{ console.log(res);}).catch(err=&gt;{ console.log(err);})request2.get('xxx/xxx?id=1').then(res=&gt;{ console.log(res);}).catch(err=&gt;{ console.log(err);})","link":"/posts/65179/"},{"title":"Vue组件化开发","text":"Vue组件化开发的思想及父子组件之间的通信方式，以及Vue中插槽的基本用法。 Vue组件 创建组件 123456789101112131415// 创建一个Vue 应用const app = Vue.createApp({})// 定义一个名为 button-counter 的新全局组件app.component('button-counter', { data() { return { count: 0 } }, template: ` &lt;button @click=&quot;count++&quot;&gt; You clicked me {{ count }} times. &lt;/button&gt;`}) 样式的传递 123456&lt;style&gt; 这里的内容可以传递到子孙组件&lt;/style&gt;&lt;style scoped&gt; 这里的内容仅能在本组件中使用&lt;/style&gt; 组件数据通信 父传子：Pass props 传递数据的父模块需要在标签中将数据以属性的形式传递 1&lt;MyMain msg=&quot;hello&quot;&gt;&lt;/MyMain&gt; 接收数据的子模块需利用props来接收 12345export default { name: &quot;MyMain&quot;, props: ['msg'], components: {MyConn}} 引用时利用插值引用即可 关于props： 如果传递的变量类型不同，需要以如下方式指定 1234props: { msg: {type: String}, article: {type: Array}, }, 用如下方式指定缺省值，即当没有数据传过来时的默认值 12345678910props: { msg: { type: String, default: '###', }, article: { type: Array, default: ['aaa', 'bbb', 'ccc'], }, }, 用如下方式要求属性必须传递 1234567props: { msg: {type: String,}, title: { type: String, required: true, }, }, 已经传递给子组件的数据，子组件还可以继续传给孙组件 子传父：$emit Event 在要传数据的子组件中绑定一个事件 1&lt;button @click=&quot;changenum(2)&quot;&gt;+&lt;/button&gt; 在方法中调用$emit方法，第一个参数为自定义的事件名，第二个参数为待传的数据 12345methods: { changenum(num) { this.$emit('mycountevent', num); }, }, 在接收数据的父模块中绑定自定义的事件 1&lt;MyConn @mycountevent=&quot;mydemo&quot;&gt;&lt;/MyConn&gt; 再利用自定义事件触发的方法使用数据 12345methods: { mydemo(data) { this.count += data; }, } 父子组件之间的访问 子组件调用父组件的方法：$parent或$root 父组件中的方法和数据 1234567891011data() { return { msg1: 'hello1', count: 0, } },methods: { changen() { this.count++; } }, 子组件中调用 123456methods: { one() { console.log(this.$parent.count); // 访问数据 this.$parent.changen(); // 访问方法 } }, 同样可利用该方法访问爷组件的方法和数据 12345methods: { one() { console.log(this.$parent.$parent.msg); // 访问数据 } }, 利用$root直接访问根组件 12345methods: { one() { console.log(this.$root.msg); // 访问数据 } }, 父组件调用子组件的方法：$children或$refs 子组件中的方法和数据 1234567891011data() { return { msg: 'This is a test.', num: 0 } },methods: { changeone() { this.num++; } }, 在父组件中给子组件标签定义ref属性 12&lt;MyConn ref=&quot;aaa&quot; @mycountevent=&quot;mydemo&quot;&gt;&lt;/MyConn&gt;&lt;button @click=&quot;two&quot;&gt;子加一&lt;/button&gt; 然后在父组件中利用$refs调用子组件方法和数据 123456methods: { two() { this.$refs.aaa.changeone(); // 方法 console.log(this.$refs.aaa.msg); // 访问数据 } } 在Vue3.x中删除了$children方法 $children的使用方式与$parent类似，只不过$children是利用数组的形式访问子组件，但数组的形式容易搞混子组件的顺序，且在插入新的子组件后数组序列会改变，所以不推荐使用该方式 插槽 实现组件的扩展性，抽取共性设计组件 子组件中添加&lt;slot&gt;标签占位 12345&lt;template&gt; &lt;div class=&quot;mybar&quot;&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt; 父组件调用子组件时可以在子组件内添加标签，多个标签也可以 123456789101112131415&lt;template&gt; SideBar &lt;MyBar&gt; &lt;button&gt;提交&lt;/button&gt; &lt;/MyBar&gt; &lt;MyBar&gt; &lt;a href=&quot;#&quot;&gt;提交&lt;/a&gt; &lt;/MyBar&gt; &lt;MyBar&gt; &lt;p&gt; &lt;span&gt;11&lt;/span&gt; &lt;span&gt;22&lt;/span&gt; &lt;/p&gt; &lt;/MyBar&gt;&lt;/template&gt;&lt;/template&gt; 还可以为设置插槽的缺省值，当父组件调用子组件且未在子组件标签内部添加标签时就会利用缺省值 1234567&lt;template&gt; &lt;div class=&quot;mybar&quot;&gt; &lt;slot&gt; &lt;button&gt;提交&lt;/button&gt; &lt;/slot&gt; &lt;/div&gt;&lt;/template&gt; 子组件中可以有多个插槽 123456&lt;template&gt; &lt;div&gt; &lt;slot&gt;&lt;/slot&gt; &lt;slot name=&quot;one&quot;&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt; 父组件调用时，若指定插槽名称，则会替换相同名称的插槽，若未指定名称，则只会替换掉没有名称的插槽 123456789101112&lt;!--指定名称替换--&gt;&lt;MyBar&gt; &lt;template v-slot:one&gt; &lt;a href=&quot;#&quot;&gt;提交&lt;/a&gt; &lt;/template&gt;&lt;/MyBar&gt;&lt;!--使用缺省值--&gt;&lt;MyBar&gt; &lt;template v-slot:default&gt; &lt;a href=&quot;#&quot;&gt;提交&lt;/a&gt; &lt;/template&gt;&lt;/MyBar&gt; 利用插槽给父组件传递数据 在子组件的插槽中，自定义一个属性 1&lt;slot :user=&quot;user&quot;&gt;&lt;/slot&gt; 父组件中获取，test接收了子组件中的自定义属性 123&lt;template v-slot:default=&quot;test&quot;&gt; &lt;a href=&quot;#&quot;&gt;{{ test.user.name }}&lt;/a&gt;&lt;/template&gt;","link":"/posts/61428/"},{"title":"axios封装","text":"封装自定义axios的方法。 创建js文件 创建一个js文件作为封装配置，引入axios 1import axios from &quot;axios&quot;; 创建一个axios实例进行自定义配置 1234const instance = axios.create({ baseURL: 'http://xxx.xxx', timeout: 5000,}) 各类请求封装 封装get 12345export function get(url, params) { return instance.get(url, { params })} 封装post 12345678910111213141516export function post(url, params) { return instance.post(url, params, { transformRequest: [ function (data) { let str = ''; for (let key in data) { str += encodeURIComponent(key) + '=' + encodeURIComponent(data[key]) + '&amp;'; } return str; } ], headers: { &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot; } })} 封装delete 123export function del(url) { return instance.delete(url)} 引用方式 在别的文件中引用 1import {方法名} from '封装js文件路径'","link":"/posts/30201/"},{"title":"axios基础","text":"axios的基本用法。 安装axios 1npm i axios -S 基础语法 默认使用get请求 1234axios('http://localhost/xxx/xxx') .then(res=&gt;{ console.log(res);}); 传参 get方法 1234567891011axios({ method:'get', // 指定请求方法 url:'http://localhost/xxx/xxx', params:{ username:'zhangsan', age:10, gender:'male' }}).then(res=&gt;{ console.log(res);}); post方法 1234567891011121314axios({ method:'post', // 指定请求方法 url:'http://localhost/xxx/xxx', headers:{ // 使用post请求必须改变content-type,否则将依然用url拼接方式传参 'content-type':'application/x-www-form-urlencoded' } data:{ // 并且数据要用data传,而不能用params username:'zhangsan', age:10, gender:'male' }}).then(res=&gt;{ console.log(res);}); 实际应用语法 get请求 1234567axios.get('http://localhost/xxx?username=zhangsan').then(res=&gt;{ console.log(res);});// 另一种传参方式axios.get('http://localhost/xxx',config:{params:{username='zhangsan'}}).then(res=&gt;{ console.log(res);}); post请求 123axios.post('http://localhost/xxx',data:&quot;username=zhangsan&quot;).then(res=&gt;{ console.log(res);}); 并发请求 结果存入数组 1234567891011axios.all([ axios.get('http://localhost/xxx?id=1'), axios.get('http://localhost/xxx?id=2'), axios.get('http://localhost/xxx?id=3'),]).then(res=&gt;{ console.log(res[0]); console.log(res[1]); console.log(res[2]);}).catch(err=&gt;{ console.log(err);}); 结果单独接收 12345678910111213axios.all([ axios.get(url:'http://localhost/xxx?id=1'), axios.get(url:'http://localhost/xxx?id=2'), axios.get(url:'http://localhost/xxx?id=3'),]).then( axios.spread((res1,res2,res3)=&gt;{ console.log(res1); console.log(res2); console.log(res3); }) ).catch(err=&gt;{ console.log(err);});","link":"/posts/63440/"},{"title":"Vue组合式API——CompositionAPI","text":"Vue组合式API，为了解决业务逻辑复杂度变高而生的神器。 Composition API（组合式API） 使用传统option配置方法写组件的时候，随着业务复杂度越来越高，代码量会不断加大，由于相关业务的代码需要遵循option的配置写到特定的区域，导致后续维护非常复杂，同时代码可复用性不高，而composition-api就是为了解决这个问题而生的。 Composition API是为了实现基于函数的逻辑复用机制而产生的，主要思想是，我们将它们定义为从新的setup函数返回的JavaScript变量，而不是将组件的功能（如state、method、computed等）定义为对象属性。 基本示例 原生Vue的实现形式 1234567&lt;template&gt; &lt;div class=&quot;home&quot;&gt; &lt;h3&gt;Count:{{ count }}&lt;/h3&gt; &lt;h3&gt;Double count:{{ double }}&lt;/h3&gt; &lt;button @click=&quot;add&quot;&gt;+&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; 1234567891011121314151617181920&lt;script&gt;export default { name: 'Home', data() { return { count: 0, } }, computed: { double() { return this.count * 2; } }, methods: { add() { this.count++; } }}&lt;/script&gt; 使用Composition API的实现形式 12345678&lt;template&gt; &lt;div class=&quot;about&quot;&gt; &lt;h3&gt;Count:{{ data.count }}&lt;/h3&gt; &lt;h3&gt;Double count:{{ data.double }}&lt;/h3&gt; &lt;button @click=&quot;add&quot;&gt;+&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; 123456789101112131415161718&lt;script&gt;import {reactive, computed} from 'vue'export default { setup() { const data = reactive({ count: 0, double: computed(() =&gt; data.count * 2), }); function add() { data.count++; } return {data, add}; }}&lt;/script&gt; setup()：Composition API的入口函数 setup()在beforeCreate()之前执行 12345678910111213141516171819202122export default { name: &quot;SubComp&quot;, data() { return { msg: 'Test message.' } }, props: { one: { type: String }, two: { type: String } }, // props是父组件传过来的数据，context是上下文 setup(props,context) { console.log('setup is called.'); console.log(this); console.log(props.one + props.two); },} context对象包含以下属性 12345678910const MyComponent = { setup(props,context){ context.attrs // 父组件传过来的属性，即使没有用props声明也可以访问 context.slots // 获取父组件传进来的插槽内容 context.parent context.root context.emit // 向父组件传递数据 context.refs }} 常用API ref()函数用来为给定的值创建一个响应式的数据对象，ref()的返回值是一个对象，这个对象只包含一个.value属性 12345678910111213export default { name: &quot;CommonAPI&quot;, setup() { let num2 = ref(22); let myfun2 = (newvalue) =&gt; { num2.value = newvalue; } return { num2, myfun2 } }} reactive()声明对象类型的响应式数据 1234567891011121314export default { name: &quot;CommonAPI&quot;, setup() { let user = reactive({ name: 'zhangsan', age: 100, sex: '男' }); return { user } }} toRefs()将对象的数据成员拆解成单独的变量，并变成响应式的 1234567891011121314export default { name: &quot;CommonAPI&quot;, setup() { let user = reactive({ name: 'zhangsan', age: 100, sex: '男' }); return { ...toRefs(user), // 三个点表示将对象拆解成单独的变量 } }} readonly()将响应式数据变为原生数据 12345678910111213141516export default { name: &quot;CommonAPI&quot;, setup() { let user = reactive({ name: 'zhangsan', age: 100, sex: '男' }); let user2 = readonly(user); return { user2 } }} isRef()判断该变量是否为响应式变量 123456789101112export default { name: &quot;CommonAPI&quot;, setup() { let num2 = 1; let num3 = isRef(num2) ? num2.value : num2 ; return { num2, num3 } }} 计算属性 123456789101112131415161718export default { name: &quot;Computed&quot;, setup() { const user = reactive({ firstname: 'san', lastname: 'zhang' }); let fullname = computed(() =&gt; { return user.firstname + '·' + user.lastname; }); return { ...toRefs(user), fullname } }} 侦听器watch 1234567891011121314151617181920212223242526272829303132333435363738394041424344export default { name: &quot;Watch&quot;, setup() { let a = ref(1); let b = ref(2); // 只写回调会初始化执行 // 函数内部用到哪个变量就会监听哪个变量 watch(() =&gt; { console.log(a.value + '---' + b.value); }); //写一个参数则会监听指定的变量 // 不会初始化执行 watch(a, () =&gt; { console.log('a changed'); }); //若想初始化执行，则加入第三个参数 watch(a, () =&gt; { console.log('a changed'); }, {immediate: true}); // 还可以传入两个参数获取变化前后的 watch(a, (newA, oldA) =&gt; { console.log('A changed from ' + oldA + ' to ' + newA); }, {immediate: true}); // 也可以监听多个值及其变化 watch([a, b], ([newA, newB], [oldA, oldB]) =&gt; { console.log('A changed from ' + oldA + ' to ' + newA); console.log('B changed from ' + oldB + ' to ' + newB); }, {immediate: true}); // 立即执行传入的函数，并响应式追踪其依赖，并在其依赖变更时重新运行该函数 watchEffect(() =&gt; { console.log(a.value + '###' + b.value); }); return { a, b } }} 若要监听对象类型的变量 123456789101112131415161718192021222324252627282930export default { name: &quot;Watch&quot;, setup() { const user = reactive({ a: 1, b: 2 }); watch(user, () =&gt; { console.log('User changed'); }); watch(() =&gt; user.a, (newx, oldx) =&gt; { console.log('User.a changed from ' + newx + ' to ' + oldx); }); watch([() =&gt; user.a, () =&gt; user.b], ([newA, newB], [oldA, oldB]) =&gt; { console.log('User.a changed from ' + newA + ' to ' + oldA); console.log('User.b changed from ' + newB + ' to ' + oldB); }); watchEffect(() =&gt; { console.log(user.a) }); return { ...toRefs(user), } }} Composition API中的生命周期函数 原生生命周期函数与Composition API之间的映射关系 beforeCreate→setup() created→setup() beforeMount→onBeforeMount() mounted→onMounted() beforeUpdate→onBeforeUpdate() updated→onUpdated() beforeUnmount→onBeforeUnmount() Unmounted→onUnmounted() 使用时要注意，是以回调方法的形式调用的 12345678export default { name: &quot;LifeHook&quot;, setup() { onBeforeMount(() =&gt; { console.log('onBeforeMount'); }); },} provide和inject的使用 provide和inject这对选项允许祖先组件向其所有子孙后代组件注入一个依赖，不论组件层次有多深，在其上下游关系成立的时间内始终生效 provide提供变量，相当于加强版父组件prop，可以跨越中间件 inject注入变量，相当于加强版子组件props 原生Vue方式 祖先组件 1234567891011121314export default { name: &quot;RootApp&quot;, components: {SecondApp}, data() { return { title: &quot;The information is provided by root component.&quot; } }, provide() { return { title: this.title, } },} 子孙组件 1234export default { name: &quot;ThirdApp&quot;, inject: ['title'],} 这种方式传递的变量不是响应式的 Composition API方式 祖先组件 12345678910111213export default { name: &quot;RootApp&quot;, components: {SecondApp}, setup() { let info = ref('The information is provided by root component through setup.'); provide('info', info); return { info, } }} 子孙组件 12345678910export default { name: &quot;ThirdApp&quot;, setup() { let info = inject('info'); return { info, } }} 这种方式传递的变量是响应式的，而且是双向的响应式，即在祖先组件中更改变量，子孙组件中会发生变化；在子孙组件中更改变量，祖先组件中也会发生变化 Composition API处理路由 因为无权访问setup()中的this，故使用useRouter()和useRoute()函数 1234567891011121314151617export default { name: &quot;Page&quot;, setup() { const route = useRoute(); const router = useRouter(); let id = ref(); watch(() =&gt; route.params, (newId) =&gt; { id.value = newId.id; }, {immediate: true}) return { id, } }} 组件级的导航守卫则替换为： onBeforeRouteLeave((to,from)=&gt;{}) onBeforeRouteUpdate(async(to,from)=&gt;{}) 12345678export default { name: &quot;Page&quot;, setup() { onBeforeRouteLeave((to, from) =&gt; { return window.confirm(`确定要从${from.fullPath}到${to.fullPath}`); }); }} Composition API结合Vuex 使用useStore()函数 12345678910111213export default { name: &quot;Vuex&quot;, setup() { const store = useStore(); return { num2: computed(() =&gt; store.state.num2), double2: computed(() =&gt; store.getters.double2), cnum2: (newnum) =&gt; store.commit('changenum2', newnum), cnum22: () =&gt; store.dispatch('timecnum2'), } }}","link":"/posts/12922/"},{"title":"axios拦截器","text":"axios的请求拦截器和响应拦截器。 请求拦截器 1234567// 可以为配置好的实例单独配置拦截器axios.interceptors.request.use(config=&gt;{ console.log(&quot;请求拦截成功，处理，放行&quot;); return config;},err=&gt;{ console.log(err);}); 响应拦截器 1234567// 可以为配置好的实例单独配置拦截器axios.interceptors.response.use(config=&gt;{ console.log(&quot;响应拦截成功，处理，放行&quot;); return config;},err=&gt;{ console.log(err);});","link":"/posts/4512/"},{"title":"hexo集成LaTex数学公式解决方案","text":"hexo集成LaTex数学公式所需要的依赖，还有一些注意事项。 hexo集成LaTex数学公式解决方案 在hexo博客根目录下打开Git Bash 步骤一 卸载默认渲染器 1npm uninstall hexo-renderer-marked 卸载hexo-math（如果之前没有安装可以跳过这步） 1npm uninstall hexo-math 步骤二 安装pandoc 1npm install hexo-renderer-pandoc --save 利用npm安装完成后还需要在电脑本地安装pandoc 官方网站：:link:Pandoc 安装完成后记得重启电脑，否则pandoc会在执行hexo g的时候报错 步骤三 安装mathjax 1npm install hexo-filter-mathjax --save 步骤四 在想要渲染LaTex公式的md文件头部加入配置项：mathjax: true即可 LaTex公式语法参考：:link:LaTex公式指导手册","link":"/posts/47466/"},{"title":"hexo集成gitalk时Error: Validation Failed问题","text":"Hexo集成Gitalk后，某些文章下方的评论显示Error: Validation Failed的原因及解决方案。 Hexo集成Gitalk的问题 集成Gitalk后进入博客发现有些页面下方的评论显示Error: Validation Failed. 原因：Gitalk会限制Label name的长度，有些文章生成的URL长度会超过限制，所以导致这个问题 解决方案 可以集成一个对文章生成唯一id的插件 hexo-abbrlink 在博客根目录下安装 1npm install --save hexo-abbrlink 并修改配置文件_config.yml 1permalink: [EveryWordsYouWant]/:abbrlink/ 生成的链接类似于： 1https://deleter-d.github.io/[EveryWordsYouWant]/30201/ hexo-uuid 这个插件也是同理的 在博客根目录下安装 1npm install --save hexo-uuid 并修改配置文件_config.yml 1permalink: [EveryWordsYouWant]/:uuid/","link":"/posts/64660/"},{"title":"npm常用命令","text":"npm换源命令，安装、更新模块命令等常用命令 换源 换源命令 1npm config set registry https://registry.npm.taobao.org 检查是否成功 1npm config get registry 常用命令 安装 1npm install &lt;Module Name&gt; 全局安装 1npm install &lt;Module Name&gt; -g 查看所有全局安装的模块 1npm list -g 查看某个模块的版本号 1npm list &lt;Module Name&gt; 更新模块版本 1npm install &lt;Module Name&gt;@&lt;version&gt; -g 在package文件的dependencies节点写入依赖，即运行时依赖 12npm install -save &lt;Module Name&gt;npm i &lt;Module Name&gt; -S # 简写 在package文件的devDependencies节点写入依赖，即开发时依赖 12npm install -save-dev &lt;Module Name&gt;npm i &lt;Module Name&gt; -D # 简写","link":"/posts/34123/"},{"title":"package.json配置文件详解","text":"有关package.json配置文件的简单解释，方便理解配置文件所配置的内容。 scripts指定运行的脚本 12345&quot;scripts&quot;:{ &quot;test1&quot;:&quot;命令1&quot;, &quot;test2&quot;:&quot;命令2&quot; # 使用npm run test1 即可运行命令1} dependencies中指定运行时依赖 12345&quot;dependencies&quot;:{ &quot;jquery&quot;:&quot;^3.5.1&quot;, # ^表示每次运行npm install时会更新后两位版本号 &quot;bootstrap&quot;:&quot;~4.5.3&quot;, # ~表示每次运行npm install时会更新最后一位版本号 &quot;layui&quot;:&quot;2.0.3&quot; # 不加符号则固定为这个版本}","link":"/posts/49919/"},{"title":"csv文件对于不同形状张量的存储与解析","text":"关于同一个csv文件存储和解析不同形状张量的问题，看似简单，暗坑很多。 csv文件对于不同形状张量的存储与解析 起因 最近写项目测试的时候，发小有一个小的需求，需要将不同形状的张量存入同一个文件中，同时需要记录其形状信息，从而方便算子的测试。但由于numpy中的savetxt等方法都要求张量形状一致，所以没办法直接使用。 一开始想的比较简单，使用csv文件来存储，分四列数据，前三列记录三个维度的形状信息，最后一列将整个张量存储下来。但实际开始写之后才发现，其中有一些问题处理起来比较麻烦，特此记录一下。 初步尝试 生成数据的代码比较简单，使用numpy随机生成一个张量，不仅张量中的数据是随机的，张量本身的形状也是在一定范围内随机生成的。 123456def generateData3D(shape_limit, dtype): dim0 = randint(1, shape_limit[0] + 1) dim1 = randint(1, shape_limit[1] + 1) dim2 = randint(1, shape_limit[2] + 1) data = randn(dim0, dim1, dim2).astype(dtype) return (dim0, dim1, dim2, data) 这个函数返回一个元组，前三个元素记录形状，最后一个元素是张量本身。然后写一个简单的批量数据生成代码。 1234567def generateDataset(filepath, count, shape_limit, dtype): with open(filepath, \"w\", encoding=\"utf-8\") as file: writer = csv.writer(file, delimiter=\",\") writer.writerow([\"dim0\", \"dim1\", \"dim2\", \"data\"]) for i in trange(count): data = generateData3D(shape_limit, dtype) writer.writerow(data) 问题出现 看起来没有任何问题，调用它来生成文件。 1generateDataset(\"test.csv\", 10, (8, 8, 320), \"float32\") 这里的意思是生成10个张量，每个张量的形状最大为(8, 8, 320)，每一个维度都是0到该数之间的一个随机整数，数据类型是float32。我们来看看生成的csv文件的内容，这里只取有问题的一部分展示。 123456789101112135,3,110,\"[[[-8.6134362e-01 3.6351961e-01 -1.4064503e-01 ... -8.0155706e-01 7.4856186e-01 3.2745436e-01] [-1.4208823e+00 4.2760447e-01 -7.0980674e-01 ... 3.3898675e-01 1.9081663e-01 1.2164949e-01] [ 2.0867598e+00 -2.5110641e-01 -7.9451543e-01 ... -9.6020055e-01 9.4596267e-01 1.8399478e-01]] [[-7.6276101e-02 1.0084456e+00 -5.4734468e-01 ... 7.9609489e-01 -2.9747225e-02 3.6186981e-01] [ 1.6717568e-01 -2.7845892e-01 -6.9172156e-01 ... -7.8677136e-01 4.0880820e-01 1.1563424e-01] [ 1.2279550e+00 2.7903655e+00 3.3148596e-01 ... -1.0443866e+00 -1.7026719e-01 -7.7582508e-01]] 会发现生成的csv文件中出现了省略号，这是numpy在输出张量的时候为了美观做的处理，但当他被解析为字符串后，数据信息就丢失了。这一点比较好处理，只需要令numpy完整输出整个张量即可，我们修改generateDataset函数。 12345678def generateDataset(filepath, count, shape_limit, dtype): np.set_printoptions(threshold=np.inf) # 注意添加这一句 with open(filepath, \"w\", encoding=\"utf-8\") as file: writer = csv.writer(file, delimiter=\",\") writer.writerow([\"dim0\", \"dim1\", \"dim2\", \"data\"]) for i in trange(count): data = generateData3D(shape_limit, dtype) writer.writerow(data) 上述问题就得到了解决。 文件解析 到此我以为这个需求已经实现了，只需要再写一个解析csv文件的函数就好了，于是我写了如下函数。 12345678def loadFromFile(filepath, shape_limit, dtype): data = [] with open(filepath, \"r\", encoding=\"utf-8\") as file: reader = csv.reader(file, delimiter=\",\") next(reader) for row in reader: data.append(row) return data 我们调用它来读取刚才生产的文件。 12data = loadFromFile(\"test.csv\", (8, 8, 320), \"float32\")print(data[0]) 这里只输出第一条记录，下面展示一部分。 1['4', '3', '216', '[[[ 3.38217378e-01 8.90219882e-02 2.17747045e+00 1.05902016e+00\\n -1.54809088e-01 -1.73685062e+00 2.45146394e-01 -8.57644677e-01\\n 2.61454940e+00 -5.65550804e-01 -6.17945969e-01 -2.49281359e+00\\n -1.82697034e+00 -2.62623811e+00 6.89034387e-02 1.78881836e+00\\n -9.63348448e-02 -2.35723400e+00 9.03523326e-01 -1.08545446e+00\\n ...... 这里发现输出的张量中有一些换行符，这是由于numpy格式化输出张量带来的后果，一开始我并没有觉得这是个问题，以numpy的强大能力，应该可以就这样将这个张量解析出来。 问题又出现 这里使用type函数查看从文件中读出来的张量的真实类型，即type(data[0][3])，发现是&lt;class 'str'&gt;，然后我做了如下尝试。 1np.fromstring(data[0][3], dtype=np.float32) 但是报如下错误。 1ValueError: string size must be a multiple of element size 经过一通查询，原来np.fromstring是根据dtype来解析字符串的，它要求字符串的大小必须是元素个数的整数倍。但在我们存文件的时候会发现，有些数字是科学计数法存入的，有些数是普通的浮点数形式。对于字符串来说，每个数字映射后的字符串长度显然不一定是float32类型的4字节，所以解析的时候肯定会出问题。（PS. 又一个因为numpy格式化输出带来的问题。） 到此遇到的两个问题都是因为numpy的格式化输出引起的，所以我就尝试令numpy不要格式化输出，但在搜索了很多资料后我放弃了这个想法。（可能是我粗心没找到解决方案。） 后来换了一种思路来解决这个问题，我尝试先将这个读取出来的字符串解析成python的list，然后再用这个list来初始化一个numpy张量，从而供其他地方使用，于是进行了如下尝试。 1ast.literal_eval(data[0][3]) 但执行会报如下错误。 123 [[[ 3.38217378e-01 8.90219882e-02 2.17747045e+00 1.05902016e+00 ^SyntaxError: invalid syntax 查询了很多资料，都没有说明这个问题是什么引起的。但在查询资料的过程中发现，别人在调用这个函数的时候，字符串都是以逗号隔开的一系列数字。这里由于numpy的格式化输出，是用空格隔开的，中间还有很多换行符。（again！） 于是我尝试令numpy输出的数据以逗号隔开，找了很多numpy中的写文件函数，均由于各种限制无法实现我的需求。所以在存文件的时候尝试将numpy数组先转换为字符串后，在写入文件。因为numpy的array2string函数是支持指定元素分隔符的，故我们改进generateData3D函数。 1234567def generateData3D(shape_limit, dtype): dim0 = randint(1, shape_limit[0] + 1) dim1 = randint(1, shape_limit[1] + 1) dim2 = randint(1, shape_limit[2] + 1) # 注意下面这句的修改 data = np.array2string(randn(dim0, dim1, dim2).astype(dtype), separator=\",\") return (dim0, dim1, dim2, data) 重新生成文件后，再次尝试将该字符串解析为list，这次成功解析了！ 1[[[0.0282006636, -0.705630183, 0.205503568, 0.10408926, -0.130971402, -0.0346300565, 1.86623621, 1.35530257, -0.83048594, 1.27699852, -0.725055277, -0.514897704, 0.423814148, 1.65991676, -0.527909875, -0.678127706, -0.269491076, -1.05497122, 0.670092762, 1.45376074, 1.53001487, -0.844848216, 0.337865025, -0.144725695, -0.4941248, 0.819156349 ...... 我们再进一步尝试将该list转为numpy张量。 1np.array(ast.literal_eval(data[0][3])).astype(np.float32) 打印该数组。 123456[[[ 0.02820066 -0.7056302 0.20550357 ... 0.01451482 -2.1041124 1.8852443 ]] [[-0.05282624 0.5842251 0.70602226 ... -0.14502124 2.547757 0.28345433]] [[-0.01983055 -0.5919099 -0.9039266 ... -1.7636172 -1.9037529 -1.0482264 ]] 发现已经变成了numpy张量的格式化输出，再查看其类型和形状进一步确认有没有问题。 12&lt;class 'numpy.ndarray'&gt;(6, 1, 264) 类型与生成的数据中记录下来的一致，问题应该是解决了。 进一步优化 写到这里，回头看看可以发现，记录下来的形状信息其实并没有用到。因为在将字符串解析为list的时候，形状的信息自然的保留了下来。所以我们将存储形状信息的代码去掉，让这个csv文件只存储张量本身。 123456def generateData3D(shape_limit, dtype): dim0 = randint(1, shape_limit[0] + 1) dim1 = randint(1, shape_limit[1] + 1) dim2 = randint(1, shape_limit[2] + 1) data = np.array2string(randn(dim0, dim1, dim2).astype(dtype), separator=\",\") return (data,) # 注意这里返回的依然是一个元组 12345678def generateDataset(filepath, count, shape_limit, dtype): np.set_printoptions(threshold=np.inf) with open(filepath, \"w\", encoding=\"utf-8\") as file: writer = csv.writer(file, delimiter=\",\") # 这里就直接写入数据了，没有写表头 for i in trange(count): data = generateData3D(shape_limit, dtype) writer.writerow(data) 在读取数据的时候做一些相应处理即可。 1234567891011def loadFromFile(filepath, shape_limit, dtype): data = [] csv.field_size_limit(sys.maxsize) with open(filepath, \"r\", encoding=\"utf-8\") as file: reader = csv.reader(file, delimiter=\",\") for row in reader: data.append(row) result = [] for item in data: result.append(np.array(ast.literal_eval(item[0]), dtype=dtype)) return result 这样读取出来的数据就是一个list，其中的每个元素都是一个numpy.ndarray。最后再写一个生成算子真值的函数。 1234567891011121314def generateGolden(output_file, input_file, dtype): np.set_printoptions(threshold=np.inf) input = tqdm(loadFromFile(input_file, dtype)) softmax = Softmax() with open(output_file, \"w\", encoding=\"utf-8\") as file: writer = csv.writer(file, delimiter=\",\") for item in input: # 获取到的张量转换为mindspore的张量进行运算 golden = softmax(ms.Tensor(item, dtype=ms.float32)) # 转回numpy张量 golden = golden.asnumpy() # numpy数组转字符串 golden = np.array2string(golden.astype(dtype), separator=\",\") writer.writerow((golden,)) 其中加了一些tqdm的内容，输出信息丰富一些。 完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import csvimport astimport sysimport argparsefrom tqdm import trange, tqdmimport numpy as npfrom numpy.random import randint, randnimport mindspore as msfrom mindspore.nn import Softmaxdef generateData3D(shape_limit, dtype): dim0 = randint(1, shape_limit[0] + 1) dim1 = randint(1, shape_limit[1] + 1) dim2 = randint(1, shape_limit[2] + 1) data = np.array2string(randn(dim0, dim1, dim2).astype(dtype), separator=\",\") return (data,)def generateDataset(filepath, count, shape_limit, dtype): np.set_printoptions(threshold=np.inf) with open(filepath, \"w\", encoding=\"utf-8\") as file: writer = csv.writer(file, delimiter=\",\") for i in trange(count): data = generateData3D(shape_limit, dtype) writer.writerow(data)def loadFromFile(filepath, dtype): data = [] csv.field_size_limit(sys.maxsize) with open(filepath, \"r\", encoding=\"utf-8\") as file: reader = csv.reader(file, delimiter=\",\") for row in reader: data.append(row) result = [] for item in data: result.append(np.array(ast.literal_eval(item[0]), dtype=dtype)) return resultdef generateGolden(output_file, input_file, dtype): np.set_printoptions(threshold=np.inf) input = tqdm(loadFromFile(input_file, dtype)) softmax = Softmax() with open(output_file, \"w\", encoding=\"utf-8\") as file: writer = csv.writer(file, delimiter=\",\") for item in input: # 获取到的张量转换为mindspore的张量进行运算 golden = softmax(ms.Tensor(item, dtype=ms.float32)) # 转回numpy张量 golden = golden.asnumpy() # numpy数组转字符串 golden = np.array2string(golden.astype(dtype), separator=\",\") writer.writerow((golden,))if __name__ == \"__main__\": parser = argparse.ArgumentParser(description=\"data generation.\") parser.add_argument( \"--input-filename\", type=str, default=\"input_data.csv\", help=\"set the filename of input data.\", ) parser.add_argument( \"--shape-limit\", nargs=\"+\", type=int, default=(32, 32, 320), help=\"the largest amount of each dimension.\", ) parser.add_argument( \"--data-amount\", type=int, default=100, help=\"the amount of input data.\", ) parser.add_argument( \"--dtype\", type=str, default=\"float32\", help=\"the data type of input data.\", ) parser.add_argument( \"--golden-filename\", type=str, default=\"golden_data.csv\", help=\"set the filename of golden data.\", ) args = parser.parse_args() input_filename = args.input_filename golden_filename = args.golden_filename data_amount = args.data_amount dtype = args.dtype shape_limit = tuple(args.shape_limit) ms.set_context(device_target=\"Ascend\", device_id=4) print(f\"input filename: {input_filename}\") print( f\"\\twill generating {data_amount} {dtype} input data with random shape less than {shape_limit}\" ) print(\"generating...\") generateDataset( input_filename, data_amount, shape_limit, dtype, ) print(f\"golden filename: {golden_filename}\") print(\"generating...\") generateGolden(golden_filename, input_filename, dtype) print(\"all done.\")","link":"/posts/18632/"},{"title":"内积空间","text":"矩阵分析简明教程第2章笔记 1. 内积与欧式空间 1.1 内积与实内积空间 定义 设是实数域上的线性空间 若存在唯一的实数与之对应 由此所定义的二元映射满足 则称为与的内积(inner product)，为实内积空间，也称欧氏空间(Euclidian space) 线性空间 定义内积 则是经典欧氏空间 给定n阶实正定阵A，定义内积 则是此内积下的欧氏空间 性质 1.2 向量的范数 定义 设是欧氏空间，称为向量的范数(norm)，长度或模 定理 向量范数满足 ，等号成立当且仅当线性相关 上述第四条就是Cauchy-Schwarz不等式，具体形式有 1.3 向量的夹角 由Cauchy-Schwarz不等式可知 定义 向量与夹角定义为 1.4 向量的正交 定义 向量与若满足，则称与正交，记为 定理 若向量与正交，则 即勾股定理 推论：向量与满足 2. 欧氏空间的正交基 2.1 标准正交基 正交向量组定义 设向量是欧式空间的一组非零向量 若它们两两正交 则称其为一个正交向量组 正交向量组定理 正交向量组必定线性无关 正交基定义 设向量是欧式空间的一组基 若它们两两正交 则称其为的一个正交基(orthogonal basis) 标准正交基定义 设向量是欧式空间的一组基 若它们两两正交，且每个向量均为单位向量 则称其为的一个标准正交基(orthonormal basis) 向量组是的标准正交基当且仅当 定理(向量的Fourier展开式) 设向量组是欧氏空间得到一组标准正交基 则对任意的，有 其中称之位Fourier系数 为向量在方向上的投影 Fourier级数 设是上平方可积的函数空间 定义内积 为的标准正交基 2.2 标准正交基之间的过度矩阵 定理 维欧氏空间中，任意两个标准正交基之间的过度矩阵是正交矩阵 2.3 Gram-Schmidt正交化过程 定理 设是欧氏空间中的一组线性无关组，则 是一组与等价的正交向量组 Gram-Schmidt正交化将线性无关组转化为与之等价的正交向量组 2.4 标准正交基的存在性 定理 维欧氏空间必存在标准正交基 求标准正交基的步骤 选取的一组基 正交化后得正交基 单位化后得标准正交基 和标准正交基之间有： 欧氏空间的标准正交基不唯一 3. 欧氏空间的同构 定义 设是欧氏空间到的一一映射，若 则称是到的同构映射(isomorphism)，且称与是同构的(isomorphic) 设是欧氏空间的标准正交基， 映射是到的同构映射 定理 任何维欧氏空间都与同构 任何两个维欧氏空间同构 4. 正交补 4.1 正交 向量与集合正交的定义 设是欧氏空间的子集， 若，有 则称向量与集合正交，记为 集合与集合正交的定义 设是欧氏空间的两个子集 若，有 则称集合与正交，记为 定理 设是子空间的基 则 4.2 正交补 定义 设是欧氏空间的子集，称为的正交补(orthogonal completion) 定理 设是欧氏空间的子集，则为子空间 设是有限维欧氏空间的子空间，则 设是欧氏空间的标准正交基，且是子空间的基，则是的基 4.3 正交投影 定义 设是有限维欧氏空间的子空间， 对的向量，存在唯一分解 则称向量为在上的正交投影(projection) 定理 设是欧氏空间的子空间， 若是在上的正交投影 则 向量成为在上的最佳逼近 4.4 最小二乘解 设有不相容的线性方程组，即 求数组使得 最小，这组数称为的最小二乘解，该方法称为最小二乘法(Least Square Method) 解法(最小二乘法)：正交投影的应用 令 设 则，且 问题转化为寻找向量使得为到的最短距离 根据正交投影定理，为在上的投影，从而，即 上述红色部分即为最小二乘解满足的充要条件 5. 正交变换 线性变换定义 设是数域上的线性空间，映射，满足 则称映射是线性变换(transformation) 正交变换定义 设是欧氏空间上的线性变换，若满足 则称是上的正交变换(orthogonal transformation) 定理 设是维欧氏空间上的线性变换，以下命题等价： 是上的正交变换 保持向量范数不变，即 保持标准正交基不变，即若为的标准正交基，则为标准正交基 在标准正交基下的矩阵为，则是正交阵，即 6. 复内积空间与酉变换 6.1 复内积空间 定义 设是复数域上的线性空间 若，存在唯一的复数与之对应 由此所定义的二元映射满足 则称为与的内积，为复内积空间，也称之为酉空间(Unitary space) 实内积空间和复内积空间的对比 在实内积空间中在复内积空间中 6.2 复内积空间和实内积空间类似的概念 称为向量的长度，记为 定义向量与正交，若 Cauchy-Schwarz不等式成立 Gram-Schmidt正交化把线性无关组化为正交向量组 有限维复内积空间必存在标准正交基 6.3 酉变换 酉变换定义 设是复内积空间中的线性变换 若满足 则称为上的酉变换 酉矩阵定义 若矩阵满足 则称为酉矩阵 称为矩阵的共轭转置 如果是欧氏空间，则酉变换即为正交变换 实正交矩阵为酉矩阵 7. 正规矩阵与正规变换 7.1 正规矩阵与正规变换 正规矩阵定义 设是复方阵，且 则称为正规矩阵(normal matrix) 下列矩阵都是正规阵 实对称阵实反对称阵矩阵反矩阵正交矩阵酉矩阵 正规变换定义 若线性变换在一组标准正交基下的矩阵为正规矩阵 则称线性变换是正规变换(normal transformation) 正规矩阵和正规变换是一一对应的关系 定理 设是复方阵，则为正规矩阵当且仅当存在酉矩阵 使得酉相似于对角阵，即 其中是的特征值 设为正规矩阵 为Hermite矩阵的特征值均为实数 为反Hermite矩阵的特征值均为0或纯虚数 为酉矩阵的特征值的模为1 7.2 矩阵的奇异值 定理 设为的复矩阵，则和满足 和均为半正定的Hermite矩阵 和具有相同的非零特征值 为半正定的Hermite矩阵 可以定义其平方根为满足的半正定Hermite矩阵，记为 为阶方阵，其特征值为 其中： 为的非零特征值 为的秩，即 定义 设为的复矩阵 则阶矩阵的特征值称为矩阵的奇异值(singular value)","link":"/posts/17412/"},{"title":"关于vec_cross_add接口的详细测试","text":"先说结论，问题出在我粗心了，磕头道歉！！本接口没有计算逻辑性问题，为上篇中不严谨的言论道歉。但在特定情况下，会有不符合预期的返回值。 关于vec_cross_add接口的详细测试 之前在写Softmax算子的时候，碰到了该接口结果不稳定的情况，所以进行一次详细测试，看看问题出在哪里。 测试方案 先用标准C++实现一个求和算子，用作计算标准。 123456789using data_t = float;data_t summary(std::vector&lt;data_t&gt; input) { data_t sum = 0.0; for (auto item : input) { sum += item; } return sum;} 测试数据从(-1,1)的均匀分布中采样，为了方便复习，设置随机种子。结果的相对误差在2%以内均认为结果正确。 12345678910111213141516171819202122#define INPUT 64int main() { std::vector&lt;data_t&gt; input; std::mt19937 gen(1234); std::uniform_real_distribution&lt;data_t&gt; urdis(-1, 1); for (std::size_t i = 0; i &lt; INPUT; i++) input.push_back(urdis(gen)); data_t sum = summary(input); data_t ascend_sum = ascend_summary(input); std::cout.precision(12); std::cout &lt;&lt; std::setw(12) &lt;&lt; \"host sum: \" &lt;&lt; std::setw(12) &lt;&lt; sum &lt;&lt; std::endl; std::cout &lt;&lt; std::setw(12) &lt;&lt; \"ascend sum: \" &lt;&lt; std::setw(12) &lt;&lt; ascend_sum &lt;&lt; std::endl; if ((std::fabs(sum - ascend_sum) / sum) &lt; 0.02) std::cout &lt;&lt; \"Result correct.\" &lt;&lt; std::endl; else std::cout &lt;&lt; \"Result error.\" &lt;&lt; std::endl; return 0;} 用例设计 为了尽可能全面测试该接口，同时排除不必要的影响，可以设置一下几种测试用例，均以float数据为例。 输入向量长度为64，字节数为256B，1个repeat，用1个group处理。 输入向量长度为128，字节数为512B，2个repeat，用1个group处理。 输入向量长度为128，字节数为512B，2个repeat，用2个group处理。 这样设计用例可以分析出，到底是接口本身有问题，还是访存过程中出现了问题。用例1可以判断接口本身计算单个repeat的结果的正确性，用例2可以判断计算多个repeat时结果的正确性，用例3可以判断分核对repeat计算的影响。 算子实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#define GROUP_NUM 1#define ELEM_PER_GROUP 64data_t ascend_summary(std::vector&lt;data_t&gt; &amp;input) { sycl::queue Q(sycl::ascend_selector{}); auto input_buf = sycl::malloc_device&lt;data_t&gt;(INPUT, Q); // 结果buf申请的长度，可以将每个核访问的block严格分离 // 避免了由于block踩踏发生的问题 const std::size_t res_vec_num = GROUP_NUM * (32 / sizeof(data_t)); auto res_buf = sycl::malloc_device&lt;data_t&gt;(res_vec_num, Q); const std::size_t repeat_num = ELEM_PER_GROUP * sizeof(data_t) / 256; // Host -&gt; GM Q.memcpy(input_buf, input.data(), INPUT * sizeof(data_t)); Q.launch&lt;class Sum&gt;(GROUP_NUM, [=](sycl::group&lt;1&gt; group) { const std::size_t group_id = group.get_group_id(); bisheng::vector&lt;data_t, ELEM_PER_GROUP&gt; input_vec; // 和向量的长度取决于本group内处理的repeat数量 bisheng::vector&lt;data_t, repeat_num&gt; res_vec; input_vec.load( sycl::global_ptr&lt;data_t&gt;(input_buf + group_id * ELEM_PER_GROUP).get(), ELEM_PER_GROUP); bisheng::vec_cross_add(res_vec.data(), input_vec); res_vec.store( sycl::global_ptr&lt;data_t&gt;(res_buf + group_id * (32 / sizeof(data_t))) .get(), repeat_num); }); // Host端的结果数组也避免了block踩踏 std::vector&lt;data_t&gt; sum_host_vec(res_vec_num, 0.0f); Q.memcpy(sum_host_vec.data(), res_buf, res_vec_num * sizeof(data_t)); Q.wait(); data_t sum; for (std::size_t i = 0; i &lt; res_vec_num; i++) // 只累加有意义的数据 if (i % (32 / sizeof(data_t)) &lt; repeat_num) sum += sum_host_vec[i]; return sum;} 针对不同的测试用例，只需要更改两个#define宏定义的数据即可。 测试结果 用例一 宏修改为： 123#define INPUT 64#define GROUP_NUM 1#define ELEM_PER_GROUP 64 结果没有任何问题。 123 host sum: 1.76275920868ascend sum: 1.76275908947Result correct. 用例二 宏修改为： 123#define INPUT 128#define GROUP_NUM 1#define ELEM_PER_GROUP 128 结果也没有任何问题。 123 host sum: 1.49505186081ascend sum: 1.49505162239Result correct. 之前问题就出在类似用例二的情况。当一个group处理多个repeat时，结果向量中会存在多个有意义的值，需要在累加时将这些有意义的值全部都加起来，之前问题就出在，没妥善处理单个核处理多repeat的情况，导致有一部分有意义的数没有累加上去，最终导致结果出错。 用例三 宏修改为： 123#define INPUT 128#define GROUP_NUM 2#define ELEM_PER_GROUP 64 结果自然也没有问题。 123 host sum: 1.49505186081ascend sum: 1.49505162239Result correct. 特定不符合预期的情况 情况描述 在此之前，我认为这个接口确实没问题了，但在偶然的情况下，还是测试出了不符合预期返回结果的情况。 在使用vec_cross_add()时，我们应该定义两个向量，一个作为输入向量，另一个作为结果向量。正常情况下，结果向量的长度应该为输入向量的repeat数量。例如： 123bisheng::vector&lt;float, 128&gt; src; // src为128个float，也就是2个repeatbisheng::vector&lt;float, 2&gt; dst; // 结果向量长度应该为2bisheng::vec_cross_add(src.data(), dst); // 正常的调用方式 这种方式确实没有问题，结果返回也正常，将结果数组中的元素都相加后，确实是输入向量元素的和。 但当我们用变长向量bisheng::vector_view时，返回结果就不像预期这样了。 下面实现了一个利用变长向量操作数据的算子。大部分代码与上面的一致，只需关注有注释的部分。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152data_t ascend_summary_view(std::vector&lt;data_t&gt; &amp;input) { sycl::queue Q(sycl::ascend_selector{}); auto input_buf = sycl::malloc_device&lt;data_t&gt;(INPUT, Q); const std::size_t res_vec_num = GROUP_NUM * (32 / sizeof(data_t)); auto res_buf = sycl::malloc_device&lt;data_t&gt;(res_vec_num, Q); const std::size_t repeat_num = ELEM_PER_GROUP * sizeof(data_t) / 256; Q.memcpy(input_buf, input.data(), INPUT * sizeof(data_t)); sycl::stream out(512 * GROUP_NUM, 512, Q.get_device()); Q.launch&lt;class SumView&gt;(GROUP_NUM, [=](sycl::group&lt;1&gt; group) { const std::size_t group_id = group.get_group_id(); // 申请较大的向量 bisheng::vector&lt;data_t, 30000&gt; input_vec; bisheng::vector&lt;data_t, 30000&gt; res_vec; input_vec.load( sycl::global_ptr&lt;data_t&gt;(input_buf + group_id * ELEM_PER_GROUP).get(), ELEM_PER_GROUP); // 使用变长向量来操作正确范围内的数据 bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), ELEM_PER_GROUP); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), repeat_num); bisheng::vec_cross_add(res_vec_v, input_vec_v); // 输出变长结果向量前20个元素 out &lt;&lt; \"group \" &lt;&lt; group_id &lt;&lt; \"\\n\"; for (std::size_t i = 0; i &lt; 20; ++i) out &lt;&lt; res_vec_v[i] &lt;&lt; \" \"; out &lt;&lt; \"\\n\"; res_vec.store( sycl::global_ptr&lt;data_t&gt;(res_buf + group_id * (32 / sizeof(data_t))) .get(), repeat_num); }); std::vector&lt;data_t&gt; sum_host_vec(res_vec_num, 0.0f); Q.memcpy(sum_host_vec.data(), res_buf, res_vec_num * sizeof(data_t)); Q.wait(); data_t sum; for (std::size_t i = 0; i &lt; res_vec_num; i++) if (i % (32 / sizeof(data_t)) &lt; repeat_num) sum += sum_host_vec[i]; return sum;} 为了更清楚的看到其中发生了什么，故定义一个sycl::stream来输出Kernel中的信息。 理论上，即使是变长向量，返回的结果向量长度也应该是输入向量的repeat数，在这里用上面的用例二进行说明。 此时的宏为： 123#define INPUT 128#define GROUP_NUM 1#define ELEM_PER_GROUP 128 先来看计算结果的输出： 123 host sum: 1.49505186081ascend sum: 1.76275908947Result error. 计算错误，这成功复现了另一种错误的情况。这个错误表面上看起来，和上面使用定长向量测试时描述的错误原因一样，原因没有将所以有意义的数据累加进去，最终导致了结果不正确。 先想一个问题，我们在Kernel中输出了结果向量的前20个元素，理论上讲，输出应该类似于下面这种形式： 11.7628 -0.2677 ...... 前两个元素应该就是两个repeat的和，后面的元素应该都是未初始化的无意义的数据。 但问题的关键来了，来看一看Kernel中输出的结果向量的前20个元素。 11.7628 0.0000000013091844320297241211 -0.0000000027893838882446289062 0.0000000034829735755920410156 0.000000041852550506591796875 -0.000000004057476043701171875 -0.0000004261577606201171875 0.0000000014236330986022949219 -0.2677 -0.000000044695949554443359375 -0.000000012639684677124023437 0.00000000012021332979202270508 -0.000000060646677017211914062 -0.0000000027346568107604980469 -0.000000011391909122467041016 -0.000000012336615324020385742 0.00000018131090164184570312 这样看不够直观，我们将每个元素都换个行再输出，得到如下。 12345678910111213141516171.76280.0000000013091844320297241211-0.00000000278938388824462890620.00000000348297357559204101560.000000041852550506591796875-0.000000004057476043701171875-0.00000042615776062011718750.0000000014236330986022949219-0.2677-0.000000044695949554443359375-0.0000000126396846771240234370.00000000012021332979202270508-0.000000060646677017211914062-0.0000000027346568107604980469-0.000000011391909122467041016-0.0000000123366153240203857420.00000018131090164184570312 观察到的结果是有些惊喜的，vec_cross_add并没有按照预期的形式返回结果。这些很小的数都是未初始化的无意义数据，真正有意义的数据被放在的位置0和8上。 而为什么是这两个位置，一种可能的解释是，该接口在运算的过程中，是按照block来计算的，一个repeat是8个block，所以理论上会有8个求和结果，然后这个接口将8个block的和再累加起来，放到结果向量的第一个位置。按照正常来讲，最终返回结果之前，应该将所有repeat的求和结果做一个紧凑排布，就会得到像定长向量那样正常的结果向量。可能在实现变长向量重载的时候没有做这个紧凑？我乱猜的（狗头保命）。 解决方案 所以只要注意这一点，在使用变长向量的时候，将正确位置的元素累加即可得到正确的结果。 正确的代码实现如下，这里只展示核心部分。 1234567891011121314151617181920Q.launch&lt;class SumViewFixed&gt;(GROUP_NUM, [=](sycl::group&lt;1&gt; group) { const std::size_t group_id = group.get_group_id(); bisheng::vector&lt;data_t, 30000&gt; input_vec; bisheng::vector&lt;data_t, 30000&gt; res_vec; input_vec.load( sycl::global_ptr&lt;data_t&gt;(input_buf + group_id * ELEM_PER_GROUP).get(), ELEM_PER_GROUP); bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), ELEM_PER_GROUP); // 使用变长向量的时候就要考虑到正确数据的存放位置 bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), repeat_num * 8); bisheng::vec_cross_add(res_vec_v, input_vec_v); // 结果就直接用标量操作写回GM for (std::size_t i = 0; i &lt; repeat_num * 8; i += 8) res_buf[group_id * (32 / sizeof(data_t))] += res_vec_v[i]; }); 测试结果 123 host sum: 1.49505186081ascend sum: 1.49505162239Result correct. 这是一个比较隐蔽的问题，在使用该接口的时候还是要多加注意。","link":"/posts/1040/"},{"title":"以张量角度考虑softmax算子","text":"在之前的文章中已经介绍了Softmax算子开发的整体思路，但笔者只从向量的角度进行了说明，本篇文章就以处理张量的角度来进一步阐述。 张量的内存排布 要使Softmax算子处理张量，首先要了解张量在内存上的排布，我们用numpy的ndarray来说明。 首先利用python来创建一个ndarray。 12import numpy as npdata = np.random.randn(32, 32).astype(np.float32) 然后我们写一个简单的C++函数（tensor.cpp），该函数接受一个对应数据类型的指针作为参数，功能就简单的打印输出。 12345678910#include &lt;iostream&gt;extern \"C\" void printTensor(float *tensor, int *shape){ for(int i = 0; i &lt; shape[0]; i++) { for(int j = 0; j &lt; shape[1]; j++) { std::cout &lt;&lt; tensor[i * shape[0] + j] &lt;&lt; \" \"; } std::cout &lt;&lt; \"\\n\"; }} 其中的extern \"C\"是必要的，否则调用时会出现undefined symbol问题。 然后将其编译成一个动态链接库，以供python调用，命令如下。 1g++ -shared -fPIC -o tensor.so tensor.cpp 注意：如果代码中使用了C++的标准库，则编译器要使用g++而不是gcc，否则会出现标准库符号找不到的问题，clang同理。 编译好后在python中调用该库，数据类型的转换是利用ctypes来实现的。 123456789101112131415161718import numpy as npfrom ctypes import CDLL, POINTER, c_float, c_intdata = np.random.randn(32, 32).astype(np.float32)c_int_arr = c_int * len(data.shape)lib = CDLL(\"./tensor.so\") # 获取动态链接库printTensor = lib.printTensor # 获取库中的函数符号printTensor.argtypes = [ # 定义函数的参数类型 POINTER(c_float), POINTER(c_int),]# 函数调用printTensor( data.ctypes.data_as(POINTER(c_float)), # 将numpy的ndarray转换为C语言的float职责 c_int_arr(data.shape[0], data.shape[1]), # 将形状信息也传递给C++) 部分执行结果如下所示。 123-1.48456 0.336725 1.69846 -0.0248114 0.39322 0.614784 0.326595 0.575949 -0.708058 -1.39587 -1.83477 0.349339 -0.610898 -0.423076 -0.136989 0.442269 0.446412 -0.486558 -0.292987 1.29332 0.187811 0.331237 0.63905 -1.46251 -0.536956 0.495119 -0.429213 -0.988436 -0.414105 -2.26553 1.23408 -0.544561 0.369648 -1.12966 -0.154628 1.09682 0.676383 0.444374 -0.706796 -0.873308 -1.32488 -0.537758 -1.81611 -2.06588 0.721618 1.02888 -0.919128 -0.765203 -0.42332 0.0602946 1.16713 0.140398 -0.534829 -0.0961945 0.0153079 -0.261519 0.0927059 -0.868659 1.27008 -0.379786 0.382002 -1.76778 0.660476 1.06135... 以上得出结论，numpy中的张量在内存上就是一个一维数组，可以用指针来操作，其他框架的张量同理。 算子逻辑 由于张量在内存上都是一维排布的，所以最内层维度在内存上是连续的。所以对于昇腾芯片来说，Softmax最适合加速的就是在张量的最后一个维度上进行计算，下面的讨论都基于最后一个维度。对于一个NHWC的张量来说，我们在最后一个维度上进行Softmax也是实际中最常用的情况。 算子涉及向量自然指数、向量归约求和、向量除法等运算，其中最需要关心的就是向量归约求和，因为它涉及到对齐的问题。 可能的数据情况 主要有以下几种情况： 情况一：数据repeat对齐 最好解决的就是repeat对齐的情况，不需要做尾块处理，直接利用vec_cross_add()归约求和即可。 情况二：数据部分repeat对齐，部分block对齐 对于部分repeat对齐，部分block对齐的情况，需要分开来处理。对于repeat对齐的部分同样简单处理，对于block对齐的部分，无法直接调用vec_cross_add接口进行归约求和，需要利用标量操作来累加进前面的结果中。 情况三：数据部分repeat对齐，部分block对齐，剩余尾块block不对齐 最后一种情况是最需要注意的情况，而且实际使用中大部分是这种情况。着重关注非block对齐部分的数据，这部分数据要从搬移的时候就开始做单独处理。因为GM与UB之间的数据搬移最小粒度是一个block，无法真正做到元素级别的搬移。 对于这种情况的数据搬移，我们考虑一种简化情况，即数据长度大于一个block但不足两个block。对于这样的数据，GM与UB之间的搬移需要一个临时空间来辅助。 具体方式是从末尾向前取一个整block进行搬移，这样不会影响到后续的数据，同时使得group之间的访存严格隔离开来。 这样处理的时候，由于会有被重复搬移的数据，所以要注意在累加的时候不要重复累加元素。 算子实现 为了避免张量过大，在UB上申请的空间超出限制，这里使group循环分批处理一个向量。即从GM搬移进UB，处理完后再搬回GM，再搬入下一批数据进行处理，直到所有数据被处理完成。 这样处理有一个好处就是，情况二和情况三的数据只会出现在最后一次迭代中。该算子的处理大体分为三个小模块，求、归约求和以及向量除法。 在写核心逻辑之前，我们需要为算子准备一系列的常量，方便后面使用。 123456789101112131415161718192021222324// 一个向量的repeat数量std::size_t total_repeat_count = vec_bytes / REPEAT_SIZE;// 需要的核内迭代次数std::size_t iteration_times = total_repeat_count / MAX_REPEAT_PER_ITERATION + 1;// 最后一次迭代处理的字节数std::size_t last_iter_bytes = vec_bytes - (iteration_times - 1) * MAX_BYTES_PER_ITERATION;// 最后一次迭代数据中元素的个数std::size_t elem_count = last_iter_bytes / sizeof(float);// 最后一次迭代数据中对齐block的个数std::size_t block_count = last_iter_bytes / BLOCK_SIZE;// 最后一次迭代数据中对齐repeate的个数std::size_t repeat_count = last_iter_bytes / REPEAT_SIZE;// 最后一次迭代数据中block对齐的元素个数std::size_t align_block_elem_count = block_count * BLOCK_SIZE / sizeof(float);// 最后一次迭代数据中repeat对齐的元素个数std::size_t align_repeat_elem_count = repeat_count * REPEAT_SIZE / sizeof(float);// 最后一次迭代数据中非对齐元素个数std::size_t tail_elem_count = elem_count - align_block_elem_count;// 最后一次迭代数据中非对齐字节数std::size_t tail_bytes = tail_elem_count * sizeof(float);// 最后一次迭代数据中，向前取整block的元素个数std::size_t tail_block_elem_count = BLOCK_SIZE / sizeof(float);// 最后一次迭代数据中，向前取整block的起点索引std::size_t tail_memcpy_index = dim2 - tail_block_elem_count; 核心逻辑如下，详细说明见注释。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788for (std::size_t i = 0; i &lt; iteration_times; i++) { index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / sizeof(float); if (i == iteration_times - 1) { tail_index = group_id * dim2 + tail_memcpy_index; // 加载最后一次迭代中，block对齐的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); if (tail_bytes) { // 加载最后一次迭代中，block非对齐的数据，向前取整block temp.load(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); } bisheng::vec_exp(input_vec.to_view(elem_count), input_vec.to_view(elem_count)); bisheng::vec_exp(temp, temp); input_vec.store(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); if (tail_bytes) { temp.store(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); } } else { // 整块的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); bisheng::vec_exp(input_vec, input_vec); input_vec.store(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); }}// 计算向量和for (std::size_t i = 0; i &lt; iteration_times; i++) { index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / sizeof(float); if (i == iteration_times - 1) { tail_index = group_id * dim2 + tail_memcpy_index; // 加载最后一次迭代中，block对齐的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); if (tail_bytes) { // 加载最后一次迭代中，block非对齐的数据，向前取整block temp.load(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); } if (align_repeat_elem_count) { // 将最后一次迭代中repeat对齐的数据求和 bisheng::vec_cross_add(sum_vec.to_view(repeat_count, 0, 1), input_vec.to_view(align_repeat_elem_count)); for (std::size_t j = 0; j &lt; repeat_count; j++) { sum += sum_vec[j]; } } // 计算repeat不对齐，但block部分对齐的数据 for (std::size_t j = align_repeat_elem_count; j &lt; align_block_elem_count; j++) { sum += input_vec[j]; } // 计算block不对齐的数据 for (std::size_t j = tail_block_elem_count - tail_elem_count; j &lt; tail_block_elem_count; j++) { sum += temp[j]; } } else { // 整块的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); bisheng::vec_cross_add(sum_vec.to_view(MAX_REPEAT_PER_ITERATION, 0, 1), input_vec.to_view(MAX_BYTES_PER_ITERATION / sizeof(float))); for (std::size_t j = 0; j &lt; MAX_BYTES_PER_ITERATION / sizeof(float); j++) { sum += sum_vec[j]; } }}// 利用向量和初始化分母向量bisheng::vector&lt;float, BLOCK_SIZE / sizeof(float)&gt; temp_res;bisheng::vector&lt;float, MAX_BYTES_PER_ITERATION / sizeof(float)&gt; divisor(sum);bisheng::vector&lt;float, BLOCK_SIZE / sizeof(float)&gt; temp_divisor(sum);for (std::size_t i = 0; i &lt; iteration_times; i++) { index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / sizeof(float); if (i == iteration_times - 1) { tail_index = group_id * dim2 + tail_memcpy_index; // 加载最后一次迭代中，block对齐的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); if (tail_bytes) { // 加载最后一次迭代中，block非对齐的数据，向前取整block temp.load(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); } bisheng::vec_div(res_vec.to_view(elem_count), input_vec.to_view(elem_count), divisor.to_view(elem_count)); bisheng::vec_div(temp_res, temp, temp_divisor); res_vec.store(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); if (tail_bytes) { temp_res.store(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); } } else { // 整块的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); bisheng::vec_div(res_vec, input_vec, divisor); res_vec.store(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); }} 算子优化 算子逻辑优化 观察上述的核心逻辑，可以观察到几个比较明显的优化点： 计算和归约求和的过程可以合并，不需要先计算后搬出，再搬入计算归约和； 最后计算除法的过程，可以用倒数乘法来代替； 可以开启double buffering。 优化后的核心逻辑如下所示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// 计算e^x并归约求和for (std::size_t i = 0; i &lt; iteration_times; i++) { index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / sizeof(float); // 判断当前缓冲区 auto &amp;input_vec = i % 2 ? input_vec_0 : input_vec_1; auto &amp;sum_vec = i % 2 ? sum_vec_0 : sum_vec_1; auto &amp;sum_temp = i % 2 ? sum_temp_0 : sum_temp_1; auto &amp;sum = i % 2 ? sum_0 : sum_1; if (i == iteration_times - 1) { tail_index = group_id * dim2 + tail_memcpy_index; // 加载最后一次迭代中，block对齐的数据 if (align_block_elem_count) { input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); bisheng::vec_exp(input_vec.to_view(elem_count), input_vec.to_view(elem_count)); // 将最后一次迭代中repeat对齐的数据求和 if (align_repeat_elem_count) { bisheng::vec_cross_add(sum_vec.to_view(repeat_count, 0, 1), input_vec.to_view()); for (int j = 0; j &lt; repeat_count; j++) { sum += sum_vec[j]; } } // 计算repeat不对齐，但block部分对齐的数据 for (std::size_t j = align_repeat_elem_count; j &lt; align_block_elem_count; j++) { sum += input_vec[j]; } input_vec.store(sycl::global_ptr&lt;float&gt;(d_exp_tensor + index).get(), align_block_elem_count); } if (tail_bytes) { // 加载最后一次迭代中，block非对齐的数据，向前取整block temp.load(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); bisheng::vec_exp(temp, temp); // 计算block不对齐的数据 for (std::size_t j = tail_block_elem_count - tail_elem_count; j &lt; tail_block_elem_count; j++) { sum += temp[j]; } temp.store(sycl::global_ptr&lt;float&gt;(d_exp_tensor + tail_index).get(), tail_block_elem_count); } } else { // 整块的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); bisheng::vec_exp(input_vec, input_vec); bisheng::vec_cross_add(sum_vec.to_view(MAX_REPEAT_PER_ITERATION, 0, 1), input_vec.to_view(MAX_BYTES_PER_ITERATION / sizeof(float))); bisheng::vec_cross_add(sum_temp.to_view(sum_vec_repeat_count, 0, 1), sum_vec.to_view(MAX_REPEAT_PER_ITERATION)); for (int j = 0; j &lt; sum_vec_repeat_count; j++) { sum += sum_temp[j]; } input_vec.store(sycl::global_ptr&lt;float&gt;(d_exp_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); }}// 两个缓冲区的和相加sum_0 += sum_1;auto &amp;sum = sum_0;bisheng::vector&lt;float, BLOCK_SIZE / sizeof(float)&gt; temp_res;float divisor = 1 / sum;// 向量除法for (std::size_t i = 0; i &lt; iteration_times; i++) { index = group_id * dim2 + i * MAX_BYTES_PER_ITERATION / sizeof(float); // 判断当前缓冲区 auto &amp;input_vec = i % 2 ? input_vec_0 : input_vec_1; auto &amp;res_vec = i % 2 ? res_vec_0 : res_vec_1; if (i == iteration_times - 1) { tail_index = group_id * dim2 + tail_memcpy_index; // 加载最后一次迭代中，block对齐的数据 if (align_block_elem_count) { input_vec.load(sycl::global_ptr&lt;float&gt;(d_exp_tensor + index).get(), align_block_elem_count); bisheng::vec_mul(res_vec.to_view(elem_count), input_vec.to_view(elem_count), divisor); res_vec.store(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), align_block_elem_count); } if (tail_bytes) { // 加载最后一次迭代中，block非对齐的数据，向前取整block temp.load(sycl::global_ptr&lt;float&gt;(d_exp_tensor + tail_index).get(), tail_block_elem_count); bisheng::vec_mul(temp_res, temp, divisor); temp_res.store(sycl::global_ptr&lt;float&gt;(d_tensor + tail_index).get(), tail_block_elem_count); } } else { // 整块的数据 input_vec.load(sycl::global_ptr&lt;float&gt;(d_exp_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); bisheng::vec_mul(res_vec, input_vec, divisor); res_vec.store(sycl::global_ptr&lt;float&gt;(d_tensor + index).get(), MAX_BYTES_PER_ITERATION / sizeof(float)); }} 分核方案优化 由于毕昇异构算子中存在一个限制，即group的数量最大为65535。按照上述的分核方案，最多只能处理65535个向量，显然是不合理的。所以，当向量个数大于65535时，要令每个逻辑核处理多个向量。 1234// 每个group处理的向量个数std::size_t vec_count_per_group = (vec_count + MAX_KERNEL_COUNT - 1) / MAX_KERNEL_COUNT;// 开启的group数量std::size_t group_count = (vec_count + vec_count_per_group - 1) / vec_count_per_group; 12345678910111213141516171819202122232425262728293031323334for (std::size_t i = 0; i &lt; vec_count_per_group; i++) { iteration_begin = group_index + i * dim3; if (iteration_begin &gt;= element_total_count) // 注意判断边界 break; bisheng::vector&lt;float, MAX_BYTES_PER_ITERATION / sizeof(float)&gt; input_vec_0; bisheng::vector&lt;float, MAX_BYTES_PER_ITERATION / sizeof(float)&gt; input_vec_1; bisheng::vector&lt;float, MAX_REPEAT_PER_ITERATION&gt; sum_vec_0(0); bisheng::vector&lt;float, MAX_REPEAT_PER_ITERATION&gt; sum_vec_1(0); const std::size_t sum_vec_repeat_count = MAX_REPEAT_PER_ITERATION * sizeof(float) / REPEAT_SIZE; bisheng::vector&lt;float, sum_vec_repeat_count&gt; sum_temp_0(0); bisheng::vector&lt;float, sum_vec_repeat_count&gt; sum_temp_1(0); bisheng::vector&lt;float, MAX_BYTES_PER_ITERATION / sizeof(float)&gt; res_vec_0; bisheng::vector&lt;float, MAX_BYTES_PER_ITERATION / sizeof(float)&gt; res_vec_1; bisheng::vector&lt;float, BLOCK_SIZE / sizeof(float)&gt; temp; __local float sum_0 = 0.0f; __local float sum_1 = 0.0f; // 计算e^x并归约求和 for (std::size_t j = 0; j &lt; iteration_times; j++) { ... } // 两个缓冲区的和相加 sum_0 += sum_1; auto &amp;sum = sum_0; bisheng::vector&lt;float, BLOCK_SIZE / sizeof(float)&gt; temp_res; float divisor = 1 / sum; // 向量除法 for (std::size_t j = 0; j &lt; iteration_times; j++) { ... }} 功能测试 功能测试采取将算子封装到MindSpore框架中进行测试，具体方案如下。先将算子代码编译为动态链接库。 123456clang++ -fsycl -fdevices=ascend_910 \\ -I ${ASCEND_TOOLKIT_HOME}/include \\ -L ${ASCEND_TOOLKIT_HOME}/lib64 -lascendcl \\ -shared -fPIC -o softmax.so \\ -mllvm -inline-threshold=9000 -mllvm -enable-explicit-vectorizer -Rpass=ascend-vec \\ ./softmax.cpp 然后按照要求封装为MindSpore可调用的状态。 1234567891011121314class SoftmaxBS(Cell): def __init__(self): super(SoftmaxBS, self).__init__() self.bisheng_softmax = ops.Custom( \"softmax.so:softmax_npu\", out_shape=lambda x: x, out_dtype=lambda x: x, func_type=\"aot\", ) self.bisheng_softmax.add_prim_attr(\"primitive_target\", \"Ascend\") def construct(self, x0): output = self.bisheng_softmax(x0) return output 在结果正确性方面，采用了numpy中的allClose()函数来对比MindSpore算子与自定义算子的结果张量，若两者在一定精度范围内接近，则认为计算结果正确。具体判断逻辑如下。 12345678910context.set_context(mode=ms.PYNATIVE_MODE, device_target=\"Ascend\")softmax_bs = SoftmaxBS()softmax = Softmax(axis=-1)data = ms.Tensor(np.random.randn(dim0, dim1, dim2, dim3), ms.float16)output_bs = softmax_bs(data)output_ms = softmax(data)if np.allclose(output_bs.asnumpy(), output_ms.asnumpy(), rtol=1e-3, atol=1e-3): print(\"correct!\")else: print(\"error!\") 经过测试，算子逻辑没有问题，精度由于使用了float16来计算，所以只设置到了1e-3。 性能测试 性能测试采用单算子测试的方式。对于MindSpore中的算子，采用框架自带的Profiler()来分析算子性能，再通过msprof.py脚本工具导出算子性能数据的summary数据，通过读取Task Duration列来获取算子的执行时间。而对于自定义算子，则采用msprof命令行工具运行算子，同样通过summary数据来获取算子执行时间。 ID Shape 数据类型 MindSpore BiSheng 加速比 1 8x16x1024x1024 half 2658.672 9720.826 0.273503 2 16x16x1024x1024 half 5274.796 18483.56 0.285378 3 16x16x1024x2048 half 10550.81 21184.74 0.498038 4 16x16x1024x4096 half 22255.22 26612.28 0.836276 5 4x4x512x8192 half 1221.49 1350.776 0.904288 6 4x4x512x16384 half 2438.494 1337.628 1.822999 7 4x4x512x32768 half 4869.044 2412.854 2.01796 8 4x4x512x65535 half 6671.878 6200.692 1.075989 9 4x4x512x131072 half 19467.07 8748.974 2.225069 10 4x4x512x8193 half 4984.124 1564.236 3.186299 11 4x4x512x16385 half 1354.314 1555.814 0.870486 12 4x4x512x32769 half 4288.27 2667.928 1.607341 13 4x4x512x65536 half 9732.024 4516.888 2.154586 14 4x4x512x131073 half 79671.69 9390.606 8.484191 经过一系列的性能测试，发现在小数据量的情况下，性能始终无法与TBE算子相比。推测可能的原因是，TBE算子针对某些静态形状有优化，但本算子针对的是动态形状场景，所以性能较差。但当数据量变大，充分发挥设备并行能力的情况下，性能有所好转。在其最擅长的形状上，加速比可以达到2左右，在用例14这种情况下，加速比甚至达到了8以上。","link":"/posts/27559/"},{"title":"基于毕昇编译器的softmax异构算子","text":"使用毕昇编译器异构开发Softmax算子，坑太多太多了。。。。 分析算子 Softmax是非常常见的激活函数，此处不过多赘述。观察其公式： 首先应该注意到的是分母中的求和，因为向量内元素求和本身就是一个不太适合于向量化的操作，初步分析可知，此处的求和可能是性能的瓶颈。而分子除以分母的运算可以在得到分母（即向量元素之和）的情况下，自然而然的向量化运算。 初步方案（方案一） 向量化方案：因为向量除法是可以自然而然向量化的操作，故暂时先将分母的求和操作放在Host端进行。 分核方案：本算子是在昇腾910B上进行开发的，由于数据对其以及访存粒度的限制，暂时令一个核处理640个元素。 初步方案实现 先用标准C++实现一个Softmax算子，作为功能验证和性能对比的基准。 12345678910111213using data_t = float;std::vector&lt;data_t&gt; softmax(std::vector&lt;data_t&gt; input) { data_t sum = 0.0; for (auto x : input) { sum += expf(x); } std::vector&lt;data_t&gt; res; for (auto x : input) { res.push_back(expf(x) / sum); } return res;} 接下来开始实现异构算子的逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980std::vector&lt;data_t&gt; ascend_softmax(std::vector&lt;data_t&gt; input) { // 首先拿到输入向量的大小 std::size_t input_sz = input.size(); // 计算出总的数据量，单位是字节 std::size_t byte_count = input_sz * sizeof(data_t); // 如果输入向量的大小不足一个block，则直接调用Host算子逻辑 if (byte_count &lt; 32) return softmax(input); sycl::queue Q(sycl::ascend_selector{}); // 申请GM上的内存，分别存储输入和结果 auto input_buf = sycl::malloc_device&lt;data_t&gt;(input_sz, Q); auto res_buf = sycl::malloc_device&lt;data_t&gt;(input_sz, Q); // host -&gt; GM 的内存搬移 Q.memcpy(input_buf, input.data(), byte_count); // 指定每个核处理的元素个数 const std::size_t elem_per_group = 640; // 计算尾块中的元素个数 const std::size_t tail_elem_count = input_sz % elem_per_group; // 逻辑核的数量，若尾块中存在元素，则多开一个逻辑核 const std::size_t group_num = (tail_elem_count &gt; 0) ? ((input_sz / elem_per_group) + 1) : (input_sz / elem_per_group); // 求和计算暂时由Host完成 data_t sum = 0.0; for (auto x : input) { sum += expf(x); } Q.launch&lt;class Softmax&gt;(group_num, [=](sycl::group&lt;1&gt; group) { // UB内存申请，分别为输入向量、指数计算结果向量、分母向量、结果向量 bisheng::vector&lt;data_t, elem_per_group&gt; input_vec; bisheng::vector&lt;data_t, elem_per_group&gt; exp_res_vec; bisheng::vector&lt;data_t, elem_per_group&gt; divisor_vec(sum); bisheng::vector&lt;data_t, elem_per_group&gt; res_vec; // 获取group id std::size_t group_id = group.get_group_id(); // GM -&gt; UB 的内存搬移 input_vec.load( sycl::global_ptr&lt;data_t&gt;(input_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // 本分支处理存在尾块，且当前是最后一个处理尾块的group // 由于尾块大概率是非整block，故采用毕昇变长向量对数据进行操作 bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; divisor_vec_v(divisor_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), tail_elem_count); bisheng::vec_exp(exp_res_vec_v, input_vec_v); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } else { // 本分支处理整block的情况 // 由于指定了每个核处理的元素个数，故此处一定是整block的 bisheng::vec_exp(exp_res_vec, input_vec); bisheng::vec_div(res_vec, exp_res_vec, divisor_vec); } // UB -&gt; GM 内存搬移 res_vec.store( sycl::global_ptr&lt;data_t&gt;(res_buf + group_id * elem_per_group).get(), elem_per_group); }); std::vector&lt;data_t&gt; res(input_sz, 0.0f); // GM -&gt; host 内存搬移 Q.memcpy(res.data(), res_buf, byte_count); Q.wait(); // 释放资源 sycl::free(input_buf, Q); sycl::free(res_buf, Q); return res;} 功能验证 由于之前实现了Host端的逻辑，所以可以用Host端的计算结果来验证异构算子的正确性，测试代码如下。输入向量的数据是从(-1, 1)均的匀分布中取的随机数。 由于设备端会有一定的精度损失，故在测试过程中留有一定的宽容度，相对精度损失在2%以内均认为计算正确。 1234567891011121314151617181920212223int main() { std::vector&lt;data_t&gt; vec; std::random_device rd; std::mt19937 gen(rd()); std::uniform_real_distribution&lt;data_t&gt; urdis(-1, 1); for (int i = 0; i &lt; INPUT_COUNT; i++) { vec.push_back(urdis(gen)); } std::vector&lt;data_t&gt; host_res = softmax(vec); std::vector&lt;data_t&gt; ascend_res = ascend_softmax(vec); for (int i = 0; i &lt; host_res.size(); ++i) { if (std::fabs(host_res[i] - ascend_res[i]) / host_res[i] &gt; 0.02) { std::cout &lt;&lt; \"Calculation error.\" &lt;&lt; std::endl; return EXIT_FAILURE; } } std::cout &lt;&lt; \"Result correct.\" &lt;&lt; std::endl; return EXIT_SUCCESS;} 性能测试 性能测试使用不同长度的输入向量进行，长度分别为640、6400、64000、640000，数据类型为float。Host端的时间统计使用&lt;time.h&gt;中的结构体，设备端的时间统计利用毕昇C++提供的profiling系列接口统计。仅统计算子计算逻辑部分的时间，并执行5次取平均值后计算加速比。之后的性能测试均为该策略，后面不再赘述。 性能测试结果如下。 测试用例 640 6400 64000 640000 加速比 0.18163 1.103832 2.968345 3.784732 可以看到在向量长度达到6400之后才勉强与Host端计算逻辑持平，虽然在长向量的情况下有速度上的提升，但远不是令人满意的效果。 求和方式优化（方案二） 在初步方案中，求和的过程是由Host端完成的，故接下来将求和也尽量的向量化。对于求和无法做到元素级别的并行，故只能将长向量拆分为多个短向量，这些短向量之间的求和操作是并行的，但单个短向量内部的求和，只能是串行的。 由于求和的每一项也需要经过指数运算，故可以把指数运算与求和放在同一个核函数内进行，计算完成后将指数运算结果向量存储下来，则后面做向量除法时就不必再运算一遍了。 总体的异构方案如图所示。 方案实现 实现代码如下，只需关注有注释的部分，没有注释的部分与上一方案中的代码相同。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114std::vector&lt;float&gt; ascend_softmax(std::vector&lt;float&gt; input) { std::size_t input_sz = input.size(); std::size_t byte_count = input_sz * sizeof(float); if (byte_count &lt; 32) return softmax(input); const std::size_t elem_per_group = 640; const std::size_t tail_elem_count = input_sz % elem_per_group; const std::size_t group_num = (tail_elem_count &gt; 0) ? ((input_sz / elem_per_group) + 1) : (input_sz / elem_per_group); // 此处计算出每个group所处理的repeat个数，方便vec_cross_add()接口调用 const std::size_t repeat_per_group = (elem_per_group * sizeof(float)) / 256; sycl::queue Q(sycl::ascend_selector{}); auto input_buf = sycl::malloc_device&lt;float&gt;(group_num * elem_per_group, Q); // 这里在GM上多申请两块内存，用于存放指数运算结果和求和结果 auto exp_res_buf = sycl::malloc_device&lt;float&gt;(group_num * elem_per_group, Q); auto sum_res_buf = sycl::malloc_device&lt;float&gt;(group_num * repeat_per_group, Q); auto res_buf = sycl::malloc_device&lt;float&gt;(group_num * elem_per_group, Q); // 由于vec_cross_add是按repeat为单位进行求和的，故申请的向量即为group数量乘以每个group的repeat数量 std::vector&lt;float&gt; sum_res((group_num * repeat_per_group), 0.0f); std::vector&lt;float&gt; res(input_sz, 0.0f); Q.memcpy(input_buf, input.data(), byte_count); // 第一个核函数进行求和与指数运算的操作 Q.launch&lt;class Summary&gt;(group_num, [=](sycl::group&lt;1&gt; group) { bisheng::vector&lt;float, elem_per_group&gt; input_vec; bisheng::vector&lt;float, elem_per_group&gt; exp_res_vec; bisheng::vector&lt;float, repeat_per_group&gt; sum_res_vec; std::size_t group_id = group.get_group_id(); input_vec.load( sycl::global_ptr&lt;float&gt;(input_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // 同样的处理尾块中存在运算，且为最后一个group的情况 bisheng::vector_view&lt;float&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vector_view&lt;float&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vec_exp(exp_res_vec_v, input_vec_v); // 由于尾块中的元素大概率不是整repeat，所以采用标量运算的的方式 for (int i = 0; i &lt; tail_elem_count; ++i) sum_res_vec[0] += exp_res_vec_v[i]; for (int i = 1; i &lt; repeat_per_group; ++i) sum_res_vec[i] = 0.0f; } else { // 整block情况 bisheng::vec_exp(exp_res_vec, input_vec); // 这里不仅确定是整block，也能确定是整repeat，故直接调用接口 bisheng::vec_cross_add(sum_res_vec.data(), exp_res_vec); } // UB -&gt; GM 内存搬移，将指数运算结果与求和结果均保存下来 exp_res_vec.store( sycl::global_ptr&lt;float&gt;(exp_res_buf + group_id * elem_per_group).get(), elem_per_group); sum_res_vec.store( sycl::global_ptr&lt;float&gt;(sum_res_buf + group_id * repeat_per_group).get(), repeat_per_group); }); Q.memcpy(sum_res.data(), sum_res_buf, group_num * repeat_per_group * sizeof(float)); Q.wait(); // 由于vec_cross_add求和后的结果是多个短向量的和 // 依然是一个向量，故须在Host端进一步计算为标量 float sum; for (auto x : sum_res) sum += x; // 第二个核函数进行向量除法的运算 Q.launch&lt;class Softmax&gt;(group_num, [=](sycl::group&lt;1&gt; group) { // 只需将上个核函数计算到的指数运算结果向量搬移进来即可 bisheng::vector&lt;float, elem_per_group&gt; exp_res_vec; bisheng::vector&lt;float, elem_per_group&gt; divisor_vec(sum); bisheng::vector&lt;float, elem_per_group&gt; res_vec; std::size_t group_id = group.get_group_id(); exp_res_vec.load( sycl::global_ptr&lt;float&gt;(exp_res_buf + group_id * elem_per_group).get(), elem_per_group); // 此处分支大同小异，不再赘述 if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { bisheng::vector_view&lt;float&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vector_view&lt;float&gt; divisor_vec_v(divisor_vec.data(), tail_elem_count); bisheng::vector_view&lt;float&gt; res_vec_v(res_vec.data(), tail_elem_count); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } else { bisheng::vec_div(res_vec, exp_res_vec, divisor_vec); } res_vec.store( sycl::global_ptr&lt;float&gt;(res_buf + group_id * elem_per_group).get(), elem_per_group); }); Q.memcpy(res.data(), res_buf, byte_count); Q.wait(); sycl::free(input_buf, Q); sycl::free(exp_res_buf, Q); sycl::free(sum_res_buf, Q); sycl::free(res_buf, Q); return res;} 功能验证 功能验证与上述方式相同，但在验证过程中出现了较为严重的问题。 在代码执行过程中，出现了计算结果时对时错的情况，在之前的项目开发过程中其实是踩过这样的坑的，所以出现这种情况时也没有特别慌张。这里分享一下定位问题的心路历程，总结一下设备端代码Debug的思路。 由于对毕昇C++和毕昇编译器这套逻辑了解不够充分，所以可能Debug的方式很笨，但只要能De出来Bug，那就是好方法。 首先可以确定的是，计算向量除法的部分一定没有问题，这是方案一里面验证过的。 其次是要确定访存过程中是否存在问题，是不是访问到了一些不该访问的地方。确定访存无误后再进行下一步。 将每一步的计算结果输出，具体查看到底哪一步计算出现了错误。 首先分析访存的问题，可以先将输入向量的长度和数据类型确定下来，然后带入这个向量长度计算每一次访存的范围。当然你也可以写个脚本来帮你完成这一步，但我懒，我选择草稿纸。一波计算后发现，访存并没有什么问题，每一步操作访问的范围也都是它们应该访问的，并没有访问的未定义数据。那么基本可以确定，这个Bug不是我自己的原因，那就看看每一步的计算结果。 因为第二个核函数已经经过了方案一的验证，所以没有过多纠结，分析第一个核函数。第一个核函数进行了两种运算，指数运算和求和运算。但指数运算也在方案一里验证过了，是没有问题的，所以直接就将问题定位在了求和过程中。使用同一个输入向量，分别输出Host算子中的和与vec_cross_add()计算的和。当然这里输出的和均为标量，vec_cross_add()返回的结果已经在Host端相加计算为了标量。 123[Debug]: Host sum: 7550.05[Debug]: Ascend sum: 7090.52[Error]: Calculation error. 123[Debug]: Host sum: 7549.67[Debug]: Ascend sum: 7549.66[Debug]: Result correct. 果然！是求和出现了问题，而且是时对时错的。然后有对这个问题进行了更详细的测试，主要是测试了两种情况，也即第一个核函数中的两个分支。 由于尾块是采用for循环计算的，理论上不会出现错误，但为了严谨还是进行了一些测试。将向量长度锁定在320，迫使它只执行尾块的逻辑，结果如下。 123[Debug]: Host sum: 387.095[Debug]: Ascend sum: 387.095[Debug]: Result correct. 123[Debug]: Host sum: 356.134[Debug]: Ascend sum: 356.134[Debug]: Result correct. 无论执行多少次，结果都是正确的。那现在基本可以确定是vec_cross_add()接口出现了问题。所以我们对代码进行修改，将vec_cross_add()接口用for循环代替。 此处的结论不正确，vec_cross_add()接口本身没有任何问题，详细测试及Softmax的重新实现详见关于vec_cross_add接口的详细测试 - 亦初 (deleter-d.github.io) 由于使用标量运算，故每个group求和的结果不再是向量，而是标量。所以存放求和结果的内存空间大小需要做一定的调整，这里申请大小为group_num * (32 / sizeof(data_t))的空间。其实理论上，每个group求和的结果只需要一个data_t数据类型的大小即可，但为了按照block为粒度严格分离group的访存空间，所以申请了与group_num个block大小相同的内存空间来存放。 1auto sum_res_buf = sycl::malloc_device&lt;data_t&gt;(group_num * (32 / sizeof(data_t)), Q); 具体求和过程则改为如下方式。 12345678910111213if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vec_exp(exp_res_vec_v, input_vec_v); for (int i = 0; i &lt; tail_elem_count; ++i) sum_res_buf[group_id * (32 / sizeof(data_t))] += exp_res_vec_v[i]; } else { bisheng::vec_exp(exp_res_vec, input_vec); for (int i = 0; i &lt; elem_per_group; ++i) { sum_res_buf[group_id * (32 / sizeof(data_t))] += exp_res_vec[i]; } } 进一步测试后，时对时错的问题解决了，到这里就可以说功能验证正确了，可喜可贺！ 性能测试 性能测试结果如下。 测试用例 640 6400 64000 640000 加速比 0.237432 1.478988 13.19605 87.72573 对比方案一可以观察到，对求和进行向量化的意义是非常大的，尤其是向量长度变得越来越长后，这种优化的提升尤为明显。现在的加速比可以说是令人比较满意的了。 空间上的优化（方案三） 通过观察方案二中的数据流动，我们可以发现，在空间利用上有些浪费的地方。先来看一下方案二的数据流动方式。 注：图中只描述了GM与UB之间的数据流，其中还发生了GM与Host之间的数据搬移。例如求和结果将会搬回Host，计算为标量后，利用该标量对分母向量进行初始化。 观察上述数据流可以发现，在使用exp_res_buf存储指数运算结果的时候，输入input_buf已经失去了作用，且后面也不会再使用其中的数据。同理，在使用res_buf存储最终结果的时候，exp_res_buf也不再使用了，因为指数运算结果此时已经读入了UB中。所以，input_buf、exp_res_buf和res_buf三者是可以合一的。 继续对UB中的内存使用进行分析。 初步的理论分析可知，Kernel 1中的input和exp_res_vec可以合一，Kernel 2中的exp_res_vec与res_vec可以合一。我们在此过程中使用了vec_exp(dst, src)和vec_div(dst, src0, src1)接口，这两个接口分别为一元运算和二元运算。 在毕昇C++中，对于基于bisheng::vector类型的通用一元运算函数接口，dst和src可以是同一个bisheng::vector对象，即原址计算。故Kernel 1中的input和exp_res_vec可以合一。而对于二元运算，目标数据和源数据在不同的repeat迭代之间不允许出现地址重叠，虽然有部分接口例外，但我们所使用的vec_div接口并不在这些例外中，故无法将Kernel 2中的exp_res_vec与res_vec合一。 经过上述一系列空间优化，最终的数据流如图所示。 方案实现 代码与方案二几乎一致，只是改变了内存搬移的源地址与目的地址，这里就不再放代码了。 功能验证 经过测试，功能验证正确。 性能测试 性能测试结果如下。 测试用例 640 6400 64000 640000 加速比 0.224613 1.512394 13.30433 88.70575 可以观察到，与方案二相比，时间上几乎没有区别。但由于优化了空间利用率，所以使得设备端可以承载更大长度的向量，优化的意义是比较大的。 分核方案的优化（方案四） 下面所有的讨论均已float类型的数据为例。 分核方案的核心思想就是，尽可能利用所有物理核心，并在此基础上令每个核心处理尽可能多的数据。而我们上面采用的方案是临时将每个核处理的元素数量固定为640，这显然不是最优的方案。 首先是尽可能利用所有的物理核心，昇腾910拥有32个物理核心，所以我们要想办法让32个核心都在工作状态，尽量避免一核干活儿，多核围观的滑稽场景。 首先分析一个问题，逻辑核的数量如何确定？假设输入向量长度为，每个逻辑核处理的运算个数为，在不考虑有尾块的情况下，可以得到逻辑核数量的公式为。由用户指定，不是我们可以控制的，故我们只能在和上做文章。为了更好的理解，我们变形一下公式。这样就可以比较直观的看出，我们需要在和之间做一个权衡。 这个权衡只有两种思考方式： 一种是确定，根据计算得到。说人话就是把逻辑核的数量定死，然后根据用户给的向量长度计算每个核要处理的元素个数。 另一种是确定，即把每个逻辑核要处理的元素数量定死，然后根据用户给的向量长度计算逻辑核数量。 情况一 先来考虑第一种情况，即将定死。假设我们就定为与物理核数相同的数量，即32。考虑一个问题，假设输入向量长度非常长，那么拆分成32份后依然非常长，长到个元素的大小超出了UB的承载范围，那么此时算子就会崩溃。 这时候有人就要说了（假装有人要说）：那不能把逻辑核数量写大一点吗？ 好！听你的，我们将逻辑核数量定为320，理想状态下，每个物理核将处理10个逻辑核。此时再考虑一种情况，用户给的输入向量非常短，短到没办法分为320份，此时为0。意味着你的每个逻辑核中，要么是处理尾块，要么根本就没有元素，但320个逻辑核依然会开启。这显然是不够合理的。 情况二 再来考虑将定死的情况，即将每个逻辑核要处理的元素个数定死，其实就是我们上面方案的使用的策略，这里我们暂时考虑n为640的情况。同样考虑一些比较极端的例子，假设输入向量非常长，此时即会非常大，即逻辑核的数量会非常多。虽然这样能够充分利用所以物理核，但每个逻辑核的承载能力远不止640个元素，这样就浪费了单个逻辑核的能力，把资源都消耗在调度逻辑核上了。 这时候又有人要说了（依然假装有人说）：那不能把逻辑核处理的元素个数写大一点吗？ 好！还是听你的，我们将定为UB能够承载的上限。这种情况下，我们甚至不用考虑输入向量长度非常短的情况，只考虑向量长度小于的情况，即向量长度小于31个物理核同时工作时可以处理的最大元素个数。此时至少会有1个物理核心在看戏，若向量长度进一步缩短，那看戏的物理核只会越来越多。这显然也是不够合理的。 动态方案 分析完两种情况，可以得出一个结论，单纯的确定与中的任何一个都是不合适的。 那我们应该怎么确定呢？动态确定！ 首先确定一个问题，我们这个算子，每个group处理多少数据是UB的上限。经过测试，每个group最多可以处理87360字节的数据，即个元素。这个上限并不是所有算子都一样的，因为每个算子在UB上申请内存的情况不同，所以要具体问题具体分析。 我们继续上面那个公式，这里为了通用性，我们换成处理的字节数，而不是元素个数。进而，那么公式变为。 当时，将定为1280，则，此时算子可能无法充分利用所有物理核。 当时，将定为2560，则，这意味着算子将充分利用所有物理核。 当时，将定为5120，则，也会充分利用所有物理核。 当时，将定为12800，则，也会充分利用所有物理核。 当时，将定为25600，则，同样充分利用所有物理核。 当时，将定为51200，则，同样充分利用所有物理核。 当时，将定为87360，则，同样充分利用所有物理核。 采取这种策略，虽然在输入向量总字节数小/于时可能会出现某些物理核不工作的情况，但考虑到实际情况下，输入向量都是比较长的向量，这种偶尔的空闲是可接受的。 这里只是展示一种思路，条件分支中的阈值是可以根据实际情况进行调整的，并不是只能按照2560、5120等阈值进行分割。 方案实现 同样还是注意带注释的地方，其余地方与之前相同。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113std::vector&lt;data_t&gt; ascend_softmax(std::vector&lt;data_t&gt; input) { std::size_t input_sz = input.size(); std::size_t byte_count = input_sz * sizeof(data_t); if (byte_count &lt; 32) return softmax(input); // 这里依照上面介绍的策略确定每个逻辑核所处理的元素个数 std::size_t elem_per_group = 0; if (byte_count &gt;= PHYSICAL_CORES * UB_MAX_BYTES) elem_per_group = UB_MAX_BYTES / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 51200) elem_per_group = 51200 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 25600) elem_per_group = 25600 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 12800) elem_per_group = 12800 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 5120) elem_per_group = 5120 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 2560) elem_per_group = 2560 / sizeof(data_t); else elem_per_group = 1280 / sizeof(data_t); const std::size_t tail_elem_count = input_sz % elem_per_group; const std::size_t group_num = (tail_elem_count &gt; 0) ? ((input_sz / elem_per_group) + 1) : (input_sz / elem_per_group); sycl::queue Q(sycl::ascend_selector{}); auto dev_buf = sycl::malloc_device&lt;data_t&gt;(group_num * elem_per_group, Q); auto sum_res_buf = sycl::malloc_device&lt;data_t&gt;(group_num * (32 / sizeof(data_t)), Q); std::vector&lt;data_t&gt; sum_res(group_num * (32 / sizeof(data_t)), 0.0f); std::vector&lt;data_t&gt; res(input_sz, 0.0f); Q.memcpy(dev_buf, input.data(), byte_count); Q.launch&lt;class Summary&gt;(group_num, [=](sycl::group&lt;1&gt; group) { // 此处直接申请最大空间，因为定义毕昇向量时指定大小必须用常量表达式，大小需要在编译时确定 // 由于前面采用了动态策略，所以不能直接使用elem_per_group来定义毕昇向量 // 只需要在使用时控制访存范围即可，第二个核函数同理，不再赘述 bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; input_vec; std::size_t group_id = group.get_group_id(); input_vec.load( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vec_exp(input_vec_v, input_vec_v); for (int i = 0; i &lt; tail_elem_count; ++i) sum_res_buf[group_id * (32 / sizeof(data_t))] += input_vec_v[i]; } else { // 由于毕昇向量定义了最大长度，故即使是整block的情况，也需要用变长向量来控制访存范围 bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), elem_per_group); bisheng::vec_exp(input_vec_v, input_vec_v); for (int i = 0; i &lt; elem_per_group; ++i) { sum_res_buf[group_id * (32 / sizeof(data_t))] += input_vec_v[i]; } } input_vec.store( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); Q.memcpy(sum_res.data(), sum_res_buf, group_num * (32 / sizeof(data_t)) * sizeof(data_t)); Q.wait(); data_t sum; for (int i = 0; i &lt; sum_res.size(); i += 32 / sizeof(data_t)) sum += sum_res[i]; Q.launch&lt;class Softmax&gt;(group_num, [=](sycl::group&lt;1&gt; group) { bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; exp_res_vec; bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; divisor_vec(sum); bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; res_vec; std::size_t group_id = group.get_group_id(); exp_res_vec.load( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; divisor_vec_v(divisor_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), tail_elem_count); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } else { bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), elem_per_group); bisheng::vector_view&lt;data_t&gt; divisor_vec_v(divisor_vec.data(), elem_per_group); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), elem_per_group); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } res_vec.store( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); Q.memcpy(res.data(), dev_buf, byte_count); Q.wait(); sycl::free(dev_buf, Q); sycl::free(sum_res_buf, Q); return res;} 功能测试 功能测试验证正确。 性能测试 性能测试结果如下。 测试用例 640 6400 64000 640000 加速比 0.234373 1.436941 12.35908 80.59147 分析了许多，本想着动态分核结果会有惊喜。嘿！您猜怎么着？还真是大惊喜！ 在动态分核的策略下，当向量长度总字节数不少于时，总能保证32个物理核都在工作，而且不至于令逻辑核数量过多，但神奇的事情来了，这种策略成功实现了负优化！！ 本方案的性能测试结果看起来还不错，但我们继续增大向量长度，使得总字节数到达划分策略的阈值附近。以float类型的数据为例，令向量长度为698880，此时总字节数为。此时这种策略将分配32个逻辑核，完美贴合物理核数量，每个核心处理87360字节的数据，完美贴合UB承载的上限。惊喜的事情来了，请看加速比 测试用例 698880 方案三加速比 96.29706 方案四加速比 67.26953 什么鬼情况？！？！ 我们分别观察一下它们的分核情况。 方案三如下： 123[PERMORMANCE]: Host time cost: 93873327 ns[Debug]: Group num: 1875 Elements per group: 640[PERMORMANCE]: Ascend time cost: 728001 ns 方案四如下： 123[PERMORMANCE]: Host time cost: 94127478 ns[Debug]: Group num: 55 Elements per group: 21840[PERMORMANCE]: Ascend time cost: 785999 ns 可以发现两者都充分利用了所有物理核，但方案四的策略使得加速比下降了，反观方案三的1875个逻辑核取得了完胜。但转念一想，是不是让每个逻辑核承载到UB的上限有点过分，那么再来测试一下正常压力下的表现。 还是以float类型数据为例，向量长度为102400，此时总字节数为，此时将分配32个逻辑核，每个核处理12800字节的数据，远不到UB承载的上限。 方案三分核情况如下： 123[PERMORMANCE]: Host time cost: 7872144 ns[Debug]: Group num: 160 Elements per group: 640[PERMORMANCE]: Ascend time cost: 375999 ns 方案四分核情况如下： 123[PERMORMANCE]: Host time cost: 7813204 ns[Debug]: Group num: 32 Elements per group: 3200[PERMORMANCE]: Ascend time cost: 400999 ns 加速比如下： 测试用例 102400 方案三加速比 20.73252 方案四加速比 19.4274 依然是有略微的下降，这也排除了UB压力过大的问题。 结论 经过一系列分析，目前能够得出的结论是，尽可能多的逻辑核数量的收益要大于单逻辑核内处理尽可能多的数据。 异构分核的坑还是太多了，踩都踩不完，过程中有很多反直觉的情况，必须靠实验来佐证。 完整代码 最后贴上目前效果最好（方案三）的完整代码，其中包括一些自定义的Debug信息，不用太纠结。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242#include &lt;cmath&gt;#include &lt;iomanip&gt;#include &lt;iostream&gt;#include &lt;random&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;#include &lt;vector&gt;#include &lt;bisheng/bisheng.hpp&gt;#include &lt;sycl/sycl.hpp&gt;#define DEBUG#define DEBUG_HEAD \"\\033[34m[Debug]: \\033[0m\"#define ERROR_HEAD \"\\033[31m[Error]: \\033[0m\"#define PERFORMANCE#define PERFORMANCE_HEAD \"\\033[36m[PERMORMANCE]: \\033[0m\"#define INPUT_COUNT 102400std::vector&lt;float&gt; softmax(std::vector&lt;float&gt; input) {#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"The host operator is called.\\n\";#endif#ifdef PERFORMANCE struct timespec time; clock_gettime(CLOCK_REALTIME, &amp;time); auto start_time = time.tv_sec * 1000000000 + time.tv_nsec;#endif float sum = 0.0; for (auto x : input) { sum += expf(x); }#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Host sum: \" &lt;&lt; sum &lt;&lt; \"\\n\";#endif std::vector&lt;float&gt; res; for (auto x : input) { res.push_back(expf(x) / sum); }#ifdef PERFORMANCE clock_gettime(CLOCK_REALTIME, &amp;time); auto end_time = time.tv_sec * 1000000000 + time.tv_nsec; std::cout &lt;&lt; PERFORMANCE_HEAD &lt;&lt; \"Host time cost: \" &lt;&lt; end_time - start_time &lt;&lt; \" ns\" &lt;&lt; std::endl;#endif return res;}std::vector&lt;float&gt; ascend_softmax(std::vector&lt;float&gt; input) { std::size_t input_sz = input.size(); std::size_t byte_count = input_sz * sizeof(float); // call the host operator if input isn't enough a full block if (byte_count &lt; 32) {#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"The input vector is not enough for a full block.\\n\";#endif return softmax(input); } // ascend code start#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"The ascend operator is called.\\n\";#endif // number of elements per group const std::size_t elem_per_group = 640; // number of elements in tail block const std::size_t tail_elem_count = input_sz % elem_per_group; // number of groups // if tail block is exist, apply for one more group const std::size_t group_num = (tail_elem_count &gt; 0) ? ((input_sz / elem_per_group) + 1) : (input_sz / elem_per_group);#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Group num: \" &lt;&lt; group_num &lt;&lt; \" Elements per group: \" &lt;&lt; elem_per_group &lt;&lt; \"\\n\";#endif sycl::queue Q(sycl::ascend_selector{}, nullptr, {sycl::property::queue::enable_profiling()}); // GM memory allocation auto dev_buf = sycl::malloc_device&lt;float&gt;(group_num * elem_per_group, Q); auto sum_res_buf = sycl::malloc_device&lt;float&gt;(group_num * (32 / sizeof(float)), Q); // Host memory allocation std::vector&lt;float&gt; sum_res(group_num * (32 / sizeof(float)), 0.0f); std::vector&lt;float&gt; res(input_sz, 0.0f); // host -&gt; GM Q.memcpy(dev_buf, input.data(), byte_count);#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Kernel function started.\\n\";#endif sycl::event e0 = Q.launch&lt;class Summary&gt;(group_num, [=](sycl::group&lt;1&gt; group) { bisheng::vector&lt;float, elem_per_group&gt; input_vec; std::size_t group_id = group.get_group_id(); // GM -&gt; UB input_vec.load( sycl::global_ptr&lt;float&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // if tail block has element and this is the last group bisheng::vector_view&lt;float&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vec_exp(input_vec_v, input_vec_v); for (int i = 0; i &lt; tail_elem_count; ++i) sum_res_buf[group_id * (32 / sizeof(float))] += input_vec_v[i]; } else { // full block data bisheng::vec_exp(input_vec, input_vec); for (int i = 0; i &lt; elem_per_group; ++i) { sum_res_buf[group_id * (32 / sizeof(float))] += input_vec[i]; } } // UB -&gt; GM input_vec.store( sycl::global_ptr&lt;float&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); // GM -&gt; Host Q.memcpy(sum_res.data(), sum_res_buf, group_num * (32 / sizeof(float)) * sizeof(float)); Q.wait(); float sum; for (int i = 0; i &lt; sum_res.size(); i += 32 / sizeof(float)) sum += sum_res[i];#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Ascend sum: \" &lt;&lt; sum &lt;&lt; \"\\n\";#endif sycl::event e1 = Q.launch&lt;class Softmax&gt;(group_num, [=](sycl::group&lt;1&gt; group) { // UB memory of exponent result bisheng::vector&lt;float, elem_per_group&gt; exp_res_vec; // UB memory of divisor bisheng::vector&lt;float, elem_per_group&gt; divisor_vec(sum); // UB memory of final result bisheng::vector&lt;float, elem_per_group&gt; res_vec; std::size_t group_id = group.get_group_id(); // GM -&gt; UB exp_res_vec.load( sycl::global_ptr&lt;float&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // if tail block has element and this is the last group bisheng::vector_view&lt;float&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vector_view&lt;float&gt; divisor_vec_v(divisor_vec.data(), tail_elem_count); bisheng::vector_view&lt;float&gt; res_vec_v(res_vec.data(), tail_elem_count); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } else { // full block data bisheng::vec_div(res_vec, exp_res_vec, divisor_vec); } // UB -&gt; GM res_vec.store( sycl::global_ptr&lt;float&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); });#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Kernel function finished.\\n\";#endif // GM -&gt; host Q.memcpy(res.data(), dev_buf, byte_count); Q.wait(); sycl::free(dev_buf, Q); sycl::free(sum_res_buf, Q); // ascend code end#ifdef PERFORMANCE const uint64_t e0_start_time = e0.get_profiling_info&lt;sycl::info::event_profiling::command_start&gt;(); const uint64_t e0_end_time = e0.get_profiling_info&lt;sycl::info::event_profiling::command_end&gt;(); const uint64_t e1_start_time = e1.get_profiling_info&lt;sycl::info::event_profiling::command_start&gt;(); const uint64_t e1_end_time = e1.get_profiling_info&lt;sycl::info::event_profiling::command_end&gt;(); std::cout &lt;&lt; PERFORMANCE_HEAD &lt;&lt; \"Ascend time cost: \" &lt;&lt; (e0_end_time - e0_start_time) + (e1_end_time - e1_start_time) &lt;&lt; \" ns\" &lt;&lt; std::endl;#endif return res;}int main() {#ifdef DEBUG std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Compile succeed\" &lt;&lt; std::endl;#endif std::vector&lt;float&gt; vec; std::random_device rd; std::mt19937 gen(rd()); std::uniform_real_distribution&lt;float&gt; urdis(-1, 1); for (int i = 0; i &lt; INPUT_COUNT; i++) { vec.push_back(urdis(gen)); } std::vector&lt;float&gt; host_res = softmax(vec); std::vector&lt;float&gt; ascend_res = ascend_softmax(vec); for (int i = 0; i &lt; host_res.size(); ++i) { if (std::fabs(host_res[i] - ascend_res[i]) / host_res[i] &gt; 0.02) { std::cout &lt;&lt; ERROR_HEAD &lt;&lt; \"Calculation error.\" &lt;&lt; std::endl; return EXIT_FAILURE; } } std::cout &lt;&lt; DEBUG_HEAD &lt;&lt; \"Result correct.\" &lt;&lt; std::endl; return EXIT_SUCCESS;}","link":"/posts/15984/"},{"title":"毕昇异构算子开发全流程","text":"毕昇异构算子开发的整体工作流，供项目成员参考。 毕昇异构算子开发全流程 前期准备 源码准备 先将源码仓库fork到自己的仓库中，并将自己的仓库克隆到本地，这里的本地指服务器。 1git clone https://gitee.com/xxx/itk.git # xxx替换成自己的gitee用户名 克隆好之后，在与源码同级的文件夹中创建两个文件夹，用来存放编译构建和安装生成的文件。 12mkdir ITK-buildmkdir ITK-install 截止目前文件结构应如下所示。 1234.|--itk|--ITK-build|--ITK-install git准备 进入源码文件夹，并新建一个分支。以我的算子为例，创建一个名为vnl_matrix_update的分支。 12cd itkgit branch vnl_matrix_update 创建好后切换到该分支上。 1git checkout vnl_matrix_update 可以看到成果切换分支的提示。 1Switched to branch 'vnl_matrix_update' 然后提交分支。 12git add . # 将所有修改添加至暂存区git commit -m 'create branch' # 将暂存区的所有内容提交至本地仓库 如果在执行commit时出现如下提示： 1234567891011*** Please tell me who you are.Rungit config --global user.email \"you@example.com\"git config --global user.name \"Your Name\"to set your account's default identity.Omit --global to set the identity only in this repository.fatal: empty ident name (for &lt;bisheng_tester2@csobluex.(none)&gt;) not allowed 则根据提示对git进行配置。 12git config --global user.email \"you@example.com\" # 邮箱替换为自己的git config --global user.name \"Your Name\" # 用户名也替换为自己的 然后推送到远程仓库。 1git push origin vnl_matrix_update # 将vnl_matrix_update分支推送到远程仓库origin 执行push后按照提示输入Gitee的用户名和密码。 12345678Username for 'https://gitee.com': xxx # xxx替换成自己的gitee用户名Password for 'https://yichu12138@gitee.com': # 输入密码Total 0 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-6.4]remote: Create a pull request for 'vnl_matrix_update' on Gitee by visiting:remote: https://gitee.com/yichu12138/itk/pull/new/yichu12138:vnl_matrix_update...yichu12138:masterTo https://gitee.com/yichu12138/itk.git * [new branch] vnl_matrix_update -&gt; vnl_matrix_update 看到上述提示后，则表明分支已经成果提交到了自己的远程仓库中。 首次编译构建 按照之前的文档ITK线上环境编译与VSCode远程环境接入，将未改动过的源码编译构建并安装。 不建议先修改代码再编译构建！！！可能会遇到问题。 通用修改项 接下来先修改大家都需要进行修改的地方，这些修改主要是为了让ITK适配毕昇编译器。 顶层CMakeLists.txt 第46行修改前： 123if(NOT CMAKE_CXX_STANDARD) set(CMAKE_CXX_STANDARD 11) # Supported values are ``11``, ``14``, and ``17``.endif() 修改后： 123if(NOT CMAKE_CXX_STANDARD) set(CMAKE_CXX_STANDARD 17) # 修改C++标准为17，源码为11endif() 第231行修改前： 1set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${ITK_REQUIRED_CXX_FLAGS}\") 修改后： 1set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${ITK_REQUIRED_CXX_FLAGS} -lsycl\") 其他修改项 其余的修改项要根据自己的算子来做相应的调整。 CMakeLists.txt 找到与算子同级的CMakeLists.txt，即管理所修改算子的CMakeLists.txt。 以vnl_matrix算子为例，vnl_matrix.h的路径为Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_matrix.h，则管理它的CMakeLists.txt路径为Modules/ThirdParty/VNL/src/vxl/core/vnl/CMakeLists.txt。 当然也不能完全靠路径来判断，在找到的CMakeLists.txt中应该能找到算子的名称之类的信息，来确定这个CMakeLists.txt到底是不是管理该算子。 例如vnl_matrix对应的CMakeLists.txt中就包含如下信息，从而可以确定。 找到对应的CMakeLists.txt后，在末尾添加一行代码。 1set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsycl -fsycl-targets=ascend_910-cce\") 算子修改 找到要修改的算子，并找到算子的实现。 我要修改的update()算子位于Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_matrix.h:421，相应的实现位于Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_matrix.hxx:634。 现在vnl_matrix.hxx中引入以下两个头文件。 12#include &lt;sycl/sycl.hpp&gt;#include &lt;bisheng/bisheng.hpp&gt; 然后对算子代码进行修改。修改前如下所示： 12345678910111213141516template &lt;class T&gt;vnl_matrix&lt;T&gt;&amp; vnl_matrix&lt;T&gt;::update (vnl_matrix&lt;T&gt; const&amp; m, unsigned top, unsigned left){ unsigned int bottom = top + m.num_rows; unsigned int right = left + m.num_cols;#ifndef NDEBUG if (this-&gt;num_rows &lt; bottom || this-&gt;num_cols &lt; right) vnl_error_matrix_dimension (\"update\", bottom, right, m.num_rows, m.num_cols);#endif for (unsigned int i = top; i &lt; bottom; i++) for (unsigned int j = left; j &lt; right; j++) this-&gt;data[i][j] = m.data[i-top][j-left]; return *this;} 目前的代码暂未考虑模板类型和数据对齐的问题，只是为了展示整个工作流程。修改后如下所示： 12345678910111213141516171819202122232425262728293031323334353637template &lt;class T&gt;vnl_matrix&lt;T&gt;&amp; vnl_matrix&lt;T&gt;::update (vnl_matrix&lt;T&gt; const&amp; m, unsigned top, unsigned left){ unsigned int bottom = top + m.num_rows; unsigned int right = left + m.num_cols;#ifndef NDEBUG if (this-&gt;num_rows &lt; bottom || this-&gt;num_cols &lt; right) vnl_error_matrix_dimension (\"update\", bottom, right, m.num_rows, m.num_cols);#endif const auto thisM = this-&gt;num_rows; const auto thisN = this-&gt;num_cols; const auto mM = m.num_rows; const auto mN = m.num_cols; sycl::queue Q(sycl::ascend_selector{}); auto * devThis = malloc_device&lt;int&gt;(thisM * thisN, Q); auto * devM = malloc_device&lt;int&gt;(mM * mN, Q); Q.memcpy(devThis, *this-&gt;data, thisM * thisN * sizeof(int)); Q.memcpy(devM, *m.data, mM * mN * sizeof(int)); Q.launch&lt;class Test&gt;(mM, [=](sycl::group&lt;1&gt; group) { __local int UBA[mN]; size_t groupId = group.get_id(); sycl::dmi::memcpy_blocks(UBA, &amp;devM[groupId * mN], mN * sizeof(int) / 32); sycl::dmi::memcpy_blocks(&amp;devThis[top * thisN + groupId * thisN + left], UBA, mN * sizeof(int) / 32); }); Q.memcpy(*this-&gt;data, devThis, thisM * thisN * sizeof(int)); Q.wait(); return *this;} 具体的业务逻辑要根据自己算子的功能来编写。 修改后编译构建 算子修改完成后，进入ITK-build文件夹。由于刚才修改了CMakeLists.txt，故需执行一次cmake来刷新Makefile。 1cmake ../itk/ 然后使用make编译构建并安装。 1make -j24 &amp;&amp; make install 安装好后就可以测试了，测试通过就可以认为完成了代码的修改工作。 提交成果 最后将修改后的成果提交至仓库中。 12git add .git commit -m 'operator vnl_matrix::update() heterogeneous code' 执行commit后会提示本次提交的代码与上次提交代码之间的差异。 12[vnl_matrix_update a158479] operator vnl_matrix::update() heterogeneous code 3 files changed, 33 insertions(+), 5 deletions(-) 最后推送到远程仓库。 1git push origin vnl_matrix_update 出现推送成果的提示即可。 12345678Counting objects: 23, done.Delta compression using up to 192 threads.Compressing objects: 100% (12/12), done.Writing objects: 100% (12/12), 1.45 KiB | 0 bytes/s, done.Total 12 (delta 10), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-6.4]To https://gitee.com/yichu12138/itk.git 2fb588c..a158479 vnl_matrix_update -&gt; vnl_matrix_update 发起Pull Request 登录Gitee到自己的仓库中，点击+ Pull Request发起PR。 输入标题即可提交，当然最好在说明中简略说明本次PR的目的和所修改的代码。","link":"/posts/35929/"},{"title":"毕昇异构算子数据搬移注意事项","text":"毕昇异构算子在搬移数据的时候，有一个比较隐蔽的问题，开发过程中一定要多加分析，避免出现类似的问题。 数据搬移注意事项 示例 在调用向量搬移接口load和store的时候，可能会遇到搬移出来的数据不符合预期的情况，用以下一个例子进行说明。 引入头文件，并定义两个常量作为矩阵的行和列数。 123456789#include &lt;iostream&gt;#include &lt;sycl/sycl.hpp&gt;#include &lt;bisheng/bisheng.hpp&gt;#include &lt;bisheng/vector.hpp&gt;using namespace sycl;using namespace bisheng;constexpr int M = 8;constexpr int N = 16; 定义毕昇异构算子，以实现以下功能。 代码实现如下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void func(){ queue Q(ascend_selector{}); // host数据 float *input_ptr = new float[M * N]; float *output_ptr = new float[M]; // 初始化数据 for (int i = 0; i &lt; M; i++) { for (int j = 0; j &lt; N; j++) { input_ptr[i * N + j] = j; } } // GM的buffer auto *input_buf = malloc_device&lt;float&gt;(M * N, Q); auto *output_buf = malloc_device&lt;float&gt;(M, Q); // 从host端拷贝到GM Q.memcpy(input_buf, input_ptr, M * N * sizeof(float)); Q.launch&lt;class Test&gt;(M, [=](group&lt;1&gt; group) { auto group_id = group.get_id(); // UB上的向量 vector&lt;float, N&gt; vec; vector&lt;float, 1&gt; res; // 从GM加载到UB上 vec.load(global_ptr&lt;float&gt;(input_buf + group_id * N)); // 取正确的数放入结果向量中 res[0] = vec[group_id]; // 从UB存储到GM上 res.store(global_ptr&lt;float&gt;(output_buf + group_id)); }); Q.wait(); Q.memcpy(output_ptr, output_buf, M * sizeof(float)); Q.memcpy(temp_ptr, temp_buf, M * N * sizeof(float)); Q.wait(); std::cout &lt;&lt; \"output data is:\" &lt;&lt; std::endl; for (int i = 0; i &lt; M; i++) { std::cout &lt;&lt; output_ptr[i] &lt;&lt; \" \"; } std::cout &lt;&lt; std::endl; free(input_buf, Q); free(output_buf, Q);} 隐蔽的问题 上面的代码按照逻辑来看，似乎不存在问题，但其中有一个很隐蔽的致命问题。让我们回看核函数的代码。 123456789101112Q.launch&lt;class Test&gt;(M, [=](group&lt;1&gt; group) { auto group_id = group.get_id(); // UB上的向量 vector&lt;float, N&gt; vec; vector&lt;float, 1&gt; res; // 从GM加载到UB上 vec.load(global_ptr&lt;float&gt;(input_buf + group_id * N)); // 取正确的数放入结果向量中 res[0] = vec[group_id]; // 从UB存储到GM上 res.store(global_ptr&lt;float&gt;(output_buf + group_id));}); 不管是向量的声明，调用load()接口加载数据，还是根据group_id取得正确的数据都没有任何问题。这个隐蔽的问题隐藏在调用store接口的时候。 依照目前的写法，我们所期望的数据在内存中的搬移流程如下图所示。将Host端的数据搬移至Global Memory后，利用向量搬移接口load()搬移至Unified Buffer，每个Group读取一行数据，然后根据group_id取得正确的数据存入一个单元素向量中，再将该结果向量利用store()搬移至Global Memory中。 我们可以执行一下这段代码，输出的结果可能是这样的。 10 1 2 5.91908e-42 4 5.91908e-42 6 7 还可能是这样的。 10 1 2 5.91908e-42 4 5.91908e-42 2.8026e-45 0 还可能是。。。。 10 1 1 -1 4 5.91908e-42 2.8026e-45 7 10 1 1 3 5.91908e-42 2.8026e-45 0 2.8026e-45 10 1 2 5.91908e-42 4 5.91908e-42 2.8026e-45 7 产生的原因 这样的结果显然不符合预期。不幸的是，实际的搬移过程并不是我们想象的这样，致命的错误发生再从Unified Buffer搬移至Global Memory的过程中。 我们可以看一下load()和store()接口的源码是如何定义的。 1234567void load(sycl::global_ptr&lt;T&gt; addr, size_t n = N) { return DMI_COPY_BLOCKS(this-&gt;data(), &amp;addr[0], n);}void store(sycl::global_ptr&lt;T&gt; addr, size_t n = N) { return DMI_COPY_BLOCKS(&amp;addr[0], this-&gt;data(), n);} 可以观察到它们调用了一个名为DMI_COPY_BLOCKS()的接口，所以load()和store()接口显然是以块粒度搬移数据的，而根据毕昇C++的文档可以得知，一个block的大小为32B。但我们所store()的数据根本不够一个block，这就会导致在store()的过程中，实际上是搬移了一整个block的数据。除了第一个位置拥有我们取出来的数据之外，其他位置均为未定义的数据。 所以实际上的搬移情况是如下图所示的。 同时，Device端的Group之间都是异步的，甚至Group内部的一些操作都是异步的，这就导致output_buf有可能会被多个Group同时写入。显而易见地，这种情况会导致最终得到的output_buf中存在不正确的数据，如果你运气足够好，那还是有可能得到正确结果的。但计算机是科学，不是玄学。 解决方案 既然load()和store()的搬移都是块粒度的，那我们索性就避免让不同的group访问到同一个block。将上面的代码稍加修改，如下所示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void correct(){ queue Q(ascend_selector{}); float *input_ptr = new float[M * N]; // 保证结果所在的block不重叠 float *output_ptr = new float[M * 8]; for (int i = 0; i &lt; M; i++) { for (int j = 0; j &lt; N; j++) { input_ptr[i * N + j] = j; } } auto *input_buf = malloc_device&lt;float&gt;(M * N, Q); // 相应的buffer也要申请更大的空间 auto *output_buf = malloc_device&lt;float&gt;(M * 8, Q); Q.memcpy(input_buf, input_ptr, M * N * sizeof(float)); Q.launch&lt;class Test&gt;(M, [=](group&lt;1&gt; group) { auto group_id = group.get_id(); vector&lt;float, N&gt; vec; vector&lt;float, 1&gt; res; vec.load(global_ptr&lt;float&gt;(input_buf + group_id * N)); res[0] = vec[group_id]; // 从UB存储到GM上是，要注意位置的计算 res.store(global_ptr&lt;float&gt;(output_buf + group_id * 8)); }); Q.wait(); Q.memcpy(output_ptr, output_buf, M * 8 * sizeof(float)); Q.wait(); std::cout &lt;&lt; \"output data is:\" &lt;&lt; std::endl; for (int i = 0; i &lt; M; i++) { for (int j = 0; j &lt; 8; j++) { std::cout &lt;&lt; output_ptr[i * 8 + j] &lt;&lt; \" \"; } std::cout &lt;&lt; std::endl; } free(input_buf, Q); free(output_buf, Q);} 关键的修改在于，我们将output_buf直接申请成了一个大矩阵，上图说话。 这种方法直接避免了block的交叠，即使Group再异步，也不会产生写冲突。虽然Global Memory中的所有红色部分都是未定义的无效数据，但所带来的性能损耗几乎可以忽略不记。 需要注意该问题的情况 一定要仔细分析自己的算子逻辑，在将Unified Buffer中的数据搬移至Global Memory的过程中，理清搬移的数据大小，分析是否存在block交叠的可能性。尤其要注意输入数据很小的情况下，会不会引起该问题。如果这种情况下无法处理这个问题，可以尝试将输入数据极小的情况做单独的处理，不使用昇腾加速卡进行加速，当然也可以分析更好的解决方案。","link":"/posts/58921/"},{"title":"打造vscode般的neovim","text":"偶然在Youtube上看到一个大佬的Neovim配置教程，深入浅出，逻辑条理，加了一点自己的内容，就产生了这么一个授人以渔的教程。 打造VS Code般的Neovim 一点废话 Neovim是什么就不过多介绍了，有兴趣可以自行Google，没兴趣那我就一句话介绍Neovim： 一个可以变得很好看很好用的基于TUI的文本编辑器。 由于Vim拒绝了两个大补丁，作者一怒之下开的新分支。 Neovim是一个积极重构Vim的项目，旨在简化维护和鼓励贡献，在多个开发人员之间分配工作，在不修改核心的情况下创建高级UI，最大化可扩展性。 就是单纯用vim觉得丑，所以跑路，尝试配置一个媲美VS Code体验的Neovim。教程来自于油管一个大佬，讲的很不错，不像某些教程，只告诉你怎么做，不告诉你为什么。这里附上链接，有兴趣可以自行观看。Neovim for Newbs. FREE NEOVIM COURSE - YouTube 后面的内容有一个很重要的宗旨，你不是非得按照这个文档描述的步骤一步一步来做，这个文档最重要的目的是告诉你Neovim配置的方法。当你学会这个方法之后，可以完全自定义想要的内容。当然，这个时代不一定非要自己造轮子，github上有很多别人配置好的预制菜，你只需要clone下来就可以用。但本文档可以让你了解整个流程，在抄别人作业过程中遇到问题可以自己解决掉。 依赖 安装之前，你大致需要以下这些依赖工具，请确保环境中已经安装。 1git, gcc, g++, python, python-venv, unzip 安装Neovim 官方仓库：neovim/neovim Windows系统可以直接下载zip包，解压到任何位置，然后运行nvim.exe。 Linux下可以下载nvim.appimage，然后执行chmod u+x nvim.appimage &amp;&amp; ./nvim.appimage。 安装好后在终端里运行nvim，就能得到下图。 安装Nerd fonts 我建议在安装完Neovim后先把字体安装好，后面用到的一些美化插件是比较依赖于Nerd fonts的。打开官方网站Nerd Fonts，选一个喜欢的字体下载。这里推荐Hack Nerd Font。 Windows下只需要双击ttf文件，点击安装即可。 Linux下需要执行以下步骤。 12345sudo unzip Hack -d /usr/share/fonts/Hackcd /usr/share/fonts/Hacksudo mkfontscale # 生成核心字体信息sudo mkfontdir # 生成字体文件夹sudo fc-cache -fv # 刷新系统字体缓存 初始化配置文件 Neovim的配置全部是基于lua的，所以后面创建的所以脚本均为lua脚本。 创建初始化配置文件init.lua，进行一些基础配置。 Windows中配置文件放在C:\\Users\\username\\AppData\\Local\\nvim下； Linux中放在~/.config/nvim下 1234vim.cmd(\"set expandtab\") -- 使用空格代替制表符，确保在不同的编辑环境中保持一致vim.cmd(\"set tabstop=2\") -- 设置制表符的宽度为2个空格vim.cmd(\"set softtabstop=2\") -- 设置软制表符的宽度也为2个空格，软制表符指的是按下Tab的时候插入的空格数vim.cmd(\"set shiftwidth=2\") -- 设置每级缩进为2个空格 然后在命令模式下执行source %，激活当前配置文件。 插件管理器 目前主流的插件管理器有两个：lazy和packer。 官方仓库： folke/lazy.nvim wbthomason/packer.nvim 两个包管理的差别不大，为了贯彻好看的宗旨，这里我们选择lazy作为包管理器。 安装lazy非常简单，只需要将README中Installation部分的语句复制粘贴到init.lua中即可。下面这些语句实现的大致功能为，为lazy指定一个存放数据的目录，然后检查lazy是否被安装，若没有则从github上拉取安装。 这里注意要修改一下链接，将仓库链接从https协议改为ssh协议。如果你的网络条件支持稳定的通过https访问github，那当我这句话没说过。 123456789101112local lazypath = vim.fn.stdpath(\"data\") .. \"/lazy/lazy.nvim\"if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \"git\", \"clone\", \"--filter=blob:none\", \"ssh://git@github.com/folke/lazy.nvim.git\", -- 注意此处需要魔改一下 \"--branch=stable\", -- latest stable release lazypath, })endvim.opt.rtp:prepend(lazypath) 然后我们创建两个变量来存放插件和选项，并调用setup()函数来配置它。这个setup()函数将伴随整个插件配置过程，具体细节无需关心，毕竟我们也不写lua，我们只是lua的搬运工。 1234local plugins = {}local opts = {}require(\"lazy\").setup(plugins, opts) 完成上面的步骤后，同样source %激活一下，这里可能会卡顿一会儿，因为此时后台在从github上拉取并安装lazy。 安装好后，命令模式下执行: Lazy就可以打开lazy的管理界面了。 主题 主题这里，大佬推荐catppuccin，确实挺好看，无脑跟！ 官方仓库：catppuccin/nvim 有了lazy，安装这些插件及其简单，只需要将下面这行放入我们上一步中创建的plugins变量中。 123local plugins = { { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000 },} 此时:q退出Neovim，然后重新打开，你会发现lazy管理界面跳了出来，然后提示你正在安装。等待一会儿就可以看到，主题颜色已经变了。但还没结束，现在主题颜色变了只是因为lazy帮你安装完成后自动加载了该插件。如果此时你再退出重开一次，会发现主题又变回了默认状态。我们需要再添加两行代码，将默认的主题配置成catppuccin。 12require(\"catppuccin\").setup()vim.cmd.colorscheme \"catppuccin\" 到此，catppuccin就配置完成了，不出意外你将得到下面这样的状态。 核心插件 Telescope telescope是一个基于列表模糊查找器，可以用来查找文件。其他更高级的功能可以参考官方仓库。 官方仓库：nvim-telescope/telescope.nvim 安装插件同样及其简单，在plugins变量中增加一项即可。 1234567local plugins = { { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000 }, { 'nvim-telescope/telescope.nvim', tag = '0.1.5', dependencies = { 'nvim-lua/plenary.nvim' } },} 退出Neovim再重新打开，你又会看到lazy在帮你安装插件。 上图是已经安装好的状态。然后在init.lua中对telescope进行一些配置。这里主要介绍两个功能，基本能够满足需要，其余的功能可以参考官方仓库自行配置。 文件搜索 在init.lua中添加如下两行。 12local builtin = require(\"telescope.builtin\") -- 用来加载telescope内置的内容vim.keymap.set('n', '&lt;C-p&gt;', builtin.find_files, {}) -- 设置快捷键，Ctrl + P为模糊搜索文件 再重开Neovim，然后按Ctrl + P就可以打开telescope，输入文件名即可搜索文件。 字符搜索 同样在init.lua中添加语句。 123vim.g.mapleader = \" \" -- 设置leader键为空格-- 快捷键为 &lt;leader&gt; + fg，这里f和g按顺序按就好，但是空格不要松开vim.keymap.set('n', '&lt;leader&gt;fg', builtin.live_grep, {}) 配置完后:source %一下，按上面配置好的快捷键即可打开字符搜索。下图是一个搜索lazy字符串的例子。 到这一步可能会出现一个问题，搜索框可以正常打开，但是搜什么都是空白的。原因是缺少一个依赖工具ripgrep，只需要按官方仓库的提示安装即可。 ripgrep官方仓库：BurntSushi/ripgrep 安装Installation章节的提示安装即可。 Windows下执行winget install BurntSushi.ripgrep.MSVC。 Linux下，以Ubuntu为例执行sudo apt-get install ripgrep。 其余操作系统官方仓库中写的都很清楚，安装完成该工具，重启终端并打开Neovim就可以正常使用了。 Treesitter treesitter是一个基于语法树的语法高亮插件。 官方仓库：nvim-treesitter/nvim-treesitter 安装过程类似，还是在plugins中加入一行。 12345678local plugins = { { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000 }, { 'nvim-telescope/telescope.nvim', tag = '0.1.5', dependencies = { 'nvim-lua/plenary.nvim' } }, { \"nvim-treesitter/nvim-treesitter\", build = \":TSUpdate\" },} 重启Neovim，lazy会帮你安装，然后对其进行配置。 在配置treesitter之前，请确保你的系统路径中有可用的C编译器，gcc、clang、MSVC都可以。 如果你是Windows用户，要确保开启开发者模式。打开设置 -&gt; 系统 -&gt; 开发者选项 -&gt; 开发人员模式。 在init.lua中添加如下代码。 123456local config = require(\"nvim-treesitter.configs\")config.setup({ ensure_installed = { \"lua\", \"c\", \"cpp\" }, -- 确保安装lua，c和cpp相关的内容 highlight = { enable = true }, -- 开启高亮 indent = { enable = true }, -- 开启缩进}) 此时:source %一下，treesitter就会开始安装语言相关的内容。安装完后会发现，当前打开的这个lua脚本已经拥有了语法高亮。 你可以用:TSInstall来安装新的语言支持，用:TSModuleInfo来查看已经支持的语言。 Neo-tree neo-tree，就如同该插件的名称一样，是一个文件tree。同样在plugins中添加。 官方仓库：nvim-neo-tree/neo-tree.nvim 1234567891011121314151617local plugins = { { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000 }, { 'nvim-telescope/telescope.nvim', tag = '0.1.5', dependencies = { 'nvim-lua/plenary.nvim' } }, { \"nvim-treesitter/nvim-treesitter\", build = \":TSUpdate\" }, { \"nvim-neo-tree/neo-tree.nvim\", branch = \"v3.x\", dependencies = { \"nvim-lua/plenary.nvim\", \"nvim-tree/nvim-web-devicons\", \"MunifTanjim/nui.nvim\", } }} 重启Neovim，等待lazy安装插件，安装完成后即可使用neo-tree。 输入命令:Neotree filesystem reveal left就可以在左侧显示文件树了。当然，为这条命令设置一个快捷键会更方便。 1vim.keymap.set('n', '&lt;C-b&gt;', ':Neotree filesystem reveal left&lt;CR&gt;', {}) 这里为了保持VS Code的习惯，设置成了Ctrl + b，你可以根据自己的习惯来配置。 模块化插件配置 配置到这里聪明的你可能已经发现一个问题了，我们所有的配置都集中在同一个文件init.lua中，这显然是不合理的。所以我们接下来将之前所做过的所有配置，拆分开来，同时体验一下neo-tree带来的便利。 按下Ctrl + b打开文件树，按a创建文件夹及文件lua/plugins.lua。将我们之前的plugins变量丢进plugins.lua脚本中，然后返回该变量，脚本内容如下。 1234567891011121314151617return { { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000 }, { 'nvim-telescope/telescope.nvim', tag = '0.1.5', dependencies = { 'nvim-lua/plenary.nvim' } }, { \"nvim-treesitter/nvim-treesitter\", build = \":TSUpdate\" }, { \"nvim-neo-tree/neo-tree.nvim\", branch = \"v3.x\", dependencies = { \"nvim-lua/plenary.nvim\", \"nvim-tree/nvim-web-devicons\", \"MunifTanjim/nui.nvim\", } }} 然后将init.lua中的plugins变量删除，并修改下面的语句。 1require(\"lazy\").setup(\"plugins\") -- 原本是 require(\"lazy\").setup(plugins, opts) 我们创建的plugins.lua脚本相对init.lua的路径为./lua/plugins.lua，这里只需要写\"plugins\"即可，lazy会自动找到这个路径。重启Neovim确保工作正常。 但是这样的模块化依然不够，这只是将依托答辩从旱厕搬进了马桶，并没有好多少，所以我们需要对插件配置进一步拆分。 在lua文件夹下创建plugins文件夹，在plugins文件夹下创建我们第一个配置的插件catppuccin对应的脚本，命名为catppuccin.lua。 此时左下角提示Config Change Detected. Reloading...，这都要归功于lazy插件管理器，它会实时的检测插件配置的变换，自动帮你重新加载。 将plugins.lua中关于catppuccin的配置都转移到catppuccin.lua中，同样的方式进行返回。 12345return { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000} 同时init.lua中还有一些关于catppuccin的配置。 12require(\"catppuccin\").setup()vim.cmd.colorscheme \"catppuccin\" 想要将这些配置也搬入catppuccin.lua脚本，就需要用到lazy提供的一个配置项config。这个config需要我们定义一个函数，在函数体中对插件进行配置。同时，使用config就相当于自动调用了require(\"...\").setup(opts)。所以我们对catppuccin.lua进行修改。 12345678return { \"catppuccin/nvim\", name = \"catppuccin\", priority = 1000, config = function() vim.cmd.colorscheme \"catppuccin\" end} 至此就实现了catppuccin插件的模块化，其他的所有插件都是同理的。我们将所有的插件都模块化，最终得到这样的文件结构。 现在我们的init.lua已经比之前简洁多了，这种模式可以更方便的管理插件，并且可以随时添加新的插件，只需要添加一个新的lua脚本即可。 到这一步，我们之前用作过渡的plugins.lua脚本就可以删掉了，因为lazy会去找plugins文件夹下的子模块。 但是！init.lua中还有一些关于Vim的基本配置，这些配置如果慢慢增多，还是会导致init.lua混乱不堪。所以我们将关于Vim的配置一并模块化。 在lua文件夹下创建一个名为vim-options.lua的脚本，将init.lua中关于Vim配置的语句全部丢进去。 同时在init.lua中添加一句。 1require(\"vim-options\") -- 本句需要在require(\"lazy\")之前 代码相关插件 LSP 先来说说什么是LSP，下面是wiki对于LSP的定义： The Language Server Protocol (LSP) is an open, JSON-RPC-based protocol for use between source code editors or integrated development environments (IDEs) and servers that provide \"language intelligence tools\": programming language-specific features like code completion, syntax highlighting and marking of warnings and errors, as well as refactoring routines. The goal of the protocol is to allow programming language support to be implemented and distributed independently of any given editor or IDE. 感觉还是有点抽象，我觉得视频中的大佬解释的非常形象，这里转述一下。 将编辑器想象成客户端，LSP想象成服务器。编辑器打开一个文件的时候，会向LSP发送一个DID OPEN信号，告知LSP目前打开了一个文件。当文件发生任何改动的时候，会向LSP发送一个DID UPDATE信号，告知LSP代码被更改过。此时LSP会返回一个JSON文件，其中包含了类似下面这样的信息，告知编辑器哪里有错误、警告等等。 1234{ \"ERRORS\": \"...\", \"WARNINGS\": \"...\"} 所以，编写代码的过程中，能够有这样一个LSP提示错误和警告是非常必要的功能。 LSP管理 创建一个lsp-config.lua脚本来配置LSP。首先需要一个插件Mason，可以帮助我们很方便的安装各种语言的LSP、Linter、Formatter等。 Mason官方仓库：williamboman/mason.nvim 脚本中添加如下内容。 123456return { \"williamboman/mason.nvim\", config = function() require(\"mason\").setup() end} 重启Neovim等待安装完成，输入:Mason即可打开mason的管理界面，在这里可以看到各种LSP、Linter、Formatter等。 LSP配置 除了mason我们还需要另一个工具mason-lspconfig来辅助配置mason的LSP。修改lsp-config.lua脚本如下。 官方仓库：williamboman/mason-lspconfig.nvim 12345678910111213141516return { { \"williamboman/mason.nvim\", config = function() require(\"mason\").setup() end }, { \"williamboman/mason-lspconfig.nvim\", config = function() require(\"mason-lspconfig\").setup({ ensure_installed = { \"lua_ls\", \"clangd\", \"pyright\" } -- 配置预安装的LSP服务 }) end }} 各种编程语言对应的LSP服务名称可以参考官方仓库的READMEavailable-lsp-servers。这里选择预装了lua、C/C++、python的LSP服务。 重启Neovim等待安装，输入:Mason检查是否安装成果，不出意外你会得到如下所示的状态。 这里有一个需要注意的地方，有些LSP是基于node.js和npm包管理器的，所以请确保你的环境已经安装了node.js。 同时，如果你使用了代理，请给npm也配置代理，具体方法自行Google。 LSP客户端 接下来我们还需要用到一个叫做nvim-lspconfig的插件，使得Neovim能够和LSP进行通信 官方仓库：neovim/nvim-lspconfig 继续修改lsp-config.lua脚本如下。 12345678910111213141516171819202122232425return { { \"williamboman/mason.nvim\", config = function() require(\"mason\").setup() end }, { \"williamboman/mason-lspconfig.nvim\", config = function() require(\"mason-lspconfig\").setup({ ensure_installed = { \"lua_ls\", \"clangd\", \"pyright\" } }) end }, { \"neovim/nvim-lspconfig\", config = function() local lspconfig = require(\"lspconfig\") lspconfig.lua_ls.setup({}) lspconfig.clangd.setup({}) lspconfig.pyright.setup({}) end }} 老样子，重启Neovim等待安装，然后输入:LspInfo查看当前LSP服务的状态。 可以看到检测到一个客户端，所配置的LSP服务叫做lua_ls。 然后配置一些快捷键，以便进行LSP相关的操作。 1234567891011121314151617{ \"neovim/nvim-lspconfig\", config = function() local lspconfig = require(\"lspconfig\") lspconfig.lua_ls.setup({}) lspconfig.clangd.setup({}) lspconfig.pyright.setup({}) vim.keymap.set('n', 'K', vim.lsp.buf.hover, {}) vim.keymap.set('n', 'gD', vim.lsp.buf.declaration, {}) vim.keymap.set('n', 'gd', vim.lsp.buf.definition, {}) vim.keymap.set('n', 'gi', vim.lsp.buf.implementation, {}) vim.keymap.set('n', '&lt;C-k&gt;', vim.lsp.buf.signature_help, {}) vim.keymap.set('n', '&lt;leader&gt;rn', vim.lsp.buf.rename, {}) vim.keymap.set('n', '&lt;leader&gt;ca', vim.lsp.buf.code_action, {}) end} 代码格式化 这里用到一个名为null-ls的插件，通过和特定语言的formatter配合进行操作，这里的formatter通过mason来安装。 官方仓库：nvimtools/none-ls.nvim 添加none-ls.lua配置脚本。 12345678910111213141516return { \"nvimtools/none-ls.nvim\", config = function() local null_ls = require(\"null-ls\") null_ls.setup({ sources = { null_ls.builtins.formatting.stylua, null_ls.builtins.formatting.clang_format, null_ls.builtins.formatting.black, null_ls.builtins.formatting.isort, }, }) vim.keymap.set(\"n\", \"&lt;leader&gt;gf\", vim.lsp.buf.format, {}) end,} 这里配置了lua、C/C++和Python的formatter。 代码自动补全 关于代码自动补全，有一系列的插件，这里推荐先捋清它们之间的关系。我们先列出可能用到的插件并附上仓库链接： nvim-cmp（hrsh7th/nvim-cmp）； LuaSnip（L3MON4D3/LuaSnip）； cmp.luasnip（saadparwaiz1/cmp_luasnip）； friendly-snippets（rafamadriz/friendly-snippets）； cmp.nvim.lsp（hrsh7th/cmp-nvim-lsp）。 nvim-cmp是一个代码补全引擎，可以根据输入来显示补全信息。nvim-cmp这个补全引擎只能提供代码补全的能力，它本身并没有补全的”素材“。这时就需要一些第三方插件来提高代码补全的来源，也就是“素材”（Snippets），并赋予这些Snippets展开的能力。 LuaSnip是一个lua写的Snippets引擎，它属于扩展Snippets的工具。是为nvim-cmp提供服务的。 cmp.luasnip则是LuaSnip的“素材”来源，它为nvim-cmp提供一系列可能的Snippets，然后LuaSnip会将这些Snippets展开。 friendly-snippets是一个针对不同编程语言的Snippets集合，可以将不同语言的“素材”集中在一起，并使得LuaSnip可以加载。 cmp.nvim.lsp也是一个Snippets来源，但可以从任何缓存中存在的LSP来获取“素材”。 解释清楚上述几个插件的关系后，就可以开始配置了。先来进行nvim-cmp的基本配置，初步配置文件如下所示。 123456789101112131415161718192021222324252627282930return { \"hrsh7th/nvim-cmp\", config = function() local cmp = require(\"cmp\") cmp.setup({ snippet = { expand = function(args) require(\"luasnip\").lsp_expand(args.body) end, }, window = { completion = cmp.config.window.bordered(), documentation = cmp.config.window.bordered(), }, mapping = cmp.mapping.preset.insert({ -- [\"&lt;C-b&gt;\"] = cmp.mapping.scroll_docs(-4), [\"&lt;C-f&gt;\"] = cmp.mapping.scroll_docs(4), [\"&lt;C-Space&gt;\"] = cmp.mapping.complete(), [\"&lt;C-e&gt;\"] = cmp.mapping.abort(), [\"&lt;CR&gt;\"] = cmp.mapping.confirm({ select = true }), }), sources = cmp.config.sources({ { name = \"nvim_lsp\" }, { name = \"luasnip\" }, }, { { name = \"buffer\" }, }), }) end,} 接下来配置LuaSnip及其Snippets来源：cmp.luasnip、friendly-snippets。将上面对nvim-cmp的配置放入一个{}中，然后在它的上面再创建一个新的{}，内容如下。 1234567{ \"L3MON4D3/LuaSnip\", dependencies = { \"saadparwaiz1/cmp_luasnip\", \"rafamadriz/friendly-snippets\", },}, 然后需要在nvim-cmp的配置中添加一行。 1require(\"luasnip.loaders.from_vscode\").lazy_load() 重启Neovim就发现，现在已经有了一定程度的代码补全能力。 最后安装cpm.nvim.lsp来提高补全的质量，使得引擎能从LSP中获取Snippets。同样地，在上面脚本的基础上再添加一个{}。 123{ \"hrsh7th/cmp-nvim-lsp\",}, 同时，在lsp-config.lua脚本中关于nvim-lspconfig插件的配置中增加一项，并在所配置的每一项LSP中增加语句，内容如下。 12345678910111213141516171819202122232425{ \"neovim/nvim-lspconfig\", config = function() local capabilities = require(\"cmp_nvim_lsp\").default_capabilities() local lspconfig = require(\"lspconfig\") lspconfig.lua_ls.setup({ capabilities = capabilities, }) lspconfig.clangd.setup({ capabilities = capabilities, }) lspconfig.pyright.setup({ capabilities = capabilities, }) vim.keymap.set(\"n\", \"K\", vim.lsp.buf.hover, {}) vim.keymap.set(\"n\", \"gD\", vim.lsp.buf.declaration, {}) vim.keymap.set(\"n\", \"gd\", vim.lsp.buf.definition, {}) vim.keymap.set(\"n\", \"gi\", vim.lsp.buf.implementation, {}) vim.keymap.set(\"n\", \"&lt;C-k&gt;\", vim.lsp.buf.signature_help, {}) vim.keymap.set(\"n\", \"&lt;leader&gt;rn\", vim.lsp.buf.rename, {}) vim.keymap.set(\"n\", \"&lt;leader&gt;ca\", vim.lsp.buf.code_action, {}) end,}, 再次尝试代码补全，发现补全的来源中已经多了来自LSP的内容。 Debugger 在安装Debugger之前，我们需要介绍一个概念叫做Debug Adapter Protocol (DAP)。也许你在之前配置LSP的时候就已经在Mason中见过这个缩写了。DAP是微软为VS Code开发的，是为了使得编辑器和Debugger能够顺畅的交流。视频中的大佬描述的非常形象，编辑器和Debugger就像酷酷的西部牛仔一样，每个人都有自己交流的方式，而DAP站出来对Debugger说“Let's make things easier.”。DAP提供了一套通用的API，使得不同语言的不同Debugger能够使用这一套API为编辑器提供统一的格式，而编辑器要做的只是利用DAP提供的这套统一格式而已。 其实这套概念和LSP有点类似。我们需要一个服务端，也需要一个客户端。服务端我们可以借助Mason来安装，客户端我们这里用到的是nvim-dap，是一个为Neovim实现的DAP客户端。 官方仓库：mfussenegger/nvim-dap 同时我们还需要一个叫做nvim-dap-ui的UI插件来辅助Debugger工作。然后进行一些配置使得UI能够根据DAP自动打开或关闭。 官方仓库：rcarriga/nvim-dap-ui 新建一个debugger.lua的配置文件。 1234567891011121314151617181920212223242526272829303132return { \"mfussenegger/nvim-dap\", dependencies = { \"rcarriga/nvim-dap-ui\", }, config = function() local dap = require(\"dap\") local dapui = require(\"dapui\") dapui.setup() dap.listeners.before.attach.dapui_config = function() dapui.open() end dap.listeners.before.launch.dapui_config = function() dapui.open() end dap.listeners.before.event_terminated.dapui_config = function() dapui.close() end dap.listeners.before.event_exited.dapui_config = function() dapui.close() end vim.keymap.set(\"n\", \"&lt;leader&gt;b\", dap.toggle_breakpoint, {}) vim.keymap.set(\"n\", \"&lt;F5&gt;\", dap.continue, {}) vim.keymap.set(\"n\", \"&lt;F6&gt;\", dap.terminate, {}) vim.keymap.set(\"n\", \"&lt;F7&gt;\", dap.restart, {}) vim.keymap.set(\"n\", \"&lt;F9&gt;\", dap.step_into, {}) vim.keymap.set(\"n\", \"&lt;F10&gt;\", dap.step_out, {}) vim.keymap.set(\"n\", \"&lt;F12&gt;\", dap.step_over, {}) end,} 除了上面的配置，我们还需要针对你要debug的语言安装对应的DAP，并在nvim-dap中配置。这里以C/C++为例，使用codelldb作为DAP。首先在Mason中安装codelldb，然后对nvim-dap进行如下配置。 1234567891011121314151617181920212223local install_root_dir = vim.fn.stdpath(\"data\") .. \"/mason\"local extension_path = install_root_dir .. \"/packages/codelldb/extension/\"local codelldb_path = extension_path .. \"adapter/codelldb\"dap.adapters.codelldb = { type = \"server\", port = \"${port}\", executable = { command = codelldb_path, args = { \"--port\", \"${port}\" }, },}dap.configurations.c = { { name = \"Launch file\", type = \"codelldb\", request = \"launch\", program = function() return vim.fn.input(\"Path to executable: \", vim.fn.getcwd() .. \"/\", \"file\") end, cwd = \"${workspaceFolder}\", },}dap.configurations.cpp = dap.configurations.c 用一个简单的C程序测试一下。 美化插件 lualine lualine是一个非常美观的底部状态栏。安装它只需要在plugins下添加一个lua脚本即可。 官方仓库：nvim-lualine/lualine.nvim 1234567891011return { 'nvim-lualine/lualine.nvim', dependencies = { 'nvim-tree/nvim-web-devicons' }, config = function() require('lualine').setup({ options = { theme = 'dracula' } }) end} 重启Neovim，然后就得到了如下图所示的效果。 好好好，越来越像VS Code了。 Telescope-ui-select 该插件是telescope插件的一个扩展，可以配合vim.lsp.buf.code_action()使用，使其以一种悬浮窗的形式显示，而不是底部命令栏。 官方仓库：nvim-telescope/telescope-ui-select.nvim alpha-nvim 该插件可以提供一个类似于VS Code的欢迎界面，配置脚本如下。 官方仓库：goolord/alpha-nvim 1234567891011121314151617181920212223242526return { \"goolord/alpha-nvim\", dependencies = { \"nvim-tree/nvim-web-devicons\", }, config = function() local alpha = require(\"alpha\") local dashboard = require(\"alpha.themes.dashboard\") dashboard.section.header.val = { [[ __ ]], [[ ___ ___ ___ __ __ /\\_\\ ___ ___ ]], [[ / _ `\\ / __`\\ / __`\\/\\ \\/\\ \\\\/\\ \\ / __` __`\\ ]], [[/\\ \\/\\ \\/\\ __//\\ \\_\\ \\ \\ \\_/ |\\ \\ \\/\\ \\/\\ \\/\\ \\ ]], [[\\ \\_\\ \\_\\ \\____\\ \\____/\\ \\___/ \\ \\_\\ \\_\\ \\_\\ \\_\\]], [[ \\/_/\\/_/\\/____/\\/___/ \\/__/ \\/_/\\/_/\\/_/\\/_/]], } dashboard.section.buttons.val = { dashboard.button(\"e\", \" New file\", \":ene &lt;BAR&gt; startinsert &lt;CR&gt;\"), dashboard.button(\"q\", \"󰅚 Quit NVIM\", \":qa&lt;CR&gt;\"), } alpha.setup(dashboard.opts) end,} header和buttons两项配置是最具有可玩性的，官方仓库中有许多用户提供了他们自定义的配置文件。上面的最简配置文件效果如下图所示。 快捷键列表 经过上面的一系列配置，我们就得到了下表中的功能。 编辑器相关 快捷键 功能 &lt;C-p&gt; 文件模糊搜索 &lt;leader&gt;fg 字符串搜索 &lt;C-b&gt; 打开文件树 LSP相关 快捷键 功能 K 悬浮窗显示函数信息 gD 转到声明 gd 转到定义 gi 转到实现 &lt;C-k&gt; 函数签名帮助信息 &lt;leader&gt;rn 重命名 &lt;leader&gt;ca 代码动作 &lt;leader&gt;gf 代码格式化 DAP相关 快捷键 功能 &lt;leader&gt;b 添加断点 &lt;F5&gt; 开始/继续执行 &lt;F6&gt; 终止debug会话 &lt;F7&gt; 重新开启debug会话 &lt;F9&gt; 单步执行 &lt;F10&gt; 单步跳出 &lt;F12&gt; 逐过程执行 写在最后 上面讲了这么多插件，但依然希望你不要教条的按照这个教程来做，重要的是学会配置的方法，同时善用Google寻找更加优秀的插件。当然，最推荐的还是直接抄作业，在巨人的肩膀上进行自定义。","link":"/posts/22702/"},{"title":"毕昇编译器异构算子开发基本思想","text":"基于毕昇编译器的异构编程基本思想，如果理解CUDA编程的话，可以类比理解。 毕昇C++异构开发基本思想 队列 首先定义任务队列，任务队列用来管理device上的可执行任务。 1queue Q(ascend_selector{}); queue来自命名空间sycl，需要引入头文件#include &lt;sycl/sycl.hpp&gt;。 Host数据 想要将host上的数据搬移到device，一个核心思想就是找到host端的数据指针。如果待迁移算子中的数据封装度较高，大体上可以分为两种情况： 指针传递式的封装。 数据结构式的封装。 如果只是指针传递式的封装，即封装过程仅仅是将数据指针一层一层传递过来，则是比较简单的情况，只需取得该指针即可。 如果是数据结构式的封装，即封装过程中使得子类无法读取到数据的指针，则是较为复杂的情况，迁移的工作量可能会比较大。但依然没有脱离最核心的思想——找到host端的数据指针。 这里举一个简单的例子，在host端定义两个数组。 1234567constexpr int M = 32;constexpr int N = 16;// 模拟M*M的矩阵auto* ptrDataA = new int[M * M];// 模拟N*N的矩阵auto *ptrDataB = new int[N * N]; ptrDataA与ptrDataB是host端的数据指针。 Device数据 为了将host端的数据搬移到device端，需要先在device端申请内存，申请的大小根据实际情况决定。这里需要将两个矩阵都搬移至device上，故申请如下大小的内容。 12auto *devA = malloc_device&lt;int&gt;(M * M, Q);auto *devB = malloc_device&lt;int&gt;(N * N, Q); devA和devB分别为device端的数据指针，这两片空间处于Global Memory中，但此时仅仅是申请了内存，这两片设备内存中并不存在任何数据。接下来就需要将host端的数据正式拷贝到device端。 12Q.memcpy(devA, ptrDataA, M * M * sizeof(int));Q.memcpy(devB, ptrDataB, N * N * sizeof(int)); memcpy()接口定义如下。 1void memcpy(void *Dst, const void *Src, size_t Size); Dst为目标地址。 Src为源地址。 Size为待搬移数据的大小。 提交任务 截止目前，数据已经在device端准备完毕，接下来就可以进行任务的提交。任务以核函数的形式，作为参数传递给launch()接口。 首先来看一下launch()的定义。 12template &lt;typename KernelName = detail::auto_name, typename KernelType&gt;event launch(size_t NumWorkGroups, _KERNELFUNCPARAM(KernelFunc) _CODELOCPARAM(&amp;CodeLoc)) 接口定义虽然比较复杂，还涉及到一些宏，但我们只需要关注两个参数： NumWorkGroups为work-group的数量。 KernelFunc为核函数。 核函数以lambda表达式的方式进行定义。 123auto KernelFunc = [=](group&lt;1&gt; group) { // TODO}; 接下来进行任务的提交。 1Q.launch&lt;class Test&gt;(N, KernelFunc); 该行代码指定了N个work-group，并传入一个核函数KernelFunc作为device端执行的实际操作。 当然也可以直接将任务提交与核函数定义的代码合并，省去单独定义KernelFunc的步骤。 123Q.launch&lt;class Test&gt;(N, [=](group&lt;1&gt; group) { // TODO}); C++中的lambda表达式定义方式如下。 1auto func = [capture] (params) mutable throw() -&gt; return-type { func_body }; [capture]：用来捕获一定范围的变量。 [ ]不捕获任何变量； [&amp;]引用捕获，捕获外部作用域所有变量，在函数体内当作引用使用； [=]值捕获，捕获外部作用域所有变量，在函数体内创建一个拷贝使用； [=, &amp;a]值捕获外部作用域所有变量，按引用捕获a变量； [a]值捕获外部作用域所有变量，按引用捕获a变量； [this]捕获当前类中的this指针。 (params)：参数列表。 mutable：当使用值捕获时，加上mutable关键字就可以对捕获到的值进行修改。 throw()：用于函数体抛出异常 return-type：用来显式指定返回类型，当不需要返回值或返回类型明确的情况下，可以将-&gt;与return-type一同省略 { func_body }：函数体。 这里以矩阵的update操作为例，该操作给定两个矩阵A和B，以及两个参数left和top，将矩阵A从(left, top)元素开始的与矩阵B大小相同的子矩阵替换为矩阵B。 123456Q.launch&lt;class Test&gt;(N, [=](group&lt;1&gt; group) { __local int UBBuf[N]; size_t groupId = group.get_id(); dmi::memcpy_blocks(UBBuf, &amp;devB[groupId * N], N * sizeof(int) / 32); dmi::memcpy_blocks(&amp;devA[top * M + groupId * M + left], UBBuf, N * sizeof(int) / 32);}); 我们来一行一行解析上面的代码。 首先看第一行__local int UBBuf[N]，该语句利用空间制导符__local在Unified Buffer中申请了一片大小为N的内存空间。 第二行size_t groupId = group.get_id()利用get_id()接口获取到了当前的work-group的id。 第三行dmi::memcpy_blocks(UBBuf, &amp;devB[groupId * N], N * sizeof(int) / 32)，利用命名空间dmi下的memcpy_blocks()接口进行连续数据的拷贝，将之前定义的Global Memory中devB的数据并行的拷贝至Unified Buffer中的UBBuf中。可以观察到拷贝的源地址是利用groupId计算得来的，这一点后面会详细解释。 第四行dmi::memcpy_blocks(&amp;devA[top * M + groupId * M + left], UBBuf, N * sizeof(int) / 32)，同样是利用连续数据拷贝的接口，将Unified Buffer中的UBBuf中的数据，拷贝到Global Memory中devA的正确位置，从而实现update操作。拷贝的目的地址同样是利用groupId与参数left和top计算得来。 work-group的理解 以上面提到的矩阵update()操作为例。 当groupId == 0时，&amp;devA[top * M + groupId * M + left]计算的结果为&amp;devA[top * M + left]，即图中groupId=0箭头所指的那一行数据。而groupId == 1时，同理，计算结果为&amp;devA[top * M + M + left]，即比groupId == 0时多向前指了一行数据，也即图中groupId=1箭头所指的数据。 理解work-group最重要的一点就是，要意识到所有group都是并行的，是同时执行的。 取回数据 通过核函数使device执行完任务后，最后一步就是要将运算结果从device上取回host，也即从Global Memory中搬移回Host Memory中。 1Q.memcpy(ptrDataA, devA, M * M * sizeof(int)); 最后可以利用wait()接口对device端的任务进行同步。 1Q.wait(); 完整示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;iostream&gt;#include &lt;vnl/vnl_matrix.h&gt;#include &lt;sycl/sycl.hpp&gt;#include &lt;bisheng/bisheng.hpp&gt;using namespace sycl;constexpr int M = 32;constexpr int N = 16;constexpr int left = 4;constexpr int top = 7;int main(int argc, char const *argv[]){ queue Q(ascend_selector{}); // host端数据指针 auto *ptrDataA = new int[M * M]; auto *ptrDataB = new int[N * N]; // 初始化数据 for (int i = 0; i &lt; M * M; i++) { ptrDataA[i] = 1; } for (int i = 0; i &lt; N * N; i++) { ptrDataB[i] = 2; } // 申请device端内存 auto *devA = malloc_device&lt;int&gt;(M * M, Q); auto *devB = malloc_device&lt;int&gt;(N * N, Q); // 将host端的数据拷贝至device端，此时数据在Global Memory中 Q.memcpy(devA, ptrDataA, M * M * sizeof(int)); Q.memcpy(devB, ptrDataB, N * N * sizeof(int)); // 提交任务 // &lt;class Test&gt;是为该任务命名，Test可以根据实际情况修改为合适的名称 Q.launch&lt;class Test&gt;(N, [=](group&lt;1&gt; group) { // 申请Unified Buffer内存 __local int UBA[N]; // 获取group id size_t groupId=group.get_id(); // 将矩阵B的数据并行地拷贝进Unified Buffer dmi::memcpy_blocks(UBA, &amp;devB[groupId * N], N * sizeof(int) / 32); // 将Unified Buffer中的数据并行的拷贝进矩阵A的正确位置 dmi::memcpy_blocks(&amp;devA[top * M + groupId * M + left], UBA, N * sizeof(int) / 32); }); // 将结果从Global Memory中取回Host Memory Q.memcpy(ptrDataA, devA, M * M * sizeof(int)); // 任务同步 Q.wait(); // 输出矩阵A，检查update操作是否正确 for (int i = 0; i &lt; M * M; i++) { if (i % M == 0) std::cout &lt;&lt; std::endl; std::cout &lt;&lt; ptrDataA[i] &lt;&lt; \" \"; } return 0;}","link":"/posts/11914/"},{"title":"毕昇编译器版本升级注意事项","text":"毕昇编译器版本升级之后，有一些需要注意和改动的地方。 编译器版本升级注意事项 版本信息 升级前 1234BiShengCPP-B030 Only For PengCheng clang version 14.0.0 (2b53695e1bb8)Target: aarch64-unknown-linux-gnuThread model: posixInstalledDir: /home/bisheng_tester2/Ascend/ascend-toolkit/latest/aarch64-linux/bisheng_cpp/bin 升级后 1234BiShengCPP B107 Only For PengCheng clang version 15.0.5 (clang-3fb32fbe51cb flang-3fb32fbe51cb)Target: aarch64-unknown-linux-gnuThread model: posixInstalledDir: /home/bisheng_tester2/Ascend/ascend-toolkit/latest/aarch64-linux/bisheng_cpp/bin 代码改动 配置文件改动 顶层CMakeLists.txt中的-lsycl不再需要。即231行改回原版的状态，如下。 1set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${ITK_REQUIRED_CXX_FLAGS}\") 包含算子的CMakeLists.txt中的编译参数有变化。由原来的： 1set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsycl -fsycl-targets=ascend_910-cce\") 改为： 1set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsycl -fdevices=ascend_910\") 接口改动 获取group的id时，接口从group.get_id()变为group.get_group_id()。 目前只知道这一个接口变动，后续如果发现有重要的变动会在此更新。 类型支持问题 如果在编译过程中并未出现错误，那么类型支持问题可以忽略不看。 升级后的编译器由暂不支持long double数据类型，故需要将涉及到的long double类型的全局变量注释掉。 所有改动可以参考本次commit的内容。","link":"/posts/29203/"},{"title":"模型评估与选择","text":"西瓜书第2章学习笔记，别问为什么没有第1章，问就是懒。。。看的我数学恐惧症都要犯了，但还是能感受到数学的魅力；西瓜书本章从学习器的性能评估方法、性能度量、比较检验等方面描述了如何评估和选择学习算法 经验误差与过拟合 基本概念 设有m各样本中有a个样本分类错误，则 错误率(error rate)： 精度(accuracy)： 误差： 训练误差(training error)：也叫经验误差(empirical error)，是学习器在训练集上的误差 测试误差(testing error)：学习器在测试集上的误差，通常作为泛化误差的近似 泛化误差(generalization error)：学习器在新样本上的误差 评估方法 留出法 将数据集D划分为两个互斥的集合，其中一个作为训练集S，另一个作为测试集T，即： 通常我们希望训练集S和测试集T的划分尽可能保持数据分布的一致性，故可以采用分层采样(stratified sampling)； 即使采用了分层采样，也需要注意一个问题，即将样本排序后，每一层级可以将前一部分样本放入训练集，也可以将后一部分样本放入训练集，故单次留出法得到的估计结果不够稳定 在使用留出法时，一般采用若干次随即划分、重复进行实验评估后取平均值作为留出法的评估结果，常见做法是将大约2/3 ~ 4/5的样本用于训练，剩余样本用于测试 交叉验证法 将数据集D划分为k个大小相似的互斥子集，即： 每个子集都尽可能保持数据分布的一致性，即从D中通过分层采样得到 每次用k-1个子集的并集作为训练集，剩下的那个子集作为测试集，这样可以获得k组训练/测试集，可进行k次训练和测试，最终返回k个测试结果的均值 通常把交叉验证法称为k折交叉验证(k-fold cross validation)，k最常用的取值为10，其他还有5、20等 为了减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值，常见的有10次10折交叉验证 设数据集D中包含m个样本，若令k=m，则得到了交叉验证法的一个特例：留一法(Leave-One-Out, LOO) 显然留一法不受随机样本划分方式的影响，因为m个样本只有唯一的方式划分为m个子集；留一法使用的训练集与初始数据集相比只少了一个样本，这使得大多数情况下，留一法中被实际评估的模型与期望评估的用D训练出来的模型很相似，故留一法的评估结果往往被认为比较准确；但当数据集较大时，训练m个模型的计算开销会大到难以忍受，而这还没有考虑调参问题 自助法 自助法(bootstrapping)以自助采样法(bootstrap sampling)为基础，即给定包含m个样本的数据集D，对他采样产生数据集 采样方式： 每次随机从D中挑选一个样本，将其拷贝放入，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍可能被采到 这个过程重复执行m次，即可得到包含m个样本的数据集，这就是自助采样的结果 通过自助采样，D在有一部分样本会在中出现多次，而一部分样本不出现，而样本在m次采样中始终不被采到的概率是 取极限可得 没有出现在训练集中的样本用于测试，这样的测试结果称为包外估计(out-of-bag estimate) 自助法在数据集较小、难以有效划分训练/测试集时很有用 在初始数据量足够时，留出法和交叉验证法更常用一些 性能度量 性能度量(performance measure)：衡量模型泛化能力的评价标准 在预测任务中，给定样例集，其中是示例的真实标记，学习器的预测结果为 回归任务最常用的性能度量是均方误差(mean squared error)，即： 更一般的，对于数据分布和概率密度函数，均方误差可描述为： 错误率与精度 适用于二分类任务、多分类任务 对样例集D，分类错误率定义为： 精度定义为： 更一般的，对于数据分布和概率密度函数，错误率描述为： 精度定义为： 查准率、查全率与F1 查准率(precision)通俗来讲，以西瓜为例，即挑出来的瓜中有多少是好瓜 查全率(recall)通俗来讲，同样以西瓜为例，即所有好瓜中有多少被挑了出来 对于二分类问题，根据样例的真实类别与学习器的预测类别可组合划分为真正例(true positive)、假正例(false positive)、真反例(true negative)、假反例(false negative)四种，分别用TP、FP、TN、FN表示，则 样例总数 则可以得到分类结果的混淆矩阵(confusion matrix) 查准率定义为： 查全率定义为： 以查准率P为纵轴，查全率R为横轴作图，即可得到P-R曲线，显示该曲线的图称为P-R图 当一个学习器的P-R曲线被另一个学习器的曲线完全包住，则认为后者性能优于前者，即图中的A、C曲线中，A的性能优于C； 若两个学习器的P-R曲线有交叉，则取平衡点(Break-Event Point, BEP)的值，认为BEP较大的性能较好，即图中的A、B曲线，A的性能优于B 平衡点是查准率=查全率时的取值 由于BEP过于简化，故更常用F1度量： 样例总数 F1度量的一般形式可以表达对查准率/查全率的不同偏好： 在该式中，度量了查全率对查准率的相对重要性 查全率影响更大退化为标准的查准率影响更大 多混淆矩阵 对于训练/测试过程中得到多个二分类混淆矩阵的情况，可以使用以下几个性能度量方式 先在各混淆矩阵上分别计算出查准率和查全率，记作，再计算平均值，可以得到： 宏查准率(macro-P) 宏查全率(macro-R) 宏F1(macro-F1) 或先将各混淆矩阵的对应元素进行平均，得到TP、FP、TN、FN的平均值，记作、、、，可以进一步得到 微查准率(micro-P) 微查全率(micro-R) 微F1(micro-F1) ROC与AUC 很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值(threshold)比较，大于阈值则为正类，否则为反类；根据这个实值或预测概率排序，“最可能”的正例排在前面，“最不可能”的正例排在后面；分类过程就相当于在这个排序中以某个截断点(cut point)将样本分为前一部分的正例和后一部分的反例 若更重视查准率，则可以选择排序中靠前的位置进行截断 若更重视查全率，则可以选择排序中靠后的位置进行截断 故排序本身的质量好坏，体现了综合考虑学习器在不同任务下的期望泛化性能的好坏，或者说一般情况下泛化性能的好坏 ROC全程受试者工作特征(Receiver Operating Characteristic)曲线，先引入两个重要的值： 真正例率(True Positive Rate, TPR) 假正例率(False Positive Rate, FPR) 以真正例率为纵轴，以假正例率为横轴作图，即可得到ROC曲线，显示ROC曲线的图称为ROC图 现实任务中仅能获取有限个(真正例率，假正例率)坐标对，无法产生光滑的ROC曲线，故只能画出近似ROC曲线 近似ROC曲线的绘制过程： 给定个正例和个反例，根据学习器预测结果对样例进行排序 将分类阈值设为最大，即将所有样例均预测为反例，此时TPR和FPR均为0，即坐标 然后将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例，设前一个点坐标为，则 当前若为真正例，则点坐标为 当前若为假正例，则点坐标为 最后用线段连接相邻点即可 与P-R图类似，若一个学习器的ROC曲线被另一个学习器的曲线完全包住，则后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则要引入接下来的概念，即AUC(Area Under ROC Curve)，也就是ROC曲线下的面积 设ROC曲线是由坐标按序连接形成，则AUC可估算为： 即上图中标有AUC的阴影部分面积 AUC考虑的是样本预测的排序质量，故它和排序误差由紧密联系；给定个正例和个反例，令和分别表示正、反例集合，则排序损失(loss)定义为： 通俗来讲，即考虑每一对正、反例，若正例的预测值小于反例，则记一个“罚分”，若相等则记0.5个“罚分” 若一个正例在ROC曲线上对应点坐标为，则恰好是排序在其之前的反例所占的比例，即假正例率，故有： 代价敏感错误率与代价曲线 以二分类任务为例，可根据任务设定一个代价矩阵(cost matrix) 其中表示第i类样本预测为第j类样本的代价； 一般来说，； 若将第0类判别为第1类所造成的损失更大，则；损失程度相差越大，与值的差别越大 之前所提到的性能度量都默认了均等代价，在非均等代价下，我们希望的是最小化总体代价(total cost)，而不是简单的最小化错误次数 将上表中的第0类作为正类、第1类作为反类，令与分别代表样例集D的正例子集和反例子集，则代价敏感(cost-sensitive)错误率为： 类似的，可以给出基于分布定义的代价敏感错误率，以及其他一些性能度量的代价敏感版本，若令中的i、j取值不限于0、1，则可以定义出多分类任务的代价敏感性能度量 在非均等代价下，ROC曲线不能直接反应学习器的期望总体代价，而代价曲线(cost curve)则可以达到目的 代价曲线图的横轴是取值为[0,1]的正例概率代价 其中是样例为正例的概率 纵轴是取值为[0,1]的归一化代价 其中FPR是式(23)中定义的假正例率，是假反例率 代价曲线的绘制过程： 设ROC曲线上点坐标为，，则可以计算出 然后在代价平面上绘制一条从，到的线段，线段下的面积即表示了该条件下的期望总体代价 重复上述过程，将ROC曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价 比较检验 对学习器进行性能比较的重要依据是统计假设检验(hypothesis test)，基于假设检验结果可以推断出，若测试集上观察到学习器A比B好，则A的泛化性能是否在统计意义上优于B，以及这个结果的把握有多大 假设检验 假设检验中的“假设”是对学习器泛化错误率分布的某种判断或猜想，我们只能得知其测试错误率，泛化错误率与测试错误率未必相同，但直观上二者接近的可能性较大，故可以根据测试错误率估推出泛化错误率的分布 二项检验 泛化错误率为的学习器在一个样本上犯错的概率是；测试错误率意味着在m个测试样本中恰有个被误分类 假设测试样本是从样本总体分布中独立采样而得，则泛化错误率为的学习器将其中个样本误分类、其余样本均分类正确的概率是；由此可估算出其将个样本误分类的概率为： 上式还表达了在包含m个样本的测试集上，泛化错误率为的学习器被测得测试错误率为的概率 给定测试错误率，则解可知，在时最大，增大时减小，这符合二项(binomial)分布 上图以为例，我们可以使用二项检验(binomial test)对(即泛化错误率不大于0.3)这样的假设进行检验 更一般的，考虑假设，则在的概率内所能观测到的最大错误率为： 这里的反映了结论的置信度(confidence)，相应于上图中的非阴影部分 此时若测试错误率小于临界值，则根据二项检验可得出结论： 在的显著度下，假设不能被拒绝，即能以的置信度认为，学习器的泛化错误率不大于 否则该假设可被拒绝，即在的显著度下，可认为学习器的泛化错误率大于 t检验 通常我们会进行多次训练/测试，会得到多个测试错误率，此时可以使用t检验(t-test)；假设我们得到了k个测试错误率，则平均测试错误率和方差为： 考虑到这k个测试错误率可看作泛化错误率的独立采样，则变量 服从自由度为k-1的t分布，下图以k=10为例 对假设和显著度，可以计算出当测试错误率均值为时，在概率内能观测到的最大错误率，即临界值 这里考虑双边(two-tailed)假设，如上图所示，两边阴影部分各有的面积；假设阴影部分范围分别为和： 若平均错误率与之差位于临界值范围内，则不能拒绝假设，即可认为泛化错误率为，置信度为 否则可拒绝该假设，即在该显著度下可认为泛化错误率与有显著不同 常用取值有0.05和0.1，下面给出一些常用临界值 以上两种方法都是针对单个学习器泛化性能的假设进行检验，下面介绍适用于对不同学习器的性能比较的假设检验方法 交叉验证t检验 对两个学习器A、B，若使用k折交叉验证法得到的测试错误率分别为和，其中和是在相同的第折训练/测试集上得到的结果，则可用k折交叉验证成对t检验(paired t-tests)来进行比较检验 若两个学习器的性能相同，则它们使用相同的训练/测试集得到的测试错误率应相同，即 对k折交叉验证产生的k对测试错误率，先对每对结果求差，，根据差值对“学习器A与B性能相同”这个假设做t检验，计算出差值的均值与方差，在显著度下，有变量： 若变量小于临界值，则假设不能被拒绝，即认为两个学习器的性能没有显著差别 否则可认为两个学习器的性能有显著差别，且平均错误率较小的那个学习器性能较优 这里的是自由度为k-1的t分布上尾部累积分布为的临界值 有效的假设检验是建立在测试错误率均为泛化错误率的独立采样之上的，然而通常样本有限，在使用交叉验证等实验估计方法时，不同轮次的训练集会有一定程度的重叠，这使得测试错误率实际上并不独立，会导致过高估计假设成立的概率 可采用5×2交叉验证法解决上述问题，即做5次2折交叉验证，在每次2折交叉验证之前随机将数据打乱，使得5次交叉验证中的数据划分不重复 对两个学习器A、B，第i次2折交叉验证将产生两对测试错误率，对它们分别求差，分别得到第1、2折上的差值；为了缓解测试错误率的非独立性，仅计算第1次2折交叉验证的两个结果的平均值，但对每次2折实验的结果都计算出其方差，变量 服从自由度为5的t分布，其双边检验的临界值当时为2.5706，时为2.0150 McNemar检验 对二分类任务，使用留出法不仅可估计出学习器A、B的测试错误率，还可获得两学习器分类结果的差异，即两者都正确、都错误、一个正确一个错误的样本数，如下列联表(contingency table)所示 若做假设“两学习器性能相同”，则应有，那么变量应当服从正态分布，且均值为1，方差为，故变量 服从自由度为1的分布(卡方分布)，即标准正态分布变量的平方，给定显著度 当变量小于临界值时，不能拒绝该假设，即认为两学习器的性能没有显著差别 否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的学习器性能较优 自由度为1的检验的临界值当时为3.8415，时为2.7055 交叉验证t检验和McNemar检验都是在一个数据集上比较两个算法的性能，接下来介绍在一组数据集上对多个算法进行比较的检验方法 Friedman检验与Nemenyi后续检验 当有多个算法参与比较时，一种做法是在每个数据集上分别列出两两比较的结果，在两两比较时可以采用前面的两种方法；另一种方法比较直接，即使用基于算法排序的Friedman检验 假设用四个数据集对算法A、B、C进行比较；首先用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然后再每个数据集上根据测试性能由好到坏排序，并赋予序值1，2，……；若算法的测试性能相同则平分序值；再求出同一个算法在不同数据集下的平均序值；以下列算法比较序值表为例 平分序值指的是，如在上表的数据集中，算法A的性能最好，算法B、C的性能相同 使用Friedman检验判断这些算法的性能是否相同；若相同，则它们的平均序值应当相同 假设在N个数据集上比较k个算法，令表示第i个算法的平均序值，以下讨论暂不考虑平分序值的情况，则服从正态分布，其均值和方差分别为和，则变量： 在k和N都较大时，服从自由度为k-1的分布 但上述的原始Friedman检验过于保守，现在通常使用变量： 其中由式(37)定义，服从自由度为和的F分布，下面给出一些常用的临界值 若“所有算法的性能相同”这个假设被拒绝，则说明算法的性能显著不同；此时需要进行后续检验(post-hoc test)来进一步区分各算法，常用Nemenyi后续检验 Nemenyi检验计算出平均序值差别的临界值域： 这里给出一些和时常用的值 若两个算法的平均序值之差超出了临界值域，则以相应的置信度拒绝“两个算法性能相同”这一假设 上述检验比较可以直观地用Friedman检验图显示；可以根据算法比较序值表绘制出Friedman检验图 上图中纵轴显示各个算法，横轴是平均序值；对每个算法，用一个圆点显示其平均序值，以圆点为中心的横线段表示临界值域的大小；若两个算法的横线段有交叠，则两个算法没有显著差别，否则说明它们有显著差别 偏差与方差 偏差-方差分解(bias-variance decomposition)是解释学习算法泛化性能的一种重要工具，即解释了为什么学习算法有这样的泛化性能 偏差-方差分解试图对学习算法的期望泛化错误率进行拆解；算法在不同训练集上学得的结果很可能不同，即便这些训练集来自同一个分布 对测试样本，令为在数据集中的标记，为的真实标记，为训练集上学得模型在上的预测输出；以回归任务为例，学习算法的期望预测为： 使用样本数相同的不同训练集产生的方差为： 噪声为： 期望输出与真实标记的差别称为偏差(bias)，即： 为便于讨论，假设噪声期望为零，即，通过多项式展开合并，可对算法的期望泛化误差进行分解(具体推导过程参考西瓜书45页)，最后可得： 也就是说，泛化误差可以分解为偏差、方差与噪声之和 偏差、方差、噪声的含义 偏差(式43)：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力； 方差(式41)：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响； 噪声(式42)：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度 偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的 对于给定的学习任务，为了取得更好的泛化性能，应 使偏差较小，即能够充分拟合数据 使方差较小，即使数据扰动产生的影响小 一般来说，偏差与方差是有冲突的，称为偏差-方差窘境(bias-variance dilemma) 上图体现了，给定学习任务，控制学习算法的训练程度 训练不足时，学习器拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导泛化错误率 随着训练程度加深，学习器拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率 在训练充足后，学习器的拟合能力已经非常强了，训练数据发生轻微的扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合","link":"/posts/13105/"},{"title":"毕昇编译器异构算子分核方案再探","text":"摘要根据vec_cross_add接口的正确用法重新实现了前面的动态分核方案，效果进一步提升。 基于vec_cross_add接口重新实现Softmax（方案五） 方案实现 分核方案沿用方案三，经过修改，使用vec_cross_add()接口的Softmax算子实现如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117using data_t = float;std::vector&lt;data_t&gt; ascend_softmax(std::vector&lt;data_t&gt; input) { std::size_t input_sz = input.size(); std::size_t byte_count = input_sz * sizeof(data_t); // call the host operator if input isn't enough a full block if (byte_count &lt; 32) { return softmax(input); } // number of elements per group const std::size_t elem_per_group = 640; // number of repeats per group const std::size_t repeat_per_group = elem_per_group * sizeof(data_t) / 256; // number of elements in tail block const std::size_t tail_elem_count = input_sz % elem_per_group; // number of groups // if tail block is exist, apply for one more group const std::size_t group_num = (tail_elem_count &gt; 0) ? ((input_sz / elem_per_group) + 1) : (input_sz / elem_per_group); sycl::queue Q(sycl::ascend_selector{}); // GM memory allocation auto dev_buf = sycl::malloc_device&lt;data_t&gt;(group_num * elem_per_group, Q); auto sum_res_buf = sycl::malloc_device&lt;data_t&gt;(group_num * (32 / sizeof(data_t)), Q); // Host memory allocation std::vector&lt;data_t&gt; sum_res(group_num * (32 / sizeof(data_t)), 0.0f); std::vector&lt;data_t&gt; res(input_sz, 0.0f); // host -&gt; GM Q.memcpy(dev_buf, input.data(), byte_count); Q.launch&lt;class Summary&gt;(group_num, [=](sycl::group&lt;1&gt; group) { bisheng::vector&lt;data_t, elem_per_group&gt; input_vec; bisheng::vector&lt;data_t, repeat_per_group&gt; sum_vec; std::size_t group_id = group.get_group_id(); // GM -&gt; UB input_vec.load( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // if tail block has element and this is the last group bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vec_exp(input_vec_v, input_vec_v); for (int i = 0; i &lt; tail_elem_count; ++i) sum_res_buf[group_id * (32 / sizeof(data_t))] += input_vec_v[i]; } else { // full block data bisheng::vec_exp(input_vec, input_vec); bisheng::vec_cross_add(sum_vec.data(), input_vec); for (int i = 0; i &lt; repeat_per_group; ++i) { sum_res_buf[group_id * (32 / sizeof(data_t))] += sum_vec[i]; } } // UB -&gt; GM input_vec.store( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); // GM -&gt; Host Q.memcpy(sum_res.data(), sum_res_buf, group_num * (32 / sizeof(data_t)) * sizeof(data_t)); Q.wait(); data_t sum; for (int i = 0; i &lt; sum_res.size(); i += 32 / sizeof(data_t)) sum += sum_res[i]; Q.launch&lt;class Softmax&gt;(group_num, [=](sycl::group&lt;1&gt; group) { // UB memory of exponent result bisheng::vector&lt;data_t, elem_per_group&gt; exp_res_vec; // UB memory of divisor bisheng::vector&lt;data_t, elem_per_group&gt; divisor_vec(sum); // UB memory of final result bisheng::vector&lt;data_t, elem_per_group&gt; res_vec; std::size_t group_id = group.get_group_id(); // GM -&gt; UB exp_res_vec.load( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // if tail block has element and this is the last group bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; divisor_vec_v(divisor_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), tail_elem_count); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } else { // full block data bisheng::vec_div(res_vec, exp_res_vec, divisor_vec); } // UB -&gt; GM res_vec.store( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); // GM -&gt; host Q.memcpy(res.data(), dev_buf, byte_count); Q.wait(); sycl::free(dev_buf, Q); sycl::free(sum_res_buf, Q); return res;} 功能测试 功能测试全部验证正确。 性能测试 与之前效果最好的方案三对比。 测试用例 640 6400 64000 640000 方案三加速比 0.224613 1.512394 13.30433 88.70575 方案五加速比 0.225836 1.330532 12.58051 101.0137 可以看到在向量长度比较大的情况下，接口的优势还是远大于for循环求和的。 毕昇编译器异构算子分核方案再探（方案六） 之前的Softmax算子实现中提到，采用动态分核方案，令每个核尽可能多的处理数据，并充分利用所以物理核带来的效果，甚至不如大量处理适量数据的逻辑核带来的效果好。当时是由于对vec_cross_add()求和接口产生了误解，所以转用for循环在逻辑核内部进行求和。 回顾一下上次的两种分核方式和性能表现。 方案三：每个核处理640个数据，无论输入向量多长，都拆分为640个元素的小向量，再单独处理尾块； 方案四：根据输入向量的长度和物理核心数量，动态确定逻辑核的数量，保证每个物理核都在工作，再单独处理尾块。 方案四详见基于毕昇编译器的Softmax异构算子 - 亦初 (deleter-d.github.io)。 当时的性能表现是： 测试用例 640 6400 64000 640000 698880 方案三加速比 0.237432 1.478988 13.19605 87.72573 96.29706 方案四加速比 0.234373 1.436941 12.35908 80.59147 67.26953 但转念一想，得到这个结果的前提是求和均使用了核内for循环，所以动态分核策略中，输入向量长度比较长的情况下，每个逻辑核分到的向量长度就会远大于方案一的策略。可想而知，效率其实是被for循环拖慢的。 所以，利用vec_cross_add()接口再次实现动态分核方案。 方案实现 代码与之前的大同小异，只在求和的地方做了修改，改用vec_cross_add()接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135std::vector&lt;data_t&gt; ascend_softmax(std::vector&lt;data_t&gt; input) { std::size_t input_sz = input.size(); std::size_t byte_count = input_sz * sizeof(data_t); // call the host operator if input isn't enough a full block if (byte_count &lt; 32) { return softmax(input); } // number of elements per group std::size_t elem_per_group = 0; if (byte_count &gt;= PHYSICAL_CORES * UB_MAX_BYTES) elem_per_group = UB_MAX_BYTES / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 51200) elem_per_group = 51200 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 25600) elem_per_group = 25600 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 12800) elem_per_group = 12800 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 5120) elem_per_group = 5120 / sizeof(data_t); else if (byte_count &gt;= PHYSICAL_CORES * 2560) elem_per_group = 2560 / sizeof(data_t); else elem_per_group = 1280 / sizeof(data_t); // number of repeat per group const std::size_t repeat_per_group = elem_per_group * sizeof(data_t) / 256; // number of elements in tail block const std::size_t tail_elem_count = input_sz % elem_per_group; // number of groups // if tail block is exist, apply for one more group const std::size_t group_num = (tail_elem_count &gt; 0) ? ((input_sz / elem_per_group) + 1) : (input_sz / elem_per_group); sycl::queue Q(sycl::ascend_selector{}); // GM memory allocation auto dev_buf = sycl::malloc_device&lt;data_t&gt;(group_num * elem_per_group, Q); auto sum_res_buf = sycl::malloc_device&lt;data_t&gt;(group_num * (32 / sizeof(data_t)), Q); // Host memory allocation std::vector&lt;data_t&gt; sum_res(group_num * (32 / sizeof(data_t)), 0.0f); std::vector&lt;data_t&gt; res(input_sz, 0.0f); // host -&gt; GM Q.memcpy(dev_buf, input.data(), byte_count); Q.launch&lt;class Summary&gt;(group_num, [=](sycl::group&lt;1&gt; group) { bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; input_vec; bisheng::vector&lt;data_t, UB_MAX_BYTES / 256&gt; sum_vec; std::size_t group_id = group.get_group_id(); // GM -&gt; UB input_vec.load( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // if tail block has element and this is the last group bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), tail_elem_count); bisheng::vec_exp(input_vec_v, input_vec_v); for (int i = 0; i &lt; tail_elem_count; ++i) sum_res_buf[group_id * (32 / sizeof(data_t))] += input_vec_v[i]; } else { // full block data bisheng::vector_view&lt;data_t&gt; input_vec_v(input_vec.data(), elem_per_group); bisheng::vector_view&lt;data_t&gt; sum_vec_v(sum_vec.data(), repeat_per_group * 8); bisheng::vec_exp(input_vec_v, input_vec_v); bisheng::vec_cross_add(sum_vec_v, input_vec_v); for (int i = 0; i &lt; repeat_per_group * 8; i += 8) { sum_res_buf[group_id * (32 / sizeof(data_t))] += sum_vec_v[i]; } } // UB -&gt; GM input_vec.store( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); // GM -&gt; Host Q.memcpy(sum_res.data(), sum_res_buf, group_num * (32 / sizeof(data_t)) * sizeof(data_t)); Q.wait(); data_t sum; for (int i = 0; i &lt; sum_res.size(); i += 32 / sizeof(data_t)) sum += sum_res[i]; Q.launch&lt;class Softmax&gt;(group_num, [=](sycl::group&lt;1&gt; group) { // UB memory of exponent result bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; exp_res_vec; // UB memory of divisor bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; divisor_vec(sum); // UB memory of final result bisheng::vector&lt;data_t, UB_MAX_BYTES / sizeof(data_t)&gt; res_vec; std::size_t group_id = group.get_group_id(); // GM -&gt; UB exp_res_vec.load( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); if (tail_elem_count &gt; 0 &amp;&amp; group_id == group_num - 1) { // if tail block has element and this is the last group bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; divisor_vec_v(divisor_vec.data(), tail_elem_count); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), tail_elem_count); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } else { // full block data bisheng::vector_view&lt;data_t&gt; exp_res_vec_v(exp_res_vec.data(), elem_per_group); bisheng::vector_view&lt;data_t&gt; divisor_vec_v(divisor_vec.data(), elem_per_group); bisheng::vector_view&lt;data_t&gt; res_vec_v(res_vec.data(), elem_per_group); bisheng::vec_div(res_vec_v, exp_res_vec_v, divisor_vec_v); } // UB -&gt; GM res_vec.store( sycl::global_ptr&lt;data_t&gt;(dev_buf + group_id * elem_per_group).get(), elem_per_group); }); // GM -&gt; host Q.memcpy(res.data(), dev_buf, byte_count); Q.wait(); sycl::free(dev_buf, Q); sycl::free(sum_res_buf, Q); return res;} 功能测试 功能测试全部正确。 性能测试 把几个方案放在一起对比，其中： 方案三和方案五：每个核心固定640个元素； 方案四和方案六：动态分核。 测试用例 640 6400 64000 640000 698880 方案三加速比 0.237432 1.478988 13.19605 87.72573 96.29706 方案四加速比 0.234373 1.436941 12.35908 80.59147 67.26953 方案五加速比 0.225836 1.330532 12.58051 101.0137 94.52815 方案六加速比 0.205704 1.29488 12.22252 120.7111 123.515 在输入向量较小的情况下，由于动态分核方案可能出现某些物理核不干活儿的情况，但在大向量的情况下，这种策略是占绝对优势的。加速比的一些波动是可接受的。同时由于使用了接口进行求和，大大减小了for循环的压力，整体效率进一步提升了。 目前还能够想到的优化手段可能就不是靠编译器能够自动完成的了，进一步的优化可能需要借助手动同步等手段追求极致性能了。 与mindspore对比 所用的mindspore版本为2.1.0，加速卡为昇腾910，测试代码如下： 123456789101112131415import numpy as npimport mindspore as msimport mindspore.ops as opsimport timeINPUT = 640input = ms.Tensor(np.random.random(INPUT), ms.float32)start = time.perf_counter_ns()ops.softmax(input)end = time.perf_counter_ns()runTime = end-startprint(f'Total time: {runTime}') 针对不同的测试用例只需修改INPUT即可，与上面效果最好的方案六做对比，各测试用例的加速比如下。 测试用例 640 6400 64000 640000 698880 加速比 1.636923067 1.72635719 1.672068458 1.71248809 1.636225576 加速比基本在1.7左右，虽然python解释器需要一定时间来解析，但通过一些手段测试后，这个时间的影响可以忽略。","link":"/posts/63148/"},{"title":"矩阵分析及其应用","text":"矩阵分析简明教程第6章笔记 1. 矩阵序列与矩阵级数 1.1 矩阵序列 定义 设，其中 称由排成的序列为矩阵序列(matrix sequence)，记作 若当时，都收敛，且 则称矩阵序列收敛于矩阵，记作 定理1 设是上任意一种矩阵范数，则中矩阵序列收敛于矩阵的充要条件是 收敛矩阵定义 设，若，则称A为收敛矩阵 谱半径定义 设，为的特征值，称为A的谱半径 定理2 设，则为收敛矩阵的充要条件是 定理3 设，为的任何一种矩阵范数，则 推论： 设，为的任何一种矩阵范数，若，则为收敛矩阵 1.2 矩阵级数 定义 设是上的矩阵序列，称无穷和 为矩阵级数(matrix series) 称为矩阵级数的前n项部分和 矩阵级数的敛散性定义 设矩阵级数的部分和序列收敛，则矩阵级数是收敛的(convergent) 不收敛的矩阵级数则为发散的(divergent) 若矩阵级数的每一个位置元所成级数是绝对收敛的，则称矩阵级数是绝对收敛的(absolutely convergent) 矩阵幂级数定义 设矩阵，称 为矩阵幂级数 定理1 设幂级数的收敛半径为，则 当时，矩阵幂级数绝对收敛 当时，矩阵幂级数发散 幂级数的收敛半径为 Neumann级数定义 设，称 为Neumann级数 定理2 Neumann级数收敛，且当时， 2. 矩阵函数及其计算 2.1 矩阵函数 定义 若函数可以表示为幂级数 则定义矩阵函数 类似的，将的变元换成，其中为参数，则相应地可以定义 常见的矩阵函数 已知函数 相应地，定义矩阵函数 2.2 矩阵函数的计算 Jordan标准形方法 矩阵函数的计算公式 其中 待定系数法 定义 设，的特征值为，最小多项式为 设函数，则 称为关于矩阵的谱上的值 定理 矩阵函数的充要条件是和关于的谱上的值相等，即 亦即 3. 矩阵的微分与积分 3.1 函数矩阵 已知 可定义 以矩阵为自变量，称之为矩阵的函数，简称为矩阵函数 定义 称变量的矩阵 为函数矩阵 3.2 函数矩阵的微积分 定义 设函数矩阵的位置元均可微(可积)，则的微分为 的积分为 性质 设为同阶可微矩阵，则 设分别为的可微矩阵，则 设为可微矩阵，则 4. 矩阵函数的应用 定理 一阶常系数微分齐次微分方程组 的解为 一阶常系数微分非齐次微分方程组 的解为","link":"/posts/29194/"},{"title":"矩阵分解","text":"矩阵分析简明教程第4章笔记 1. 矩阵的LU分解 1.1 LU分解 定义 设为阶复方阵 若可以表示成一个下三角矩阵和一个上三角矩阵的乘积 则称其为矩阵的LU分解 定理 设为阶复方阵 若的顺序主子式 则可唯一分解为，其中 为主对角元为1的下三角阵 为上三角阵 1.2 LU分解方法 原理 由于可逆，故存在，使得 步骤 对矩阵仅做初等行变换，得上三角阵 求矩阵的逆矩阵，得下三角阵 1.3 LU分解的改进 定理(LDU分解) 设为阶复方阵 若的顺序主子式 则可唯一分解为，其中 为主对角元为1的下三角阵 为上三角阵 为对角阵 定理(Cholesky分解，也称平方根方法) 设为阶复方阵 若的顺序主子式 且，则可唯一分解为，其中 为主对角元为1的下三角阵 为实对角矩阵 2. 矩阵的QR分解 2.1 QR分解 定理 设为的复矩阵，，即列满秩 则存在非奇异上三角阵和矩阵，使 称等式为矩阵的QR分解 若是实方阵，则为正交阵 2.2 QR分解方法 利用Gram-Schmidt过程的QR分解 正交化单位化 当即列不满秩时，利用G-S过程所得的QR分解不唯一 Householder变换的QR分解 定义 设，则为正交阵 称正交变换为Householder变换 定理 设 则是阶Householder矩阵，且 任一复方阵都存在酉矩阵和上三角阵，使 矩阵不必可逆 使用Householder方法所得的QR分解唯一 3. 矩阵的满秩分解 3.1 满秩分解 定理(矩阵的等价标准形) 任何矩阵均可经过有限次初等变换化为 或存在可逆阵，使得 其中 其中(列满秩)，(行满秩) 定义 设矩阵的秩为 若可以分解为列满秩矩阵和行满秩矩阵的乘积，即 则称其为的满秩分解 3.2 满秩分解方法 定理 设矩阵秩为 若的行最简形矩阵的首1元分别在的第列 取的前行构成的矩阵为，的第列构成的矩阵为 则为矩阵的满秩分解 4. 矩阵的奇异值分解 4.1 奇异值分解 奇异值定义 设是秩为的的复矩阵，矩阵的特征值为 称为的奇异值(singular value) 对奇异值进行排序，令 定理 设是秩为的复矩阵，则存在酉矩阵使，其中 其中是的奇异值 奇异值分解定义 称为矩阵的奇异值分解(singular value decomposition, SVD) 4.2 奇异值分解方法 求酉矩阵使得对角化 为的正特征值所对应的特征向量矩阵 取 扩充为的标准正交基： 取有 详细地说： 由给出的矩阵得到，并求得到特征值从大到小依次为 取大于0的特征值的平方根得到奇异值 由特征值得到矩阵，并由此得到矩阵 将特征值带入得特征向量，单位化正交化后得 正特征值对应的特征向量组成矩阵，其他特征值对应的特征向量组成矩阵 得到，若特征值全为正，则 求矩阵 解方程得到的特征向量单位化后组成矩阵，由此得到矩阵 则矩阵的奇异值分解为 5. 广义逆矩阵 5.1 广义逆 定义 设为矩阵 若存在矩阵满足 则称为的Moore-Penrose逆，记作 任何矩阵都可以有广义逆矩阵 若矩阵有逆矩阵，则其逆就是广义逆矩阵 定理 设为矩阵，则其广义逆存在且唯一 若为的满秩分解 则 推论 设为矩阵 若列满秩，则 若A行满秩，则 定理 设是的奇异值分解 则，其中 5.2 广义逆的性质 设的广义逆为，则 ，其中 ，为正整数 5.3 广义逆的应用 设线性方程组有解(相容)的充要条件为 方程组有解时，通解为 其中，是的特解，是任意列向量","link":"/posts/1094/"},{"title":"算法学习——减治","text":"减治算法的一些经典算法，如两序列中位数、折半查找、二叉树查找、插入排序等。 减治 经典算法 两个序列的中位数 1234567891011121314151617181920public static int SearchMid(int[] A, int[] B) { int s1 = 0, e1 = A.length - 1, s2 = 0, e2 = B.length - 1;// 两个序列的上下界 int mid1, mid2; while (s1 &lt; e1 &amp;&amp; s2 &lt; e2) { mid1 = (s1 + e1) / 2;// A的中位数下标 mid2 = (s2 + e2) / 2;// B的中位数下标 if (A[mid1] == B[mid2]) return A[mid1];// 第①种情况 if (A[mid1] &lt; B[mid2]) {// 第②种情况 if ((s1 + e1) % 2 == 0) s1 = mid1; else s1 = mid1 + 1;// 保证两序列长度相等 e2 = mid2; } else {// 第③种情况 if ((s2 + e2) % 2 == 0) s2 = mid2; else s2 = mid2 + 1; e1 = mid1; } } if (A[s1] &lt; B[s2]) return A[s1]; else return B[s2];} 折半查找 1234567891011public static int BinSearch(int[] r, int key) { int low = 0, high = r.length - 1; int mid; while (low &lt;= high) { mid = (low + high) / 2; if (key &lt; r[mid]) high = mid - 1; else if (key &gt; r[mid]) low = mid + 1; else return mid; } return -1;} 二叉查找树 123456789101112131415161718192021222324252627282930public static BinaryTree InsertBST(BinaryTree root, int data) { if (root == null) { root = new BinaryTree(); root.setData(data); root.setLchild(null); root.setRchild(null); return root; } if (data &lt;= root.getData()) { root.setLchild(InsertBST(root.getLchild(), data)); } else { root.setRchild(InsertBST(root.getRchild(), data)); } return root;}public static BinaryTree CreateBST(int[] A) { BinaryTree T = new BinaryTree(); for (int i = 0; i &lt; A.length; i++) { T = InsertBST(T, A[i]); } return T;}public static BinaryTree SearchBST(BinaryTree root, int key) { if (root == null) return null; else if (root.getData() == key) return root; else if (key &lt; root.getData()) return SearchBST(root.getLchild(), key); else return SearchBST(root.getRchild(), key);} 选择问题 123456789101112131415161718192021222324252627282930public static int Partition(int[] r, int low, int high) {// 划分 int i = low, j = high; while (i &lt; j) { while (i &lt; j &amp;&amp; r[i] &lt;= r[j]) j--;// 右侧扫描 if (i &lt; j) {// 将较小的元素交换到前面 int temp = r[i]; r[i] = r[j]; r[j] = temp; i++; } while (i &lt; j &amp;&amp; r[i] &lt;= r[j]) i++;// 左侧扫描 if (i &lt; j) {// 将较大元的元素交换到后面 int temp = r[i]; r[i] = r[j]; r[j] = temp; j--; } } return i;// 返回枢轴位置}public static int SelectMinK(int[] r, int low, int high, int k) {// 在r[low]和r[high]之间寻找第k小的元素 int pivot = Partition(r, low, high);// 划分得到枢轴位置 if (pivot == k)// 查找成功 return r[pivot]; if (pivot &gt; k)// 枢轴大于k，则说明第k小元素在枢轴左侧 return SelectMinK(r, low, pivot - 1, k); else// 否则在右侧寻找 return SelectMinK(r, pivot + 1, high, k);} 插入排序 123456789public static void InsertSort(int[] r) { int j; for (int i = 2; i &lt;= r.length - 1; i++) { r[0] = r[i]; for (j = i - 1; r[0] &lt; r[j]; j--) r[j + 1] = r[j]; r[j + 1] = r[0]; }} 堆排序 123456789101112131415161718192021222324252627public static void SiftHeap(int[] r, int key) { int i = key, j = 2 * i + 1, temp;// i为待筛的结点，j为i的左孩子 while (j &lt; r.length) {// 筛选还没有进行到叶子 if (j &lt; r.length - 1 &amp;&amp; r[j] &lt; r[j + 1]) j++;// 比较i的左右孩子，j为较大者 if (r[i] &gt; r[j]) break;// 根结点已经大于左右孩子中的较大者 else {// 根节点与较大者交换 temp = r[i]; r[i] = r[j]; r[j] = temp; i = j; j = 2 * i + 1;// 被筛的结点位于原来j的位置 } }}public static void Sort(int[] r) { int i, temp; for (i = (r.length - 1) / 2; i &gt;= 0; i--) {// 初始建堆 SiftHeap(r, i); } for (i = 1; i &lt;= r.length - 1; i++) {// 循环执行移走堆顶元素及重新调整堆的操作 temp = r[0]; r[0] = r[r.length - i]; r[r.length - i] = temp; SiftHeap(r, 0); }} 淘汰赛冠军问题 1234567891011121314151617181920public static char Game(char[] r) { int i = r.length; System.out.println(r); while (i &gt; 1) { i = i / 2; for (int j = 0; j &lt; i; j++) if (Comp(r[j + i], r[j]))// 分组比赛 r[j] = r[j + i]; // 胜者填入r[j] for (int k = 0; k &lt; i; k++) { System.out.print(r[k]); } System.out.println(); } return r[0];}public static boolean Comp(char i, char j) {// 模拟比赛，若i胜则返回true return i &gt; j;} 假币问题 123456789101112131415161718public static int Coin(int low, int high, int n) { int i, num1, num2, num3;// num1、2、3存储3组硬币的数量 int add1 = 0, add2 = 0;// add1、2存储前两组硬币的重量 if (n == 1) return low + 1;// 递归结束条件 if (n % 3 == 0) num1 = num2 = n / 3;// 返回的是序号，下标加1 else num1 = num2 = n / 3 + 1; // 前两组有n/3(向上取整)枚硬币 num3 = n - num1 - num2; for (i = 0; i &lt; num1; i++) add1 += a[low + i]; for (i = num1; i &lt; num1 + num2; i++) add2 += a[low + i]; if (add1 &lt; add2)// 在第一组查找，下标范围low ~ low+num1-1 return Coin(low, low + num1 - 1, num1); else if (add1 &gt; add2)// 在第二组查找，下标范围low+num1 ~ low+num1+num2-1 return Coin(low + num1, low + num1 + num2 - 1, num2); else// 在第三组查找，下标范围low+num1+num2 ~ high return Coin(low + num1 + num2, high, num3);}","link":"/posts/11853/"},{"title":"矩阵的标准形","text":"矩阵分析简明教程第3章笔记 1. Jordan标准形 1.1 Jordan标准形 Jordan块定义 形如下列形式的矩阵称为阶Jordan块 Jordan型矩阵定义 形如下列形式的矩阵称为阶Jordan型矩阵 其中为阶的Jordan块，且 对角矩阵也是Jordan型矩阵 对角阵的Jordan标准形为其本身 定理 每个阶复方阵都和一个Jordan型矩阵相似 即存在可逆阵，使 称矩阵为的Jordan标准形 1.2 计算Jordan标准形的方法一 行列式因子不变因子初等因子块 特征矩阵定义 称下列-矩阵为的特征矩阵 行列式因子定义 中所有阶子式首项系数为1的最大公因式 称为的级行列式因子，记为 (能够整除，即是的因子) 不变因子定义 称为的不变因子 初等因子定义 将的所有次数大于零的不变因子分解为互不相同的一次因式方幂的乘积 所有这些一次因式方幂称为的初等因子 来自不同的不变因子的一次因子方幂不能合并 初等因子与Jordan块一一对应 Jordan标准形与Jordan块的顺序无关 复方阵的Jordan标准形在不考虑Jordan块顺序的情况下唯一 2. -矩阵及其Smith标准形 2.1 -矩阵概念 定义 形如下列形式的矩阵称为-矩阵 其中位置元为多项式 阶数字矩阵的特征矩阵是一个特殊的-矩阵，它的秩为 任何一个-矩阵都和一个Smith标准形等价，即经过有限次初等变换可化为Smith标准形 逆矩阵定义 若-矩阵满足 则称是可逆的，且称为的逆矩阵 定理（可逆） -矩阵可逆当且仅当为非零常数 -矩阵的运算、行列式、子式、余子式、伴随矩阵等概念与数字矩阵一致 秩定义 -矩阵的不恒为零多项式的子式的最高阶数称为的秩，记为 初等变换定义 交换两行(列)，记作 第行(列)乘以非零数，记作 第行(列)加上第行(列)的倍，记作 等价定义 若-矩阵经过若干次初等变换变为 则称与等价，记为 定理（等价） -矩阵的初等变换不会改变其秩 等价的-矩阵的秩相等 2.2 -矩阵的Smith标准形 定理 -矩阵都可经过若干次初等变换化为Smith标准形 即秩为的的-矩阵与矩阵等价 其中是首一多项式，且 矩阵称为的Smith标准形 2.3 -矩阵的三种因子 设-矩阵 行列式因子定义 中所有阶子式首项系数为1的最大公因式 称为的级行列式因子，记为 不变因子定义 设 称为的不变因子 初等因子定义 将的所有的次数大于零的不变因子分解为互不相同的一次因式方幂的乘积 所有这些一次因式方幂称为的初等因子 三种因子的关系 行列式因子与不变因子 行列式因子不变因子 不变因子与初等因子 设的各阶不变因子在复数域的标准分解式为 即为的初等因子 定理 初等变换不改变-矩阵的各级行列式因子 推论 等价的-矩阵有相同的行列式因子 等价的-矩阵有相同的不变因子 等价的-矩阵有相同的初等因子 设-矩阵的Smith标准形为 或的不变因子为： 定理 -矩阵的Smith标准形是唯一的 2.4 计算Jordan标准形的方法二 标准形不变因子初等因子块 2.5 Jordan标准形基本定理 每一个阶复方阵都和一个Jordan型矩阵相似 即存在可逆阵，使 2.6 矩阵相似的条件 定理 数字矩阵A相似于B特征矩阵等价于 方阵相似于的充要条件为以下其一： 相同的行列式因子组 相同的不变因子组 相同的初等因子组 基本定理 任何复方阵都和一个Jordan标准形相似 3. Cayley-Hamilton定理与矩阵的最小多项式 3.1 多项式矩阵 设为阶方阵，多项式 定义矩阵多项式 3.2 Cayley-Hamilton定理 设为阶方阵，，则 3.3 零化多项式 定义 设为阶方阵，若多项式满足 则称为的零化多项式 定理 特征多项式即为矩阵A的零化多项式 零化多项式不唯一，且没有次数最高的零化多项式 3.4 最小多项式 定义 设为阶方阵，称的次数最低的首一零化多项式为的最小多项式，记为 定理 最小多项式可以整除任何零化多项式 矩阵的最小多项式是唯一的，特别的，最小多项式可以整除特征多项式 矩阵的最小多项式和特征多项式有相同的根，但重数不相同 矩阵的特征多项式 最小多项式的形式如下 最小多项式是的特征矩阵的第个不变因子，即","link":"/posts/60155/"},{"title":"算法学习——动态规划","text":"关于动态规划的经典算法，如多段图最短路径问题、TSP问题、最长公共子序列问题等。 动态规划 经典算法 数塔问题 12345678910111213141516171819202122232425262728public static int Tower(int[][] d) { int n = d.length; int[][] maxAdd = new int[n][n]; int[][] path = new int[n][n]; int i, j; for (j = 0; j &lt; n; j++) { maxAdd[n - 1][j] = d[n - 1][j]; } for (i = n - 2; i &gt;= 0; i--) { for (j = 0; j &lt;= i; j++) { if (maxAdd[i + 1][j] &gt; maxAdd[i + 1][j + 1]) { maxAdd[i][j] = d[i][j] + maxAdd[i + 1][j]; path[i][j] = j; } else { maxAdd[i][j] = d[i][j] + maxAdd[i + 1][j + 1]; path[i][j] = j + 1; } } } System.out.println(&quot;路径：&quot; + d[0][0]); j = path[0][0]; for (i = 1; i &lt; n; i++) { System.out.println(&quot;--&gt;&quot; + d[i][j]); j = path[i][j]; } System.out.println(Arrays.deepToString(maxAdd)); return maxAdd[0][0];} 多段图最短路径问题 1234567891011121314151617181920212223242526272829public static int BackPath(Graph graph) { int n = graph.getVnum(); int i, j, temp; int[] cost = new int[n]; int[] path = new int[n]; for (i = 1; i &lt; n; i++) {// 初始化路径为∞ cost[i] = MAX; path[i] = -1; } cost[0] = 0;// 0为源点 path[0] = -1; for (j = 1; j &lt; n; j++) {// 填表 for (i = j - 1; i &gt;= 0; i--) {// 考察所有入边 if (graph.getMatrix()[i][j] &gt;= 0)// 如果边存在 if (graph.getMatrix()[i][j] + cost[i] &lt; cost[j]) { cost[j] = graph.getMatrix()[i][j] + cost[i]; path[j] = i; } } } System.out.println(&quot;-----&quot; + (n - 1));// 输出终点 i = n - 1; while (path[i] &gt;= 0) {// 依次输出path[i] System.out.println(&quot;-----&quot; + path[i]); i = path[i];// 路径上顶点i的前一个顶点 } System.out.println(Arrays.toString(cost)); return cost[n - 1];} 多源点最短路径问题（Floyd算法） 123456789101112131415161718192021public static int[][] FloydAlgorithm(Graph graph) { int i, j, k; int n = graph.getVnum(); int[][] dist = new int[n][n]; for (i = 0; i &lt; n; i++) { for (j = 0; j &lt; n; j++) { dist[i][j] = graph.getMatrix()[i][j]; } } for (k = 0; k &lt; n; k++) { for (i = 0; i &lt; n; i++) { for (j = 0; j &lt; n; j++) { if (i != j &amp;&amp; i != k &amp;&amp; k != j) if (dist[i][k] + dist[k][j] &lt; dist[i][j]) dist[i][j] = dist[i][k] + dist[k][j]; } } } return dist;} TSP问题（待解决） 1 最长递增子序列问题 12345678910111213141516171819202122232425262728293031323334353637383940414243public static int IncreaseOrder(int[] a) { int i, j, k, index; int n = a.length; int[] L = new int[n]; int[][] x = new int[n][n]; for (i = 0; i &lt; n; i++) {// 初始化，最长递增子序列长度为1 L[i] = 1; x[i][0] = a[i]; } System.out.println(&quot;初始化完成&quot;); for (int[] item : x) { System.out.println(Arrays.toString(item)); } for (i = 1; i &lt; n; i++) { int max = 1; for (j = i - 1; j &gt;= 0; j--) { if ((a[j] &lt; a[i]) &amp;&amp; (max &lt; L[j] + 1)) { max = L[j] + 1; L[i] = max; for (k = 0; k &lt; max - 1; k++) { x[i][k] = x[j][k]; } x[i][max - 1] = a[i]; } } } for (index = 0, i = 1; i &lt; n; i++) {// 求所有递增子序列的最大长度 if (L[index] &lt; L[i]) index = i; } System.out.println(&quot;最长子序列：&quot;); for (i = 0; i &lt; L[index]; i++) {// 输出最长递增子序列 System.out.println(x[index][i]); } for (int[] item : x) { System.out.println(Arrays.toString(item)); } return L[index];// 返回最长递增子序列的长度} 最长公共子序列问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344private static int CommonOrder(char[] x, char[] y) { int i, j, k; int n = y.length, m = x.length; char[] Z = new char[Math.max(n, m)];// 存储最长公共子序列 int[][] DP = new int[m + 1][n + 1];// 长度矩阵 int[][] S = new int[m + 1][n + 1];// 状态矩阵 for (j = 0; j &lt;= n; j++)// 初始化第0行 DP[0][j] = 0; for (i = 0; i &lt;= m; i++)// 初始化第0列 DP[i][0] = 0; for (i = 1; i &lt;= m; i++) for (j = 1; j &lt;= n; j++) if (x[i - 1] == y[j - 1]) {// 情况①：两字符相同，此处i和j减一是因为矩阵中前面要留出一个空字符的位置，对应到原字符串中就需要减一 DP[i][j] = DP[i - 1][j - 1] + 1;// 左上方的数字+1填入 S[i][j] = 1; } else if (DP[i][j - 1] &gt;= DP[i - 1][j]) {// 情况②：两字符不同，且左侧的数&gt;=上方的数 DP[i][j] = DP[i][j - 1];// 填入左侧数字 S[i][j] = 2; } else {// 情况③：两数字不同，且左侧的数&lt;上方的数 DP[i][j] = DP[i - 1][j];// 填入上方数字 S[i][j] = 3; } i = m; j = n; k = DP[m][n];// 从长度矩阵的最后一个元素开始回溯 while (i &gt; 0 &amp;&amp; j &gt; 0) { if (S[i][j] == 1) {// 情况①：往左上方回溯，同时记录当前字符 Z[k] = x[i - 1]; k--; i--; j--; } else if (S[i][j] == 2) {// 情况②：往左侧回溯 j--; } else {// 情况③：往上方回溯 i--; } } for (k = 1; k &lt;= DP[m][n]; k++) { System.out.println(Z[k]); } return DP[m][n];} 0/1背包问题 123456789101112131415161718192021222324252627public static int KnapSack(int[] w, int[] v, int C) {// w:物品重量,v:物品价值,C:背包容量 int i, j; int n = w.length; int[] x = new int[n];// 存放物品装入情况 int[][] V = new int[n + 1][C + 1];// 迭代数组,含义:任取物品[0,i]放入容量为j的背包中 for (i = 0; i &lt;= n; i++)// 初始化第0列 V[i][0] = 0; for (j = 0; j &lt;= C; j++)// 初始化第0行 V[0][j] = 0; for (i = 1; i &lt;= n; i++) for (j = 1; j &lt;= C; j++) if (j &lt; w[i - 1])// 当前迭代的容量如果小于物品重量 V[i][j] = V[i - 1][j];// 则不放入物品，总价值与它上方的数值相同 else// 否则，取“上方数值”和“不放物品i时的最大价值+物品i的价值”较大者 V[i][j] = Math.max(V[i - 1][j], V[i - 1][j - w[i - 1]] + v[i - 1]); for (j = C, i = n; i &gt; 0; i--) { if (V[i][j] &gt; V[i - 1][j]) { x[i - 1] = 1; j = j - w[i - 1]; } else x[i - 1] = 0; } System.out.println(Arrays.toString(x)); return V[n][C];// 返回最大价值} 最优二叉搜索树（待解决） 1 近似串匹配问题（待理解） 12345678910111213141516171819public static int ASM(char[] P, char[] T) { int i, j; int m = P.length, n = T.length; int[][] D = new int[m + 1][n + 1]; for (j = 1; j &lt;= n; j++) D[0][j] = j; for (i = 0; i &lt;= m; i++) D[i][0] = i; for (j = 1; j &lt;= n; j++) { for (i = 1; i &lt;= m; i++) { if (P[i - 1] == T[j - 1]) D[i][j] = Math.min(Math.min(D[i - 1][j - 1], D[i - 1][j] + 1), D[i][j - 1] + 1); else D[i][j] = Math.min(Math.min(D[i - 1][j - 1] + 1, D[i - 1][j] + 1), D[i][j - 1] + 1); } } return D[m][n];} 练习 力扣.1143. 最长公共子序列 以序列X={a,b,c,b,d,b}和Y={a,c,b,b,a,b,d,b,b}为例 长度矩阵为： 0 a c b b a b d b b 0 0 0 0 0 0 0 0 0 0 0 a 0 b 0 c 0 b 0 d 0 b 0 表格的第一行、第一列全部初始化为0，表示空字符串与任何字符串的最长公共子序列长度均为0 从第一个空格开始遍历表格 若所在行和列的字符不相同，则在它上方和左侧的两个数字中选取较大的一个填入（DP[i][j] = max{DP[i-1][j], DP[i][j-1]}） 若所在行和列的字符相同，则将它左上方的数字+1填入（DP[i][j] = DP[i-1][j-1] + 1） 在处理上述矩阵的同时，可定义另一个格式相同的矩阵用来记录状态，成为状态矩阵 情况①，两字符相同，则填入1 情况②，两字符不同，且长度矩阵中左侧数字&gt;=上方数字，则填入2 情况③，两字符不同，且长度矩阵中左侧数字&lt;上方数字，则填入3 回溯时，从状态矩阵的最右下角元素开始 遇到1，向左上方回溯 遇到2，向左侧回溯 遇到3，向上方回溯 回溯至最左上角元素后，经过的路线中所有1所在位置对应的字符组成的字符串即为最长公共子序列","link":"/posts/21128/"},{"title":"算法学习——分治","text":"分治算法的经典算法，如归并排序、快速排序、最大子段和问题等，以及一些力扣练习题。 分治 经典算法 数字旋转方阵 12345678910111213141516171819202122232425262728293031323334public static int[][] Full(int[][] data, int number, int begin, int size) {// 从number开始填写size阶方阵，左上角下标为(begin,begin) int i, j, k; if (size == 0)// 递归边界，若size为0则无需填写 return data; if (size == 1) {// 递归边界，若size为1 data[begin][begin] = number;// 则只需填写number return data; } i = begin; j = begin; for (k = 0; k &lt; size - 1; k++) { data[i][j] = number; number++; i++;// 往下移动 } for (k = 0; k &lt; size - 1; k++) { data[i][j] = number; number++; j++;// 往右移动 } for (k = 0; k &lt; size - 1; k++) { data[i][j] = number; number++; i--;// 往上移动 } for (k = 0; k &lt; size - 1; k++) { data[i][j] = number; number++; j--;// 往左移动 } Full(data, number, begin + 1, size - 2);// 递归填写除最外面一圈的部分 return data;} 归并排序 12345678910111213141516171819202122232425262728293031public static void Merge(int[] r, int[] res, int start, int mid, int end) { int i = start, j = mid + 1, k = start; while (i &lt;= mid &amp;&amp; j &lt;= end) { if (r[i] &lt;= r[j]) { res[k++] = r[i++]; } else { res[k++] = r[j++]; } } while (i &lt;= mid) { res[k++] = r[i++]; } while (j &lt;= end) { res[k++] = r[j++]; }}public static void Sort(int[] r, int start, int end) { int mid; int[] temp = new int[r.length]; if (start == end) return; else { mid = (start + end) / 2; Sort(r, start, mid); Sort(r, mid + 1, end); Merge(r, temp, start, mid, end); for (int i = start; i &lt;= end; i++) { r[i] = temp[i]; } }} 快速排序 1234567891011121314151617181920212223242526272829303132public static int Partition(int[] r, int low, int high) { int i = low, j = high; while (i &lt; j) { while (i &lt; j &amp;&amp; r[i] &lt;= r[j]) { j--; } if (i &lt; j) { int temp = r[i]; r[i] = r[j]; r[j] = temp; } while (i &lt; j &amp;&amp; r[i] &lt;= r[j]) { i++; } if (i &lt; j) { int temp = r[i]; r[i] = r[j]; r[j] = temp; j--; } } return i;}public static void Sort(int[] r, int low, int high) { int pivot; if (low &lt; high) { pivot = Partition(r, low, high); Sort(r, low, pivot - 1); Sort(r, pivot + 1, high); }} 最大子段和问题 1234567891011121314151617181920212223242526272829public static int MaxSum(int[] a, int left, int right) { int sum = 0, midSum = 0, leftSum = 0, rightSum = 0; int center, s1, s2, lefts, rights; if (left == right)// 若序列长度为1，则直接求解 sum = a[left]; else { center = (left + right) / 2;// 从中间划分 leftSum = MaxSum(a, left, center);// 情况①，最大和在左半部分，递归求解 rightSum = MaxSum(a, center + 1, right);// 情况②，最大和在右半部分，递归求解 s1 = 0; lefts = 0;// 以下为情况③，组成最大和的元素跨越中轴线 for (int i = center; i &gt;= left; i--) {// 先求解s1 lefts += a[i];// 指针向左运动并累加 if (lefts &gt; s1)// 遇到负数会导致lefts变小，故不会赋值给s1 s1 = lefts; } s2 = 0; rights = 0; for (int j = center + 1; j &lt;= right; j++) {// 再求解s2 rights += a[j];// 指针向右运动并累加 if (rights &gt; s2)// 遇到负数会导致rights变小，故不会赋值给s2 s2 = rights; } midSum = s1 + s2;// 计算情况③的最大子段和 sum = Math.max(Math.max(midSum, leftSum), rightSum);// 三者取最大 } return sum;} 棋盘覆盖问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * @param board 棋盘 * @param tr 棋盘左上角的行标 * @param tc 棋盘左上角的列标 * @param dr 特殊方块的行标 * @param dc 特殊方块的列标 * @param size 棋盘的阶数 * @return 骨牌放置的结果 */public static int[][] ChessBoard(int[][] board, int tr, int tc, int dr, int dc, int size) { int s, t1;// t1表示本次覆盖使用的L型骨牌编号 if (size == 1) return board; t1 = ++t; s = size / 2;// 划分 // 处理左上角子棋盘 if (dr &lt; tr + s &amp;&amp; dc &lt; tc + s) {// 若特殊方格在左上角的子棋盘中 board = ChessBoard(board, tr, tc, dr, dc, s);// 递归处理 } else {// 否则用t1号骨牌覆盖右下角，再递归处理子棋盘 board[tr + s - 1][tc + s - 1] = t1; board = ChessBoard(board, tr, tc, tr + s - 1, tc + s - 1, s); } // 处理右上角子棋盘 if (dr &lt; tr + s &amp;&amp; dc &gt;= tc + s) {// 若特殊方格在右上角的子棋盘中 board = ChessBoard(board, tr, tc + s, dr, dc, s);// 递归处理 } else {// 否则用t1号骨牌覆盖左下角，再递归处理子棋盘 board[tr + s - 1][tc + s] = t1; board = ChessBoard(board, tr, tc + s, tr + s - 1, tc + s, s); } // 处理左下角子棋盘 if (dr &gt;= tr + s &amp;&amp; dc &lt; tc + s) {// 若特殊方格在左下角的子棋盘中 board = ChessBoard(board, tr + s, tc, dr, dc, s);// 递归处理 } else {// 否则用t1号骨牌覆盖右上角，再递归处理子棋盘 board[tr + s][tc + s - 1] = t1; board = ChessBoard(board, tr + s, tc, tr + s, tc + s - 1, s); } // 处理右下角子棋盘 if (dr &gt;= tr + s &amp;&amp; dc &gt;= tc + s) {// 若特殊方格在右下角的子棋盘中 board = ChessBoard(board, tr + s, tc + s, dr, dc, s);// 递归处理 } else {// 否则用t1号骨牌覆盖左上角，再递归处理子棋盘 board[tr + s][tc + s] = t1; board = ChessBoard(board, tr + s, tc + s, tr + s, tc + s, s); } return board;} 最近对问题 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public static double Closest(Point[] S, int low, int high) { double d1, d2, d3, d; int mid, i, j, index; Point[] P = new Point[S.length]; //存放点集P1和P2 if (high - low == 1) //只有两个点 return Distance(S[low], S[high]); if (high - low == 2) { //只有三个点 d1 = Distance(S[low], S[low + 1]); d2 = Distance(S[low + 1], S[high]); d3 = Distance(S[low], S[high]); if ((d1 &lt; d2) &amp;&amp; (d1 &lt; d3)) return d1; else if (d2 &lt; d3) return d2; else return d3; } mid = (low + high) / 2; //计算中间点 d1 = Closest(S, low, mid); //递归求解子问题① d2 = Closest(S, mid + 1, high); //递归求解子问题② d = Math.min(d1, d2); //一下求解子问题③ index = 0; for (i = mid; (i &gt;= low) &amp;&amp; (S[mid].getX() - S[i].getX() &lt; d); i--) { //建立点集P1 P[index++] = S[i]; } for (i = mid + 1; (i &lt;= high) &amp;&amp; (S[i].getX() - S[mid].getX() &lt; d); i++) { //建立点集P2 P[index++] = S[i]; } PointQuickSort.Sort(P, 0, index - 1);//将集合P1和P2按y坐标升序排列 for (i = 0; i &lt; index; i++) { for (j = i + 1; j &lt; index; j++) { if (P[j].getY() - P[i].getY() &gt;= d) break; else { d3 = Distance(P[i], P[j]); if (d3 &lt; d) d = d3; } } } return d;}public static double Distance(Point a, Point b) { return Math.sqrt(Math.pow(a.getX() - b.getX(), 2) + Math.pow(a.getY() - b.getY(), 2));} 凸包问题（待解决） 1 练习 力扣.53. 最大子数组和 定义一个操作get(a,l,r)表示查询a序列[l,r]区间内的最大子段和，则最终答案就是get(nums,0,nums.length-1)。 对于区间[l,r]，取\\(m=\\lfloor\\frac{l+r}{2}\\rfloor\\)，对区间[l,m]和[m+1,l]分治求解，当递归逐层深入到区间长度为1时，递归开始回升。 对于区间[l,r]维护四个量： lSum表示[l,r]内以l为左端点的最大子段和。 rSum表示[l,r]内以l为右端点的最大子段和。 mSum表示[l,r]内的最大子段和。 iSum表示[l,r]的区间和。 对于长度为1的区间[i,i]，上述四个量均与nums[i]相等。 对于长度大于1的区间： iSum最好维护，区间[l,r]的iSum就等于左子区间的iSum加右子区间的iSum。 lSum存在两种可能，要么等于左子区间的lSum，要么等于左子区间的iSum+右子区间的lSum，二者取大。 rSum同理，要么等于右子区间的rSum，要么等于右子区间的iSum+左子区间的rSum，二者取大。 mSum同样有两种情况，一是[l,r]的mSum对应的区间不跨越m，则[l,r]的mSum可能是左子区间和右子区间的mSum中的一个，二是[l,r]的mSum对应的区间跨越m，则可能是左子区间的rSum+右子区间的lSum，三者取大。 12345678910111213141516171819202122232425262728293031323334class Solution { public class Status { public int lSum, rSum, mSum, iSum; public Status(int lSum, int rSum, int mSum, int iSum) { this.lSum = lSum; this.rSum = rSum; this.mSum = mSum; this.iSum = iSum; } } public int maxSubArray(int[] nums) { return getInfo(nums, 0, nums.length - 1).mSum; } public Status getInfo(int[] a, int l, int r) { if (l == r) { return new Status(a[l], a[l], a[l], a[l]); } int m = (l + r) &gt;&gt; 1; Status lSub = getInfo(a, l, m); Status rSub = getInfo(a, m + 1, r); return pushUp(lSub, rSub); } public Status pushUp(Status l, Status r) { int iSum = l.iSum + r.iSum; int lSum = Math.max(l.lSum, l.iSum + r.lSum); int rSum = Math.max(r.rSum, r.iSum + l.rSum); int mSum = Math.max(Math.max(l.mSum, r.mSum), l.rSum + r.lSum); return new Status(lSum, rSum, mSum, iSum); }} 力扣.108. 将有序数组转换为二叉搜索树 由于数组是按升序排列的，故可将问题划分为子问题，即 取数组中间元素作为根节点。 中间元素左侧的所有元素均为左子树中的元素。 中间元素右侧的所有元素均为右子树中的元素。 以上述方式递归处理左侧和右侧的数组，设置递归边界： 当end &lt; begin时，说明该侧数组为空，直接返回null。 当end == begin时，说明该侧数组只有一个元素，直接返回以该元素为根节点的子树 123456789101112131415161718public TreeNode sortedArrayToBST(int[] nums) { if (nums.length == 0) return null; return Solution(nums, 0, nums.length - 1);}public TreeNode Solution(int[] nums, int begin, int end) { if (end &lt; begin) return null; if (end == begin) return new TreeNode(nums[begin]); int mid = (begin + end) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = Solution(nums, begin, mid - 1); root.right = Solution(nums, mid + 1, end); return root;} 力扣.169. 多数元素 如果数 a 是数组 nums 的众数，如果我们将 nums 分成两部分，那么 a 必定是至少一部分的众数。 证明： 假设a既不是左半部分的众数，也不是右半部分的众数。 那么a出现的次数少于 L / 2 + R / 2 次，其中L和R分别是左半部分和右半部分的长度。 由于L / 2 + R / 2 &lt;= (L + R) / 2，说明a也不是数组nums的众数，因此出现了矛盾。 故a必定是至少一部分的众数。 拆分子问题，将数组分为左右两部分： 左侧众数若与右侧众数相同，则众数为该数。 左侧众数若与右侧众数不同，则需要分别统计这两个数在左右两部分中的总共出现的次数，次数大者为众数。 递归边界：当区间长度为1时，该数即为众数，直接返回。 123456789101112131415161718192021222324public int majorityElement(int[] nums) { return Solution(nums, 0, nums.length - 1); } public int Solution(int[] nums, int low, int high) { if (low == high) return nums[low]; int mid = (low + high) / 2; int left = Solution(nums, low, mid); int right = Solution(nums, mid + 1, high); if (left == right) return left; int leftC = Count(nums, left, low, high); int rightC = Count(nums, right, low, high); return leftC &gt; rightC ? left : right; } public int Count(int[] nums, int num, int low, int high) { int count = 0; for (int i = low; i &lt;= high; i++) if (nums[i] == num) count++; return count; } 力扣.190. 颠倒二进制位 若要翻转一个二进制串，可以将其均分成左右两部分，对每部分递归执行翻转操作，然后将左半部分拼在右半部分的后面，即完成了翻转。 由于左右两部分的计算方式是相似的，利用位掩码和位移运算，我们可以自底向上地完成这一分治流程。 12345678910111213private static final int M1 = 0x55555555; // 01010101010101010101010101010101private static final int M2 = 0x33333333; // 00110011001100110011001100110011private static final int M4 = 0x0f0f0f0f; // 00001111000011110000111100001111private static final int M8 = 0x00ff00ff; // 00000000111111110000000011111111public static int reverseBits(int n) { n = n &gt;&gt;&gt; 1 &amp; M1 | (n &amp; M1) &lt;&lt; 1;// 奇偶位互换 n = n &gt;&gt;&gt; 2 &amp; M2 | (n &amp; M2) &lt;&lt; 2;// 每两位互换 n = n &gt;&gt;&gt; 4 &amp; M4 | (n &amp; M4) &lt;&lt; 4;// 每四位互换 n = n &gt;&gt;&gt; 8 &amp; M8 | (n &amp; M8) &lt;&lt; 8;// 每八位互换 return n &gt;&gt;&gt; 16 | n &lt;&lt; 16;// 最终将左右两半部分互换}","link":"/posts/45850/"},{"title":"算法学习——贪心","text":"贪心算法的经典算法，如埃及分数、TSP问题、图着色问题、背包问题等。 贪心 经典算法 埃及分数 12345678910111213141516public static void EgyptFrac(int A, int B) { int E, R; System.out.println(A + &quot;/&quot; + B + &quot;=&quot;); do { E = B / A + 1;// 求A/B包含的最大埃及分数 System.out.println(&quot;1/&quot; + E + &quot;+&quot;); A = A * E - B;// 本行及下一行求A/B - 1/E B = B * E; R = CommFactor.getCommFactor(B, A);// 求A，B最大公约数 if (R &gt; 1) {// 化简A/B A = A / R; B = B / R; } } while (A &gt; 1);// 当A/B不是埃及分数时继续循环 System.out.println(&quot;1/&quot; + B);} 欧几里得法求公约数（即辗转相除法） 123456789public static int getCommFactor(int m, int n) { int r = m % n; while (r != 0) { m = n; n = r; r = m % n; } return n;} TSP问题 最近邻点策略（类似Prim算法） 123456789101112131415161718192021222324public static int TSP1(int[][] arc, int w) {// arc为邻接矩阵，w为出发顶点 int edgeCount = 0, TSPLength = 0; int min, u, v = 0; int n = arc.length; int[] flag = new int[n];// 标记顶点是否在哈密顿回路中 u = w; flag[w] = 1; while (edgeCount &lt; n - 1) {// 哈密顿回路中只有n-1条边 min = 1000; for (int j = 1; j &lt; n; j++) {// 求整个邻接矩阵中的最小值 if ((flag[j] == 0) &amp;&amp; (arc[u][j] != 0) &amp;&amp; (arc[u][j] &lt; min)) { v = j; min = arc[u][j]; } } TSPLength += arc[u][v]; flag[v] = 1;// 将顶点加入哈密顿回路 edgeCount++; System.out.println(u + &quot;---&gt;&quot; + v); u = v;// 更新下次出发的顶点 } System.out.println(v + &quot;---&gt;&quot; + w); return TSPLength + arc[u][w]; } 最短链接策略（类似Kruskal算法）（待解决） 1 图着色问题 1234567891011121314151617181920212223242526272829303132private static int[] color;public static int ColorGraph(int[][] arc) { int k = 0; int n = arc.length; color = new int[n]; boolean flag = true;// flag为true表示图中还有顶点未着色 while (flag) { k++; flag = false; for (int i = 0; i &lt; n; i++) { if (color[i] == 0) { color[i] = k;// 顶点i着色k if (!Ok(arc, i)) {// 发生冲突，取消着色 color[i] = 0; flag = true; } } } } System.out.println(Arrays.toString(color)); return k;}public static boolean Ok(int[][] arc, int i) {// 判断顶点i的着色是否发生冲突 for (int j = 0; j &lt; arc.length; j++) {// 考察其他所有顶点 if (arc[i][j] == 1 &amp;&amp; color[i] == color[j])// arc矩阵为无向图的邻接矩阵，1表示连通，0表示不连通 return false; } return true;} 最小生成树问题 Prim算法 12345678910111213141516171819202122232425262728293031public static void Prim(int[][] arc, int w) {// 从顶点w出发，初始集合U={} int i, j, k = 0; int min; int n = arc.length; ShortEdge[] shortEdges = new ShortEdge[n];// 存储候选的边集合 for (i = 0; i &lt; n; i++) { shortEdges[i] = new ShortEdge(); } for (i = 0; i &lt; n; i++) {// 初始化辅助数组 shortEdges[i].setLowcost(arc[w][i]); shortEdges[i].setAdjvex(w); } shortEdges[w].setLowcost(0);// 将顶点w加入集合U for (i = 0; i &lt; n - 1; i++) { min = 1000;// 设权值不超过1000 for (j = 0; j &lt; n; j++) {// 寻找最短边的邻接点k if ((shortEdges[j].getLowcost() != 0) &amp;&amp; (shortEdges[j].getLowcost() &lt; min)) { min = shortEdges[j].getLowcost(); k = j; } } System.out.println(shortEdges[k].getAdjvex() + &quot;---&quot; + k);// 输出最小生成树的边 shortEdges[k].setLowcost(0);// 将顶点k加入集合U中 for (j = 0; j &lt; n; j++) {// 调整数组shortEdge[n] if (arc[k][j] &lt; shortEdges[j].getLowcost()) { shortEdges[j].setLowcost(arc[k][j]); shortEdges[j].setAdjvex(k); } } }} Kruskal算法（待解决） 1 背包问题 注意：不同于0/1背包问题，背包问题中的物品无需整个放入，可以只放一个物品的一部分 为了方便，默认物品是按照单位价值降序排列的 12345678910111213public static double KnapSack(int[] w, int[] v, int C) { double[] x = new double[w.length];// 记录物品装入的部分 int i; double maxValue = 0; for (i = 0; w[i] &lt; C; i++) { x[i] = 1; maxValue += v[i]; C = C - w[i]; } x[i] = (double) C / w[i]; maxValue += x[i] * v[i]; return maxValue;} 活动安排问题 将活动按照结束时间非降序排列 1234567891011121314151617181920public static int ActiveManage(int[] s, int[] f) { int i, j, count; int n = s.length; int[] B = new int[n]; B[0] = 1;// 安排活动1 j = 0; count = 1; for (i = 1; i &lt; n; i++) {// 依次考察每个活动 if (s[i] &gt;= f[j]) {// 活动i与集合B中最后结束的活动j相容 B[i] = 1;// 安排活动i j = i;// j是目前可以安排的最后一个活动 count++; } else { B[i] = 0; } } System.out.println(Arrays.toString(B)); return count;// 返回已经安排的活动数} 多机调度问题 将作业处理时间按非升序排列 123456789101112131415161718192021222324252627282930313233public static void MultiMachine(int[] t, int[] d) {// t存储n个作业的处理时间，d存储m台机器的已占用时间 int n = t.length, m = d.length;// m台机器，n个任务 int[][] S = new int[m][n];// S[i]存储机器i处理作业的队列，rear[i]为队尾下标 int[] rear = new int[m]; int i, j, k; for (i = 0; i &lt; m; i++) {// 初始化S for (j = 0; j &lt; n; j++) { S[i][j] = -1; } } for (i = 0; i &lt; m; i++) {// 安排前m个作业 S[i][0] = i; rear[i] = 0; d[i] = t[i]; } for (i = m; i &lt; n; i++) {// 依次安排余下的作业 for (j = 0, k = 1; k &lt; m; k++) {// 查找最先空闲的机器 if (d[k] &lt; d[j]) j = k; } rear[j]++; S[j][rear[j]] = i;// 将作业i插入队列S[j] d[j] = d[j] + t[i]; } for (i = 0; i &lt; m; i++) { System.out.println(&quot;机器&quot; + i + &quot;:&quot;); for (j = 0; S[i][j] &gt;= 0; j++) { System.out.println(&quot;---作业&quot; + S[i][j]); } }}","link":"/posts/31158/"},{"title":"算法学习——回溯","text":"回溯算法的经典算法，如素数环问题、哈密顿回路、N皇后问题等。 回溯 经典算法 素数环问题 将正整数1~n填入环中，满足如下条件： 每个数字只能用一次 相邻两个数字之和是素数，最后一个元素与第一个元素之和也为素数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public static void PrimeCircle(int n) { int i, k; int[] circle = new int[n];// 素数环 for (i = 0; i &lt; n; i++) {// 初始化为0 circle[i] = 0; } circle[0] = 1;// 第0个位置填1 k = 1; while (k &gt;= 1) { circle[k]++; while (circle[k] &lt;= n) { if (Check(circle, k))// 若位置k可以填写整数circle[k]则跳出内层循环 break; else// 否则试探下一个数 circle[k]++; } if (circle[k] &lt;= n &amp;&amp; k == n - 1) {// 若求解完毕则输出解，结束算法 for (int item : circle) { System.out.println(item); } return; } else if (circle[k] &lt;= n &amp;&amp; k &lt; n - 1)// 若未结束则填写下一个位置 k++; else{// 若每个数字都不能填入，则回溯 circle[k--] = 0; } }}public static boolean Check(int[] circle, int k) {// 判断第k个位置填写是否满足约束条件 boolean flag; for (int i = 0; i &lt; k; i++) { if (circle[i] == circle[k])// 判断是否重复 return false; } flag = Prime(circle[k] + circle[k - 1]);// 判断相邻数之和是否为素数 if (flag &amp;&amp; k == circle.length - 1) {// 判断第一个和最后一个数之和是否为素数 flag = Prime(circle[k] + circle[0]); } return flag;}public static boolean Prime(int x) {// 判断x是否为素数 int i, n; n = (int) Math.sqrt(x); for (i = 2; i &lt;= n; i++) { if (x % i == 0) return false; } return true;} 图着色问题 123456789101112131415161718192021222324252627282930313233public static void GraphColor(int[][] arc, int m) {// m种颜色 int i, k = 0; int n = arc.length; int[] color = new int[n]; for (i = 0; i &lt; n; i++) {// 初始化 color[i] = 0; } while (k &gt;= 0) { color[k]++;// 取下一种颜色 while (color[k] &lt;= m) { if (Ok(arc, color, k))// 若顶点k可以填入颜色color[k]则跳出内层循环 break; else// 否则试探下一种颜色 color[k]++; } if (color[k] &lt;= m &amp;&amp; k == n - 1) {// 若求解完毕，输出解 for (int item : color) { System.out.println(item); } return; } else if (color[k] &lt;= m &amp;&amp; k &lt; n - 1)// 若未结束，则填充下一个顶点 k++; else// 若每个颜色都不能填入，则回溯 color[k--] = 0; }}public static boolean Ok(int[][] arc, int[] color, int k) {// 判断顶点k的着色是否发生冲突 for (int i = 0; i &lt; k; i++) if (arc[k][i] == 1 &amp;&amp; color[i] == color[k]) return false; return true;} 哈密顿回路 1234567891011121314151617181920212223242526272829303132333435public static void Hamiton(int[][] arc) { int i, k; int n = arc.length; int[] visited = new int[n]; int[] x = new int[n];// 存储哈密顿回路经过的顶点 for (i = 0; i &lt; n; i++) { x[i] = 0; visited[i] = 0; } x[0] = 0; visited[0] = 1;// 从顶点0出发 k = 1; while (k &gt;= 1) { x[k]++; while (x[k] &lt; n) { if (visited[x[k]] == 0 &amp;&amp; arc[x[k - 1]][x[k]] == 1)// 顶点x[k]不在哈密顿回路上,且边(x[k-1],x[k])存在 break;// 则跳出内层循环 else// 否则试探下一个顶点 x[k]++; } if (x[k] &lt; n &amp;&amp; k == n - 1 &amp;&amp; arc[x[k]][0] == 1) {// 若已经形成哈密顿回路则输出结果 for (k = 0; k &lt; n; k++) System.out.println(x[k] + 1); return; } else if (x[k] &lt; n &amp;&amp; k &lt; n - 1) {// 若还未形成哈密顿回路则继续算法 visited[x[k]] = 1; k++; } else {// 否则取消x[k]顶点的访问标识，回溯 visited[x[k]] = 0; x[k] = 0; k--; visited[x[k]] = 0;// 此处是为了将回溯后的顶点，即x[k-1]恢复为未访问状态 } }} N皇后问题 1234567891011121314151617181920212223242526272829303132public static void Queen(int n) { int k = 0; int[] x = new int[n];// x[i]表示第i个皇后放在第i行的第x[i]列 for (int i = 0; i &lt; n; i++)// 初始化为-1 x[i] = -1; while (k &gt;= 0) {// 摆放皇后k x[k]++;// 在下一列摆放皇后k while (x[k] &lt; n &amp;&amp; Place(x, k)) {// 发生冲突 x[k]++; } if (x[k] &lt; n &amp;&amp; k == n - 1) {// 求解完成，输出 for (int i = 0; i &lt; n; i++) { System.out.println(x[i] + 1); } return; } else if (x[k] &lt; n &amp;&amp; k &lt; n - 1) {// 求解未完成，摆放下一个皇后 k++; } else {// 重置x[k]，回溯 x[k--] = -1; } } System.out.println(&quot;无解&quot;);}public static boolean Place(int[] x, int k) {// 判断放置是否冲突 for (int i = 0; i &lt; k; i++) { if (x[i] == x[k] || Math.abs(i - k) == Math.abs(x[i] - x[k])) {// 若在同一列或同一斜线 return true;// 返回冲突 } } return false;} 批处理作业调度问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static int BatchJob(int[] a, int[] b) {// a记录n个作业在机器1上所需时间，b记录n个作业在机器2上所需时间 int i, k; int n = a.length; int[] x = new int[n + 1];// 存储具体的作业调度，x[k]表示第k个作业的编号 int[] sum1 = new int[n + 1];// 存储机器1的完成时间 int[] sum2 = new int[n + 1];// 存储机器2的完成时间 int bestTime = 10000;// 假设时间不超过10000 for (i = 1; i &lt;= n; i++) { x[i] = -1; sum1[i] = 0; sum2[i] = 0; } sum1[0] = 0; sum2[0] = 0; k = 1; while (k &gt;= 1) { x[k]++;// 安排第k个作业，作业编号为x[k] while (x[k] &lt; n) { for (i = 1; i &lt; k; i++) {// 检测作业x[k]是否重复处理 if (x[i] == x[k]) { break; } } if (i == k) {// 作业x[k]还未处理 sum1[k] = sum1[k - 1] + a[x[k]]; sum2[k] = Math.max(sum1[k], sum2[k - 1]) + b[x[k]]; if (sum2[k] &lt;= bestTime)// 未超过目前最短时间则跳出内层循环 break; else// 否则剪枝 x[k]++; } else // 作业x[k]已经处理，则处理下一个作业 x[k]++; } if (x[k] &lt; n &amp;&amp; k &lt; n) { k++;// 安排下一个作业 } else { if (x[k] &lt; n &amp;&amp; k == n) { if (bestTime &gt;= sum2[k]) { bestTime = sum2[k]; System.out.println(&quot;目前最短作业安排是：&quot;); for (int j = 1; j &lt;= n; j++) System.out.println(x[j] + 1); System.out.println(&quot;最短时间是：&quot; + bestTime); } }else x[k--] = -1;// 重置x[k]，回溯 } } return bestTime;}","link":"/posts/8094/"},{"title":"算法练习——哈希表","text":"力扣，哈希表相关练习。 242. 有效的字母异位词（简单） 本题可以利用map来统计两个字符串出现过的字符数量，最后比较相同字母出现的次数是否全部相等即可。要注意的一点是，比较时一定要遍历较长的map，否则可能导致较短map对应的字符串中没有出现过的字符未得到判断。 12345678910111213141516171819bool isAnagram(string s, string t) { map&lt;char, int&gt; s_counter, t_counter; for (char c : s) { // 统计s字符串出现字母的数量 s_counter[c]++; } for (char c : t) { // 统计t字符串出现字母的数量 t_counter[c]++; } if (s_counter.size() &lt; t_counter.size()) // 为了遍历出现字母更多的map而交换 swap(s_counter, t_counter); for (auto begin = s_counter.cbegin(); begin != s_counter.cend(); begin++) { if (t_counter[begin-&gt;first] != begin-&gt;second) return false; } return true;} 349. 两个数组的交集（简单） 判断一个元素是否出现过，自然而然想到了用set来解决。由于没有顺序要求，所以使用unordered_set来省去排序的过程。 12345678910111213vector&lt;int&gt; intersection(vector&lt;int&gt; &amp;nums1, vector&lt;int&gt; &amp;nums2) { unordered_set&lt;int&gt; res; // 为了去重，结果暂时存放在set中 // 将nums1的数据存入一个set去重 unordered_set&lt;int&gt; nums_set(nums1.cbegin(), nums1.cend()); for (int num : nums2) { // 判断nums2中的数有没有在nums1中出现过 if (nums_set.find(num) != nums_set.cend()) { res.insert(num); } } return vector&lt;int&gt;(res.cbegin(), res.cend());} 202. 快乐数（简单） 本题有一个关键线索就是无限循环，表明非快乐数求每位数字的平方和时，这个平方和会重复出现。这时就又回到了判断元素是否重复的问题了，使用unordered_set来判断即可。 12345678910111213141516171819202122232425262728vector&lt;int&gt; getNums(int n) { // 获取数字的每一位 vector&lt;int&gt; nums; while (n != 0) { nums.push_back(n % 10); n /= 10; } return nums;}bool isHappy(int n) { unordered_set&lt;int&gt; sums; while (true) { vector&lt;int&gt; nums = getNums(n); int sum = 0; for (int num : nums) { sum += num * num; // 计算每一位数的平方和 } if (sum == 1) return true; if (sums.find(sum) != sums.cend()) return false; // 若和之前出现过，则为非快乐数 else { sums.insert(sum); n = sum; } }} 1. 两数之和（简单） 本题暴力解法当然可行，这也是这道题可以作为简单题出现的理由。但本题可以采用另一种角度来思考，想要找到当前数符合要求的另一个数字，可以试图找当前数与目标数的差值。这就将问题转换为了寻找某个元素是否出现过，自然而然的使用哈希表。但由于这里需要返回的是下标，所以不仅要记录值本身，还需要记录对应的下标，使用map最为合适。并且对key没有排序的要求，可以使用unordered_map来省去排序过程。 123456789101112vector&lt;int&gt; twoSum(vector&lt;int&gt; &amp;nums, int target) { unordered_map&lt;int, int&gt; record; // 记录出现过的数字和下标 for (int i = 0; i &lt; nums.size(); i++) { // 寻找目标数与当前数的差值是否出现过 auto iter = record.find(target - nums[i]); if (iter != record.cend()) { return {i, iter-&gt;second}; } record[nums[i]] = i; // 没有出现则将当前数记录下来 } return {};} 454. 四数相加II（中等） 这道题可以沿用两数之和的思想，将4个数组分为两组。从这两组的视角来看，他们就变成了两数之和，只不过目标值永远为0。先统计前两个数组中每对数之和，由于可能存在不同对的和相同的情况，所以需要记录下出现过的次数，这里使用unordered_map。然后再对后两个数组进行遍历，再map中查询0与每对数之和的差值是否出现过，若出现过则证明有四元组符合要求，而且符合要求的个数是map中所记录的个数。 12345678910111213141516171819int fourSumCount(vector&lt;int&gt; &amp;nums1, vector&lt;int&gt; &amp;nums2, vector&lt;int&gt; &amp;nums3, vector&lt;int&gt; &amp;nums4) { unordered_map&lt;int, int&gt; record; // 记录前两个数组出现过的和 for (int num1 : nums1) { for (int num2 : nums2) { record[num1 + num2]++; } } int count = 0; for (int num3 : nums3) { for (int num4 : nums4) { // 判断0与后两个数组出现的和的差值是否出现过 if (record.find(0 - (num3 + num4)) != record.cend()) { count += record[0 - (num3 + num4)]; } } } return count;} 383. 赎金信（简单） 本题还是判断元素是否存在的问题，但本题中涉及重复元素，可以使用multiset。遍历magazine字符串，将出现过的字符都存入multiset中。然后遍历ransomNote，将出现过的字符一一从multiset中去掉，一旦发现multiset中没有的字符，则证明ransomNote无法由maganize中的字符构成。 12345678910111213bool canConstruct(string ransomNote, string magazine) { multiset&lt;char&gt; record(magazine.cbegin(), magazine.cend()); for (char c : ransomNote) { auto iter = record.find(c); if (iter != record.cend()) { record.erase(iter); } else { return false; } } return true;} 但本题有一个很重要的条件，两个字符串都只由小写字母构成，这意味着只会有26种字符。此时可以使用一个长度为26的数组来记录每个字符出现的次数，从而省去multiset的各种操作，毕竟底层是红黑树，操作代价比较大。 12345678910111213141516bool canConstruct(string ransomNote, string magazine) { vector&lt;int&gt; record(26, 0); if (ransomNote.size() &gt; magazine.size()) return false; for (char c : magazine) { record[c - 'a']++; } for (char c : ransomNote) { record[c - 'a']--; if (record[c - 'a'] &lt; 0) return false; } return true;} 15. 三数之和（中等） 本题可以沿用两数之和的思路，用一个双层for循环来确定三元组前两个元素的值，然后再判断0与前两个值的差值是否在数组里出现过即可。但题目中有一个关键的要求是，不允许包含重复的三元组，所以涉及到一系列的去重操作。 1234567891011121314151617181920212223242526272829303132vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt; &amp;nums) { vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size(); i++) { // 若排序之后的第一个元素已经大于0，则不可能有满足条件的三元组 if (nums[i] &gt; 0) break; // 三元组第一个元素去重 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; unordered_set&lt;int&gt; record; for (int j = i + 1; j &lt; nums.size(); j++) { // 三元组第二个元素去重 if (j &gt; i + 2 &amp;&amp; nums[j] == nums[j - 1] &amp;&amp; nums[j - 1] == nums[j - 2]) continue; int c = 0 - (nums[i] + nums[j]); if (record.find(c) != record.cend()) { res.push_back({nums[i], nums[j], c}); // 三元组第三个元素去重 record.erase(c); } else { record.insert(nums[j]); } } } return res;} 这样的解法不仅要考虑复杂的去重问题，还无法有效的剪枝，所以耗时非常严重。 本题可以采用另一个解法，同样先将数组排序。然后定义三个指针，第一个指针i从0开始遍历数组，第二个指针left指向i+1位置，第三个指针right指向数组的最后一个元素。 当nums[i] + nums[left] + nums[right] &gt; 0时，说明三数之和大了，由于数组已经排序，所以必须让right向左移动，使三数之和变小。 当nums[i] + nums[left] + nums[right] &lt; 0时，说明三数之和小了，必须让left向右移动，使三数之和变大。 直到left和right相邻。 12345678910111213141516171819202122232425262728293031323334353637vector&lt;vector&lt;int&gt;&gt; threeSum2(vector&lt;int&gt; &amp;nums) { vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size(); i++) { if (nums[i] &gt; 0) break; // 三元组第一个元素去重 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; int left = i + 1; int right = nums.size() - 1; while (left &lt; right) { int sum = nums[i] + nums[left] + nums[right]; if (sum &gt; 0) right--; else if (sum &lt; 0) left++; else { res.push_back({nums[i], nums[left], nums[right]}); // 三元组第二个元素去重 while (left &lt; right &amp;&amp; nums[right] == nums[right - 1]) right--; // 三元组第三个元素去重 while (left &lt; right &amp;&amp; nums[left] == nums[left + 1]) left++; // 找到符合条件的三元组后两个指针同时收缩 left++; right--; } } } return res;} 本题的关键就在于去重。关于nums[i]的去重，如果nums[i]重复了，则应该直接跳过，因为它是最外层的循环。但问题的关键是判断重复的条件应该是nums[i] == nums[i - 1]还是nums[i] == nums[i + 1]。如果是nums[i] == nums[i + 1]则是判断当前数与下一个数是否相等，这样会导致三元组本身存在重复数字的情况被直接排除，例如{-1, -1, 2}。所以应该使用nums[i] == nums[i - 1]来判断第一个元素的去重。 18. 四数之和（中等） 本题沿用三数之和多指针解法的思路即可，但要注意几个点。三数之和用最外层循环来固定三元组的第一个元素，这里的四数之和就需要两层循环来固定四元组的前两个元素。 第一层循环剪枝的时候，不能像三数之和那样简单判断nums[i] &gt; target就剪枝，例如-4 &gt; -10这种情况不可以被剪掉。所以需要附加一个nums[i] &gt;= 0的条件，此时才能剪枝。 第二层循环还可以进行剪枝，与第一层同理，不能简单判断nums[i] + nums[j] &gt; target就剪枝，需要nums[i] + nums[j] &gt;= 0的情况才能剪枝。 一旦固定前两个元素，后续的思路和三数之和就一模一样了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748vector&lt;vector&lt;int&gt;&gt; fourSum(vector&lt;int&gt; &amp;nums, int target) { vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size(); i++) { // 第一层剪枝，但不能简单的因为nums[i] &gt; target就剪枝 if (nums[i] &gt; target &amp;&amp; nums[i] &gt;= 0) break; // 对四元组第一个元素去重 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; for (int j = i + 1; j &lt; nums.size(); j++) { // 第二层剪枝，条件判断与第一层同理 if (nums[i] + nums[j] &gt; target &amp;&amp; nums[i] + nums[j] &gt;= 0) break; // 对四元组第二个元素去重 if (j &gt; i + 1 &amp;&amp; nums[j] == nums[j - 1]) continue; int left = j + 1; int right = nums.size() - 1; while (left &lt; right) { // 用long类型防止溢出 long sum = (long)nums[i] + nums[j] + nums[left] + nums[right]; if (sum &gt; target) right--; else if (sum &lt; target) left++; else { res.push_back({nums[i], nums[j], nums[left], nums[right]}); // 对四元组第三个元素去重 while (left &lt; right &amp;&amp; nums[right] == nums[right - 1]) right--; // 对四元组第四个元素去重 while (left &lt; right &amp;&amp; nums[left] == nums[left + 1]) left++; left++; right--; } } } } return res;}","link":"/posts/51387/"},{"title":"算法练习——二叉树","text":"力扣，二叉树相关练习。 二叉树的遍历 144. 二叉树的前序遍历（简单） 递归方式 12345678910111213void preOrder(TreeNode *node, vector&lt;int&gt; &amp;res) { if (node != nullptr) { res.push_back(node-&gt;val); preOrder(node-&gt;left, res); preOrder(node-&gt;right, res); }}vector&lt;int&gt; preorderTraversal(TreeNode *root) { vector&lt;int&gt; res; preOrder(root, res); return res;} 迭代方式 123456789101112131415161718192021vector&lt;int&gt; preorderTraversal2(TreeNode *root) { stack&lt;TreeNode *&gt; st; vector&lt;int&gt; res; if (root == nullptr) return res; st.push(root); while (!st.empty()) { // 栈顶元素即为中间结点 TreeNode *node = st.top(); st.pop(); res.push_back(node-&gt;val); // 中 // 要使出栈顺序是中左右，则必须先将右孩子入栈 if (node-&gt;right) st.push(node-&gt;right); // 右 if (node-&gt;left) st.push(node-&gt;left); // 左 } return res;} 统一迭代方式 123456789101112131415161718192021222324252627vector&lt;int&gt; preorderTraversal3(TreeNode *root) { stack&lt;TreeNode *&gt; st; vector&lt;int&gt; res; if (root != nullptr) st.push(root); while (!st.empty()) { TreeNode *node = st.top(); if (node != nullptr) { st.pop(); // 弹出当前结点避免重复操作 if (node-&gt;right) st.push(node-&gt;right); // 右 if (node-&gt;left) st.push(node-&gt;left); // 左 st.push(node); // 中 st.push(nullptr); } else { st.pop(); node = st.top(); st.pop(); res.push_back(node-&gt;val); } } return res;} 94. 二叉树的中序遍历（简单） 递归方式 12345678910111213void inOrder(TreeNode *node, vector&lt;int&gt; &amp;res) { if (node != nullptr) { inOrder(node-&gt;left, res); res.push_back(node-&gt;val); inOrder(node-&gt;right, res); }}vector&lt;int&gt; inorderTraversal(TreeNode *root) { vector&lt;int&gt; res; inOrder(root, res); return res;} 迭代方式 123456789101112131415161718192021vector&lt;int&gt; inorderTraversal2(TreeNode *root) { stack&lt;TreeNode *&gt; st; vector&lt;int&gt; res; TreeNode *cur = root; while (cur != nullptr || !st.empty()) { if (cur != nullptr) { // 一直遍历到树的最左下角结点 st.push(cur); cur = cur-&gt;left; // 左 } else { // 栈顶元素为待处理的结点 cur = st.top(); st.pop(); res.push_back(cur-&gt;val); // 中 cur = cur-&gt;right; // 右 } } return res;} 统一迭代方式 123456789101112131415161718192021222324252627vector&lt;int&gt; inorderTraversal3(TreeNode *root) { stack&lt;TreeNode *&gt; st; vector&lt;int&gt; res; if (root != nullptr) st.push(root); while (!st.empty()) { TreeNode *node = st.top(); if (node != nullptr) { st.pop(); // 弹出当前结点避免重复操作 if (node-&gt;right) st.push(node-&gt;right); // 右 st.push(node); // 中 st.push(nullptr); // 中间结点访问过但还未处理，加入nullptr作为标记 if (node-&gt;left) st.push(node-&gt;left); // 左 } else { // 遇到nullptr才将下一个结点放入结果集中 st.pop(); // 弹出空结点 node = st.top(); // 取出栈中元素 st.pop(); res.push_back(node-&gt;val); // 加入结果集 } } return res;} 145. 二叉树的后序遍历（简单） 递归方式 12345678910111213void postOrder(TreeNode *node, vector&lt;int&gt; &amp;res) { if (node != nullptr) { postOrder(node-&gt;left, res); postOrder(node-&gt;right, res); res.push_back(node-&gt;val); }}vector&lt;int&gt; postorderTraversal(TreeNode *root) { vector&lt;int&gt; res; postOrder(root, res); return res;} 迭代方式 123456789101112131415161718192021222324vector&lt;int&gt; postorderTraversal2(TreeNode *root) { stack&lt;TreeNode *&gt; st; vector&lt;int&gt; res; // 大部分与前序遍历相同 if (root == nullptr) return res; st.push(root); while (!st.empty()) { TreeNode *node = st.top(); st.pop(); res.push_back(node-&gt;val); // 中 // 这里颠倒左右结点入栈顺序 // 使遍历顺序变为中右左 if (node-&gt;left) st.push(node-&gt;left); // 左 if (node-&gt;right) st.push(node-&gt;right); // 右 } // 反转遍历结果，变为左右中 reverse(res.begin(), res.end()); return res;} 统一迭代方式 123456789101112131415161718192021222324252627vector&lt;int&gt; postorderTraversal3(TreeNode *root) { stack&lt;TreeNode *&gt; st; vector&lt;int&gt; res; if (root != nullptr) st.push(root); while (!st.empty()) { TreeNode *node = st.top(); if (node != nullptr) { st.pop(); st.push(node); // 中 st.push(nullptr); if (node-&gt;right) st.push(node-&gt;right); // 右 if (node-&gt;left) st.push(node-&gt;left); // 左 } else { st.pop(); node = st.top(); st.pop(); res.push_back(node-&gt;val); } } return res;} 102. 二叉树的层序遍历（中等） 递归方式 12345678910111213141516void order(TreeNode *node, vector&lt;vector&lt;int&gt;&gt; &amp;res, int depth) { if (node == nullptr) return; if (res.size() == depth) res.push_back(vector&lt;int&gt;()); res[depth].push_back(node-&gt;val); order(node-&gt;left, res, depth + 1); order(node-&gt;right, res, depth + 1);}vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode *root) { vector&lt;vector&lt;int&gt;&gt; res; int depth = 0; order(root, res, depth); return res;} 迭代方式 12345678910111213141516171819202122232425vector&lt;vector&lt;int&gt;&gt; levelOrder2(TreeNode *root) { queue&lt;TreeNode *&gt; q; vector&lt;vector&lt;int&gt;&gt; res; if (root == nullptr) return res; q.push(root); while (!q.empty()) { // 记录当前队列大小，即当前层的结点数 int size = q.size(); vector&lt;int&gt; vec; for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); vec.push_back(node-&gt;val); // 遍历本层结点 if (node-&gt;left) q.push(node-&gt;left); // 左子结点入队 if (node-&gt;right) q.push(node-&gt;right); // 右子结点入队 } res.push_back(vec); // 将当前层加入结果集 } return res;} 层序遍历衍生题目 107. 二叉树的层序遍历 II（中等） 正常将二叉树层序遍历，最后将遍历结果数组逆置即可。 12345678910111213141516171819202122232425vector&lt;vector&lt;int&gt;&gt; levelOrderBottom(TreeNode *root) { vector&lt;vector&lt;int&gt;&gt; res; queue&lt;TreeNode *&gt; q; if (root == nullptr) return res; q.push(root); while (!q.empty()) { int size = q.size(); vector&lt;int&gt; vec; for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); vec.push_back(node-&gt;val); if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } res.push_back(vec); } reverse(res.begin(), res.end()); return res;} 199. 二叉树的右视图（中等） 层序遍历二叉树时，判断当前元素是否为本层最后一个元素，若是则放入结果集。 1234567891011121314151617181920212223vector&lt;int&gt; rightSideView(TreeNode *root) { vector&lt;int&gt; res; queue&lt;TreeNode *&gt; q; if (root == nullptr) return res; q.push(root); while (!q.empty()) { int size = q.size(); for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); if (i == size - 1) res.push_back(node-&gt;val); } } return res;} 637. 二叉树的层平均值（简单） 在层序遍历的同时，计算出每层结点的和，遍历完当前层后将该层的平均值放入结果集。 123456789101112131415161718192021222324vector&lt;double&gt; averageOfLevels(TreeNode *root) { vector&lt;double&gt; res; queue&lt;TreeNode *&gt; q; if (root == nullptr) return res; q.push(root); while (!q.empty()) { int size = q.size(); double sum = 0.0; for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); sum += node-&gt;val; if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } res.push_back(sum / size); } return res;} 429. N 叉树的层序遍历（中等） 与二叉树层序遍历类似，只需要在遍历当前结点的孩子结点时改为for循环，以保证遍历到该结点的每一个孩子节点。 1234567891011121314151617181920212223vector&lt;vector&lt;int&gt;&gt; levelOrder(Node *root) { vector&lt;vector&lt;int&gt;&gt; res; queue&lt;Node *&gt; q; if (root == nullptr) return res; q.push(root); while (!q.empty()) { int size = q.size(); vector&lt;int&gt; vec; for (int i = 0; i &lt; size; i++) { Node *node = q.front(); q.pop(); vec.push_back(node-&gt;val); for (Node *child : node-&gt;children) { q.push(child); } } res.push_back(vec); } return res;} 515. 在每个树行中找最大值（中等） 层序遍历二叉树的过程中，找出每层的最大值放入结果集即可。 12345678910111213141516171819202122232425vector&lt;int&gt; largestValues(TreeNode *root) { vector&lt;int&gt; res; queue&lt;TreeNode *&gt; q; if (root == nullptr) return res; q.push(root); while (!q.empty()) { int size = q.size(); int max = INT_MIN; for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); if (node-&gt;val &gt; max) max = node-&gt;val; if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } res.push_back(max); } return res;} 116. 填充每个节点的下一个右侧节点指针（中等） 层序遍历过程中，判断当前遍历结点在本层是否有后继结点，若有则将next指向它的后继结点，若没有则置为null。 123456789101112131415161718192021222324Node *connect(Node *root) { queue&lt;Node *&gt; q; if (root == nullptr) return nullptr; q.push(root); while (!q.empty()) { int size = q.size(); for (int i = 0; i &lt; size; i++) { Node *node = q.front(); q.pop(); if (i &lt; size - 1) node-&gt;next = q.front(); else node-&gt;next = nullptr; if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } } return root;} 117. 填充每个节点的下一个右侧节点指针 II（中等） 与116. 填充每个节点的下一个右侧节点指针题没有任何差别。 123456789101112131415161718192021222324Node *connect(Node *root) { queue&lt;Node *&gt; q; if (root == nullptr) return nullptr; q.push(root); while (!q.empty()) { int size = q.size(); for (int i = 0; i &lt; size; i++) { Node *node = q.front(); q.pop(); if (i &lt; size - 1) node-&gt;next = q.front(); else node-&gt;next = nullptr; if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } } return root;} 104. 二叉树的最大深度（简单） 利用层序遍历，没遍历一层深度就加一。 12345678910111213141516171819202122int maxDepth(TreeNode *root) { int depth = 0; queue&lt;TreeNode *&gt; q; if (root == nullptr) return depth; q.push(root); while (!q.empty()) { int size = q.size(); depth++; for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } } return depth;} 111. 二叉树的最小深度（简单） 同样利用层序遍历，当碰到的第一个叶结点所属的层数就是最小深度。 123456789101112131415161718192021222324int minDepth(TreeNode *root) { int depth = 0; queue&lt;TreeNode *&gt; q; if (root == nullptr) return depth; q.push(root); while (!q.empty()) { int size = q.size(); depth++; for (int i = 0; i &lt; size; i++) { TreeNode *node = q.front(); q.pop(); if (node-&gt;left == nullptr &amp;&amp; node-&gt;right == nullptr) return depth; if (node-&gt;left) q.push(node-&gt;left); if (node-&gt;right) q.push(node-&gt;right); } } return depth;} 二叉树练习 226. 翻转二叉树（简单） 递归的将每个结点的左右孩子都互换即可完成对整个树的翻转。 值得注意的是，本题可以用前序或后序遍历，但不可以使用中序遍历，因为中序遍历先将左孩子的孩子调换，再将根节点孩子调换，最后再调换右孩子时，其实调换的是原来的左孩子。 12345678TreeNode *invertTree(TreeNode *root) { if (root == nullptr) return root; swap(root-&gt;left, root-&gt;right); invertTree(root-&gt;left); invertTree(root-&gt;right); return root;} 也可以用迭代法来解决。 1234567891011121314151617TreeNode *invertTree2(TreeNode *root) { if (root == nullptr) return root; stack&lt;TreeNode *&gt; st; st.push(root); while (!st.empty()) { TreeNode *node = st.top(); st.pop(); swap(node-&gt;left, node-&gt;right); if (node-&gt;right) st.push(node-&gt;right); if (node-&gt;left) st.push(node-&gt;left); } return root;} 101. 对称二叉树（简单） 本题的关键是想明白要比较的是什么，对称的二叉树本质上是根结点的左子树和右子树拥有相互翻转关系。所以要比较的是两棵树，在递归遍历的过程中要同时遍历两颗树。左子树需要通过左右中的顺序来遍历，右子树需要通过右左中的顺序来遍历，都可以算是后序遍历。 12345678910111213141516171819bool compare(TreeNode *left, TreeNode *right) { // 首先排除存在空结点的情况 if (left == nullptr &amp;&amp; right != nullptr) // 左空右不空 return false; else if (left != nullptr &amp;&amp; right == nullptr) // 左不空右空 return false; else if (left == nullptr &amp;&amp; right == nullptr) // 左右都空 return true; // 再排除数值不同的情况 else if (left-&gt;val != right-&gt;val) // 左右都不空，但值不相等 return false; // 此时剩下的就是左右结点都不空，且数值相同的情况 bool outside = compare(left-&gt;left, right-&gt;right); // 左子树：左、右子树：右 bool inside = compare(left-&gt;right, right-&gt;left); // 左子树：右、右子树：左 return outside &amp;&amp; inside; // 左子树：中、右子树：中}bool isSymmetric(TreeNode *root) { return compare(root-&gt;left, root-&gt;right); } 也可以用迭代法解决，但迭代方式和前中后序遍历的任何一种都不同。在迭代过程中要将两个待比较的结点入队，然后从队列中成对的取出进行比较。 123456789101112131415161718192021222324252627bool isSymmetric2(TreeNode *root) { queue&lt;TreeNode *&gt; q; q.push(root-&gt;left); // 左子树头结点入队 q.push(root-&gt;right); // 右子树头结点入队 while (!q.empty()) { TreeNode *leftNode = q.front(); q.pop(); TreeNode *rightNode = q.front(); q.pop(); // 左右子树都空 if (leftNode == nullptr &amp;&amp; rightNode == nullptr) continue; // 左右子树有一个不空，或都不为空但值不相等 if (leftNode == nullptr || rightNode == nullptr || leftNode-&gt;val != rightNode-&gt;val) return false; q.push(leftNode-&gt;left); // 左结点的左孩子 q.push(rightNode-&gt;right); // 右结点的右孩子 q.push(leftNode-&gt;right); // 左结点的右孩子 q.push(rightNode-&gt;left); // 右结点的左孩子 } return true;} 222. 完全二叉树的节点个数（简单） 本题用遍历的方法很简单就可以解决，但由于完全二叉树的特性，可以使用更低的复杂度来解决。 完全二叉树有两种情况，一种是满二叉树，一种是最后一层叶子结点未满。对于满二叉树，结点个数就是\\(2^n-1\\)，\\(n\\)为树的深度。对于未满的二叉树，分别递归左孩子和右孩子，递归到一定深度一定会有满二叉树，可以用满二叉树的公式来计算。 12345678910111213141516171819int countNodes(TreeNode *root) { if (root == nullptr) return 0; TreeNode *left = root-&gt;left; TreeNode *right = root-&gt;right; int leftDepth = 0, rightDepth = 0; while (left != nullptr) { // 求左子树深度 left = left-&gt;left; leftDepth++; } while (right != nullptr) { // 求右子树深度 right = right-&gt;right; rightDepth++; } if (leftDepth == rightDepth) // 满二叉树的情况 return (2 &lt;&lt; leftDepth) - 1; // 叶子结点未满的情况 return countNodes(root-&gt;left) + countNodes(root-&gt;right) + 1;} 110. 平衡二叉树（简单） 判断是否为平衡二叉树只需要判断左右子树的高度差是否不大于1，所以需要一个函数来求得树的高度。求高度可以用递归的方式，一层一层求下去。递归函数的返回值自然是树的高度。终止条件就是遇到空结点，空结点的高度为0。单层递归的主要逻辑就是判断左右子树高度差，如果此时左右子树有一个不是平衡二叉树，那么就可以直接返回-1作为标记，不必再返回高度了。若左右子树高度差不大于1，则返回较高子树的高度+1，加1将当前结点的高度也计算进去。 123456789101112131415161718int getHeight(TreeNode *node) { if (node == nullptr) return 0; // 左右子树任何一个不是平衡二叉树就直接返回-1 int leftHeight = getHeight(node-&gt;left); if (leftHeight == -1) return -1; int rightHeight = getHeight(node-&gt;right); if (rightHeight == -1) return -1; // 左右子树高度差大于1则返回-1 // 不大于1则返回较高子树高度+1 return abs(leftHeight - rightHeight) &gt; 1 ? -1 : 1 + max(leftHeight, rightHeight);}bool isBalanced(TreeNode *root) { return getHeight(root) == -1 ? false : true; } 257. 二叉树的所有路径（简单） 本题强烈的体现了回溯的思想，需要一个递归的函数来寻找路径。递归终止条件是当前结点为叶子结点，此时就需要生成根节点到这个叶结点的路径并存入结果集中。单层递归的逻辑就是访问当前结点的左孩子和右孩子，访问完之后，也就是递归函数返回之后，需要将上一个访问的结点从路径中去除，这就是回溯的过程。 123456789101112131415161718192021222324252627282930313233void traversal(TreeNode *node, vector&lt;int&gt; &amp;path, vector&lt;string&gt; &amp;res) { path.push_back(node-&gt;val); // 当前结点的值存入path数组 // 碰到叶子结点 if (node-&gt;left == nullptr &amp;&amp; node-&gt;right == nullptr) { string sPath; for (int i = 0; i &lt; path.size() - 1; i++) { sPath += to_string(path[i]); sPath += &quot;-&gt;&quot;; } sPath += to_string(path[path.size() - 1]); res.push_back(sPath); return; } // 处理左子树 if (node-&gt;left != nullptr) { traversal(node-&gt;left, path, res); path.pop_back(); // 回溯 } // 处理右子树 if (node-&gt;right != nullptr) { traversal(node-&gt;right, path, res); path.pop_back(); // 回溯 }}vector&lt;string&gt; binaryTreePaths(TreeNode *root) { vector&lt;string&gt; res; vector&lt;int&gt; path; if (root == nullptr) return res; traversal(root, path, res); return res;}","link":"/posts/41828/"},{"title":"算法练习——数组","text":"力扣，数组相关练习。 704. 二分查找（简单） 二分查找中，最需要注意的一点就是循环过程中范围的变化。要将范围区间确定下来，左闭右闭区间或左闭右开区间都可以，但要保证每次循环确定区间的一致性。 以左闭右闭区间为例，每次寻找的范围必须是[begin, end]，此时要考虑begin == end时有没有意义。显然，对于左闭右闭区间，begin == end时，当前区间内还有一个元素，所以是有意义的。故可以得出循环条件应该保持begin &lt;= end。 更新区间的时候要注意，当目标值小于中间位置元素时，要将end更新为middle - 1，因为是右闭区间，所以不能让更新后的区间右侧包含刚才已经比较过的元素。同理，当目标值大于中间位置元素时，要将begin更新为middle + 1。故可以得出更新的条件为begin = middle + 1与end = middle - 1。 其中的middle可以通过(end - begin) / 2 + begin得到，这是随机访问数据结构中常用的确定中点的方式。 123456789101112131415int search(vector&lt;int&gt; &amp;nums, int target){ int begin = 0, end = nums.size() - 1; while (begin &lt;= end) { int middle = (end - begin) / 2 + begin; if (target == nums[middle]) return middle; else if (target &lt; nums[middle]) end = middle - 1; else begin = middle + 1; } return -1;} 而以左闭右开区间为例，每次寻找的范围是[begin, end)。这种情况下，当begin == end时区间是没有意义的，所以循环条件应为begin &lt; end。 更新区间时，也要保证更新后的区间不包含之前比较过的元素，同时保证区间有意义。当目标值小于中间位置元素时，更新end = middle，由于是右开区间，所以更新后的end位置元素不会参与比较。当目标值大于中间位置元素时，更新begin = middle + 1，因为更新之前的middle位置元素已经被比较过了。 123456789101112131415int search(vector&lt;int&gt; &amp;nums, int target){ int begin = 0, end = nums.size(); while (begin &lt; end) { int middle = (end - begin) / 2 + begin; if (target == nums[middle]) return middle; else if (target &lt; nums[middle]) end = middle; else begin = middle + 1; } return -1;} 27. 移除元素（简单） 本题的核心思想就是用后面的元素覆盖前面等于目标值的元素。 暴力法是容易想到的，使用两层for循环，第一层遍历整个数组，第二层更新数组。注意在更新数组后，要将当前的下标前移一位，因为后续的所以元素都向前移动了一位。同时注意循环次数的控制，当新数组长度减少后，相应地，循环次数也应该减少。 123456789101112131415int removeElement(vector&lt;int&gt; &amp;nums, int val){ int size = nums.size(); for (int i = 0; i &lt; size; ++i) // 利用size而不是nums.size()控制循环次数 { if (nums[i] == val) { for (int j = i + 1; j &lt; size; j++) nums[j - 1] = nums[j]; --i; // 注意此处的下标前移 --size; // 每次遇到满足条件的元素都要将最终返回的数组长度减1 } } return size;} 更巧妙的方法是双指针法，也叫快慢指针法。核心思想是要找到快慢指针分别代表的意义。 快指针将寻找不等于目标值的元素，也即新数组的元素。 慢指针指向待更新元素。 12345678int removeElement(vector&lt;int&gt; &amp;nums, int val){ int slowIndex = 0; for (int fastIndex = 0; fastIndex &lt; nums.size(); fastIndex++) if (nums[fastIndex] != val) // 快指针碰到不满足条件的值 nums[slowIndex++] = nums[fastIndex]; // 将该元素覆盖到慢指针指向的待更新，并将慢指针向前移动 return slowIndex; // 最终慢指针指向的就是数组尾后位置} 977. 有序数组的平方（简单） 本题同样可以采用双指针的方法，但需要转变一下思路。一开始的时候容易想到先找到绝对值最小的元素，然后两个指针向两边移动。但可以反过来想一想，双指针从数组的两端开始往中间移动，自然的就能依次找到绝对值从大到小的元素。 故使用两个指针，一个指向数组首元素，一个指向数组尾元素。再定义一个与原数组大小相等的结果数组，由于要求结果是非降序排列，故从结果数组的末尾开始，依次向前放置元素的平方。 1234567891011121314151617181920vector&lt;int&gt; sortedSquares(vector&lt;int&gt; &amp;nums){ int k = nums.size() - 1; vector&lt;int&gt; res(nums.size(), 0); int i = 0, j = nums.size() - 1; while (i &lt;= j) { if (nums[i] * nums[i] &lt; nums[j] * nums[j]) { res[k--] = nums[j] * nums[j]; --j; } else { res[k--] = nums[i] * nums[i]; ++i; } } return res;} 209. 长度最小的子数组（中等） 该题利用滑动窗口解决，即设定两个指针left和right，当窗口内的元素和小于target时，将right往右移动扩大窗口，继续判断，当窗口内元素和大于等于target时，则说明找到了一个答案，此时记录下窗口大小，然后将left向右移动，即将窗口的左侧缩小一个元素，若此时不满足，就继续右移right，并继续循环判断。 12345678910111213141516171819int minSubArrayLen(int target, vector&lt;int&gt; &amp;nums) { int slow = 0, fast = 0; int sum = 0; int minlen = INT32_MAX; for (; fast &lt; nums.size(); fast++) { sum += nums[fast]; // 滑动窗口不断扩大，并将加入窗口的元素累加到sum中 while (sum &gt;= target) { // 当窗口中的元素和满足条件后 if ((fast - slow + 1) &lt; minlen) minlen = fast - slow + 1; // 记录当前滑动窗口的大小 sum -= nums[slow]; // 将滑动窗口的左侧缩小一个元素 slow++; } } if (minlen == INT32_MAX) return 0; else return minlen;} 59. 螺旋矩阵 II（中等） 该题的解法就是模拟旋转的过程，最重要的一点就是保持循环过程中，所控制的区间不变。这里采取左闭右开的模式比较合理，即每一行或每一列的最后一个元素，交给拐弯后的循环去控制。 123456789101112131415161718192021222324252627282930313233vector&lt;vector&lt;int&gt;&gt; generateMatrix(int n) { int start_row = 0, start_col = 0; // 记录起始行和列 vector&lt;vector&lt;int&gt;&gt; res(n, vector&lt;int&gt;(n, 0)); int loop = n / 2; // 计算所需的圈数 int offset = 1; // 控制每次遍历的长度，即末端已经处理过的数据宽度 int count = 1; // 用于计数和赋值 int i, j; while (loop--) { for (j = start_col; j &lt; n - offset; j++) { // 向右移动 res[start_row][j] = count++; } for (i = start_row; i &lt; n - offset; i++) { // 向下移动 res[i][j] = count++; } for (; j &gt; start_col; j--) { // 向左移动 res[i][j] = count++; } for (; i &gt; start_row; i--) { // 向上移动 res[i][j] = count++; } start_row++; // 起始行加一 start_col++; // 起始列加一 offset++; // 已经处理过的数据宽度加一 } if (n % 2) { // 若n为奇数，则存在独立的中心点 int mid = n / 2; res[mid][mid] = count; // 单独赋值 } return res;}","link":"/posts/56699/"},{"title":"算法练习——字符串","text":"力扣，字符串相关练习。 344. 反转字符串（简单） 简简单单的数组原地逆置，不多解释。 12345678910void reverseString(vector&lt;char&gt; &amp;s) { int left = 0, right = s.size() - 1; while (left &lt; right) { char temp = s[left]; s[left] = s[right]; s[right] = temp; left++; right--; }} 当然还可以用异或运算实现逆置 12345678910111213void reverseString2(vector&lt;char&gt; &amp;s) { int left = 0, right = s.size() - 1; while (left &lt; right) { // 构造 a ^ b 的结果，并放在 a 中 s[left] ^= s[right]; // 将 a ^ b 这一结果再 ^ b ，存入b中，此时 b = a, a = a ^ b s[right] ^= s[left]; // a ^ b 的结果再 ^ a ，存入 a 中，此时 b = a, a = b 完成交换 s[left] ^= s[right]; left++; right--; }} 541. 反转字符串 II（简单） 本题是以2 * k为一个单位进行反转的，每够2k个字符就将前k个字符反转。所以在遍历字符的时候就能够以2k为步长，只需要每次判断剩余字符的个数即可。由于2k个字符的情况与小于2k但大于k个字符的情况相同，均为反转前k个字符，所以可以将这两种情况共同处理。小于k个字符的情况单独处理。 123456789101112131415161718192021void reverse(string &amp;s, int start, int end) { for (int i = start, j = end; i &lt; j; i++, j--) { char temp = s[i]; s[i] = s[j]; s[j] = temp; }}string reverseStr(string s, int k) { // for循环一次前进2k个字符 for (int i = 0; i &lt; s.size(); i += (2 * k)) { // 若剩余字符小于2k但大于k个，则反转前k个 if (i + k &lt;= s.size()) { reverse(s, i, i + k - 1); continue; } // 剩余字符少于k个，则将剩余字符全部反转 reverse(s, i, s.size() - 1); } return s;} 卡码54. 替换数字 本题使用额外的辅助空间会非常简单，只要遍历字符串，碰到字母就原封不动添加到新字符串中，碰到数字就向新字符串中添加字符串number。 123456789101112string replaceNumber(string s) { string res = &quot;&quot;; for (int i = 0; i &lt; s.size(); i++) { if (s[i] &gt;= 'a' &amp;&amp; s[i] &lt;= 'z') { res += s[i]; } else { res += &quot;number&quot;; } } return res;} 但进一步思考，若不借助额外的空间呢。可以先将原先的字符串扩充到替换数字后的大小，由于要将数字替换为长度为6的number字符串，所以每有一个数字，结果字符串长度就会增加5。 然后使用双指针法，指针left指向原字符串的最后一个字符，指针right指向扩充后的字符串的最后一个位置。然后同时向前遍历，若left指向的是字母，则原封不动拷贝。若left指向数字，则right指针向左移动6次，分别将number填充。 这里采用从后向前的方式，可以避免每次将后续字符向后拷贝，降低了时间复杂度。 12345678910111213141516171819202122232425262728293031string replaceNumber(string s) { int count = 0; // 统计数字的个数 for (int i = 0; i &lt; s.size(); i++) { if (s[i] &gt;= '0' &amp;&amp; s[i] &lt;= '9') count++; } // 扩充之前将原字符串的长度记录下来 int left = s.size() - 1; // 扩充原字符串 s.resize(s.size() + 5 * count); int right = s.size() - 1; while (left &gt;= 0 &amp;&amp; right &gt;= 0) { if (s[left] &gt;= '0' &amp;&amp; s[left] &lt;= '9') { s[right] = 'r'; s[right - 1] = 'e'; s[right - 2] = 'b'; s[right - 3] = 'm'; s[right - 4] = 'u'; s[right - 5] = 'n'; right -= 6; } else { s[right] = s[left]; right--; } left--; } return s;} 151. 反转字符串中的单词（中等） 本题建议使用O(1)的空间复杂度解，所以就只能原地想办法。该题要求将单词顺序反转，但单词本身不反转，可以利用两次反转来解决。第一次将整个字符串反转，此时每个单词也是反转的状态，第二次再将每个单词单独反转，就正回来了。但输入字符串还有多余的空格，要优先去除掉这些空格。 12345678910111213141516171819202122void removeExtraSpace(string &amp;s) { int slow = 0, fast = 0; // 去除字符串开头的空格 while (s.size() &gt; 0 &amp;&amp; fast &lt; s.size() &amp;&amp; s[fast] == ' ') { fast++; } for (; fast &lt; s.size(); fast++) { // 去掉字符串中间的冗余空格，只保留一个空格 if (fast - 1 &gt; 0 &amp;&amp; s[fast - 1] == s[fast] &amp;&amp; s[fast] == ' ') { continue; } else { s[slow] = s[fast]; slow++; } } if (slow - 1 &gt; 0 &amp;&amp; s[slow - 1] == ' ') { // 去除字符串末尾的空格 s.resize(slow - 1); } else { s.resize(slow); }} 去除空格可以用双指针法，先借助快指针去除开头的所有空格。然后开始处理中间的冗余空格，若遇到空格，则快指针向前走，直到遇到下一个非空格的字符，然后将快指针指向的字符赋值给慢指针指向的字符，此时快慢指针同时向前一步。最后处理末尾的空格，只需要简单的resize即可。 此外还需要一个反转字符串的函数，之前已经提到过了。 12345void reverse(string &amp;s, int start, int end) { for (int i = start, j = end; i &lt; j; i++, j--) { swap(s[i], s[j]); }} 最终的处理如下。 1234567891011121314151617string reverseWords(string s) { // 去除冗余空格 removeExtraSpace(s); // 先整个反转 reverse(s, 0, s.size() - 1); int start = 0; for (int i = 0; i &lt;= s.size(); i++) { // 再逐单词反转 if (i == s.size() || s[i] == ' ') { reverse(s, start, i - 1); start = i + 1; } } return s;} 卡码55. 右旋字符串 本题要求将字符串右旋指定位数，常规的解法可以先将待右旋的部分记录下来，再将这部分拼接到原字符串前面，最后将拼接好的字符串resize到原大小即可。 1234567void rightRotate(int k, string &amp;s) { int size = s.size(); // 记录待右旋部分 string temp(s.cbegin() + s.size() - k, s.cend()); s = temp + s; s.resize(size);} 但本题可以原地解决，参考上一题的思路。可以先将字符串整体反转，然后将待右旋的部分和剩余部分再分别反转，就是所求结果。 1234567void rightRotate(int k, string &amp;s) { // 整体反转 reverse(s.begin(), s.end()); // 两部分分别反转 reverse(s.begin(), s.begin() + k); reverse(s.begin() + k, s.end());} 28. 找出字符串中第一个匹配项的下标（简单） 本题用到一个经典算法——KMP算法，主要用于匹配字符串。当字符串不匹配时，可以知道一部分已经匹配的内容，而不需要重新从头匹配。 前缀表是KMP算法的核心，它记录了模式串下标i（包括i）之前的子串的最长公共前后缀长度。 以模式串aabaaf为例，子串a的最长公共前后缀长度为0，子串aa的为1，子串aab为0，子串aaba为1，子串aabaa为2，最后aabaaf为0。 当字符串遇到不匹配的字符时，模式串的指针向前移动长度为前一个字符的最长公共前后缀长度。 这里还涉及一个概念就是next数组，next可以是前缀表本身，也可以是前缀表整体减1后的数组。这里减不减一无关KMP算法的原理，只是实现上不同。 首先要建立next数组。 123456789101112131415161718vector&lt;int&gt; getNext(string s) { // i指向前缀末尾，j指向后缀末尾 vector&lt;int&gt; next(s.size()); int j = -1; next[0] = j; // 初始化为-1 // j初始化为-1,所以i从1开始，与j+1比较 for (int i = 1; i &lt; s.size(); i++) { // 前后缀不同的情况 while (j &gt;= 0 &amp;&amp; s[i] != s[j + 1]) { j = next[j]; // 向前回退 } if (s[i] == s[j + 1]) { // 前后缀相同 j++; } next[i] = j; // 记录最长公共前后缀长度 } return next;} 然后利用next数组进行模式匹配。 1234567891011121314151617181920212223int strStr(string haystack, string needle) { if (needle.size() == 0) return 0; vector&lt;int&gt; next = getNext(needle); int j = -1; // 因为next数组记录的起始位置为-1 // 这里i从0开始 for (int i = 0; i &lt; haystack.size(); i++) { // 字符不匹配的情况 while (j &gt;= 0 &amp;&amp; haystack[i] != needle[j + 1]) { j = next[j]; // 寻找之前匹配的位置 } // 字符匹配则i，j同时向后移动 if (haystack[i] == needle[j + 1]) { j++; } // 字符串完全匹配 if (j == (needle.size() - 1)) { return (i - needle.size() + 1); } } return -1;} KMP算法详细的解释参考代码随想录。 459. 重复的子字符串（简单） 当一个字符串是由重复的子串构成的，那么它一定可以分为几部分，每一部分都是一样的子串。这样的字符串如果进行前后拼接，那么必然在拼接起来的新字符串的中间部分找到一个原字符串，所以就有了如下解法。 12345678910bool repeatedSubstringPattern(string s) { string t = s + s; // 拼接 t.erase(t.begin()); // 掐头 t.erase(t.end() - 1); // 去尾 // find()函数未找到时会返回string::npos if (t.find(s) != string::npos) return true; return false;} 当然也可以用上题的KMP算法，通过next数组来判断是否具有重复子串。 12345678910111213141516171819202122232425262728293031323334vector&lt;int&gt; getNext(string s) { vector&lt;int&gt; next(s.size()); next[0] = -1; int j = -1; for (int i = 1; i &lt; s.size(); i++) { while (j &gt;= 0 &amp;&amp; s[i] != s[j + 1]) { j = next[j]; } if (s[i] == s[j + 1]) { j++; } next[i] = j; } return next;}bool repeatedSubstringPattern2(string s) { if (s.size() == 0) { return false; } vector&lt;int&gt; next = getNext(s); int size = s.size(); // 若next[size - 1] != -1说明字符串中存在最长公共前后缀 // 如果字符串长度-最长公共前后缀长度可以被字符串长度整除 // 即 size % (size - (next[size - 1] + 1)) == 0 // 说明有重复的子串 if (next[size - 1] != -1 &amp;&amp; size % (size - (next[size - 1] + 1)) == 0) { return true; } return false;}","link":"/posts/12452/"},{"title":"算法练习——栈与队列","text":"力扣，栈与队列相关练习。 232. 用栈实现队列（简单） 本题比较简单，使用两个栈，一个作为存放数据的栈，另一个作为临时中转的栈。 123456789101112131415161718192021222324252627282930313233343536373839class MyQueue { public: MyQueue() {} void push(int x) { stack1.push(x); } int pop() { while (!stack1.empty()) { // 数据转移到中转栈 stack2.push(stack1.top()); stack1.pop(); } int res = stack2.top(); // 获取队头数据 stack2.pop(); // 该数据出队 while (!stack2.empty()) { // 转移回数据栈 stack1.push(stack2.top()); stack2.pop(); } return res; } int peek() { while (!stack1.empty()) { stack2.push(stack1.top()); stack1.pop(); } int res = stack2.top(); while (!stack2.empty()) { stack1.push(stack2.top()); stack2.pop(); } return res; } bool empty() { return stack1.empty(); } private: stack&lt;int&gt; stack1; // 数据栈 stack&lt;int&gt; stack2; // 中转栈}; 但这样每次pop或peek操作都会发生大量的数据转移，可以用一个技巧来解决这个问题。同样是使用两个栈，一个作为输入栈，一个作为输出栈。push操作只要向输入栈push即可。pop操作时，若输出栈为空，则将所有数据都从输入栈转移到输出栈，再pop数据，若输出栈不为空，则可以直接pop输出栈。 123456789101112131415161718192021222324252627282930313233class MyQueue { public: MyQueue() {} void push(int x) { stack_in.push(x); } int pop() { int res; if (stack_out.empty()) { // 若输出栈空则搬移 while (!stack_in.empty()) { stack_out.push(stack_in.top()); stack_in.pop(); } } // 否则直接pop res = stack_out.top(); stack_out.pop(); return res; } int peek() { int temp = this-&gt;pop(); // 借助pop stack_out.push(temp); // 再将pop的元素push回输出栈 return temp; } bool empty() { return stack_in.empty() &amp;&amp; stack_out.empty(); } private: stack&lt;int&gt; stack_in; // 输入栈 stack&lt;int&gt; stack_out; // 输出栈}; 225. 用队列实现栈（简单） 由于队列的操作方式限制，所以本题只能采取上题中的第一种思路，使用两个队列，一个作为数据队列，一个作为中转队列。 123456789101112131415161718192021222324252627282930class MyStack { public: MyStack() {} void push(int x) { queue1.push(x); } int pop() { int size = queue1.size() - 1; while (size--) { // 中转，但留下最后一个元素 queue2.push(queue1.front()); queue1.pop(); } int res = queue1.front(); queue1.pop(); while (!queue2.empty()) { // 再转移回去 queue1.push(queue2.front()); queue2.pop(); } return res; } int top() { return queue1.back(); } bool empty() { return queue1.empty(); } private: queue&lt;int&gt; queue1; // 数据队列 queue&lt;int&gt; queue2; // 中转队列}; 20. 有效的括号（简单） 本题有一个小技巧，当碰到左括号时，入栈对应的右括号。碰到右括号就判断栈顶元素是否与当前括号相同，相同则出栈，不同则表明不匹配。 12345678910111213141516171819202122bool isValid(string s) { if (s.size() % 2 != 0) return false; stack&lt;char&gt; st; for (char c : s) { // 碰到左括号，则push对应类型的右括号 if (c == '(') st.push(')'); else if (c == '[') st.push(']'); else if (c == '{') st.push('}'); // 若栈空了或栈顶元素与当前括号不相同，则括号不匹配 else if (st.empty() || st.top() != c) return false; // 若栈顶元素与当前括号相同，则出栈 else st.pop(); } return st.empty();} 1047. 删除字符串中的所有相邻重复项（简单） 本题核心的思路是利用栈来记录前一个字符，下一个字符与当前栈顶元素对比，若相同则代表是相邻的重复项。 1234567891011121314151617181920string removeDuplicates(string s) { stack&lt;char&gt; st; for (char c : s) { // 栈空或栈顶元素与当前字符不相同则入栈 if (st.empty() || st.top() != c) st.push(c); else st.pop(); } // 栈中剩余的元素即为逆序的结果字符串 string res(&quot;&quot;); while (!st.empty()) { res += st.top(); st.pop(); } reverse(res.begin(), res.end()); return res;} 150. 逆波兰表达式求值（中等） 本题只要理解逆波兰表达式的规则就很容易做出来。若碰到数字则入栈，碰到运算符则取出栈顶的两个数字进行对应运算，再将运算结果入栈即可。 12345678910111213141516171819202122232425262728int evalRPN(vector&lt;string&gt; &amp;tokens) { stack&lt;int&gt; st; int left, right; for (string s : tokens) { if (s == &quot;+&quot; || s == &quot;-&quot; || s == &quot;*&quot; || s == &quot;/&quot;) { right = st.top(); st.pop(); left = st.top(); st.pop(); if (s == &quot;+&quot;) st.push(left + right); if (s == &quot;-&quot;) st.push(left - right); if (s == &quot;*&quot;) st.push(left * right); if (s == &quot;/&quot;) st.push(left / right); } else { int num; istringstream iss(s); iss &gt;&gt; num; st.push(num); } } return st.top();} 239. 滑动窗口最大值（困难） 本题暴力解法的思路很简单，但遇到k较大的情况会超时。力扣给出了三个提升： 可以使用一个双向队列； 队列的size不必和窗口的大小相同； 移除冗余的元素，队列只需要存储需要被考虑的元素。 结合这几条提示可以想到一种数据结构——单调队列。单调队列的pop和push操作规则如下： pop：若窗口移除的元素等于单调队列的出口元素，则将队列出口的元素弹出，否则不进行操作； push：若push的元素大于单调队列的入口元素，则将队列入口的元素弹出，直到push的元素小于等于队列入口的元素。 按照上述规则操作，每次窗口移动时，queue.front就是当前窗口的最大值。先借助deque实现单调队列。 1234567891011121314151617181920212223class MonotonicQueue { public: void pop(int value) { // 窗口移除元素等于队列出口元素 if (!que.empty() &amp;&amp; value == que.front()) { que.pop_front(); // 弹出出口元素 } } void push(int value) { // push元素大于队列入口元素 while (!que.empty() &amp;&amp; value &gt; que.back()) { que.pop_back(); // 弹出入口元素 } // 最后向入口push元素 que.push_back(value); } int front() { return que.front(); } private: deque&lt;int&gt; que;}; 最终利用单调队列解决本题。 1234567891011121314151617vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt; &amp;nums, int k) { MonotonicQueue que; vector&lt;int&gt; res; // 将前k个元素放入队列 for (int i = 0; i &lt; k; i++) { que.push(nums[i]); } // 记录当前窗口最大值 res.push_back(que.front()); for (int i = k; i &lt; nums.size(); i++) { que.pop(nums[i - k]); // 窗口移除最前面的元素 que.push(nums[i]); // 窗口加入最后面的元素 res.push_back(que.front()); // 记录当前窗口最大值 } return res;} 347. 前 K 个高频元素（中等） 本题要求统计前K个高频的元素，首先想到的是利用map来存储每个元素出现过的次数。在此基础上还需要实现按照出现次数排序的功能，可以使用优先级队列来实现，它的本质是一个堆。这里可以使用大小为K的小顶堆，因为统计的是最高频的K个元素，小顶堆每次会将最小频率的元素弹出，最后堆中剩余的元素即为前K个高频元素。 由于在优先级队列中存放的是map，且我们只想利用频率来排序，所以需要自定义一个比较器。 1234567891011121314151617181920212223242526272829vector&lt;int&gt; topKFrequent(vector&lt;int&gt; &amp;nums, int k) { unordered_map&lt;int, int&gt; record; // 统计元素频率 for (int num : nums) { record[num]++; } // 定义比较器 auto cmp = [](const pair&lt;int, int&gt; &amp;lhs, const pair&lt;int, int&gt; &amp;rhs) { return lhs.second &gt; rhs.second; }; // 利用自定义比较器定义优先级队列 priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, decltype(cmp)&gt; small_top_heap(cmp); for (pair&lt;int, int&gt; elem : record) { small_top_heap.push(elem); // 保持小顶堆中只有k个元素 if (small_top_heap.size() &gt; k) { small_top_heap.pop(); } } vector&lt;int&gt; res; for (int i = 0; i &lt; k; i++) { res.push_back(small_top_heap.top().first); small_top_heap.pop(); } return res;}","link":"/posts/3160/"},{"title":"算法练习——链表","text":"力扣，链表相关练习。 203. 移除链表元素（简单） 力扣中的链表，头结点默认指向链表的第一个元素，故在解决链表问题时，可以手动增加一个虚结点作为头结点，这样可以不用单独处理原来的头结点。 1234567891011121314151617181920ListNode *removeElements(ListNode *head, int val) { ListNode *dummy_head = new ListNode(0); dummy_head-&gt;next = head; ListNode *ptr = dummy_head; while (ptr-&gt;next != nullptr) { if (ptr-&gt;next-&gt;val == val) { ListNode *temp = ptr-&gt;next; ptr-&gt;next = ptr-&gt;next-&gt;next; delete temp; } else { ptr = ptr-&gt;next; } } head = dummy_head-&gt;next; delete dummy_head; return head;} 707. 设计链表（中等） 一道题考察了5个链表的基础操作，对于这种数据结构类的题要多加练习，有时候觉得在纸上画图模拟很简单，但想要用代码实现的时候会发现有很多细节问题。 以下为各方法要实现的功能： get(index)：获取链表中第 index 个结点的值。如果索引无效，则返回-1。 addAtHead(val)：在链表的第一个元素之前添加一个值为val的结点。插入后，新结点将成为链表的第一个结点。 addAtTail(val)：将值为val的结点追加到链表的最后一个元素。 addAtIndex(index,val)：在链表中的第index个结点之前添加值为val 的结点。如果index等于链表的长度，则该结点将附加到链表的末尾。如果index大于链表长度，则不会插入结点。如果index小于0，则在头部插入结点。 deleteAtIndex(index)：如果索引index有效，则删除链表中的第index个结点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104class MyLinkedList { public: // 定义链表结点 struct LinkedNode { int val; LinkedNode *next; LinkedNode(int val) : val(val), next(nullptr) {} }; // 初始化链表 MyLinkedList() { _dummy_head = new LinkedNode(0); // 虚头结点 _size = 0; // 记录链表长度 } int get(int index) { // 若index不合法则返回-1 if (index &gt; (_size - 1) || index &lt; 0) { return -1; } // index从0开始，所以第0个结点是真正的头结点，不是虚头结点 LinkedNode *ptr = _dummy_head-&gt;next; // for (int i = 0; i &lt; index; i++) { // ptr = ptr-&gt;next; // } while (index--) { ptr = ptr-&gt;next; } return ptr-&gt;val; } void addAtHead(int val) { LinkedNode *new_node = new LinkedNode(val); new_node-&gt;next = _dummy_head-&gt;next; _dummy_head-&gt;next = new_node; _size++; } void addAtTail(int val) { LinkedNode *new_node = new LinkedNode(val); LinkedNode *ptr = _dummy_head; while (ptr-&gt;next != nullptr) { ptr = ptr-&gt;next; } ptr-&gt;next = new_node; _size++; } void addAtIndex(int index, int val) { if (index &gt; _size) return; if (index &lt; 0) index = 0; LinkedNode *new_node = new LinkedNode(val); LinkedNode *ptr = _dummy_head; // for (int i = 0; i &lt; index; i++) { // ptr = ptr-&gt;next; // } while (index--) { ptr = ptr-&gt;next; } new_node-&gt;next = ptr-&gt;next; ptr-&gt;next = new_node; _size++; } void deleteAtIndex(int index) { if (index &gt;= _size || index &lt; 0) return; // 这里与get中不同，因为本质上是寻找目标结点的前一个结点 LinkedNode *ptr = _dummy_head; // for (int i = 0; i &lt; index; i++) { // ptr = ptr-&gt;next; // } while (index--) { ptr = ptr-&gt;next; } LinkedNode *temp = ptr-&gt;next; ptr-&gt;next = ptr-&gt;next-&gt;next; delete temp; // 释放temp后需要赋值为nullptr，否则temp就变成了野指针，比较危险 temp = nullptr; _size--; } void printLinkedList() { LinkedNode *ptr = _dummy_head; while (ptr-&gt;next != nullptr) { cout &lt;&lt; ptr-&gt;next-&gt;val &lt;&lt; &quot; &quot;; ptr = ptr-&gt;next; } cout &lt;&lt; endl; } private: // 此处一定要使用有符号数，因为存在虚头结点，判断链表尺寸时可能出现-1的情况 int _size; LinkedNode *_dummy_head;}; 206. 反转链表（简单） 本题可以用双指针的方法解决，从头依次将指针的方向反转。 12345678910111213ListNode *reverseList(ListNode *head) { ListNode *cur = head; // 记录当前结点 ListNode *prev = nullptr; // 记录原链表的前一个结点 ListNode *temp; while (cur != nullptr) { temp = cur-&gt;next; // 记录原链表中当前结点的下一个结点 cur-&gt;next = prev; // 将当前结点的next指针反转，指向前一个结点 prev = cur; // prev指针向原链表方向前进一步 cur = temp; // cur指针也向原链表方向前进一步 } return prev; // 当cur指向了nullptr，prev指向的就是原链表的最后一个结点} 还可以利用递归的方式解决，原理同双指针法一样，只不过用递归的形式表达。 12345678910111213ListNode *reverse(ListNode *prev, ListNode *cur) { if (cur == nullptr) // 递归终止条件为cur指向了nullptr return prev; ListNode *temp = cur-&gt;next; cur-&gt;next = prev; // 这里的递归等价于prev = cur; cur = temp;这两步 return reverse(cur, temp);}ListNode *reverseList2(ListNode *head) { return reverse(nullptr, head);} 24. 两两交换链表中的结点（中等） 本题直接对该过程进行模拟即可。 1234567891011121314151617ListNode *swapPairs(ListNode *head) { ListNode *dummy_head = new ListNode(0, head); ListNode *ptr = dummy_head; while (ptr-&gt;next != nullptr &amp;&amp; ptr-&gt;next-&gt;next != nullptr) { ListNode *temp = ptr-&gt;next; // 待交换对的左结点 ListNode *temp1 = ptr-&gt;next-&gt;next-&gt;next; // 下一个待交换对的左结点 ptr-&gt;next = ptr-&gt;next-&gt;next; // 上一对的右结点指向当前待交换对的右结点 ptr-&gt;next-&gt;next = temp; // 当前待交换对的右结点指向左结点 // 当前待交换对的左结点（即交换后的右结点）指向下一对的左结点 ptr-&gt;next-&gt;next-&gt;next = temp1; ptr = ptr-&gt;next-&gt;next; // 向后移动两个结点 } return dummy_head-&gt;next;} 19. 删除链表的倒数第 N 个结点（中等） 本题使用快慢指针法即可很简单的解决。 12345678910111213141516171819ListNode *removeNthFromEnd(ListNode *head, int n) { ListNode *dummy_head = new ListNode(0, head); ListNode *slow = dummy_head; ListNode *fast = dummy_head; for (int i = 0; i &lt; n; i++) { fast = fast-&gt;next; // 快指针先走n步 } // 快慢指针一起走，直到快指针指向最后一个结点 while (fast-&gt;next != nullptr) { slow = slow-&gt;next; fast = fast-&gt;next; } ListNode *temp = slow-&gt;next; slow-&gt;next = slow-&gt;next-&gt;next; delete temp; return dummy_head-&gt;next;} 面试题 02.07. 链表相交（简单） 经典问题，当两个链表长度不统一，且末尾有公共部分时，考虑将两链表的末尾对其，然后分别用指针进行遍历。 123456789101112131415161718192021222324252627282930313233343536373839ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) { ListNode *dummy_headA = new ListNode(0,headA); ListNode *dummy_headB = new ListNode(0,headB); int size_A = 0,size_B =0; ListNode *ptrA = dummy_headA; ListNode *ptrB = dummy_headB; while(ptrA-&gt;next != nullptr){ // 统计链表A的长度 ptrA = ptrA-&gt;next; size_A++; } while(ptrB-&gt;next!=nullptr){ // 统计链表B的长度 ptrB = ptrB-&gt;next; size_B++; } ptrA = dummy_headA; ptrB = dummy_headB; int diff = abs(size_A -size_B); // 令较长的链表先走长度差，使得ptrA和ptrB对于两个链表的末尾对齐 if(size_A &gt; size_B){ for(int i=0;i&lt;diff;i++){ ptrA = ptrA -&gt;next; } }else { for(int i=0;i&lt;diff;i++){ ptrB = ptrB-&gt;next; } } // 然后共同前进，直到指向的结点相同 while(ptrA != ptrB){ ptrA = ptrA-&gt;next; ptrB = ptrB-&gt;next; } // 若到末尾都不相同，此时ptrA指向nullptr，符合要求 return ptrA;} 142. 环形链表 II（中等） 本题可以使用快慢指针法，快指针每次走两步，慢指针每次走一步。这里涉及两个问题： 快慢指针一定相遇而不是永远错开吗？ 快慢指针相遇的位置一定是环内吗？ 第一个问题，慢指针一次走一步，快指针一次走两步，对于慢指针来说，快指针在环内是一步一步靠近慢指针的，所以早晚会相遇。 第二个问题，因为快指针一定先进入环中，而后慢指针才到。所以一旦快慢指针相遇，一定是在环内。 找到环之后，就是要找到环的入口。假设从头结点到环形入口结点的结点数为\\(x\\)。 环形入口结点到快指针与慢指针相遇结点的结点数为\\(y\\)。 从相遇结点再到环形入口结点的结点数为\\(z\\)。 当快慢指针相遇时，慢指针走过了\\(x+y\\)个结点，快指针走过了\\(x+y+n(y+z)\\)，其中\\(n\\)为快慢指针相遇时快指针在环内走的圈数。由于快指针一次走两步，慢指针一次走一步，所以快指针走过的结点数是慢指针的两倍，即\\((x+y)\\times2=x+y+n(y+z)\\)。环的入口距离头结点的距离是\\(x\\)，将式子化简就得到了\\(x\\)的值\\(x=n(y+z)-y\\)。 由于我们要找到关于环的信息，所以将公式进一步变换为\\(x=(n-1)(y+z)+z\\)，这样就将环独立了出来。这个公式的含义就比较明确了，一个指针从头结点出发，另一个指针从快慢指针相遇的结点出发，当这两个指针相遇时，就是环的入口。 123456789101112131415161718ListNode *detectCycle(ListNode *head) { ListNode *slow = head; ListNode *fast = head; while (fast != nullptr &amp;&amp; fast-&gt;next != nullptr) { // 保证fast走两步的合法性 slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if (slow == fast) { // 若相遇则必定有环 ListNode *ptr1 = head; // 一个指针从头结点出发 ListNode *ptr2 = fast; // 另一个从快慢指针相遇的结点出发 while (ptr1 != ptr2) { ptr1 = ptr1-&gt;next; ptr2 = ptr2-&gt;next; } return ptr2; // 返回环入口 } } return nullptr;}","link":"/posts/29899/"},{"title":"范数理论及其应用","text":"矩阵分析简明教程第5章笔记 1. 向量范数 1.1 内积诱导的范数 欧式空间中，向量与内积为 定义向量的长度(或范数)为 中的向量长度满足以下性质： 非负性： 齐次性： 三角不等式： 1.2 向量范数 定义 设是维线性空间，对于中的每一个向量赋以一实数，这个实数称之为向量的范数(norm)，记为，并要求范数满足如下条件： 非负性： 齐次性： 三角不等式： 称为赋范空间(normed space) 1.3 常见的向量范数 在(或)中，对于任意向量 向量的1-范数 所有项绝对值的和 向量的2-范数 所有项的平方和的算术平方根 向量的无穷范数 绝对值最大的项 向量的p-范数 -范数()满足 当在复数域时，指的模 1.4 向量范数的等价 定义 设和是维线性空间上定义的两种向量范数 若存在与无关的正数使得 则称范数与等价(equivalent) 此处的和指两种不同的范数，并不是向量的1-范数和2-范数 定理1 有限维线性空间上的任意两个向量范数都是等价的 该结论不能推广到无穷维空间 定理2 在中，对于向量序列，则 其中为任意一种向量范数 有限维空间中序列在各种范数下收敛是等价的 2. 矩阵范数 2.1 矩阵范数定义 若对于任一阶复方阵，都有一个实数与之对应，且满足 非负性： 齐次性： 三角不等式： 相容性： 则称为矩阵的范数(norm) 2.2 常见的矩阵范数 设矩阵 矩阵的m1-范数 所有项绝对值的和，对应向量的1-范数 矩阵的Frobenius-范数 所有项的平方和的算术平方根，对应向量的2-范数 矩阵的m无穷范数 绝对值最大的项的n倍，对应向量的-范数 矩阵的1-范数 矩阵中元素绝对值列和最大的一列元素绝对值之和，也称列和范数 矩阵的无穷范数 矩阵中元素绝对值行和最大的一行元素绝对值之和，也称行和范数 矩阵的2-范数 其中是的最大特征值，也称谱范数 向量范数诱导的矩阵范数 设矩阵，设是上的向量范数，则 是矩阵范数，称之为由向量范数诱导的矩阵范数，或算子范数 2.3 矩阵范数的等价 定义 设和是上定义的两种矩阵范数 若存在与无关的正数使得 则称范数与等价(equivalent) 定理 上的任意两个矩阵范数都是等价的 2.4 矩阵范数与向量范数的相容性 定义 设 若向量范数与矩阵范数满足 则称矩阵范数与向量范数是相容的(compatible) 矩阵的-范数与向量的1-范数是相容的 矩阵的Frobenius-范数与向量的2-范数是相容的 矩阵的-范数与向量的-范数是相容的 定理 每一种向量范数都有与之相容的矩阵范数 每一种矩阵范数也都有与之相容的向量范数 3. 范数的应用 3.1 最小二乘解 设有不相容的线性方程组，即 求数组使得最小 定义 若向量使得 则称为方程组的一个最小二乘解(Least square solution) 根据正交投影定理，或多元函数极值条件得，方程组的最小二乘解满足的充要条件为 该问题在正交补部分也有提及，详见最小二乘解与正交补 定理 设，则方程组的全部最小二乘解为 其中为任意列向量 3.2 极小范数的最小二乘解 定义 设是的最小二乘解 若对于的每一个最小二乘解都有 则称是方程组的极小范数的最小二乘解，或最佳逼近解 定理 设，则方程组有唯一的极小范数的最小二乘解","link":"/posts/61446/"},{"title":"设计模式——代理模式","text":"找个管家帮你做事吧，本篇介绍代理模式。 代理模式 在某些情况下，一个客户不想或不能直接引用一个对象，此时可以通过一个称之为“代理”的第三者来实现间接引用。 角色 Subject（抽象主题角色） 抽象主题角色声明了真实主题和代理主题的共同接口，在任何使用真实主题的地方都可以使用代理主题。客户端需要针对抽象主题角色进行编程。 Proxy（代理主题角色） 代理主题角色包含对真实主题的引用，在代理主题角色中提供一个与真实主题角色相同的接口，以便在任何时候都可以替代真实主题。同时可以控制真实主题的使用，负责在需要的时候创建和删除真实主题对象，并对真实主题对象的使用加以约束。代理主题角色往往在客户端调用真实主题操作之前或之后需要执行其他操作，并不仅仅是单纯的调用真实主题对象中的操作。 Real Subject（真实主题角色） 真实主题角色定义了代理角色所代表的真实对象，在真实主题角色中实现了真实的业务操作。 类图 image.png 实例 定义一个抽象主题角色 123public interface Image { void display();} 定义真实主题角色 1234567891011121314151617public class RealImage implements Image { private String fileName; public RealImage(String fileName) { this.fileName = fileName; loadFromDisk(fileName); } @Override public void display() { System.out.println(&quot;Displaying &quot; + fileName + &quot;.&quot;); } public void loadFromDisk(String fileName) { System.out.println(&quot;Loading &quot; + fileName + &quot;from disk.&quot;); }} 定义代理主题角色 12345678910111213141516public class ProxyImage implements Image { private RealImage realImage; private String fileName; public ProxyImage(String fileName) { this.fileName = fileName; } @Override public void display() { if (realImage == null) { realImage = new RealImage(fileName); } realImage.display(); }} 客户端测试类 1234567891011public class Client { public static void main(String[] args) { // 此时还没有从硬盘读取真正的图片 ProxyImage proxyImage = new ProxyImage(&quot;test_image.jpg&quot;); // 只有调用真实图片对象的方法时，才由代理图片创建真实图片对象，并调用该方法 proxyImage.display(); System.out.println(&quot;Display it again.&quot;); // 再次调用时无需从硬盘中重复读取 proxyImage.display(); }} 运行结果为 1234Loading test_image.jpgfrom disk.Displaying test_image.jpg.Display it again.Displaying test_image.jpg. 代理模式的种类 远程代理 远程代理可以作为另一个JVM上对象的本地代表。调用代理的方法，会被代理利用网络转发到远程执行，并且结果会通过网络返回给代理，再由代理将结果转给客户。 虚拟代理 虚拟代理作为创建开销大的对象的代表，经常会直到我们真正需要一个对象的时候才创建它。当对象在创建前和创建中时，由虚拟代理地来扮演对象的替身。对象创建后，代理就会将请求直接委托给对象。 保护代理（Protect or Access） 对真实对象的功能做一些访问限制，在代理层做身份验证，通过了验证，才调用真实的主体对象的相应方法。 智能引用代理（Smart Reference） 当调用真实的对象时，代理处理另外一些事情。比如，在访问一个实际对象前，检查是否已经锁定它，以确保其他对象不能改变它。也就是在访问一个对象时附加的 一些内务处理。 Windows系统中的快捷方式、Spring框架中的AOP均利用了代理模式。 模式优缺点 优点 代理模式能够协调被调用者和调用者，在一定程度上降低了系统的耦合度； 远程代理使得客户端可以访问在远程机器上的对象，远程机器可能具有更好的计算性能与处理速度，可以快速响应并处理客户端请求； 虚拟代理通过使用一个小对象来代表一个大对象，可以减少系统资源的消耗，对系统进行优化并提高运行速度； 保护代理可以控制对真实对象的使用权限。 缺点 由于在客户端和真是主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢； 实现代理模式需要额外的工作，有些代理模式的实现非常复杂。","link":"/posts/28022/"},{"title":"线性空间与线性变换","text":"矩阵分析简明教程第1章笔记 1. 线性空间的基本概念 1.1 数域 定义 设是复数集的一个子集，满足 是一个数集 至少包含0和1 关于数的和、差、积、商等运算是封闭的 则是一个数域 常见数域： 1.2 线性空间 定义 设是一个非空集合，其中的元素称为向量；是数域，其中的元素称为数或纯量 若在中定义两个运算 向量与向量的加法，使得有 数与向量的数乘，使得有 且满足如下定理： 对于加法有 零向量使得有 使得称为的负向量记作 对于数乘有 则称是数域上的一个线性空间(linear space)或向量空间(vector space) 基本性质 定理：设是数域上的线性空间，则 中的零向量唯一 中的任何向量的负向量唯一 当且仅当(数0)或(零向量) 1.3 线性空间的基和维数 定义 设是数域的线性空间，若存在一个有限元素的部分组满足 线性无关 中任意一个向量可以由线性表示 则称为的一组基(basis)，称为的维数(dimension)，记作 基 = 线性空间的一个极大线性无关组 维数 = 基向量的个数 零空间的维数 在维线性空间中，任意个线性无关的向量组都是它的一组基，且任何个向量都是线性相关的 基的作用 定理：设是线性空间的基，则的任一向量都可以由基元素唯一表示，即 坐标 设是线性空间的基，的向量可以由基唯一线性表示为 则称有序数组为向量在基下的坐标(cordinate)，记作 记号 向量与坐标是一一对应的关系 同一向量在不同的基底下的坐标不相等 1.4 基变换和坐标变换 基变换的定义 设和是线性空间V的两组基 故 称矩阵为基到基(的过渡矩阵 同时有基(到基的过渡矩阵，即 基变换的定理 设是线性空间的一组基，是数域的一个阶方阵， 则向量组是的基当且仅当可逆 坐标变换的定义 设向量分别在两组基和下的坐标为和，即 又因为 故 则同一向量在不同基下的坐标之间的关系为 2. 子空间与维数定理 2.1 子空间 定义 设是数域上的线性空间，是的非空子集 若对中的加法和数乘构成数域上的线性空间 则称是的线性子空间(subspace) 子空间中的两种运算是原线性空间的运算 子空间本身是线性空间 零空间和都是的子空间，称为平凡子空间 子空间的判定定理 设是数域上的线性空间，是的非空子集，若对中的加法和数乘两种运算封闭，即 有 有 则是的子空间 相当于只需证明有即可证明对两种运算封闭 2.2 生成子空间 定义 设是线性空间的一组向量，令 则是的子空间，称为由生成的子空间，记作或 命题 若线性无关，则为其生成子空间的基 若是向量组的极大线性无关组，则 是的一组基 若是线性空间的一组基，则 2.3 子空间的运算 定义 设和是线性空间的子空间，则定义 交(intersection)：且 并(union)：或 和(sum)： 定理 设和是线性空间的子空间，则 交是子空间，称为交空间 并可构成子空间，当且仅当或 和是子空间，称为和空间 2.4 基的扩张定理 设是维线性空间的子空间，，为的一组基 则存在个中的向量，使得为的一组基 2.5 维数公式 定理 设和是线性空间的子空间 则 交空间与和空间满足 2.6 子空间的直和 定义 设和是数域上线性空间的子空间 若中每个向量都能唯一表示成 则称是与的直和(direct sum)，记作 子空间的直和仍然是和： 有两个含义 和“+” 交空间为零空间 定理 设和是线性空间的子空间，则下列命题等价 与的和是直和 零向量分解唯一，即若，则有 3. 线性空间的同构 3.1 函数 给定数集，若对于中的每个元素，在中都有唯一的元素与之对应 则称此对应关系为由数集到的函数，记为或 3.2 映射的概念 给定集合，若对于中的每个元素，在中都有唯一的元素与之对应 则称此对应关系为由集合到的映射，记为或 称为映射的像集 设映射 若，则称是满射 若，则称是单射 若既是单射又是满射，则称是一一映射 若是一一的，则其逆映射存在，且也是一一的 若是一一的，则复合映射或也是一一的 3.3 线性空间的同构 定义 设和是线性空间，若存在双射对满足 则称线性空间和是同构的，称为到的同构映射 性质 设为同构映射，则 若为的基，则为的基 定理 同构映射的逆映射是同构映射 两个同构映射的乘积仍然是同构映射 同构关系满足 自反性：与其自身同构 对称性：若与同构，则与同构 传递性：若与同构，与同构，则与同构 数域上的维线性空间同构于 数域上有限维线性空间同构的充要条件是它们的维数相等 4. 线性变换及其矩阵表示 4.1 线性变换 定义 设是数域上的线性空间，映射满足 则称映射是线性变换 常见的线性变换 设矩阵，定义映射，则是上的线性变换 特别的：直线函数为上的线性变换 在多项式空间上定义映射，则是上的线性变换，称之为微分变换，称为微分算子 在连续函数空间上定义映射，则是上的线性变换，称之为积分变换，称为积分算子 设是数域上的线性空间 定义零变换 定义恒等变换 4.2 线性变换的核和像空间 定义 设是线性空间上的线性变换 分别称为的核(kernel)和像(image) 命题 线性变换的核和像均为线性空间 和又称之为核空间和像空间 且和为的子空间 定理 设是线性空间上的线性变换，则 线性相关也线性相关 上述定理表明，线性变换 通过原点 映负元为负元 映线性组合为线性组合 映线性相关向量为线性相关向量 4.3 线性变换的相等 定义 设是线性空间上的线性变换 若 则称与相等，记为 定理 设是线性空间的一组基 则上线性变换与相等的充要条件为 确定两个线性变换相等仅需有限个点 设是线性空间的一组基，为任意给定的向量 则存在唯一的线性变换，使得 4.4 线性变换的矩阵 定理 设是线性空间上的线性变换，是的一组基 则 定义 设是线性空间上的线性变换，是的一组基，基元的像 写成矩阵乘积的形式 即 矩阵称为线性变换在基下的矩阵 4.5 线性变换在不同基下的矩阵 定理 设是线性空间上的线性变换，有两组基与 则与相似，且 线性变换在不同基下的矩阵相似 相似的矩阵可看做同一个线性变换在不同基下的矩阵","link":"/posts/55086/"},{"title":"设计模式——单例模式","text":"用过Spring的都知道bean是单例，来看看单例模式的各种实现方式。 单例模式 对于系统中的某些类来说，只有一个实例很重要。单例模式就是让类自身负责保存它的唯一实例，这个类可以保证没有其他实例被创建，并且它可以提供一个访问该实例的方法。 角色 Singleton（单例角色） 在单例类的内部实现只生成一个实例，同时提供一个静态的getInstance()工厂方法，让客户可以使用它的唯一实例；为了防止在外部对其实例化，构造方法设为私有；在单例类内部定义了一个Singleton类型的静态对象，作为外部共享的唯一实例。 类图 image.png 实例 12345678910111213141516171819202122232425public class IDCardNumber { private static IDCardNumber instance = null; private String number; private IDCardNumber() {} public static IDCardNumber getInstance() { if (instance == null) { System.out.println(&quot;First Application for id card, get a new number.&quot;); instance = new IDCardNumber(); instance.setNumber(&quot;No10086&quot;); } else { System.out.println(&quot;Duplicate application for id card, get the old number.&quot;); } return instance; } public String getNumber() { return number; } public void setNumber(String number) { this.number = number; }} 客户端测试类 1234567891011121314public class Client { public static void main(String[] args) { IDCardNumber card_1 = IDCardNumber.getInstance(); IDCardNumber card_2 = IDCardNumber.getInstance(); System.out.println(&quot;Are the id cards the same: &quot; + ((card_1 == card_2) ? &quot;yes&quot; : &quot;no&quot;)); String id_1 = card_1.getNumber(); String id_2 = card_2.getNumber(); System.out.println(&quot;The first number: &quot; + id_1); System.out.println(&quot;The second number: &quot; + id_2); System.out.println(&quot;Are the id numbers the same: &quot; + ((id_1.equals(id_2)) ? &quot;yes&quot; : &quot;no&quot;)); System.out.println(&quot;Are these two String objects the same: &quot; + ((id_1 == id_2) ? &quot;yes&quot; : &quot;no&quot;)); }} 运行结果为 1234567First Application for id card, get a new number.Duplicate application for id card, get the old number.Are the id cards the same: yesThe first number: No10086The second number: No10086Are the id numbers the same: yesAre these two String objects the same: yes 实现单例模式的几种方式 懒汉式（线程不安全） 上述实例中看到的即为懒汉式，且线程不安全，所以不能算作真正意义上的单例。 是否懒（Lazy）初始化：是 是否线程安全：否 123456789101112public class Singleton { private static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 懒汉式（线程安全） 在线程不安全的懒汉式基础上加锁以实现线程安全，但效率很低。 是否懒（Lazy）初始化：是 是否线程安全：是 123456789101112public class Singleton { private static Singleton instance; private Singleton() {} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 饿汉式 饿汉式由于没有加锁，所以效率会高很多，它基于classloader机制避免了多线程的同步问题，但instance在类装载时就被实例化，故无法达到懒初始化的效果。 是否懒（Lazy）初始化：否 是否线程安全：是 123456789public class Singleton { private static Singleton instance = new Singleton(); private Singleton() {} public static Singleton getInstance() { return instance; } } 双检锁/双重校验锁（DCL，double-checked locking） 该方式从JDK 1.5之后支持，采用双锁机制，是线程安全的，并能在多线程情况下保持高性能。 是否懒（Lazy）初始化：是 是否线程安全：是 123456789101112131415161718public class Singleton { // 用volatile关键字修饰该变量，JVM会把线程本地内存中的变量强制刷新到主内存中 // 由于创建实例并不是一个原子的指令，该过程中可能发生指令重排，而volatile关键字还可以避免指令重排 private volatile static Singleton singleton; private Singleton() {} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 登记式/静态内部类 这种方式以更简单的实现方式达到了双检锁方式的效果，同样是利用classloader机制解决多线程的同步问题，是对饿汉式的优化。在饿汉式中，只要Singleton类被装载，则instance就会被实例化，但在该方式中，Singleton类被装载后不会同时将instance实例化，而是等待getInstance()方法被调用后，才会显示装载SingletonHolder类，从而达到了懒初始化的效果。 是否懒（Lazy）初始化：是 是否线程安全：是 1234567891011public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton() {} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; }} 枚举 这种方式是 Effective Java 作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。JDK 1.5之后才加入了enum特性，实际中较少用到。 是否懒（Lazy）初始化：否 是否线程安全：是 12345public enum Singleton { INSTANCE; public void whateverMethod() {} } 一般情况下不建议使用懒汉式，建议使用饿汉式；只有在明确要实现懒初始化的情况下才使用登记式/静态内部类；若涉及到反序列化创建对象时，可以使用枚举方式；如果有其他特殊需求，也可考虑双检锁/双重校验锁方式。 模式优缺点 优点 提供了对唯一实例的受控访问； 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式可以提高系统的性能； 允许可变数目的实例，基于单例模式可以进行扩展，使用与单例控制相似的方法来获得指定个数的对象实例。 缺点 由于单例模式没有抽象层，因此单例类的扩展有很大难度； 单例类的职责过重，在一定程度上违背了单一职责原则； 滥用单例将带来一些负面问题，例如为了节省资源将数据库连接池对象设计为单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出；如Java、C#等拥有自动垃圾回收机制的语言，会将长时间未被利用的单例对象回收，将导致对象状态的丢失。 Spring框架中，当我们试图从Spring容器中获取某个类的实例时，默认情况下Spring会以单例模式创建实例。","link":"/posts/25281/"},{"title":"线性模型","text":"最简单的一种模型，但也是很多非线性模型的基础，输入与输出之间的关系用多项式表征，有很好的可解释性 基本形式 给定由个属性描述的示例，其中是在第个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即： 一般用向量形式写成： 其中，和学得之后，模型就得以确定 许多功能更为强大的非线性模型(nonlinear model)可在线性模型的基础上通过引入层级结构或高维映射而得 由于直观表达了各属性在预测中的重要性，故线性模型有很好的可解释性(comprehensibility) 线性回归 给定数据集，其中，线性回归(linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记 简单情形 先讨论一种最简单的情形，输入属性的数目只有一个，即，若属性值之间存在序(order)关系，可通过连续化将其转化为连续值 线性回归试图学得： 使得 欲确定和，关键在于如何衡量和之间的差别，由于均方误差是回归任务中最常用的性能度量，故可以试图让均方误差最小化，即： 均方误差有很好的几何意义，它对应了欧氏距离(Euclidean distance)；基于均方误差最小化来进行模型求解的方法称为最小二乘法(least square method)；在线性回归中，最小二乘法就是试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小 求解和使最小化的过程，称为线性回归模型的最小二乘参数估计(parameter estimation) 将分别对和求导可得： 然后令式(5)和式(6)为零可得到和最优解的闭式(closed-form)解： 其中为的均值 一般情形 更一般的情形是形如本节开头的数据集，样本由个属性描述，此时线性回归试图学得： 使得 这称为多元线性回归(multivariate linear regression) 类似的，可以利用最小二乘法来对和进行估计；为了方便讨论，把和吸收入向量形式，相应的把数据集表示为一个大小的矩阵，其中每行对应一个示例，该行的前个元素对应于示例的个属性值，最后一个元素恒置为1，即： 再把标记也写成向量形式，则类似式(4)，有： 令，对求导可得： 令上式为零可得最优解的闭式解，由于涉及矩阵逆的计算，故下面做一个简单的讨论 当为满秩矩阵(full-rank matrix)或正定矩阵(positive definite matrix)时，零式(12)为零可得： 令，则最终学得的多元线性回归模型为： 回到现实情况，往往不是满秩矩阵，此时可解出多个，它们都能使均方误差最小化；选择哪一个解作为输出，将由学习算法的归纳偏好决定，常通过引入正则化(regularization)项来解决这一问题 线性模型虽简单，但有丰富的变化 对于样例，当我们希望线性模型的预测值逼近真实标记时，我们就得到了线性回归模型；为了便于观察，将线性回归模型简写为 当我们认为示例所对应的输出标记是在指数尺度上变化，则可以将输出标记的对数作为线性模型逼近的目标，即： 这就是对数线性回归(log-linear regression)，它实质上是试图让逼近；式(15)形式上仍然是线性回归，但实质上已经是在求取输入空间到输出空间的非线性函数映射，如下图所示 更一般地，考虑单调可微函数，令： 这样得到的模型称为广义线性模型(generalized linear model)，其中函数称为联系函数(link function)；上述的对数线性回归是广义线性模型在时的特例 对数回归几率 若要做的是分类任务，只需在式(16)定义的广义线性模型中找一个单调可微函数，将分类任务的真是标记与线性回归模型的预测值联系起来 考虑二分类任务，其输出标记，而线性回归模型产生的预测值是实值，故需要将实值转换为0/1值；最理想的就是单位阶跃函数(unit-step function)： 即若预测值大于零就判为正例，小于零则判为反例，预测值为临界值零则可任意判别，如下图所示 但单位阶跃函数并不连续，不能直接用作式(16)中的，于是希望找到一个在一定程度上近似单位阶跃函数的替代函数(surrogate function)，并希望它单调可微，一个常用的替代函数就是对数几率函数(logistic function)： 从上图可以看出，对数几率函数是一种Sigmoid函数，将对数几率函数作为带入式(16)中可得： 类似式(15)，可将式(19)化为： 若将视作样本为正例的可能性，则是其反例可能性，两者的比值称为几率(odds)，反映了作为正例的相对可能性，对几率取对数可得对数几率(log odds, logit)： 由此可看出，式(19)实际上是用线性回归模型的预测结果去逼近真实标记的对数几率，故其对应的模型称为对数几率回归(logistic regression, logit regression) 特别需注意，虽然它的名字是“回归”，但却是一种分类学习方法 欲确定式(19)中的和，将式(19)中的视为类后验概率估计，则式(20)可重写为： 显然有： 于是可通过极大似然法(maximum likelihood method)来估计和； 给定数据集，对率回归模型最大化对数似然(log-likelihood)： 即令每个样本属于其真实标记的概率越大越好； 令，则可简写成；再令，则式(25)中的似然项可重写为： 将式(26)带入式(25)，并根据式(23)、(24)可知，最大化式(25)等价于最小化： 式(27)是关于的高阶可导连续凸函数，根据凸优化理论，经典的数值优化算法如梯度下降法(gradient descent method)、牛顿法(Newton method)等都可以求得其最优解，于是得到： 以牛顿法为例，其第轮迭代解的更新公式为： 其中关于的一阶、二阶导数分别为： 线性判别分析 线性判别分析(Linear Discriminant Analysis, LDA)是一种经典的线性学习方法，亦称Fisher判别分析 二分类 LDA的思想： 给定训练样例集，设法将样例投影到一条直线上，使同类样例的投影点尽可能接近、异类样例的投影点尽可能远离； 在对新样本进行分类时，将其投影到该直线上，根据投影点的位置来确定新样本的类别； 上图中“+”、“-”分别代表正例和反例，椭圆表示数据簇的外轮廓，虚线表示投影，红色实心圆和实心三角形分别表示两类样本投影后的中心点 给定数据集，令、、分别表示第类示例的集合、均值向量、协方差矩阵 若将数据投影到直线上，则两类样本的中心在直线上的投影分别为和； 若将所有样本点都投影到直线上，则两类样本的协方差分别为和； 由于直线是一维空间，因此、、和均为实数 欲使同类样例的投影点尽可能接近，则可以让同类样例投影点的协方差尽可能小，即尽可能小； 欲使一类样例的投影点尽可能远离，则可以让类中心之间的距离尽可能大，即尽可能大； 同时考虑二者，则可得到欲最大化的目标： 定义类内散度矩阵(within-class scatter matrix)： 以及类间散度矩阵(between-class scatter matrix)： 则式(32)可重写为： 式(35)即为LDA欲最大化的目标，即欲的广义瑞利商(generalized Rayleigh quotient) 该式的分子分母都是关于的二次项，故式(35)的解与的长度无关，只与其方向有关；不失一般性，令，则式(35)等价于： 由拉格朗日乘子法，上式等价于： 其中是拉格朗日乘子 注意到的方向恒为，不妨令 带入式(37)得： 考虑到数值解的稳定性，在实践中通常是对进行奇异值分解，即，这里是一个实对角矩阵，其对角线上的元素是的奇异值，然后再由得到 LDA可从贝叶斯决策理论的角度来阐释，并可证明，当两类数据同先验、满足高斯分布且协方差相等时，LDA可达到最优分类 多分类 可以将LDA推广到多分类任务中；假设存在个类，且第类示例数为 定义全局散度矩阵： 其中是所有示例的均值向量 将类内散度矩阵重新定义为每个类别的散度矩阵之和，即： 其中 由式(40)~(42)可得： 显然，多分类LDA可以有多种实现方法：使用三者中的任何两个即可 常见的一种实现是采用优化目标： 其中，表示矩阵的迹；上式可通过如下广义特征值问题求解： 的闭式解则是的个最大广义特征值所对应的特征向量组成的矩阵 若将视为一个投影矩阵，则多分类LDA将样本投影到维空间，通常远小于数据原有的属性数；故可通过这个投影来减小样本点的维数，且投影过程中使用了类别信息，因此LDA也常被视为一种经典的监督降维技术 多分类学习 有些二分类学习方法可直接推广到多分类，但更多的情况是基于一些基本策略，利用二分类学习器来解决多分类问题 不失一般性，考虑个类别，多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解；具体来说就是对问题进行拆分，为拆分出的每个二分类任务训练一个分类器，测试时对这些分类器预测的结果进行集成以获得最终的多分类结果 最经典的拆分策略：一对一(One vs. One, OvO)、一对其余(One vs. Rest, OvR)、多对多(Many vs. Many, MvM) 给定数据集 OvO与OvR OvO将这个类别两两配对，从而产生个二分类任务；在测试阶段，新样本将同时提交给所有分类器，于是得到个分类结果，最终结果通过投票产生，即把被预测得最多的类别作为最终分类结果； OvR则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练个分类器；在测试阶段，若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果；若有多个分类器预测为正类，则通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果 MvM MvM是每次将若干个类作为正类，若干个其他类作为反类；显然OvO和OvR是MvM的特例 MvM的正、反类构造必须有特殊的设计，不能随意选取；下面介绍一种最常用的MvM技术：纠错输出码(Error Correcting Output, ECOC); ECOC是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性，工作过程主要分两步： 编码：对个类别做次划分，每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集；这样共产生个训练集，可训练出个分类器； 解码：个分类器分别对测试样本进行预测，这些预测标记组成一个编码；将该预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果； 类别划分通过编码矩阵(coding matrix)指定；编码矩阵有多种形式，常见的有二元码和三元码 二元码：将每个类别分别指定为正类和反类； 三元码：除正、反类之外，还可指定“停用类”； 上图中“+1”，“-1”分别表示学习器将该类样本作为正、反例；三元码中“0”表示不使用该类样本 在测试阶段，ECOC编码对分类器的错误有一定的容忍和修正能力； 以上图中的(a)图为例，测试示例的正确预测编码应为，假设在预测时某分类器出错了，例如图中的，导致预测的编码为，但基于这个有错误的编码仍能产生正确的最终分类结果 一般来说，对同一个学习任务，ECOC编码越长，纠错能力越强；但编码越长意味着需要训练的分类器越多，另一方面，对有限类别数，可能的组合数是有限的，码长超过一定范围后就失去了意义 对于等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强 因此，在码长较小时可根据这个原则计算出理论最优编码；然而码长稍大一些就难以有效确定最优编码，这是NP难问题 不过通常我们并不需要获得理论最优编码，因为非最优编码在实践中往往已经能产生足够好的分类器 类别不平衡问题 类别不平衡(class-imbalance)是指分类任务中不同类别的训练样例数目差别很大的情况 从线性分类器的角度讨论，在用对新样本进行分类时，实际上是用预测出的值与一个阈值进行比较； 实际表达了正例的可能性，几率则反映了正例可能性与反例可能性之比，阈值设置为0.5则表明分类器认为真实正、反例可能性相同，即分类器决策规则为 若则预测为正例 但当训练集中正、反例的数目不同时，令、分别表示正、反例数目，则观测几率是，由于我们通常假设训练集是真实样本的无偏采样，故观测几率就代表真实几率；于是，只要分类器的预测几率高于观测几率就判为正例，即 若则预测为正例 但分类器是基于式(46)进行决策的，故需对其预测值进行调整，令 这就是类别不平衡学习的一个基本策略——再缩放(rescaling) 由于在实际中，“训练集是真实样本总体的无偏采样”这个假设往往并不成立，也就是说，我们未必能有效地基于训练集观测几率来推断出真实几率 现有技术大体上有三类做法(假设正例少、反例多)： 欠采样(undersampling)：即去除一些反例，使得正、反例数目接近，然后再进行学习； 过采样(oversampling)：即增加一些正例，使得正、反例数目接近，然后再进行学习； 直接基于原始训练集学习：但在用训练好的分类器进行预测时，将式(48)嵌入其决策过程中，称为阈值移动(threshold-moving) 再缩放是代价敏感学习(cost-sensitive learning)的基础，在代价敏感学习中将式(48)中的用代替即可，其中是将正例误分为反例的代价，是将反例误分为正例的代价","link":"/posts/5222/"},{"title":"设计模式——工厂方法模式","text":"以简单工厂模式切入（虽然简单工厂模式不是GoF经典模式之一），介绍工厂方法模式。 简单工厂模式 简单工厂模式（Simple Factory Pattern）又称静态工厂方法（Static Factory Method）模式，属于创建型模式。 简单工厂模式并非GoF 23种经典模式之一。 在简单工厂模式中，可以根据参数的不同返回不同的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 角色 Factory（工厂角色） 工厂角色即工厂类，是简单工厂模式的核心，负责实现创建所有实例的内部逻辑； 工厂类可以被外界直接调用，创建所需的产品对象； 在工厂类中提供了静态的工厂方法factoryMethod()，它返回一个抽象产品类Product，所有的具体产品都是抽象产品的子类。 Product（抽象产品角色） 抽象产品角色是简单工厂模式所创建的所有对象的父类，负责描述所有实例所共有的公共接口； 它的引入将提高系统的灵活性，使得在工厂类中只需定义一个工厂方法，因为所有创建的具体产品对象都是其子类对象。 Concrete Product（具体产品角色） 具体产品角色是简单工厂模式的创建目标，所有创建的对象都充当这个角色的某个具体类的实例； 每个具体产品角色都继承了抽象产品角色，需要实现定义在抽象产品中的抽象方法。 类图 image.png 实例 定义一个抽象产品角色 123public interface Phone { public void get();} 定义两个具体产品，实现抽象产品接口 123456public class Huawei implements Phone { @Override public void get() { System.out.println(&quot;Get the Huawei phone.&quot;); }} 123456public class iPhone implements Phone { @Override public void get() { System.out.println(&quot;Get the iPhone.&quot;); }} 再定义一个工厂类负责创建实例 12345678910111213public class PhoneFactory { public static Phone producePhone(String brand) throws Exception { if (brand.equalsIgnoreCase(&quot;Huawei&quot;)) { System.out.println(&quot;A Huawei phone have been produced.&quot;); return new Huawei(); } else if (brand.equalsIgnoreCase(&quot;iPhone&quot;)) { System.out.println(&quot;An iPhone have been produced.&quot;); return new iPhone(); } else { throw new Exception(&quot;Sorry,the product of this brand can not be produced.&quot;); } }} 客户端测试类 12345678910public class Client { public static void main(String[] args) { try { Phone phone = PhoneFactory.producePhone(&quot;iphone&quot;); phone.get(); } catch (Exception e) { e.printStackTrace(); } }} 此时运行结果为 12An iPhone have been produced.Get the iPhone. 若将品牌改为huawei，则结果如下 12A Huawei phone have been produced.Get the Huawei phone. 若改为一个不存在的品牌，如boluo，则结果如下 123java.lang.Exception: Sorry,the product of this brand can not be produced. at wyp.CreationalPatterns.SimpleFactoryPattern.Factory.PhoneFactory.producePhone(PhoneFactory.java:16) at wyp.CreationalPatterns.SimpleFactoryPattern.Client.main(Client.java:9) 模式优缺点 优点 免除了客户端直接创建产品对象的责任，仅仅”消费“产品，实现了责任的分割； 客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数； 可以引入配置文件，再不修改客户端代码的情况下更换和增加新的具体产品类。 缺点 工厂类集中了所有产品的创建逻辑，一旦不能正常工作，整个系统都要受到影响； 使用该模式会增加系统中类的个数，一定程度上增加了系统的复杂度和理解难度； 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，不利于系统的维护； 该模式使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构，无法像产品类一样定义一个抽象层，也无法通过具体类进行扩展。 工厂方法模式 工厂方法模式（Factory Method Pattern）又称虚拟构造器（Virtual Constructor）模式或多态工厂（Polymorphic Factory）模式，属于创建型模式。 工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类负责生成具体的产品对象，将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪个具体产品类。 角色 Product（抽象产品） 抽象产品是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的共同父类或接口。 Concrete Product（具体产品） 具体产品实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，它们之间一一对应。 Factory（抽象工厂） 抽象工厂中声明了工厂方法，用于返回一个产品。抽象工厂是工厂方法模式的核心，它与程序无关。任何在模式中创建对象的工厂类都必须实现该接口。 Concrete Factory（具体工厂） 具体工厂是抽象工厂的子类，实现了抽象工厂中定义的工厂方法，并可由客户调用，返回一个具体产品类的实例。具体工厂中包含与程序密切相关的逻辑，并接受程序调用以创建产品对象。 类图 image.png 实例 定义抽象产品类 123public interface Phone { public void get();} 定义两个具体产品类 123456public class Huawei implements Phone { @Override public void get() { System.out.println(&quot;Get the Huawei phone.&quot;); }} 123456public class iPhone implements Phone { @Override public void get() { System.out.println(&quot;Get the iPhone.&quot;); }} 定义抽象工厂类 123public interface PhoneFactory { public Phone producePhone();} 定义与具体产品类对应的具体工厂类 1234567public class HuaweiFactory implements PhoneFactory { @Override public Phone producePhone() { System.out.println(&quot;A Huawei phone have been produced.&quot;); return new Huawei(); }} 1234567public class iPhoneFactory implements PhoneFactory { @Override public Phone producePhone() { System.out.println(&quot;An iPhone have been produced.&quot;); return new iPhone(); }} 客户端测试类 1234567891011public class Client { public static void main(String[] args) { HuaweiFactory huaweiFactory = new HuaweiFactory(); Phone phone1 = huaweiFactory.producePhone(); phone1.get(); iPhoneFactory iPhoneFactory = new iPhoneFactory(); Phone phone2 = iPhoneFactory.producePhone(); phone2.get(); }} 此时运行结果为 1234A Huawei phone have been produced.Get the Huawei phone.An iPhone have been produced.Get the iPhone. 若要增加新产品，只需创建一个新的具体产品类实现抽象产品接口，并创建与之对应的具体工厂类实现抽象工厂接口即可。 模式优缺点 优点 在该模式中，工厂方法用来创建客户所需的产品，同时向客户隐藏了哪种具体产品将被实例化这一细节，用户只需关心所需产品对应的工厂，无须关心创建细节与具体产品类的类名； 基于工厂角色和产品角色的多态性设计是该模式的关键，能够使工厂自主确定创建何种产品对象； 在加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，只要添加一个具体工厂和具体产品即可。这样增强了系统的扩展性，完全符合开闭原则。 缺点 添加新产品时需要编写新的具体产品类和与之对应的具体工厂类，系统中类的个数将成对增加，一定程度上增加了系统的复杂度，有额外的类需要编译和运行，给系统带来了额外的开销； 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。","link":"/posts/3827/"},{"title":"设计模式——抽象工厂模式","text":"进一步优化工厂方法模式，将之泛化，以适应更加复杂的业务结构。 抽象工厂模式 抽象工厂模式是工厂方法模式的泛化版，在工厂方法模式中，每个具体的工厂类只能生产一种具体产品，而在抽象工厂方法模式中，每个具体的工厂可以生产多个具体产品。 引入两个概念 产品等级结构：即产品的继承结构，如一个抽象类是手机，其子类有iPhone、Huawei等，则抽象手机与具体品牌的手机之间构成了一个产品等级结构。 产品族：在抽象工厂模式中，产品族是指同一个工厂生产的，位于不同产品等级结构中的一组产品，如Apple公司生产的iPhone、iPad，iPhone位于手机产品等级结构中，iPad位于平板电脑产品等级结构中。 角色 Abstract Factory（抽象工厂） 抽象工厂用于声明生产抽象产品的方法，在一个抽象工厂中可以定义一组方法，每个方法对应一个产品等级结构。 Concrete Factory（具体工厂） 具体工厂实现了抽象工厂声明的生成抽象产品的方法，生成一组具体产品，这些产品构成了一个产品族，每个产品都位于某个产品等级结构中。 Abstract Product（抽象产品） 抽象产品为每种产品声明接口，在抽象产品中定义了产品的抽象业务方法。 Concrete Product （具体产品） 具体产品定义具体工厂生产的具体产品对象，实现抽象产品接口中定义的业务方法。 类图 image.png 实例 定义抽象产品手机 123public interface Phone { public void powerOn();} 定义该产品等级结构中的具体产品 123456public class iPhone implements Phone { @Override public void powerOn() { System.out.println(&quot;The iPhone is powered on.&quot;); }} 123456public class HuaweiPhone implements Phone { @Override public void powerOn() { System.out.println(&quot;The Huawei phone is powered on.&quot;); }} 定义抽象产品平板电脑 123public interface Pad { public void powerOn();} 定义该产品等级结构中的具体产品 123456public class iPad implements Pad { @Override public void powerOn() { System.out.println(&quot;The iPad is powered on.&quot;); }} 123456public class HuaweiPad implements Pad { @Override public void powerOn() { System.out.println(&quot;The Huawei pad is powered on.&quot;); }} 定义抽象工厂类，其中声明了生产两个抽象产品的方法 12345public interface DeviceFactory { public Phone producePhone(); public Pad producePad();} 定义两个具体工厂，每个具体工厂都实现了抽象工厂中声明的生产抽象产品的方法 1234567891011public class Apple implements DeviceFactory { @Override public Phone producePhone() { return new iPhone(); } @Override public Pad producePad() { return new iPad(); }} 1234567891011public class Huawei implements DeviceFactory { @Override public Phone producePhone() { return new HuaweiPhone(); } @Override public Pad producePad() { return new HuaweiPad(); }} 客户端测试类 123456789101112131415public class Client { public static void main(String[] args) { DeviceFactory deviceFactory = new Apple(); Phone phone = deviceFactory.producePhone(); phone.powerOn(); Pad pad = deviceFactory.producePad(); pad.powerOn(); deviceFactory = new Huawei(); Phone phone1 = deviceFactory.producePhone(); phone1.powerOn(); Pad pad1 = deviceFactory.producePad(); pad1.powerOn(); }} 运行结果为 1234The iPhone is powered on.The iPad is powered on.The Huawei phone is powered on.The Huawei pad is powered on. 模式优缺点 优点 抽象工厂模式隔离了具体类的生产，使得客户端不需要知道什么被创建，由于这种隔离，更换一个具体工厂就变得相对容易，所有的具体工程都实现了抽象工厂中定义的那些公共接口，因此只需改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为； 当一个产品族中的对各对象被设计成一起工作时，它能够保证客户端始终只使用同一个产品族中的对象。这对一些需要根据当前环境来决定其行为的软件系统来说非常实用； 增加新的具体工厂和产品族很方便，无需修改已有系统，符合开闭原则。 缺点 在添加新的产品对象时，难以扩展抽象工厂来生产新种类的产品，这是因为在抽象工厂角色中规定了所有可能被创建的产品集合，要支持新种类的产品就意味着要对该接口进行扩展，而这将涉及对抽象工厂角色及其所有子类的修改。","link":"/posts/43994/"},{"title":"设计模式——装饰模式","text":"我想有新功能，但我不想改自己的代码，那就装饰一下吧。 装饰模式 装饰模式可以在不改变一个对象本身的基础上，给对象增加额外的新行为。 角色 Component（抽象构件） 抽象构件定义了对象的接口，可以给这些对象动态增加职责（方法）。抽象构件是具体构建和抽象装饰类的共同父类，它声明了在具体构件中实现的业务方法，它的引入能够使客户端以一致的方式处理未被装饰的对象以及装饰后的对象，实现客户端的透明操作。 Concrete Component（具体构件） 具体构件定义了具体的构件对象，实现了在抽象构件中声明的方法，装饰器可以给它增加额外的职责（方法）。 Decorator（抽象装饰类） 抽象装饰类使抽象构件类的子类，用于给具体构件增加职责，但是具体职责在其子类中实现。 Concrete Decorator（具体装饰类） 具体装饰类是抽象装饰类的子类，负责向构件添加新的职责。 类图 image.png 实例 定义抽象构件 123public interface Shape { void draw();} 定义具体构件 123456public class Circle implements Shape { @Override public void draw() { System.out.println(&quot;Shape: Circle&quot;); }} 123456public class Rectangle implements Shape { @Override public void draw() { System.out.println(&quot;Shape: Rectangle&quot;); }} 定义抽象装饰类 1234567891011public abstract class ShapeDecorator implements Shape { protected Shape decoratedShape; public ShapeDecorator(Shape decoratedShape) { this.decoratedShape = decoratedShape; } public void draw() { decoratedShape.draw(); }} 定义具体装饰类 123456789101112131415public class RedShapeDecorator extends ShapeDecorator { public RedShapeDecorator(Shape decoratedShape) { super(decoratedShape); } @Override public void draw() { decoratedShape.draw(); setRedBorder(decoratedShape); } public void setRedBorder(Shape decoratedShape) { System.out.println(&quot;Border Color: Red&quot;); }} 客户端测试类 123456789101112131415public class Client { public static void main(String[] args) { Shape circle = new Circle(); Shape rectangle = new Rectangle(); System.out.println(&quot;Current state of shape: &quot;); circle.draw(); rectangle.draw(); ShapeDecorator redCircle = new RedShapeDecorator(circle); ShapeDecorator redRectangle = new RedShapeDecorator(rectangle); System.out.println(&quot;\\nCurrent state of shape: &quot;); redCircle.draw(); redRectangle.draw(); }} 运行结果为 123456789Current state of shape: Shape: CircleShape: RectangleCurrent state of shape: Shape: CircleBorder Color: RedShape: RectangleBorder Color: Red 给对象增加行为的两种方式 继承机制 通过继承一个现有类可以使得子类在拥有自身方法的同时还拥有父类的方法，但这种方法是静态的，用户不能控制增加行为的方式和时机。 关联机制 关联机制是装饰模式的核心，是更加灵活的方法，即将一个类的对象嵌入另一个新对象中，由另一个对象来决定是否调用嵌入对象的行为并扩展新的行为，这个新的对象即为装饰器（Decorator）。 为了使装饰器与它所装饰的对象对客户端透明，装饰器类和被装饰的类必须实现相同的接口，客户端使用时无须关心一个类的对象是否被装饰过，可以一致性地使用未被装饰的对象以及装饰过的对象。已经被装饰过的对象可以继续作为新的被装饰的对象进行装饰，这种透明性可以是我们递归的嵌套多个装饰。 模式优缺点 优点 装饰模式与继承关系的目的都是要扩展对象的功能，但装饰模式可以提供比继承更多的灵活性； 可以通过一种动态的方式来扩展一个对象的功能，通过配置文件可以在运行时选择不同的装饰器，从而实现不同的行为； 通过使用不同的具体装饰类以及这些装饰类的排列组合，可以创造出很多不同行为的组合，可以使用多个具体装饰类来装饰同一对象，得到功能更为强大的对象； 具体构件类与具体装饰类可独立变化，用户可以根据需要增加新的具体构件类和具体装饰类，在使用时再对其进行组合，符合开闭原则。 缺点 使用装饰模式进行系统设计时将产生很多小对象，这些对象的区别在于它们之间相互连接的方式不同，而不是它们的类或者属性值不同，同时还将产生很多具体装饰类，将会增加系统的复杂度，加大学习与理解的难度； 这种比继承更加灵活的特性，也同时意味着装饰模式比继承更容易出错，排错也很困难，对于多次装饰的对象，调试时寻找错误需要逐级排查。","link":"/posts/57376/"},{"title":"面向对象设计原则及设计模式简介","text":"面向对象不能只停留在OOP（面向对象开发），要学会OOD（面向对象设计），甚至OOA（面向对象分析），否则只能当CRUD的码农。 面向对象设计原则 单一职责原则（Single Responsibility Principle, SRP） 定义一：一个对象应该只包含单一的职责，并且该职责被完整的封装在一个类中。 定义二：就一个类而言，应该仅有一个引起它变化的原因。 开闭原则（Open-Closed Principle, OCP） 定义：一个软件实体应当对扩展开放，对修改关闭。 里氏代换原则（Liskov Substitution Principle, LSP） 定义一：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1都代换o2时，程序P的行为没有变化，那么类型S是类型T的子类型。 定义二：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 通俗表达：在软件中如果能够使用基类对象，那么一定能够使用其子类对象。把基类都替换成它的子类，程序将不会产生任何错误和异常；反之不成立，即如果软件实体中使用的是子类，则它不一定能够使用基类。 使用里氏代换原则时的注意事项 子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法； 在运用里氏代换原则时，尽量把父类设计为抽象类或接口，让子类继承父类或实现父接口，并实现在父类中声明的方法。 依赖倒转原则（Dependence Inversion Principle, DIP） 定义一：高层模块不应该依赖低层模块，它们都应该依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 定义二：要针对接口编程，不要针对实现编程。 依赖倒转原则中的两个概念 类之间的耦合 零耦合：两个类之间没有任何耦合关系。 具体耦合：发生在两个具体类（可实例化的类）之间，由一个类对另一个具体类实例的直接引用产生。 抽象耦合：发生在一个具体类和一个抽象类之间或两个抽象类之间，使两个发生关系的类之间存有最大的灵活性。由于抽象耦合中至少有一端是抽象的，故可以通过不同的具体实现来进行扩展。 依赖注入（Dependence Injection, DI） 依赖注入就是将一个类的对象传入另一个类，注入时应该尽量注入父类对象，在程序运行时再通过子类对象来覆盖父类对象。 依赖注入的三种方式： 构造注入（Constructor Injection）：通过构造函数注入实例变量。 设值注入（Setter Injection）：通过Setter方法注入实例变量。 接口注入（Interface Injection）：通过接口方法注入实例变量。 接口隔离原则（Interface Segregation Principle, ISP） 定义一：客户端不应该依赖那些它不需要的接口。 定义二：一旦一个接口太大，则需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。 合成复用原则（Composite Reuse Principle, CRP） 又称组合/聚合复用原则（Composite/ Aggregate Reuse Principle, CARP） 定义：尽量使用对象组合，而不是继承来达到复用的目的。 简言之就是，要尽量使用组合/聚合关系，少用继承。在软件开发中，一般首选使用组合/聚合来实现复用，其次才考虑继承。使用继承时应严格遵循里氏代换原则，有效使用继承有助于解决问题，降低复杂度，而滥用继承反而会增加系统的构建和维护的难度。 迪米特法则（Law of Demeter, LoD） 又称最少知识原则（Least Knowledge Principle, LKP） 定义一：不要和“陌生人”说话。 定义二：只与你的直接朋友通信。 定义三：每个软件单元对其他的单元都只有最少的知识，而且局限于那些与本单元密切相关的软件单元。 在迪米特法则中，对于一个对象，它的朋友包括 当前对象本身（unit）； 以参数形式传入到当前对象方法中的对象； 当前对象的成员对象； 如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友； 当前对象所创建的对象。 使用迪米特法则时的注意事项 在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及； 在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限； 在类的设计上，只要有可能，一个类型应当设计成不变类； 在对其他类的引用上，一个对象对其他对象的引用应当降到最低。 GoF设计模式简介 范围/目的 创建型模式 结构型模式 行为型模式 类模式 工厂方法模式 适配器模式（类） 解释器模式模板方法模式 对象模式 抽象工厂模式建造者模式原型模式单例模式 适配器模式（对象）桥接模式组合模式装饰模式外观模式享元模式代理模式 职责链模式命令模式迭代器模式中介者模式备忘录模式观察者模式状态模式策略模式访问者模式 创建型模式：主要用于创建对象。 结构型模式：主要用于处理类或对象的组合。 行为型模式：主要用于描述对类或对象怎样交互和怎样分配职责。","link":"/posts/23116/"}],"tags":[{"name":"论文","slug":"论文","link":"/tags/%E8%AE%BA%E6%96%87/"},{"name":"ICCV","slug":"ICCV","link":"/tags/ICCV/"},{"name":"3D人体姿态估计","slug":"3D人体姿态估计","link":"/tags/3D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/"},{"name":"异构计算","slug":"异构计算","link":"/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"},{"name":"AscendC","slug":"AscendC","link":"/tags/AscendC/"},{"name":"CUDA","slug":"CUDA","link":"/tags/CUDA/"},{"name":"高性能计算","slug":"高性能计算","link":"/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"},{"name":"ITK","slug":"ITK","link":"/tags/ITK/"},{"name":"VS Code远程开发","slug":"VS-Code远程开发","link":"/tags/VS-Code%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"},{"name":"毕昇编译器","slug":"毕昇编译器","link":"/tags/%E6%AF%95%E6%98%87%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"GC","slug":"GC","link":"/tags/GC/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"CVPR","slug":"CVPR","link":"/tags/CVPR/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Pytorch","slug":"Pytorch","link":"/tags/Pytorch/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"Vue_CLI","slug":"Vue-CLI","link":"/tags/Vue-CLI/"},{"name":"Vue-Router","slug":"Vue-Router","link":"/tags/Vue-Router/"},{"name":"Vuex","slug":"Vuex","link":"/tags/Vuex/"},{"name":"v-指令","slug":"v-指令","link":"/tags/v-%E6%8C%87%E4%BB%A4/"},{"name":"axios","slug":"axios","link":"/tags/axios/"},{"name":"promise","slug":"promise","link":"/tags/promise/"},{"name":"RESTFul","slug":"RESTFul","link":"/tags/RESTFul/"},{"name":"配置文件","slug":"配置文件","link":"/tags/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"name":"Vue组件","slug":"Vue组件","link":"/tags/Vue%E7%BB%84%E4%BB%B6/"},{"name":"Composition API","slug":"Composition-API","link":"/tags/Composition-API/"},{"name":"组合式API","slug":"组合式API","link":"/tags/%E7%BB%84%E5%90%88%E5%BC%8FAPI/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"LaTex","slug":"LaTex","link":"/tags/LaTex/"},{"name":"Gitalk","slug":"Gitalk","link":"/tags/Gitalk/"},{"name":"npm","slug":"npm","link":"/tags/npm/"},{"name":"node.js","slug":"node-js","link":"/tags/node-js/"},{"name":"package.json","slug":"package-json","link":"/tags/package-json/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"csv","slug":"csv","link":"/tags/csv/"},{"name":"矩阵论","slug":"矩阵论","link":"/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/"},{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"异构编程","slug":"异构编程","link":"/tags/%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"Neovim","slug":"Neovim","link":"/tags/Neovim/"},{"name":"编辑器","slug":"编辑器","link":"/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"毕昇C++","slug":"毕昇C","link":"/tags/%E6%AF%95%E6%98%87C/"},{"name":"西瓜书","slug":"西瓜书","link":"/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"减治","slug":"减治","link":"/tags/%E5%87%8F%E6%B2%BB/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"分治","slug":"分治","link":"/tags/%E5%88%86%E6%B2%BB/"},{"name":"贪心","slug":"贪心","link":"/tags/%E8%B4%AA%E5%BF%83/"},{"name":"回溯","slug":"回溯","link":"/tags/%E5%9B%9E%E6%BA%AF/"},{"name":"哈希表","slug":"哈希表","link":"/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"力扣","slug":"力扣","link":"/tags/%E5%8A%9B%E6%89%A3/"},{"name":"二叉树","slug":"二叉树","link":"/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"数组","slug":"数组","link":"/tags/%E6%95%B0%E7%BB%84/"},{"name":"字符串","slug":"字符串","link":"/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"栈","slug":"栈","link":"/tags/%E6%A0%88/"},{"name":"队列","slug":"队列","link":"/tags/%E9%98%9F%E5%88%97/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"代理模式","slug":"代理模式","link":"/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","link":"/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"工厂模式","slug":"工厂模式","link":"/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"抽象工厂模式","slug":"抽象工厂模式","link":"/tags/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"装饰模式","slug":"装饰模式","link":"/tags/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/"},{"name":"面向对象","slug":"面向对象","link":"/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"}],"categories":[{"name":"文献阅读笔记","slug":"文献阅读笔记","link":"/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"高性能计算","slug":"高性能计算","link":"/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/"},{"name":"CUDA","slug":"高性能计算/CUDA","link":"/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA/"},{"name":"AscendC","slug":"高性能计算/AscendC","link":"/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/AscendC/"},{"name":"项目","slug":"项目","link":"/categories/%E9%A1%B9%E7%9B%AE/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Pytorch","slug":"机器学习/Pytorch","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"axios","slug":"前端/axios","link":"/categories/%E5%89%8D%E7%AB%AF/axios/"},{"name":"Vue","slug":"前端/Vue","link":"/categories/%E5%89%8D%E7%AB%AF/Vue/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"nodejs","slug":"前端/nodejs","link":"/categories/%E5%89%8D%E7%AB%AF/nodejs/"},{"name":"数学","slug":"数学","link":"/categories/%E6%95%B0%E5%AD%A6/"},{"name":"折腾","slug":"折腾","link":"/categories/%E6%8A%98%E8%85%BE/"},{"name":"西瓜书笔记","slug":"机器学习/西瓜书笔记","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"矩阵论","slug":"数学/矩阵论","link":"/categories/%E6%95%B0%E5%AD%A6/%E7%9F%A9%E9%98%B5%E8%AE%BA/"},{"name":"经典算法","slug":"算法/经典算法","link":"/categories/%E7%AE%97%E6%B3%95/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/"},{"name":"力扣","slug":"算法/力扣","link":"/categories/%E7%AE%97%E6%B3%95/%E5%8A%9B%E6%89%A3/"}]}